{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 64\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([GlobalAvgPool1D()(output) for output in layer_outputs[-2:]])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 64)    384         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 64)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 64)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 64)     20544       max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 64)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 64)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 64)     20544       max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 64)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 64)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 64)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 64)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           2064        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 43,536\n",
      "Trainable params: 43,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 64)    384         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 64)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 64)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 64)     20544       max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 64)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 64)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 64)     20544       max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 64)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 64)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 64)      20544       max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 64)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 64)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 64)           0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 64)           0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128)          0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           2064        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,080\n",
      "Trainable params: 64,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 64)    384         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 64)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 64)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 64)     20544       max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 64)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 64)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 64)     20544       max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 64)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 64)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 64)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 64)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 128)     0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 128)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 64)           0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 128)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192)          0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 192)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           3088        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 106,192\n",
      "Trainable params: 106,192\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 64)    384         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 64)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 64)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 64)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 64)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 64)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 64)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 64)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 64)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 128)     0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 128)      0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 128)      0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 128)      0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 128)          0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 128)          0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 256)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           4112        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 189,264\n",
      "Trainable params: 189,264\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 64)    384         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 64)    0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 64)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 64)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 64)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 64)     0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 64)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 64)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 64)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 128)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 128)      0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 128)      0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 128)      0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 128)      0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 128)       0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 128)          0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 128)          0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256)          0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 256)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           4112        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 271,312\n",
      "Trainable params: 271,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 64)    384         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 64)    0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 64)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 64)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 64)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 64)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 64)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 64)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 64)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 128)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 128)      0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 128)      0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 128)      0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 128)      0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 128)       0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 128)       82048       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 128)       0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 128)       0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 128)          0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 128)          0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256)          0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 256)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           4112        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 353,360\n",
      "Trainable params: 353,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.7228 - acc: 0.1000- ETA: 1s - lo\n",
      "Epoch 00001: val_loss improved from inf to 2.65632, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/001-2.6563.hdf5\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 2.7227 - acc: 0.1000 - val_loss: 2.6563 - val_acc: 0.2092\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5915 - acc: 0.1751\n",
      "Epoch 00002: val_loss improved from 2.65632 to 2.45005, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/002-2.4500.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 2.5914 - acc: 0.1751 - val_loss: 2.4500 - val_acc: 0.2874\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.4217 - acc: 0.2164\n",
      "Epoch 00003: val_loss improved from 2.45005 to 2.26399, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/003-2.2640.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 2.4216 - acc: 0.2165 - val_loss: 2.2640 - val_acc: 0.3154\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3003 - acc: 0.2427\n",
      "Epoch 00004: val_loss improved from 2.26399 to 2.13589, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/004-2.1359.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 2.3002 - acc: 0.2428 - val_loss: 2.1359 - val_acc: 0.3452\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2116 - acc: 0.2647\n",
      "Epoch 00005: val_loss improved from 2.13589 to 2.04555, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/005-2.0455.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 2.2117 - acc: 0.2647 - val_loss: 2.0455 - val_acc: 0.3645\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1529 - acc: 0.2847\n",
      "Epoch 00006: val_loss improved from 2.04555 to 1.98557, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/006-1.9856.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 2.1529 - acc: 0.2847 - val_loss: 1.9856 - val_acc: 0.3927\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0928 - acc: 0.3029\n",
      "Epoch 00007: val_loss improved from 1.98557 to 1.92842, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/007-1.9284.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 2.0928 - acc: 0.3029 - val_loss: 1.9284 - val_acc: 0.4086\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0493 - acc: 0.3196\n",
      "Epoch 00008: val_loss improved from 1.92842 to 1.88381, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/008-1.8838.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 2.0493 - acc: 0.3195 - val_loss: 1.8838 - val_acc: 0.4244\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0102 - acc: 0.3316\n",
      "Epoch 00009: val_loss improved from 1.88381 to 1.83849, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/009-1.8385.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 2.0102 - acc: 0.3316 - val_loss: 1.8385 - val_acc: 0.4486\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9798 - acc: 0.3440\n",
      "Epoch 00010: val_loss improved from 1.83849 to 1.80655, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/010-1.8066.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.9799 - acc: 0.3438 - val_loss: 1.8066 - val_acc: 0.4589\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9440 - acc: 0.3524\n",
      "Epoch 00011: val_loss improved from 1.80655 to 1.78037, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/011-1.7804.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.9440 - acc: 0.3523 - val_loss: 1.7804 - val_acc: 0.4712\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9155 - acc: 0.3656\n",
      "Epoch 00012: val_loss improved from 1.78037 to 1.74761, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/012-1.7476.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.9153 - acc: 0.3656 - val_loss: 1.7476 - val_acc: 0.4794\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8944 - acc: 0.3750\n",
      "Epoch 00013: val_loss improved from 1.74761 to 1.72308, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/013-1.7231.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.8944 - acc: 0.3751 - val_loss: 1.7231 - val_acc: 0.4852\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8638 - acc: 0.3888\n",
      "Epoch 00014: val_loss improved from 1.72308 to 1.68538, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/014-1.6854.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.8638 - acc: 0.3888 - val_loss: 1.6854 - val_acc: 0.5001\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8307 - acc: 0.3964\n",
      "Epoch 00015: val_loss improved from 1.68538 to 1.66211, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/015-1.6621.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.8308 - acc: 0.3964 - val_loss: 1.6621 - val_acc: 0.5090\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8117 - acc: 0.4090\n",
      "Epoch 00016: val_loss improved from 1.66211 to 1.62887, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/016-1.6289.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.8114 - acc: 0.4091 - val_loss: 1.6289 - val_acc: 0.5155\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7828 - acc: 0.4164\n",
      "Epoch 00017: val_loss improved from 1.62887 to 1.60854, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/017-1.6085.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.7828 - acc: 0.4164 - val_loss: 1.6085 - val_acc: 0.5306\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7612 - acc: 0.4251\n",
      "Epoch 00018: val_loss improved from 1.60854 to 1.57616, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/018-1.5762.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.7611 - acc: 0.4249 - val_loss: 1.5762 - val_acc: 0.5362\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7371 - acc: 0.4373\n",
      "Epoch 00019: val_loss improved from 1.57616 to 1.55122, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/019-1.5512.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.7375 - acc: 0.4372 - val_loss: 1.5512 - val_acc: 0.5460\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7172 - acc: 0.4433\n",
      "Epoch 00020: val_loss improved from 1.55122 to 1.53249, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/020-1.5325.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.7172 - acc: 0.4434 - val_loss: 1.5325 - val_acc: 0.5511\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6935 - acc: 0.4523\n",
      "Epoch 00021: val_loss improved from 1.53249 to 1.51462, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/021-1.5146.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.6940 - acc: 0.4521 - val_loss: 1.5146 - val_acc: 0.5528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6793 - acc: 0.4612\n",
      "Epoch 00022: val_loss improved from 1.51462 to 1.48733, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/022-1.4873.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.6792 - acc: 0.4611 - val_loss: 1.4873 - val_acc: 0.5628\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6577 - acc: 0.4679\n",
      "Epoch 00023: val_loss improved from 1.48733 to 1.46926, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/023-1.4693.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.6573 - acc: 0.4681 - val_loss: 1.4693 - val_acc: 0.5693\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6486 - acc: 0.4692\n",
      "Epoch 00024: val_loss improved from 1.46926 to 1.45467, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/024-1.4547.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.6488 - acc: 0.4691 - val_loss: 1.4547 - val_acc: 0.5714\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6281 - acc: 0.4757\n",
      "Epoch 00025: val_loss improved from 1.45467 to 1.43164, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/025-1.4316.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.6279 - acc: 0.4758 - val_loss: 1.4316 - val_acc: 0.5802\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6160 - acc: 0.4810\n",
      "Epoch 00026: val_loss improved from 1.43164 to 1.41482, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/026-1.4148.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.6161 - acc: 0.4810 - val_loss: 1.4148 - val_acc: 0.5872\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5976 - acc: 0.4909\n",
      "Epoch 00027: val_loss improved from 1.41482 to 1.39911, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/027-1.3991.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.5976 - acc: 0.4909 - val_loss: 1.3991 - val_acc: 0.5830\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5785 - acc: 0.4957\n",
      "Epoch 00028: val_loss improved from 1.39911 to 1.38564, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/028-1.3856.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.5785 - acc: 0.4956 - val_loss: 1.3856 - val_acc: 0.5877\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5690 - acc: 0.4996\n",
      "Epoch 00029: val_loss improved from 1.38564 to 1.37137, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/029-1.3714.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.5687 - acc: 0.4997 - val_loss: 1.3714 - val_acc: 0.5970\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5494 - acc: 0.5064\n",
      "Epoch 00030: val_loss improved from 1.37137 to 1.35518, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/030-1.3552.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.5491 - acc: 0.5065 - val_loss: 1.3552 - val_acc: 0.5986\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5481 - acc: 0.5093\n",
      "Epoch 00031: val_loss improved from 1.35518 to 1.34619, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/031-1.3462.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.5480 - acc: 0.5093 - val_loss: 1.3462 - val_acc: 0.6010\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5298 - acc: 0.5135\n",
      "Epoch 00032: val_loss improved from 1.34619 to 1.32739, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/032-1.3274.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.5299 - acc: 0.5135 - val_loss: 1.3274 - val_acc: 0.6096\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5195 - acc: 0.5186\n",
      "Epoch 00033: val_loss improved from 1.32739 to 1.31335, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/033-1.3134.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.5194 - acc: 0.5186 - val_loss: 1.3134 - val_acc: 0.6124\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5036 - acc: 0.5225\n",
      "Epoch 00034: val_loss improved from 1.31335 to 1.30105, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/034-1.3011.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.5035 - acc: 0.5226 - val_loss: 1.3011 - val_acc: 0.6201\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4924 - acc: 0.5276\n",
      "Epoch 00035: val_loss improved from 1.30105 to 1.28530, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/035-1.2853.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.4924 - acc: 0.5275 - val_loss: 1.2853 - val_acc: 0.6240\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4799 - acc: 0.5315\n",
      "Epoch 00036: val_loss improved from 1.28530 to 1.27580, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/036-1.2758.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.4799 - acc: 0.5315 - val_loss: 1.2758 - val_acc: 0.6278\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4715 - acc: 0.5361\n",
      "Epoch 00037: val_loss improved from 1.27580 to 1.26535, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/037-1.2653.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.4716 - acc: 0.5361 - val_loss: 1.2653 - val_acc: 0.6271\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4643 - acc: 0.5381\n",
      "Epoch 00038: val_loss improved from 1.26535 to 1.25830, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/038-1.2583.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.4643 - acc: 0.5381 - val_loss: 1.2583 - val_acc: 0.6294\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4506 - acc: 0.5412\n",
      "Epoch 00039: val_loss improved from 1.25830 to 1.23759, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/039-1.2376.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.4506 - acc: 0.5412 - val_loss: 1.2376 - val_acc: 0.6394\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4418 - acc: 0.5464\n",
      "Epoch 00040: val_loss improved from 1.23759 to 1.23272, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/040-1.2327.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.4418 - acc: 0.5464 - val_loss: 1.2327 - val_acc: 0.6401\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4344 - acc: 0.5498\n",
      "Epoch 00041: val_loss improved from 1.23272 to 1.21689, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/041-1.2169.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.4344 - acc: 0.5498 - val_loss: 1.2169 - val_acc: 0.6420\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4230 - acc: 0.5529\n",
      "Epoch 00042: val_loss improved from 1.21689 to 1.20911, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/042-1.2091.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.4231 - acc: 0.5529 - val_loss: 1.2091 - val_acc: 0.6473\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4147 - acc: 0.5570\n",
      "Epoch 00043: val_loss improved from 1.20911 to 1.20054, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/043-1.2005.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.4146 - acc: 0.5570 - val_loss: 1.2005 - val_acc: 0.6476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4052 - acc: 0.5620\n",
      "Epoch 00044: val_loss improved from 1.20054 to 1.19390, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/044-1.1939.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.4052 - acc: 0.5619 - val_loss: 1.1939 - val_acc: 0.6501\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3985 - acc: 0.5633\n",
      "Epoch 00045: val_loss improved from 1.19390 to 1.17937, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/045-1.1794.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.3986 - acc: 0.5632 - val_loss: 1.1794 - val_acc: 0.6557\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3912 - acc: 0.5659\n",
      "Epoch 00046: val_loss improved from 1.17937 to 1.17202, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/046-1.1720.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.3913 - acc: 0.5659 - val_loss: 1.1720 - val_acc: 0.6573\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3776 - acc: 0.5693\n",
      "Epoch 00047: val_loss improved from 1.17202 to 1.16182, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/047-1.1618.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.3772 - acc: 0.5694 - val_loss: 1.1618 - val_acc: 0.6599\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3772 - acc: 0.5741\n",
      "Epoch 00048: val_loss improved from 1.16182 to 1.15956, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/048-1.1596.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.3774 - acc: 0.5740 - val_loss: 1.1596 - val_acc: 0.6643\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3658 - acc: 0.5733\n",
      "Epoch 00049: val_loss improved from 1.15956 to 1.14159, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/049-1.1416.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.3656 - acc: 0.5733 - val_loss: 1.1416 - val_acc: 0.6660\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3565 - acc: 0.5769\n",
      "Epoch 00050: val_loss improved from 1.14159 to 1.14093, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/050-1.1409.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.3566 - acc: 0.5767 - val_loss: 1.1409 - val_acc: 0.6664\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3468 - acc: 0.5801\n",
      "Epoch 00051: val_loss improved from 1.14093 to 1.12637, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/051-1.1264.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.3464 - acc: 0.5801 - val_loss: 1.1264 - val_acc: 0.6727\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3447 - acc: 0.5824\n",
      "Epoch 00052: val_loss improved from 1.12637 to 1.12321, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/052-1.1232.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.3447 - acc: 0.5824 - val_loss: 1.1232 - val_acc: 0.6720\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3352 - acc: 0.5834\n",
      "Epoch 00053: val_loss improved from 1.12321 to 1.11569, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/053-1.1157.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.3352 - acc: 0.5833 - val_loss: 1.1157 - val_acc: 0.6716\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3269 - acc: 0.5873\n",
      "Epoch 00054: val_loss improved from 1.11569 to 1.11229, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/054-1.1123.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.3269 - acc: 0.5874 - val_loss: 1.1123 - val_acc: 0.6758\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3207 - acc: 0.5889\n",
      "Epoch 00055: val_loss improved from 1.11229 to 1.09875, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/055-1.0987.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.3207 - acc: 0.5889 - val_loss: 1.0987 - val_acc: 0.6788\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3102 - acc: 0.5926\n",
      "Epoch 00056: val_loss improved from 1.09875 to 1.08701, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/056-1.0870.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.3103 - acc: 0.5926 - val_loss: 1.0870 - val_acc: 0.6841\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3120 - acc: 0.5933\n",
      "Epoch 00057: val_loss did not improve from 1.08701\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.3119 - acc: 0.5933 - val_loss: 1.0895 - val_acc: 0.6825\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3094 - acc: 0.5938\n",
      "Epoch 00058: val_loss improved from 1.08701 to 1.08245, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/058-1.0824.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.3094 - acc: 0.5938 - val_loss: 1.0824 - val_acc: 0.6841\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2948 - acc: 0.5976\n",
      "Epoch 00059: val_loss improved from 1.08245 to 1.07948, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/059-1.0795.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.2946 - acc: 0.5977 - val_loss: 1.0795 - val_acc: 0.6897\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2918 - acc: 0.6007\n",
      "Epoch 00060: val_loss improved from 1.07948 to 1.06897, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/060-1.0690.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.2915 - acc: 0.6008 - val_loss: 1.0690 - val_acc: 0.6890\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2860 - acc: 0.6020\n",
      "Epoch 00061: val_loss improved from 1.06897 to 1.06022, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/061-1.0602.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.2859 - acc: 0.6020 - val_loss: 1.0602 - val_acc: 0.6925\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2812 - acc: 0.6011\n",
      "Epoch 00062: val_loss did not improve from 1.06022\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.2812 - acc: 0.6011 - val_loss: 1.0621 - val_acc: 0.6935\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2780 - acc: 0.6039\n",
      "Epoch 00063: val_loss improved from 1.06022 to 1.05453, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/063-1.0545.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.2776 - acc: 0.6040 - val_loss: 1.0545 - val_acc: 0.6958\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2712 - acc: 0.6081\n",
      "Epoch 00064: val_loss improved from 1.05453 to 1.04554, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/064-1.0455.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.2711 - acc: 0.6082 - val_loss: 1.0455 - val_acc: 0.7016\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2646 - acc: 0.6099\n",
      "Epoch 00065: val_loss did not improve from 1.04554\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.2646 - acc: 0.6099 - val_loss: 1.0520 - val_acc: 0.6914\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2710 - acc: 0.6068\n",
      "Epoch 00066: val_loss improved from 1.04554 to 1.03378, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/066-1.0338.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2710 - acc: 0.6068 - val_loss: 1.0338 - val_acc: 0.7011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2604 - acc: 0.6131\n",
      "Epoch 00067: val_loss did not improve from 1.03378\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.2604 - acc: 0.6132 - val_loss: 1.0339 - val_acc: 0.7000\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2540 - acc: 0.6131\n",
      "Epoch 00068: val_loss improved from 1.03378 to 1.02231, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/068-1.0223.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.2539 - acc: 0.6132 - val_loss: 1.0223 - val_acc: 0.7018\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2503 - acc: 0.6141\n",
      "Epoch 00069: val_loss improved from 1.02231 to 1.01597, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/069-1.0160.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.2502 - acc: 0.6142 - val_loss: 1.0160 - val_acc: 0.7060\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2414 - acc: 0.6184\n",
      "Epoch 00070: val_loss improved from 1.01597 to 1.01573, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/070-1.0157.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2414 - acc: 0.6184 - val_loss: 1.0157 - val_acc: 0.7072\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2423 - acc: 0.6137\n",
      "Epoch 00071: val_loss did not improve from 1.01573\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.2422 - acc: 0.6137 - val_loss: 1.0166 - val_acc: 0.7053\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2392 - acc: 0.6213\n",
      "Epoch 00072: val_loss improved from 1.01573 to 1.01429, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/072-1.0143.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.2393 - acc: 0.6213 - val_loss: 1.0143 - val_acc: 0.7114\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2313 - acc: 0.6204\n",
      "Epoch 00073: val_loss improved from 1.01429 to 1.00271, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/073-1.0027.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2312 - acc: 0.6204 - val_loss: 1.0027 - val_acc: 0.7079\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2216 - acc: 0.6229\n",
      "Epoch 00074: val_loss improved from 1.00271 to 0.99743, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/074-0.9974.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.2216 - acc: 0.6229 - val_loss: 0.9974 - val_acc: 0.7109\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2293 - acc: 0.6252\n",
      "Epoch 00075: val_loss improved from 0.99743 to 0.99680, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/075-0.9968.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2294 - acc: 0.6252 - val_loss: 0.9968 - val_acc: 0.7151\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2194 - acc: 0.6268\n",
      "Epoch 00076: val_loss improved from 0.99680 to 0.99162, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/076-0.9916.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 1.2194 - acc: 0.6268 - val_loss: 0.9916 - val_acc: 0.7154\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2115 - acc: 0.6266\n",
      "Epoch 00077: val_loss did not improve from 0.99162\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.2116 - acc: 0.6265 - val_loss: 1.0039 - val_acc: 0.7063\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2142 - acc: 0.6283\n",
      "Epoch 00078: val_loss improved from 0.99162 to 0.98110, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/078-0.9811.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.2149 - acc: 0.6282 - val_loss: 0.9811 - val_acc: 0.7156\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2044 - acc: 0.6304\n",
      "Epoch 00079: val_loss did not improve from 0.98110\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.2043 - acc: 0.6304 - val_loss: 0.9902 - val_acc: 0.7109\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2107 - acc: 0.6301\n",
      "Epoch 00080: val_loss improved from 0.98110 to 0.97881, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/080-0.9788.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.2107 - acc: 0.6301 - val_loss: 0.9788 - val_acc: 0.7174\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2025 - acc: 0.6312\n",
      "Epoch 00081: val_loss improved from 0.97881 to 0.97855, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/081-0.9785.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.2026 - acc: 0.6312 - val_loss: 0.9785 - val_acc: 0.7181\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1956 - acc: 0.6325\n",
      "Epoch 00082: val_loss improved from 0.97855 to 0.96735, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/082-0.9674.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.1956 - acc: 0.6323 - val_loss: 0.9674 - val_acc: 0.7249\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1969 - acc: 0.6325\n",
      "Epoch 00083: val_loss improved from 0.96735 to 0.96352, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/083-0.9635.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1965 - acc: 0.6325 - val_loss: 0.9635 - val_acc: 0.7209\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1852 - acc: 0.6382\n",
      "Epoch 00084: val_loss improved from 0.96352 to 0.96237, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/084-0.9624.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1852 - acc: 0.6382 - val_loss: 0.9624 - val_acc: 0.7191\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1847 - acc: 0.6386\n",
      "Epoch 00085: val_loss did not improve from 0.96237\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.1847 - acc: 0.6386 - val_loss: 0.9654 - val_acc: 0.7249\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1862 - acc: 0.6387\n",
      "Epoch 00086: val_loss improved from 0.96237 to 0.95826, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/086-0.9583.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1863 - acc: 0.6386 - val_loss: 0.9583 - val_acc: 0.7251\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1817 - acc: 0.6374\n",
      "Epoch 00087: val_loss improved from 0.95826 to 0.95365, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/087-0.9536.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1816 - acc: 0.6374 - val_loss: 0.9536 - val_acc: 0.7272\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1852 - acc: 0.6370\n",
      "Epoch 00088: val_loss improved from 0.95365 to 0.94416, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/088-0.9442.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 1.1852 - acc: 0.6370 - val_loss: 0.9442 - val_acc: 0.7284\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1799 - acc: 0.6420\n",
      "Epoch 00089: val_loss did not improve from 0.94416\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.1799 - acc: 0.6419 - val_loss: 0.9462 - val_acc: 0.7298\n",
      "Epoch 90/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1670 - acc: 0.6448\n",
      "Epoch 00090: val_loss did not improve from 0.94416\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1671 - acc: 0.6447 - val_loss: 0.9499 - val_acc: 0.7265\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1735 - acc: 0.6409\n",
      "Epoch 00091: val_loss improved from 0.94416 to 0.93844, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/091-0.9384.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 1.1737 - acc: 0.6409 - val_loss: 0.9384 - val_acc: 0.7293\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1668 - acc: 0.6421\n",
      "Epoch 00092: val_loss improved from 0.93844 to 0.93396, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/092-0.9340.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1667 - acc: 0.6421 - val_loss: 0.9340 - val_acc: 0.7331\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1686 - acc: 0.6429\n",
      "Epoch 00093: val_loss did not improve from 0.93396\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.1685 - acc: 0.6430 - val_loss: 0.9348 - val_acc: 0.7349\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1603 - acc: 0.6439\n",
      "Epoch 00094: val_loss did not improve from 0.93396\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1607 - acc: 0.6439 - val_loss: 0.9416 - val_acc: 0.7279\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1590 - acc: 0.6451\n",
      "Epoch 00095: val_loss did not improve from 0.93396\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.1586 - acc: 0.6453 - val_loss: 0.9360 - val_acc: 0.7305\n",
      "Epoch 96/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1628 - acc: 0.6435\n",
      "Epoch 00096: val_loss improved from 0.93396 to 0.93059, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/096-0.9306.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1628 - acc: 0.6434 - val_loss: 0.9306 - val_acc: 0.7352\n",
      "Epoch 97/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1544 - acc: 0.6493\n",
      "Epoch 00097: val_loss improved from 0.93059 to 0.92087, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/097-0.9209.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1543 - acc: 0.6493 - val_loss: 0.9209 - val_acc: 0.7365\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1530 - acc: 0.6494\n",
      "Epoch 00098: val_loss did not improve from 0.92087\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.1531 - acc: 0.6494 - val_loss: 0.9214 - val_acc: 0.7368\n",
      "Epoch 99/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1454 - acc: 0.6514\n",
      "Epoch 00099: val_loss improved from 0.92087 to 0.91511, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/099-0.9151.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1456 - acc: 0.6512 - val_loss: 0.9151 - val_acc: 0.7368\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1489 - acc: 0.6479\n",
      "Epoch 00100: val_loss did not improve from 0.91511\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.1489 - acc: 0.6479 - val_loss: 0.9177 - val_acc: 0.7405\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1412 - acc: 0.6513\n",
      "Epoch 00101: val_loss improved from 0.91511 to 0.90608, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/101-0.9061.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.1411 - acc: 0.6513 - val_loss: 0.9061 - val_acc: 0.7389\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1400 - acc: 0.6491\n",
      "Epoch 00102: val_loss did not improve from 0.90608\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.1402 - acc: 0.6490 - val_loss: 0.9142 - val_acc: 0.7375\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1289 - acc: 0.6548\n",
      "Epoch 00103: val_loss improved from 0.90608 to 0.90376, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/103-0.9038.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 1.1289 - acc: 0.6548 - val_loss: 0.9038 - val_acc: 0.7431\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1411 - acc: 0.6528\n",
      "Epoch 00104: val_loss did not improve from 0.90376\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.1411 - acc: 0.6528 - val_loss: 0.9142 - val_acc: 0.7384\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1343 - acc: 0.6554\n",
      "Epoch 00105: val_loss improved from 0.90376 to 0.90165, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/105-0.9017.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1340 - acc: 0.6553 - val_loss: 0.9017 - val_acc: 0.7407\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1294 - acc: 0.6559\n",
      "Epoch 00106: val_loss did not improve from 0.90165\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.1294 - acc: 0.6558 - val_loss: 0.9119 - val_acc: 0.7386\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1263 - acc: 0.6551\n",
      "Epoch 00107: val_loss improved from 0.90165 to 0.89338, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/107-0.8934.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.1262 - acc: 0.6551 - val_loss: 0.8934 - val_acc: 0.7421\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1200 - acc: 0.6602\n",
      "Epoch 00108: val_loss improved from 0.89338 to 0.88796, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/108-0.8880.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.1200 - acc: 0.6602 - val_loss: 0.8880 - val_acc: 0.7456\n",
      "Epoch 109/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1272 - acc: 0.6589\n",
      "Epoch 00109: val_loss did not improve from 0.88796\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.1268 - acc: 0.6589 - val_loss: 0.8887 - val_acc: 0.7461\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1202 - acc: 0.6591\n",
      "Epoch 00110: val_loss did not improve from 0.88796\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.1202 - acc: 0.6591 - val_loss: 0.8988 - val_acc: 0.7442\n",
      "Epoch 111/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1233 - acc: 0.6579\n",
      "Epoch 00111: val_loss did not improve from 0.88796\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.1234 - acc: 0.6579 - val_loss: 0.8923 - val_acc: 0.7489\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1171 - acc: 0.6599\n",
      "Epoch 00112: val_loss improved from 0.88796 to 0.88373, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/112-0.8837.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.1169 - acc: 0.6600 - val_loss: 0.8837 - val_acc: 0.7519\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1184 - acc: 0.6621\n",
      "Epoch 00113: val_loss did not improve from 0.88373\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.1184 - acc: 0.6621 - val_loss: 0.8908 - val_acc: 0.7456\n",
      "Epoch 114/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1132 - acc: 0.6613\n",
      "Epoch 00114: val_loss did not improve from 0.88373\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.1131 - acc: 0.6614 - val_loss: 0.8878 - val_acc: 0.7489\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1122 - acc: 0.6621\n",
      "Epoch 00115: val_loss improved from 0.88373 to 0.88286, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/115-0.8829.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 1.1124 - acc: 0.6621 - val_loss: 0.8829 - val_acc: 0.7524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1024 - acc: 0.6662\n",
      "Epoch 00116: val_loss improved from 0.88286 to 0.87431, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/116-0.8743.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.1024 - acc: 0.6662 - val_loss: 0.8743 - val_acc: 0.7533\n",
      "Epoch 117/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1129 - acc: 0.6602\n",
      "Epoch 00117: val_loss did not improve from 0.87431\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.1125 - acc: 0.6603 - val_loss: 0.8757 - val_acc: 0.7519\n",
      "Epoch 118/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1084 - acc: 0.6633\n",
      "Epoch 00118: val_loss improved from 0.87431 to 0.87092, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/118-0.8709.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.1087 - acc: 0.6633 - val_loss: 0.8709 - val_acc: 0.7531\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1009 - acc: 0.6655\n",
      "Epoch 00119: val_loss did not improve from 0.87092\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.1013 - acc: 0.6655 - val_loss: 0.8729 - val_acc: 0.7570\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1034 - acc: 0.6637\n",
      "Epoch 00120: val_loss did not improve from 0.87092\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.1034 - acc: 0.6636 - val_loss: 0.8801 - val_acc: 0.7522\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0986 - acc: 0.6651\n",
      "Epoch 00121: val_loss improved from 0.87092 to 0.86843, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/121-0.8684.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0985 - acc: 0.6651 - val_loss: 0.8684 - val_acc: 0.7561\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1044 - acc: 0.6675\n",
      "Epoch 00122: val_loss did not improve from 0.86843\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.1044 - acc: 0.6675 - val_loss: 0.8712 - val_acc: 0.7545\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0971 - acc: 0.6682\n",
      "Epoch 00123: val_loss improved from 0.86843 to 0.86357, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/123-0.8636.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0971 - acc: 0.6683 - val_loss: 0.8636 - val_acc: 0.7554\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0913 - acc: 0.6699\n",
      "Epoch 00124: val_loss did not improve from 0.86357\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 1.0914 - acc: 0.6699 - val_loss: 0.8655 - val_acc: 0.7536\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0964 - acc: 0.6699\n",
      "Epoch 00125: val_loss improved from 0.86357 to 0.86067, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/125-0.8607.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0965 - acc: 0.6699 - val_loss: 0.8607 - val_acc: 0.7591\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0906 - acc: 0.6693\n",
      "Epoch 00126: val_loss did not improve from 0.86067\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0907 - acc: 0.6693 - val_loss: 0.8648 - val_acc: 0.7549\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0883 - acc: 0.6719\n",
      "Epoch 00127: val_loss did not improve from 0.86067\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0883 - acc: 0.6719 - val_loss: 0.8646 - val_acc: 0.7549\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0886 - acc: 0.6716\n",
      "Epoch 00128: val_loss improved from 0.86067 to 0.85269, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/128-0.8527.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0885 - acc: 0.6716 - val_loss: 0.8527 - val_acc: 0.7619\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0898 - acc: 0.6689\n",
      "Epoch 00129: val_loss did not improve from 0.85269\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0898 - acc: 0.6689 - val_loss: 0.8530 - val_acc: 0.7598\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0836 - acc: 0.6714\n",
      "Epoch 00130: val_loss did not improve from 0.85269\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0835 - acc: 0.6714 - val_loss: 0.8589 - val_acc: 0.7563\n",
      "Epoch 131/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0809 - acc: 0.6738\n",
      "Epoch 00131: val_loss did not improve from 0.85269\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0810 - acc: 0.6738 - val_loss: 0.8535 - val_acc: 0.7650\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0835 - acc: 0.6694\n",
      "Epoch 00132: val_loss improved from 0.85269 to 0.84334, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/132-0.8433.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0837 - acc: 0.6694 - val_loss: 0.8433 - val_acc: 0.7629\n",
      "Epoch 133/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0803 - acc: 0.6736\n",
      "Epoch 00133: val_loss did not improve from 0.84334\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0800 - acc: 0.6737 - val_loss: 0.8471 - val_acc: 0.7636\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0828 - acc: 0.6723\n",
      "Epoch 00134: val_loss did not improve from 0.84334\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0827 - acc: 0.6723 - val_loss: 0.8481 - val_acc: 0.7615\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0772 - acc: 0.6762\n",
      "Epoch 00135: val_loss did not improve from 0.84334\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0771 - acc: 0.6762 - val_loss: 0.8469 - val_acc: 0.7638\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0727 - acc: 0.6735\n",
      "Epoch 00136: val_loss did not improve from 0.84334\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0726 - acc: 0.6735 - val_loss: 0.8491 - val_acc: 0.7647\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0729 - acc: 0.6752\n",
      "Epoch 00137: val_loss improved from 0.84334 to 0.83689, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/137-0.8369.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0728 - acc: 0.6752 - val_loss: 0.8369 - val_acc: 0.7661\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0710 - acc: 0.6761\n",
      "Epoch 00138: val_loss did not improve from 0.83689\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0712 - acc: 0.6761 - val_loss: 0.8427 - val_acc: 0.7643\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0706 - acc: 0.6747\n",
      "Epoch 00139: val_loss did not improve from 0.83689\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0706 - acc: 0.6747 - val_loss: 0.8432 - val_acc: 0.7657\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0680 - acc: 0.6764\n",
      "Epoch 00140: val_loss improved from 0.83689 to 0.83533, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/140-0.8353.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0681 - acc: 0.6763 - val_loss: 0.8353 - val_acc: 0.7661\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0703 - acc: 0.6801\n",
      "Epoch 00141: val_loss did not improve from 0.83533\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0704 - acc: 0.6800 - val_loss: 0.8383 - val_acc: 0.7671\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0674 - acc: 0.6792\n",
      "Epoch 00142: val_loss improved from 0.83533 to 0.83507, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/142-0.8351.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0675 - acc: 0.6792 - val_loss: 0.8351 - val_acc: 0.7652\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0700 - acc: 0.6789\n",
      "Epoch 00143: val_loss did not improve from 0.83507\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0700 - acc: 0.6789 - val_loss: 0.8360 - val_acc: 0.7713\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0684 - acc: 0.6793\n",
      "Epoch 00144: val_loss improved from 0.83507 to 0.83061, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/144-0.8306.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0684 - acc: 0.6792 - val_loss: 0.8306 - val_acc: 0.7659\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0642 - acc: 0.6783\n",
      "Epoch 00145: val_loss improved from 0.83061 to 0.82441, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/145-0.8244.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0641 - acc: 0.6784 - val_loss: 0.8244 - val_acc: 0.7680\n",
      "Epoch 146/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0554 - acc: 0.6811\n",
      "Epoch 00146: val_loss did not improve from 0.82441\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0558 - acc: 0.6811 - val_loss: 0.8282 - val_acc: 0.7703\n",
      "Epoch 147/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0548 - acc: 0.6818\n",
      "Epoch 00147: val_loss did not improve from 0.82441\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0546 - acc: 0.6819 - val_loss: 0.8323 - val_acc: 0.7708\n",
      "Epoch 148/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0558 - acc: 0.6819\n",
      "Epoch 00148: val_loss did not improve from 0.82441\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0554 - acc: 0.6821 - val_loss: 0.8285 - val_acc: 0.7692\n",
      "Epoch 149/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0571 - acc: 0.6801\n",
      "Epoch 00149: val_loss did not improve from 0.82441\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0575 - acc: 0.6801 - val_loss: 0.8324 - val_acc: 0.7696\n",
      "Epoch 150/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0489 - acc: 0.6813\n",
      "Epoch 00150: val_loss improved from 0.82441 to 0.81740, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/150-0.8174.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0490 - acc: 0.6813 - val_loss: 0.8174 - val_acc: 0.7738\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0533 - acc: 0.6802\n",
      "Epoch 00151: val_loss did not improve from 0.81740\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0532 - acc: 0.6802 - val_loss: 0.8213 - val_acc: 0.7727\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0479 - acc: 0.6833\n",
      "Epoch 00152: val_loss did not improve from 0.81740\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 1.0478 - acc: 0.6833 - val_loss: 0.8180 - val_acc: 0.7752\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0551 - acc: 0.6826\n",
      "Epoch 00153: val_loss did not improve from 0.81740\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0550 - acc: 0.6826 - val_loss: 0.8192 - val_acc: 0.7694\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0453 - acc: 0.6846\n",
      "Epoch 00154: val_loss improved from 0.81740 to 0.81705, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/154-0.8171.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0452 - acc: 0.6847 - val_loss: 0.8171 - val_acc: 0.7703\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0495 - acc: 0.6844\n",
      "Epoch 00155: val_loss did not improve from 0.81705\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0494 - acc: 0.6844 - val_loss: 0.8172 - val_acc: 0.7754\n",
      "Epoch 156/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0514 - acc: 0.6862\n",
      "Epoch 00156: val_loss improved from 0.81705 to 0.81491, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/156-0.8149.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0510 - acc: 0.6864 - val_loss: 0.8149 - val_acc: 0.7738\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0514 - acc: 0.6811\n",
      "Epoch 00157: val_loss improved from 0.81491 to 0.81149, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/157-0.8115.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0514 - acc: 0.6811 - val_loss: 0.8115 - val_acc: 0.7773\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0409 - acc: 0.6864\n",
      "Epoch 00158: val_loss did not improve from 0.81149\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0408 - acc: 0.6865 - val_loss: 0.8159 - val_acc: 0.7713\n",
      "Epoch 159/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0435 - acc: 0.6863\n",
      "Epoch 00159: val_loss did not improve from 0.81149\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0436 - acc: 0.6861 - val_loss: 0.8124 - val_acc: 0.7731\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0436 - acc: 0.6868\n",
      "Epoch 00160: val_loss did not improve from 0.81149\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0435 - acc: 0.6868 - val_loss: 0.8130 - val_acc: 0.7727\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0400 - acc: 0.6876\n",
      "Epoch 00161: val_loss did not improve from 0.81149\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0402 - acc: 0.6875 - val_loss: 0.8118 - val_acc: 0.7738\n",
      "Epoch 162/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0426 - acc: 0.6849\n",
      "Epoch 00162: val_loss improved from 0.81149 to 0.80933, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/162-0.8093.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 1.0428 - acc: 0.6847 - val_loss: 0.8093 - val_acc: 0.7738\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0335 - acc: 0.6871\n",
      "Epoch 00163: val_loss improved from 0.80933 to 0.80745, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/163-0.8075.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0335 - acc: 0.6871 - val_loss: 0.8075 - val_acc: 0.7722\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0351 - acc: 0.6874\n",
      "Epoch 00164: val_loss improved from 0.80745 to 0.80214, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/164-0.8021.hdf5\n",
      "36805/36805 [==============================] - 29s 802us/sample - loss: 1.0352 - acc: 0.6874 - val_loss: 0.8021 - val_acc: 0.7796\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0394 - acc: 0.6844\n",
      "Epoch 00165: val_loss did not improve from 0.80214\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0395 - acc: 0.6844 - val_loss: 0.8027 - val_acc: 0.7754\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0371 - acc: 0.6876\n",
      "Epoch 00166: val_loss improved from 0.80214 to 0.80162, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/166-0.8016.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0371 - acc: 0.6876 - val_loss: 0.8016 - val_acc: 0.7764\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0336 - acc: 0.6896\n",
      "Epoch 00167: val_loss improved from 0.80162 to 0.79847, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/167-0.7985.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0336 - acc: 0.6895 - val_loss: 0.7985 - val_acc: 0.7801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0301 - acc: 0.6887\n",
      "Epoch 00168: val_loss did not improve from 0.79847\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0295 - acc: 0.6888 - val_loss: 0.8001 - val_acc: 0.7799\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0304 - acc: 0.6886\n",
      "Epoch 00169: val_loss improved from 0.79847 to 0.79722, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/169-0.7972.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0305 - acc: 0.6885 - val_loss: 0.7972 - val_acc: 0.7799\n",
      "Epoch 170/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0305 - acc: 0.6897\n",
      "Epoch 00170: val_loss did not improve from 0.79722\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0306 - acc: 0.6896 - val_loss: 0.7977 - val_acc: 0.7792\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0236 - acc: 0.6929\n",
      "Epoch 00171: val_loss improved from 0.79722 to 0.79697, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/171-0.7970.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0236 - acc: 0.6928 - val_loss: 0.7970 - val_acc: 0.7792\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0273 - acc: 0.6915\n",
      "Epoch 00172: val_loss did not improve from 0.79697\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0273 - acc: 0.6915 - val_loss: 0.8040 - val_acc: 0.7761\n",
      "Epoch 173/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0232 - acc: 0.6899\n",
      "Epoch 00173: val_loss improved from 0.79697 to 0.79222, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/173-0.7922.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0234 - acc: 0.6898 - val_loss: 0.7922 - val_acc: 0.7792\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0253 - acc: 0.6924\n",
      "Epoch 00174: val_loss did not improve from 0.79222\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0252 - acc: 0.6925 - val_loss: 0.7976 - val_acc: 0.7796\n",
      "Epoch 175/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0256 - acc: 0.6920\n",
      "Epoch 00175: val_loss did not improve from 0.79222\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0254 - acc: 0.6921 - val_loss: 0.7952 - val_acc: 0.7789\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0209 - acc: 0.6946\n",
      "Epoch 00176: val_loss did not improve from 0.79222\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0209 - acc: 0.6946 - val_loss: 0.7935 - val_acc: 0.7808\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0218 - acc: 0.6943\n",
      "Epoch 00177: val_loss improved from 0.79222 to 0.78891, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/177-0.7889.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0217 - acc: 0.6943 - val_loss: 0.7889 - val_acc: 0.7843\n",
      "Epoch 178/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0225 - acc: 0.6924\n",
      "Epoch 00178: val_loss did not improve from 0.78891\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0220 - acc: 0.6925 - val_loss: 0.7926 - val_acc: 0.7808\n",
      "Epoch 179/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0191 - acc: 0.6932\n",
      "Epoch 00179: val_loss improved from 0.78891 to 0.78656, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/179-0.7866.hdf5\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 1.0190 - acc: 0.6931 - val_loss: 0.7866 - val_acc: 0.7806\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0163 - acc: 0.6946\n",
      "Epoch 00180: val_loss did not improve from 0.78656\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0163 - acc: 0.6947 - val_loss: 0.7948 - val_acc: 0.7792\n",
      "Epoch 181/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0233 - acc: 0.6941\n",
      "Epoch 00181: val_loss did not improve from 0.78656\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0237 - acc: 0.6941 - val_loss: 0.7924 - val_acc: 0.7789\n",
      "Epoch 182/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0170 - acc: 0.6928\n",
      "Epoch 00182: val_loss did not improve from 0.78656\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0173 - acc: 0.6928 - val_loss: 0.7870 - val_acc: 0.7815\n",
      "Epoch 183/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0170 - acc: 0.6926\n",
      "Epoch 00183: val_loss did not improve from 0.78656\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0174 - acc: 0.6925 - val_loss: 0.7872 - val_acc: 0.7799\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0169 - acc: 0.6945\n",
      "Epoch 00184: val_loss improved from 0.78656 to 0.78226, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/184-0.7823.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0169 - acc: 0.6945 - val_loss: 0.7823 - val_acc: 0.7866\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0200 - acc: 0.6944\n",
      "Epoch 00185: val_loss did not improve from 0.78226\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 1.0199 - acc: 0.6944 - val_loss: 0.7907 - val_acc: 0.7813\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0154 - acc: 0.6962\n",
      "Epoch 00186: val_loss did not improve from 0.78226\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.0154 - acc: 0.6962 - val_loss: 0.7840 - val_acc: 0.7866\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0110 - acc: 0.6967\n",
      "Epoch 00187: val_loss improved from 0.78226 to 0.77965, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/187-0.7797.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 1.0109 - acc: 0.6967 - val_loss: 0.7797 - val_acc: 0.7899\n",
      "Epoch 188/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0195 - acc: 0.6941\n",
      "Epoch 00188: val_loss did not improve from 0.77965\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 1.0198 - acc: 0.6941 - val_loss: 0.7819 - val_acc: 0.7848\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0135 - acc: 0.6951\n",
      "Epoch 00189: val_loss did not improve from 0.77965\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 1.0136 - acc: 0.6950 - val_loss: 0.7840 - val_acc: 0.7845\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0121 - acc: 0.6953\n",
      "Epoch 00190: val_loss improved from 0.77965 to 0.77786, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/190-0.7779.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 1.0120 - acc: 0.6953 - val_loss: 0.7779 - val_acc: 0.7855\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0140 - acc: 0.6945\n",
      "Epoch 00191: val_loss did not improve from 0.77786\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0140 - acc: 0.6945 - val_loss: 0.7785 - val_acc: 0.7848\n",
      "Epoch 192/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0028 - acc: 0.6981\n",
      "Epoch 00192: val_loss did not improve from 0.77786\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0033 - acc: 0.6981 - val_loss: 0.7861 - val_acc: 0.7843\n",
      "Epoch 193/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0024 - acc: 0.6984\n",
      "Epoch 00193: val_loss improved from 0.77786 to 0.76721, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/193-0.7672.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 1.0023 - acc: 0.6984 - val_loss: 0.7672 - val_acc: 0.7899\n",
      "Epoch 194/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0071 - acc: 0.6983\n",
      "Epoch 00194: val_loss did not improve from 0.76721\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0072 - acc: 0.6983 - val_loss: 0.7738 - val_acc: 0.7892\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0020 - acc: 0.7006\n",
      "Epoch 00195: val_loss did not improve from 0.76721\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 1.0020 - acc: 0.7006 - val_loss: 0.7681 - val_acc: 0.7883\n",
      "Epoch 196/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0116 - acc: 0.6981\n",
      "Epoch 00196: val_loss did not improve from 0.76721\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 1.0118 - acc: 0.6981 - val_loss: 0.7758 - val_acc: 0.7855\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0111 - acc: 0.6991\n",
      "Epoch 00197: val_loss did not improve from 0.76721\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 1.0110 - acc: 0.6991 - val_loss: 0.7706 - val_acc: 0.7887\n",
      "Epoch 198/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0072 - acc: 0.6980\n",
      "Epoch 00198: val_loss did not improve from 0.76721\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 1.0070 - acc: 0.6981 - val_loss: 0.7744 - val_acc: 0.7908\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0041 - acc: 0.6982\n",
      "Epoch 00199: val_loss did not improve from 0.76721\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 1.0041 - acc: 0.6982 - val_loss: 0.7779 - val_acc: 0.7864\n",
      "Epoch 200/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9984 - acc: 0.6999\n",
      "Epoch 00200: val_loss improved from 0.76721 to 0.76601, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/200-0.7660.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9982 - acc: 0.6999 - val_loss: 0.7660 - val_acc: 0.7897\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9987 - acc: 0.7007\n",
      "Epoch 00201: val_loss did not improve from 0.76601\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9987 - acc: 0.7006 - val_loss: 0.7662 - val_acc: 0.7892\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9985 - acc: 0.7001\n",
      "Epoch 00202: val_loss did not improve from 0.76601\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9985 - acc: 0.7001 - val_loss: 0.7677 - val_acc: 0.7901\n",
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9965 - acc: 0.6984\n",
      "Epoch 00203: val_loss did not improve from 0.76601\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9961 - acc: 0.6985 - val_loss: 0.7695 - val_acc: 0.7894\n",
      "Epoch 204/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9943 - acc: 0.7009\n",
      "Epoch 00204: val_loss improved from 0.76601 to 0.76346, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/204-0.7635.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9949 - acc: 0.7008 - val_loss: 0.7635 - val_acc: 0.7913\n",
      "Epoch 205/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9980 - acc: 0.7010\n",
      "Epoch 00205: val_loss did not improve from 0.76346\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9983 - acc: 0.7007 - val_loss: 0.7656 - val_acc: 0.7908\n",
      "Epoch 206/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9980 - acc: 0.7001\n",
      "Epoch 00206: val_loss did not improve from 0.76346\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9979 - acc: 0.7002 - val_loss: 0.7641 - val_acc: 0.7885\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9877 - acc: 0.7046\n",
      "Epoch 00207: val_loss did not improve from 0.76346\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9877 - acc: 0.7046 - val_loss: 0.7648 - val_acc: 0.7927\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9937 - acc: 0.7001\n",
      "Epoch 00208: val_loss improved from 0.76346 to 0.76112, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/208-0.7611.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9937 - acc: 0.7001 - val_loss: 0.7611 - val_acc: 0.7906\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9925 - acc: 0.7007\n",
      "Epoch 00209: val_loss improved from 0.76112 to 0.75856, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/209-0.7586.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9923 - acc: 0.7008 - val_loss: 0.7586 - val_acc: 0.7959\n",
      "Epoch 210/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9998 - acc: 0.6978\n",
      "Epoch 00210: val_loss improved from 0.75856 to 0.75765, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/210-0.7577.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 1.0002 - acc: 0.6979 - val_loss: 0.7577 - val_acc: 0.7927\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9945 - acc: 0.7048\n",
      "Epoch 00211: val_loss did not improve from 0.75765\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9945 - acc: 0.7047 - val_loss: 0.7599 - val_acc: 0.7899\n",
      "Epoch 212/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9904 - acc: 0.7021\n",
      "Epoch 00212: val_loss improved from 0.75765 to 0.75451, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/212-0.7545.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9903 - acc: 0.7020 - val_loss: 0.7545 - val_acc: 0.7899\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9972 - acc: 0.7002\n",
      "Epoch 00213: val_loss did not improve from 0.75451\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9972 - acc: 0.7002 - val_loss: 0.7678 - val_acc: 0.7925\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9934 - acc: 0.7010\n",
      "Epoch 00214: val_loss improved from 0.75451 to 0.75124, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/214-0.7512.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9933 - acc: 0.7010 - val_loss: 0.7512 - val_acc: 0.7915\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9912 - acc: 0.7028\n",
      "Epoch 00215: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9912 - acc: 0.7027 - val_loss: 0.7642 - val_acc: 0.7918\n",
      "Epoch 216/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9888 - acc: 0.7065\n",
      "Epoch 00216: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.9888 - acc: 0.7064 - val_loss: 0.7654 - val_acc: 0.7922\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9914 - acc: 0.7046\n",
      "Epoch 00217: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.9913 - acc: 0.7046 - val_loss: 0.7561 - val_acc: 0.7899\n",
      "Epoch 218/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9849 - acc: 0.7067\n",
      "Epoch 00218: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9846 - acc: 0.7067 - val_loss: 0.7543 - val_acc: 0.7934\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9853 - acc: 0.7026\n",
      "Epoch 00219: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9852 - acc: 0.7026 - val_loss: 0.7536 - val_acc: 0.7943\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9839 - acc: 0.7044\n",
      "Epoch 00220: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9838 - acc: 0.7044 - val_loss: 0.7540 - val_acc: 0.7927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 221/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9803 - acc: 0.7065\n",
      "Epoch 00221: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9800 - acc: 0.7066 - val_loss: 0.7536 - val_acc: 0.7890\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9879 - acc: 0.7005\n",
      "Epoch 00222: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9879 - acc: 0.7005 - val_loss: 0.7524 - val_acc: 0.7945\n",
      "Epoch 223/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9791 - acc: 0.7019\n",
      "Epoch 00223: val_loss did not improve from 0.75124\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9790 - acc: 0.7021 - val_loss: 0.7567 - val_acc: 0.7939\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9807 - acc: 0.7067\n",
      "Epoch 00224: val_loss improved from 0.75124 to 0.74710, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/224-0.7471.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9807 - acc: 0.7068 - val_loss: 0.7471 - val_acc: 0.7945\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9810 - acc: 0.7033\n",
      "Epoch 00225: val_loss improved from 0.74710 to 0.74537, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/225-0.7454.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9809 - acc: 0.7034 - val_loss: 0.7454 - val_acc: 0.7983\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9813 - acc: 0.7065\n",
      "Epoch 00226: val_loss improved from 0.74537 to 0.74237, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/226-0.7424.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9813 - acc: 0.7065 - val_loss: 0.7424 - val_acc: 0.7957\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9825 - acc: 0.7066\n",
      "Epoch 00227: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9825 - acc: 0.7066 - val_loss: 0.7461 - val_acc: 0.7941\n",
      "Epoch 228/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9835 - acc: 0.7046\n",
      "Epoch 00228: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9838 - acc: 0.7045 - val_loss: 0.7430 - val_acc: 0.7969\n",
      "Epoch 229/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9790 - acc: 0.7077\n",
      "Epoch 00229: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9787 - acc: 0.7077 - val_loss: 0.7586 - val_acc: 0.7894\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9792 - acc: 0.7070\n",
      "Epoch 00230: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9791 - acc: 0.7070 - val_loss: 0.7454 - val_acc: 0.7911\n",
      "Epoch 231/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9769 - acc: 0.7075\n",
      "Epoch 00231: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9767 - acc: 0.7076 - val_loss: 0.7482 - val_acc: 0.7952\n",
      "Epoch 232/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9811 - acc: 0.7071\n",
      "Epoch 00232: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9811 - acc: 0.7070 - val_loss: 0.7444 - val_acc: 0.7959\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9784 - acc: 0.7102\n",
      "Epoch 00233: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9783 - acc: 0.7103 - val_loss: 0.7455 - val_acc: 0.7990\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9763 - acc: 0.7075\n",
      "Epoch 00234: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9762 - acc: 0.7076 - val_loss: 0.7441 - val_acc: 0.7997\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9765 - acc: 0.7083\n",
      "Epoch 00235: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9765 - acc: 0.7083 - val_loss: 0.7498 - val_acc: 0.7966\n",
      "Epoch 236/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9729 - acc: 0.7099\n",
      "Epoch 00236: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.9729 - acc: 0.7100 - val_loss: 0.7443 - val_acc: 0.7950\n",
      "Epoch 237/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9767 - acc: 0.7090\n",
      "Epoch 00237: val_loss did not improve from 0.74237\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.9764 - acc: 0.7090 - val_loss: 0.7426 - val_acc: 0.7957\n",
      "Epoch 238/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9710 - acc: 0.7079\n",
      "Epoch 00238: val_loss improved from 0.74237 to 0.73596, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/238-0.7360.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9711 - acc: 0.7079 - val_loss: 0.7360 - val_acc: 0.8032\n",
      "Epoch 239/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9726 - acc: 0.7105\n",
      "Epoch 00239: val_loss improved from 0.73596 to 0.73495, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/239-0.7349.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9726 - acc: 0.7106 - val_loss: 0.7349 - val_acc: 0.7990\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9712 - acc: 0.7079\n",
      "Epoch 00240: val_loss did not improve from 0.73495\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9715 - acc: 0.7078 - val_loss: 0.7372 - val_acc: 0.8015\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9718 - acc: 0.7092\n",
      "Epoch 00241: val_loss improved from 0.73495 to 0.73434, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/241-0.7343.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9718 - acc: 0.7092 - val_loss: 0.7343 - val_acc: 0.8001\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9671 - acc: 0.7071\n",
      "Epoch 00242: val_loss did not improve from 0.73434\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9672 - acc: 0.7071 - val_loss: 0.7428 - val_acc: 0.7959\n",
      "Epoch 243/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9761 - acc: 0.7080\n",
      "Epoch 00243: val_loss did not improve from 0.73434\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9762 - acc: 0.7081 - val_loss: 0.7441 - val_acc: 0.7971\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9708 - acc: 0.7083\n",
      "Epoch 00244: val_loss did not improve from 0.73434\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9707 - acc: 0.7083 - val_loss: 0.7380 - val_acc: 0.7985\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9701 - acc: 0.7084\n",
      "Epoch 00245: val_loss did not improve from 0.73434\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9701 - acc: 0.7084 - val_loss: 0.7349 - val_acc: 0.7992\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9744 - acc: 0.7095\n",
      "Epoch 00246: val_loss improved from 0.73434 to 0.73308, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/246-0.7331.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9744 - acc: 0.7094 - val_loss: 0.7331 - val_acc: 0.7992\n",
      "Epoch 247/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9657 - acc: 0.7097\n",
      "Epoch 00247: val_loss did not improve from 0.73308\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9668 - acc: 0.7094 - val_loss: 0.7408 - val_acc: 0.7997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9700 - acc: 0.7112\n",
      "Epoch 00248: val_loss did not improve from 0.73308\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9699 - acc: 0.7112 - val_loss: 0.7354 - val_acc: 0.8018\n",
      "Epoch 249/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9642 - acc: 0.7121\n",
      "Epoch 00249: val_loss improved from 0.73308 to 0.72669, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/249-0.7267.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9643 - acc: 0.7122 - val_loss: 0.7267 - val_acc: 0.8004\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9623 - acc: 0.7126\n",
      "Epoch 00250: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9623 - acc: 0.7125 - val_loss: 0.7363 - val_acc: 0.8022\n",
      "Epoch 251/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9664 - acc: 0.7126\n",
      "Epoch 00251: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9664 - acc: 0.7126 - val_loss: 0.7344 - val_acc: 0.8011\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9670 - acc: 0.7104\n",
      "Epoch 00252: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9669 - acc: 0.7104 - val_loss: 0.7392 - val_acc: 0.7964\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9649 - acc: 0.7112\n",
      "Epoch 00253: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9649 - acc: 0.7112 - val_loss: 0.7330 - val_acc: 0.8013\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9592 - acc: 0.7126\n",
      "Epoch 00254: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9592 - acc: 0.7126 - val_loss: 0.7362 - val_acc: 0.7999\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9585 - acc: 0.7152\n",
      "Epoch 00255: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9584 - acc: 0.7152 - val_loss: 0.7314 - val_acc: 0.7992\n",
      "Epoch 256/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9630 - acc: 0.7120\n",
      "Epoch 00256: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9627 - acc: 0.7121 - val_loss: 0.7311 - val_acc: 0.8001\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9633 - acc: 0.7154\n",
      "Epoch 00257: val_loss did not improve from 0.72669\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9633 - acc: 0.7154 - val_loss: 0.7291 - val_acc: 0.8050\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9594 - acc: 0.7149\n",
      "Epoch 00258: val_loss improved from 0.72669 to 0.72560, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/258-0.7256.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9594 - acc: 0.7149 - val_loss: 0.7256 - val_acc: 0.8046\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9594 - acc: 0.7135\n",
      "Epoch 00259: val_loss did not improve from 0.72560\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9594 - acc: 0.7135 - val_loss: 0.7431 - val_acc: 0.7945\n",
      "Epoch 260/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9604 - acc: 0.7135\n",
      "Epoch 00260: val_loss did not improve from 0.72560\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9602 - acc: 0.7135 - val_loss: 0.7279 - val_acc: 0.8018\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9616 - acc: 0.7136\n",
      "Epoch 00261: val_loss improved from 0.72560 to 0.72185, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/261-0.7219.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9615 - acc: 0.7136 - val_loss: 0.7219 - val_acc: 0.8041\n",
      "Epoch 262/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9608 - acc: 0.7127\n",
      "Epoch 00262: val_loss improved from 0.72185 to 0.72095, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/262-0.7209.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9610 - acc: 0.7125 - val_loss: 0.7209 - val_acc: 0.8048\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9586 - acc: 0.7120\n",
      "Epoch 00263: val_loss did not improve from 0.72095\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9585 - acc: 0.7120 - val_loss: 0.7276 - val_acc: 0.8032\n",
      "Epoch 264/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9583 - acc: 0.7136\n",
      "Epoch 00264: val_loss did not improve from 0.72095\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9579 - acc: 0.7136 - val_loss: 0.7317 - val_acc: 0.7980\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9618 - acc: 0.7135\n",
      "Epoch 00265: val_loss did not improve from 0.72095\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9617 - acc: 0.7135 - val_loss: 0.7258 - val_acc: 0.8039\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9609 - acc: 0.7132\n",
      "Epoch 00266: val_loss did not improve from 0.72095\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9608 - acc: 0.7132 - val_loss: 0.7316 - val_acc: 0.8006\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9544 - acc: 0.7143\n",
      "Epoch 00267: val_loss improved from 0.72095 to 0.72051, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/267-0.7205.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9545 - acc: 0.7142 - val_loss: 0.7205 - val_acc: 0.8050\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9592 - acc: 0.7139\n",
      "Epoch 00268: val_loss improved from 0.72051 to 0.71981, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/268-0.7198.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9592 - acc: 0.7138 - val_loss: 0.7198 - val_acc: 0.8036\n",
      "Epoch 269/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9563 - acc: 0.7153\n",
      "Epoch 00269: val_loss did not improve from 0.71981\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9559 - acc: 0.7154 - val_loss: 0.7264 - val_acc: 0.8046\n",
      "Epoch 270/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9546 - acc: 0.7143\n",
      "Epoch 00270: val_loss did not improve from 0.71981\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9546 - acc: 0.7143 - val_loss: 0.7262 - val_acc: 0.8039\n",
      "Epoch 271/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9508 - acc: 0.7143\n",
      "Epoch 00271: val_loss did not improve from 0.71981\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9512 - acc: 0.7141 - val_loss: 0.7294 - val_acc: 0.7987\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9581 - acc: 0.7138\n",
      "Epoch 00272: val_loss did not improve from 0.71981\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9581 - acc: 0.7138 - val_loss: 0.7222 - val_acc: 0.8055\n",
      "Epoch 273/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9471 - acc: 0.7161\n",
      "Epoch 00273: val_loss improved from 0.71981 to 0.71784, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/273-0.7178.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9475 - acc: 0.7161 - val_loss: 0.7178 - val_acc: 0.8076\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9600 - acc: 0.7101\n",
      "Epoch 00274: val_loss did not improve from 0.71784\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9599 - acc: 0.7101 - val_loss: 0.7214 - val_acc: 0.8053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9497 - acc: 0.7145\n",
      "Epoch 00275: val_loss did not improve from 0.71784\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9498 - acc: 0.7145 - val_loss: 0.7261 - val_acc: 0.8039\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9541 - acc: 0.7166\n",
      "Epoch 00276: val_loss did not improve from 0.71784\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9541 - acc: 0.7166 - val_loss: 0.7232 - val_acc: 0.8034\n",
      "Epoch 277/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9493 - acc: 0.7149\n",
      "Epoch 00277: val_loss did not improve from 0.71784\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9493 - acc: 0.7148 - val_loss: 0.7245 - val_acc: 0.8041\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9459 - acc: 0.7168\n",
      "Epoch 00278: val_loss did not improve from 0.71784\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9459 - acc: 0.7168 - val_loss: 0.7190 - val_acc: 0.8060\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9481 - acc: 0.7167\n",
      "Epoch 00279: val_loss improved from 0.71784 to 0.71588, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/279-0.7159.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9481 - acc: 0.7168 - val_loss: 0.7159 - val_acc: 0.8050\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7178\n",
      "Epoch 00280: val_loss did not improve from 0.71588\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9471 - acc: 0.7178 - val_loss: 0.7199 - val_acc: 0.8064\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9498 - acc: 0.7151\n",
      "Epoch 00281: val_loss improved from 0.71588 to 0.71165, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/281-0.7116.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9498 - acc: 0.7151 - val_loss: 0.7116 - val_acc: 0.8067\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9466 - acc: 0.7176\n",
      "Epoch 00282: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.9468 - acc: 0.7175 - val_loss: 0.7161 - val_acc: 0.8053\n",
      "Epoch 283/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9492 - acc: 0.7168\n",
      "Epoch 00283: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9496 - acc: 0.7167 - val_loss: 0.7156 - val_acc: 0.8081\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9513 - acc: 0.7160\n",
      "Epoch 00284: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9512 - acc: 0.7161 - val_loss: 0.7163 - val_acc: 0.8043\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9461 - acc: 0.7183\n",
      "Epoch 00285: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9461 - acc: 0.7183 - val_loss: 0.7121 - val_acc: 0.8085\n",
      "Epoch 286/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9483 - acc: 0.7176\n",
      "Epoch 00286: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9479 - acc: 0.7177 - val_loss: 0.7141 - val_acc: 0.8085\n",
      "Epoch 287/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9463 - acc: 0.7192\n",
      "Epoch 00287: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9464 - acc: 0.7189 - val_loss: 0.7231 - val_acc: 0.8027\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9480 - acc: 0.7159\n",
      "Epoch 00288: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9479 - acc: 0.7159 - val_loss: 0.7189 - val_acc: 0.8048\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9542 - acc: 0.7166\n",
      "Epoch 00289: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9544 - acc: 0.7166 - val_loss: 0.7140 - val_acc: 0.8032\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9546 - acc: 0.7155\n",
      "Epoch 00290: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9546 - acc: 0.7155 - val_loss: 0.7145 - val_acc: 0.8071\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9395 - acc: 0.7170\n",
      "Epoch 00291: val_loss did not improve from 0.71165\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9395 - acc: 0.7170 - val_loss: 0.7121 - val_acc: 0.8064\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9419 - acc: 0.7201\n",
      "Epoch 00292: val_loss improved from 0.71165 to 0.70676, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/292-0.7068.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9421 - acc: 0.7200 - val_loss: 0.7068 - val_acc: 0.8155\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9403 - acc: 0.7196\n",
      "Epoch 00293: val_loss did not improve from 0.70676\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9402 - acc: 0.7196 - val_loss: 0.7159 - val_acc: 0.8050\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9406 - acc: 0.7202\n",
      "Epoch 00294: val_loss did not improve from 0.70676\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9406 - acc: 0.7202 - val_loss: 0.7099 - val_acc: 0.8109\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9457 - acc: 0.7185\n",
      "Epoch 00295: val_loss did not improve from 0.70676\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9457 - acc: 0.7185 - val_loss: 0.7084 - val_acc: 0.8113\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9415 - acc: 0.7190\n",
      "Epoch 00296: val_loss did not improve from 0.70676\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9414 - acc: 0.7190 - val_loss: 0.7141 - val_acc: 0.8085\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9325 - acc: 0.7188\n",
      "Epoch 00297: val_loss improved from 0.70676 to 0.70570, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/297-0.7057.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9325 - acc: 0.7188 - val_loss: 0.7057 - val_acc: 0.8083\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9384 - acc: 0.7192\n",
      "Epoch 00298: val_loss did not improve from 0.70570\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9383 - acc: 0.7192 - val_loss: 0.7114 - val_acc: 0.8116\n",
      "Epoch 299/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9412 - acc: 0.7192\n",
      "Epoch 00299: val_loss did not improve from 0.70570\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9408 - acc: 0.7193 - val_loss: 0.7113 - val_acc: 0.8097\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9339 - acc: 0.7203\n",
      "Epoch 00300: val_loss did not improve from 0.70570\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9339 - acc: 0.7203 - val_loss: 0.7133 - val_acc: 0.8048\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9448 - acc: 0.7173\n",
      "Epoch 00301: val_loss did not improve from 0.70570\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9448 - acc: 0.7173 - val_loss: 0.7133 - val_acc: 0.8062\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9367 - acc: 0.7199\n",
      "Epoch 00302: val_loss did not improve from 0.70570\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9367 - acc: 0.7199 - val_loss: 0.7150 - val_acc: 0.8074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9391 - acc: 0.7193\n",
      "Epoch 00303: val_loss improved from 0.70570 to 0.70554, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/303-0.7055.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9390 - acc: 0.7193 - val_loss: 0.7055 - val_acc: 0.8071\n",
      "Epoch 304/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9389 - acc: 0.7228\n",
      "Epoch 00304: val_loss did not improve from 0.70554\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9388 - acc: 0.7228 - val_loss: 0.7073 - val_acc: 0.8090\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9388 - acc: 0.7218\n",
      "Epoch 00305: val_loss did not improve from 0.70554\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9389 - acc: 0.7218 - val_loss: 0.7074 - val_acc: 0.8055\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9366 - acc: 0.7196\n",
      "Epoch 00306: val_loss did not improve from 0.70554\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9365 - acc: 0.7196 - val_loss: 0.7107 - val_acc: 0.8057\n",
      "Epoch 307/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9435 - acc: 0.7174\n",
      "Epoch 00307: val_loss did not improve from 0.70554\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9435 - acc: 0.7173 - val_loss: 0.7059 - val_acc: 0.8139\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9339 - acc: 0.7217\n",
      "Epoch 00308: val_loss did not improve from 0.70554\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9338 - acc: 0.7217 - val_loss: 0.7106 - val_acc: 0.8067\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9423 - acc: 0.7200\n",
      "Epoch 00309: val_loss did not improve from 0.70554\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.9423 - acc: 0.7200 - val_loss: 0.7059 - val_acc: 0.8104\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9412 - acc: 0.7196\n",
      "Epoch 00310: val_loss improved from 0.70554 to 0.70203, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/310-0.7020.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9411 - acc: 0.7196 - val_loss: 0.7020 - val_acc: 0.8085\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9356 - acc: 0.7199\n",
      "Epoch 00311: val_loss did not improve from 0.70203\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9356 - acc: 0.7200 - val_loss: 0.7069 - val_acc: 0.8055\n",
      "Epoch 312/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9315 - acc: 0.7225\n",
      "Epoch 00312: val_loss did not improve from 0.70203\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9316 - acc: 0.7225 - val_loss: 0.7059 - val_acc: 0.8109\n",
      "Epoch 313/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9302 - acc: 0.7216\n",
      "Epoch 00313: val_loss did not improve from 0.70203\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9297 - acc: 0.7217 - val_loss: 0.7023 - val_acc: 0.8109\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9349 - acc: 0.7232\n",
      "Epoch 00314: val_loss did not improve from 0.70203\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9349 - acc: 0.7232 - val_loss: 0.7033 - val_acc: 0.8090\n",
      "Epoch 315/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9357 - acc: 0.7189\n",
      "Epoch 00315: val_loss did not improve from 0.70203\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9364 - acc: 0.7189 - val_loss: 0.7049 - val_acc: 0.8123\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9330 - acc: 0.7202\n",
      "Epoch 00316: val_loss improved from 0.70203 to 0.70126, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/316-0.7013.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9330 - acc: 0.7202 - val_loss: 0.7013 - val_acc: 0.8102\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9282 - acc: 0.7220\n",
      "Epoch 00317: val_loss did not improve from 0.70126\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9281 - acc: 0.7220 - val_loss: 0.7068 - val_acc: 0.8060\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9310 - acc: 0.7218\n",
      "Epoch 00318: val_loss improved from 0.70126 to 0.69534, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/318-0.6953.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9310 - acc: 0.7218 - val_loss: 0.6953 - val_acc: 0.8120\n",
      "Epoch 319/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9327 - acc: 0.7210\n",
      "Epoch 00319: val_loss did not improve from 0.69534\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9323 - acc: 0.7210 - val_loss: 0.7060 - val_acc: 0.8106\n",
      "Epoch 320/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9277 - acc: 0.7238\n",
      "Epoch 00320: val_loss did not improve from 0.69534\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9274 - acc: 0.7239 - val_loss: 0.7072 - val_acc: 0.8050\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9303 - acc: 0.7210\n",
      "Epoch 00321: val_loss did not improve from 0.69534\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9302 - acc: 0.7210 - val_loss: 0.6967 - val_acc: 0.8116\n",
      "Epoch 322/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9331 - acc: 0.7206\n",
      "Epoch 00322: val_loss did not improve from 0.69534\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9327 - acc: 0.7207 - val_loss: 0.6958 - val_acc: 0.8120\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9368 - acc: 0.7209\n",
      "Epoch 00323: val_loss did not improve from 0.69534\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.9368 - acc: 0.7209 - val_loss: 0.7005 - val_acc: 0.8137\n",
      "Epoch 324/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9286 - acc: 0.7226\n",
      "Epoch 00324: val_loss improved from 0.69534 to 0.69512, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/324-0.6951.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9288 - acc: 0.7227 - val_loss: 0.6951 - val_acc: 0.8099\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9291 - acc: 0.7211\n",
      "Epoch 00325: val_loss did not improve from 0.69512\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9291 - acc: 0.7212 - val_loss: 0.7037 - val_acc: 0.8111\n",
      "Epoch 326/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9287 - acc: 0.7216\n",
      "Epoch 00326: val_loss did not improve from 0.69512\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9289 - acc: 0.7214 - val_loss: 0.7013 - val_acc: 0.8104\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9308 - acc: 0.7230\n",
      "Epoch 00327: val_loss improved from 0.69512 to 0.69118, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/327-0.6912.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9308 - acc: 0.7230 - val_loss: 0.6912 - val_acc: 0.8130\n",
      "Epoch 328/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9282 - acc: 0.7231\n",
      "Epoch 00328: val_loss did not improve from 0.69118\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9287 - acc: 0.7229 - val_loss: 0.6986 - val_acc: 0.8113\n",
      "Epoch 329/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9300 - acc: 0.7224\n",
      "Epoch 00329: val_loss did not improve from 0.69118\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9301 - acc: 0.7225 - val_loss: 0.6955 - val_acc: 0.8132\n",
      "Epoch 330/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9411 - acc: 0.7188\n",
      "Epoch 00330: val_loss did not improve from 0.69118\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9409 - acc: 0.7188 - val_loss: 0.6987 - val_acc: 0.8109\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.7252\n",
      "Epoch 00331: val_loss did not improve from 0.69118\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9240 - acc: 0.7252 - val_loss: 0.7034 - val_acc: 0.8097\n",
      "Epoch 332/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9205 - acc: 0.7248\n",
      "Epoch 00332: val_loss did not improve from 0.69118\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9204 - acc: 0.7248 - val_loss: 0.6950 - val_acc: 0.8141\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9225 - acc: 0.7250\n",
      "Epoch 00333: val_loss did not improve from 0.69118\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.9226 - acc: 0.7249 - val_loss: 0.6933 - val_acc: 0.8109\n",
      "Epoch 334/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9190 - acc: 0.7247\n",
      "Epoch 00334: val_loss improved from 0.69118 to 0.68648, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/334-0.6865.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9186 - acc: 0.7249 - val_loss: 0.6865 - val_acc: 0.8137\n",
      "Epoch 335/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9278 - acc: 0.7255\n",
      "Epoch 00335: val_loss did not improve from 0.68648\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9283 - acc: 0.7252 - val_loss: 0.6958 - val_acc: 0.8125\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9185 - acc: 0.7265\n",
      "Epoch 00336: val_loss did not improve from 0.68648\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9185 - acc: 0.7265 - val_loss: 0.6946 - val_acc: 0.8148\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9277 - acc: 0.7228\n",
      "Epoch 00337: val_loss did not improve from 0.68648\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9277 - acc: 0.7228 - val_loss: 0.6938 - val_acc: 0.8102\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9196 - acc: 0.7267\n",
      "Epoch 00338: val_loss did not improve from 0.68648\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9197 - acc: 0.7267 - val_loss: 0.6992 - val_acc: 0.8078\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9258 - acc: 0.7228\n",
      "Epoch 00339: val_loss improved from 0.68648 to 0.68646, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/339-0.6865.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9257 - acc: 0.7228 - val_loss: 0.6865 - val_acc: 0.8155\n",
      "Epoch 340/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9260 - acc: 0.7238\n",
      "Epoch 00340: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9262 - acc: 0.7238 - val_loss: 0.6993 - val_acc: 0.8069\n",
      "Epoch 341/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9250 - acc: 0.7241\n",
      "Epoch 00341: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9247 - acc: 0.7242 - val_loss: 0.6895 - val_acc: 0.8157\n",
      "Epoch 342/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9223 - acc: 0.7239\n",
      "Epoch 00342: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9221 - acc: 0.7238 - val_loss: 0.6921 - val_acc: 0.8167\n",
      "Epoch 343/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9210 - acc: 0.7271\n",
      "Epoch 00343: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.9210 - acc: 0.7271 - val_loss: 0.6906 - val_acc: 0.8120\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9209 - acc: 0.7259\n",
      "Epoch 00344: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9208 - acc: 0.7259 - val_loss: 0.6953 - val_acc: 0.8099\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9222 - acc: 0.7262\n",
      "Epoch 00345: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9222 - acc: 0.7262 - val_loss: 0.6901 - val_acc: 0.8155\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9214 - acc: 0.7244\n",
      "Epoch 00346: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9213 - acc: 0.7244 - val_loss: 0.6976 - val_acc: 0.8139\n",
      "Epoch 347/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9201 - acc: 0.7265\n",
      "Epoch 00347: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9200 - acc: 0.7266 - val_loss: 0.6915 - val_acc: 0.8150\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9214 - acc: 0.7289\n",
      "Epoch 00348: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.9215 - acc: 0.7288 - val_loss: 0.6959 - val_acc: 0.8132\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9137 - acc: 0.7291\n",
      "Epoch 00349: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9136 - acc: 0.7291 - val_loss: 0.7000 - val_acc: 0.8090\n",
      "Epoch 350/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9235 - acc: 0.7273\n",
      "Epoch 00350: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9236 - acc: 0.7272 - val_loss: 0.6896 - val_acc: 0.8164\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9176 - acc: 0.7262\n",
      "Epoch 00351: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.9175 - acc: 0.7263 - val_loss: 0.6881 - val_acc: 0.8134\n",
      "Epoch 352/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9214 - acc: 0.7251\n",
      "Epoch 00352: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.9213 - acc: 0.7250 - val_loss: 0.6871 - val_acc: 0.8155\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9192 - acc: 0.7274\n",
      "Epoch 00353: val_loss did not improve from 0.68646\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.9192 - acc: 0.7275 - val_loss: 0.7020 - val_acc: 0.8081\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9172 - acc: 0.7288\n",
      "Epoch 00354: val_loss improved from 0.68646 to 0.68206, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/354-0.6821.hdf5\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.9172 - acc: 0.7288 - val_loss: 0.6821 - val_acc: 0.8162\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9193 - acc: 0.7273\n",
      "Epoch 00355: val_loss did not improve from 0.68206\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.9193 - acc: 0.7273 - val_loss: 0.6869 - val_acc: 0.8195\n",
      "Epoch 356/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9162 - acc: 0.7257\n",
      "Epoch 00356: val_loss did not improve from 0.68206\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9161 - acc: 0.7257 - val_loss: 0.6846 - val_acc: 0.8185\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9173 - acc: 0.7265\n",
      "Epoch 00357: val_loss improved from 0.68206 to 0.68100, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/357-0.6810.hdf5\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.9173 - acc: 0.7265 - val_loss: 0.6810 - val_acc: 0.8185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9094 - acc: 0.7295\n",
      "Epoch 00358: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.9095 - acc: 0.7295 - val_loss: 0.6906 - val_acc: 0.8153\n",
      "Epoch 359/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9191 - acc: 0.7253\n",
      "Epoch 00359: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.9190 - acc: 0.7252 - val_loss: 0.6898 - val_acc: 0.8125\n",
      "Epoch 360/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9249 - acc: 0.7252\n",
      "Epoch 00360: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.9248 - acc: 0.7252 - val_loss: 0.6870 - val_acc: 0.8155\n",
      "Epoch 361/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9171 - acc: 0.7251\n",
      "Epoch 00361: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.9169 - acc: 0.7251 - val_loss: 0.6889 - val_acc: 0.8169\n",
      "Epoch 362/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9147 - acc: 0.7266\n",
      "Epoch 00362: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9146 - acc: 0.7265 - val_loss: 0.6869 - val_acc: 0.8150\n",
      "Epoch 363/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9135 - acc: 0.7244\n",
      "Epoch 00363: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.9139 - acc: 0.7242 - val_loss: 0.6893 - val_acc: 0.8113\n",
      "Epoch 364/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9137 - acc: 0.7262\n",
      "Epoch 00364: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.9131 - acc: 0.7264 - val_loss: 0.6830 - val_acc: 0.8169\n",
      "Epoch 365/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9083 - acc: 0.7298\n",
      "Epoch 00365: val_loss did not improve from 0.68100\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.9085 - acc: 0.7297 - val_loss: 0.6877 - val_acc: 0.8160\n",
      "Epoch 366/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9127 - acc: 0.7259\n",
      "Epoch 00366: val_loss improved from 0.68100 to 0.67699, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/366-0.6770.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.9124 - acc: 0.7260 - val_loss: 0.6770 - val_acc: 0.8202\n",
      "Epoch 367/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9137 - acc: 0.7286\n",
      "Epoch 00367: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9136 - acc: 0.7286 - val_loss: 0.6879 - val_acc: 0.8169\n",
      "Epoch 368/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9146 - acc: 0.7270\n",
      "Epoch 00368: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9141 - acc: 0.7271 - val_loss: 0.6796 - val_acc: 0.8155\n",
      "Epoch 369/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9102 - acc: 0.7304\n",
      "Epoch 00369: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.9099 - acc: 0.7305 - val_loss: 0.6886 - val_acc: 0.8132\n",
      "Epoch 370/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9144 - acc: 0.7285\n",
      "Epoch 00370: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.9143 - acc: 0.7286 - val_loss: 0.6872 - val_acc: 0.8167\n",
      "Epoch 371/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9095 - acc: 0.7278\n",
      "Epoch 00371: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.9093 - acc: 0.7279 - val_loss: 0.6876 - val_acc: 0.8130\n",
      "Epoch 372/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9133 - acc: 0.7284\n",
      "Epoch 00372: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9134 - acc: 0.7284 - val_loss: 0.6871 - val_acc: 0.8162\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9115 - acc: 0.7283\n",
      "Epoch 00373: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.9115 - acc: 0.7282 - val_loss: 0.6834 - val_acc: 0.8150\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9086 - acc: 0.7283\n",
      "Epoch 00374: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.9090 - acc: 0.7283 - val_loss: 0.6838 - val_acc: 0.8164\n",
      "Epoch 375/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9100 - acc: 0.7288\n",
      "Epoch 00375: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.9101 - acc: 0.7289 - val_loss: 0.6774 - val_acc: 0.8164\n",
      "Epoch 376/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9110 - acc: 0.7280\n",
      "Epoch 00376: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.9109 - acc: 0.7280 - val_loss: 0.6792 - val_acc: 0.8169\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9089 - acc: 0.7304\n",
      "Epoch 00377: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.9089 - acc: 0.7304 - val_loss: 0.6826 - val_acc: 0.8174\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9148 - acc: 0.7270\n",
      "Epoch 00378: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.9147 - acc: 0.7270 - val_loss: 0.6858 - val_acc: 0.8153\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9097 - acc: 0.7294\n",
      "Epoch 00379: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.9096 - acc: 0.7294 - val_loss: 0.6805 - val_acc: 0.8153\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9115 - acc: 0.7300\n",
      "Epoch 00380: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.9116 - acc: 0.7300 - val_loss: 0.6776 - val_acc: 0.8202\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9122 - acc: 0.7294\n",
      "Epoch 00381: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.9121 - acc: 0.7294 - val_loss: 0.6824 - val_acc: 0.8167\n",
      "Epoch 382/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9104 - acc: 0.7291\n",
      "Epoch 00382: val_loss did not improve from 0.67699\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.9104 - acc: 0.7292 - val_loss: 0.6834 - val_acc: 0.8143\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9042 - acc: 0.7306\n",
      "Epoch 00383: val_loss improved from 0.67699 to 0.67138, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/383-0.6714.hdf5\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.9042 - acc: 0.7306 - val_loss: 0.6714 - val_acc: 0.8227\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9046 - acc: 0.7295\n",
      "Epoch 00384: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.9045 - acc: 0.7295 - val_loss: 0.6763 - val_acc: 0.8183\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9099 - acc: 0.7276\n",
      "Epoch 00385: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.9098 - acc: 0.7276 - val_loss: 0.6737 - val_acc: 0.8188\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9073 - acc: 0.7298\n",
      "Epoch 00386: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.9073 - acc: 0.7298 - val_loss: 0.6753 - val_acc: 0.8230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9098 - acc: 0.7292\n",
      "Epoch 00387: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.9099 - acc: 0.7292 - val_loss: 0.6782 - val_acc: 0.8160\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8997 - acc: 0.7305\n",
      "Epoch 00388: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.8996 - acc: 0.7305 - val_loss: 0.6780 - val_acc: 0.8213\n",
      "Epoch 389/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9083 - acc: 0.7280\n",
      "Epoch 00389: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.9084 - acc: 0.7278 - val_loss: 0.6794 - val_acc: 0.8148\n",
      "Epoch 390/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9069 - acc: 0.7295\n",
      "Epoch 00390: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.9071 - acc: 0.7296 - val_loss: 0.6796 - val_acc: 0.8183\n",
      "Epoch 391/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9084 - acc: 0.7283\n",
      "Epoch 00391: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.9085 - acc: 0.7283 - val_loss: 0.6814 - val_acc: 0.8178\n",
      "Epoch 392/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9016 - acc: 0.7317\n",
      "Epoch 00392: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.9019 - acc: 0.7317 - val_loss: 0.6728 - val_acc: 0.8202\n",
      "Epoch 393/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8998 - acc: 0.7323\n",
      "Epoch 00393: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8999 - acc: 0.7323 - val_loss: 0.6796 - val_acc: 0.8183\n",
      "Epoch 394/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9065 - acc: 0.7307\n",
      "Epoch 00394: val_loss did not improve from 0.67138\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.9061 - acc: 0.7308 - val_loss: 0.6790 - val_acc: 0.8143\n",
      "Epoch 395/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8952 - acc: 0.7318\n",
      "Epoch 00395: val_loss improved from 0.67138 to 0.67026, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/395-0.6703.hdf5\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8951 - acc: 0.7319 - val_loss: 0.6703 - val_acc: 0.8190\n",
      "Epoch 396/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9026 - acc: 0.7324\n",
      "Epoch 00396: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.9029 - acc: 0.7322 - val_loss: 0.6791 - val_acc: 0.8171\n",
      "Epoch 397/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9048 - acc: 0.7302\n",
      "Epoch 00397: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.9050 - acc: 0.7303 - val_loss: 0.6758 - val_acc: 0.8202\n",
      "Epoch 398/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9007 - acc: 0.7318\n",
      "Epoch 00398: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9003 - acc: 0.7319 - val_loss: 0.6735 - val_acc: 0.8204\n",
      "Epoch 399/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9013 - acc: 0.7337\n",
      "Epoch 00399: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.9012 - acc: 0.7338 - val_loss: 0.6758 - val_acc: 0.8197\n",
      "Epoch 400/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9001 - acc: 0.7317\n",
      "Epoch 00400: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.9002 - acc: 0.7317 - val_loss: 0.6765 - val_acc: 0.8225\n",
      "Epoch 401/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9027 - acc: 0.7305\n",
      "Epoch 00401: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.9026 - acc: 0.7305 - val_loss: 0.6786 - val_acc: 0.8164\n",
      "Epoch 402/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9000 - acc: 0.7297\n",
      "Epoch 00402: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.8997 - acc: 0.7297 - val_loss: 0.6762 - val_acc: 0.8190\n",
      "Epoch 403/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8985 - acc: 0.7317\n",
      "Epoch 00403: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8982 - acc: 0.7317 - val_loss: 0.6778 - val_acc: 0.8150\n",
      "Epoch 404/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9042 - acc: 0.7322\n",
      "Epoch 00404: val_loss did not improve from 0.67026\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.9044 - acc: 0.7322 - val_loss: 0.6754 - val_acc: 0.8195\n",
      "Epoch 405/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8965 - acc: 0.7312\n",
      "Epoch 00405: val_loss improved from 0.67026 to 0.66758, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/405-0.6676.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.8959 - acc: 0.7313 - val_loss: 0.6676 - val_acc: 0.8211\n",
      "Epoch 406/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8995 - acc: 0.7321\n",
      "Epoch 00406: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.8995 - acc: 0.7322 - val_loss: 0.6794 - val_acc: 0.8162\n",
      "Epoch 407/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9014 - acc: 0.7330\n",
      "Epoch 00407: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.9012 - acc: 0.7331 - val_loss: 0.6740 - val_acc: 0.8181\n",
      "Epoch 408/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8942 - acc: 0.7328\n",
      "Epoch 00408: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.8943 - acc: 0.7328 - val_loss: 0.6719 - val_acc: 0.8192\n",
      "Epoch 409/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8932 - acc: 0.7331\n",
      "Epoch 00409: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8931 - acc: 0.7331 - val_loss: 0.6726 - val_acc: 0.8232\n",
      "Epoch 410/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9030 - acc: 0.7329\n",
      "Epoch 00410: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.9029 - acc: 0.7328 - val_loss: 0.6744 - val_acc: 0.8197\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8971 - acc: 0.7325\n",
      "Epoch 00411: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8970 - acc: 0.7325 - val_loss: 0.6701 - val_acc: 0.8209\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8971 - acc: 0.7296\n",
      "Epoch 00412: val_loss did not improve from 0.66758\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8971 - acc: 0.7296 - val_loss: 0.6711 - val_acc: 0.8199\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8948 - acc: 0.7340\n",
      "Epoch 00413: val_loss improved from 0.66758 to 0.66687, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/413-0.6669.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8948 - acc: 0.7340 - val_loss: 0.6669 - val_acc: 0.8223\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8968 - acc: 0.7323\n",
      "Epoch 00414: val_loss improved from 0.66687 to 0.66655, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/414-0.6666.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8968 - acc: 0.7322 - val_loss: 0.6666 - val_acc: 0.8223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 415/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8970 - acc: 0.7313\n",
      "Epoch 00415: val_loss did not improve from 0.66655\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8965 - acc: 0.7314 - val_loss: 0.6724 - val_acc: 0.8206\n",
      "Epoch 416/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8985 - acc: 0.7335\n",
      "Epoch 00416: val_loss did not improve from 0.66655\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8982 - acc: 0.7336 - val_loss: 0.6689 - val_acc: 0.8225\n",
      "Epoch 417/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8937 - acc: 0.7354\n",
      "Epoch 00417: val_loss did not improve from 0.66655\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8936 - acc: 0.7354 - val_loss: 0.6668 - val_acc: 0.8220\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8942 - acc: 0.7340\n",
      "Epoch 00418: val_loss did not improve from 0.66655\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8941 - acc: 0.7341 - val_loss: 0.6712 - val_acc: 0.8213\n",
      "Epoch 419/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8994 - acc: 0.7336\n",
      "Epoch 00419: val_loss improved from 0.66655 to 0.66650, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/419-0.6665.hdf5\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8993 - acc: 0.7335 - val_loss: 0.6665 - val_acc: 0.8244\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8967 - acc: 0.7332\n",
      "Epoch 00420: val_loss did not improve from 0.66650\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8968 - acc: 0.7332 - val_loss: 0.6740 - val_acc: 0.8192\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8913 - acc: 0.7345\n",
      "Epoch 00421: val_loss improved from 0.66650 to 0.66511, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/421-0.6651.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8912 - acc: 0.7345 - val_loss: 0.6651 - val_acc: 0.8213\n",
      "Epoch 422/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8986 - acc: 0.7301\n",
      "Epoch 00422: val_loss did not improve from 0.66511\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.8990 - acc: 0.7300 - val_loss: 0.6699 - val_acc: 0.8248\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8933 - acc: 0.7320\n",
      "Epoch 00423: val_loss improved from 0.66511 to 0.66308, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/423-0.6631.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8933 - acc: 0.7320 - val_loss: 0.6631 - val_acc: 0.8220\n",
      "Epoch 424/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8924 - acc: 0.7334\n",
      "Epoch 00424: val_loss did not improve from 0.66308\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8924 - acc: 0.7335 - val_loss: 0.6675 - val_acc: 0.8220\n",
      "Epoch 425/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8949 - acc: 0.7325\n",
      "Epoch 00425: val_loss did not improve from 0.66308\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.8948 - acc: 0.7325 - val_loss: 0.6679 - val_acc: 0.8223\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8857 - acc: 0.7329\n",
      "Epoch 00426: val_loss improved from 0.66308 to 0.66218, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/426-0.6622.hdf5\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8856 - acc: 0.7329 - val_loss: 0.6622 - val_acc: 0.8211\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8868 - acc: 0.7348\n",
      "Epoch 00427: val_loss did not improve from 0.66218\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8867 - acc: 0.7349 - val_loss: 0.6626 - val_acc: 0.8216\n",
      "Epoch 428/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8888 - acc: 0.7332\n",
      "Epoch 00428: val_loss did not improve from 0.66218\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.8884 - acc: 0.7332 - val_loss: 0.6703 - val_acc: 0.8143\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8879 - acc: 0.7328\n",
      "Epoch 00429: val_loss improved from 0.66218 to 0.66164, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/429-0.6616.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.8879 - acc: 0.7328 - val_loss: 0.6616 - val_acc: 0.8237\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8925 - acc: 0.7314\n",
      "Epoch 00430: val_loss did not improve from 0.66164\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.8925 - acc: 0.7314 - val_loss: 0.6665 - val_acc: 0.8181\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8904 - acc: 0.7348\n",
      "Epoch 00431: val_loss did not improve from 0.66164\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8904 - acc: 0.7347 - val_loss: 0.6652 - val_acc: 0.8223\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8921 - acc: 0.7355\n",
      "Epoch 00432: val_loss did not improve from 0.66164\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8922 - acc: 0.7355 - val_loss: 0.6662 - val_acc: 0.8225\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8960 - acc: 0.7340\n",
      "Epoch 00433: val_loss did not improve from 0.66164\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8960 - acc: 0.7340 - val_loss: 0.6671 - val_acc: 0.8188\n",
      "Epoch 434/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8904 - acc: 0.7369\n",
      "Epoch 00434: val_loss did not improve from 0.66164\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.8902 - acc: 0.7369 - val_loss: 0.6699 - val_acc: 0.8160\n",
      "Epoch 435/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8950 - acc: 0.7335\n",
      "Epoch 00435: val_loss did not improve from 0.66164\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8954 - acc: 0.7333 - val_loss: 0.6671 - val_acc: 0.8190\n",
      "Epoch 436/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8892 - acc: 0.7326\n",
      "Epoch 00436: val_loss improved from 0.66164 to 0.66156, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/436-0.6616.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8902 - acc: 0.7325 - val_loss: 0.6616 - val_acc: 0.8223\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8923 - acc: 0.7330\n",
      "Epoch 00437: val_loss improved from 0.66156 to 0.66000, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/437-0.6600.hdf5\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8923 - acc: 0.7330 - val_loss: 0.6600 - val_acc: 0.8262\n",
      "Epoch 438/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8938 - acc: 0.7347\n",
      "Epoch 00438: val_loss did not improve from 0.66000\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8938 - acc: 0.7347 - val_loss: 0.6686 - val_acc: 0.8225\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8935 - acc: 0.7358\n",
      "Epoch 00439: val_loss did not improve from 0.66000\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8935 - acc: 0.7358 - val_loss: 0.6682 - val_acc: 0.8181\n",
      "Epoch 440/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8921 - acc: 0.7350\n",
      "Epoch 00440: val_loss did not improve from 0.66000\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8924 - acc: 0.7350 - val_loss: 0.6689 - val_acc: 0.8199\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8889 - acc: 0.7360\n",
      "Epoch 00441: val_loss did not improve from 0.66000\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8888 - acc: 0.7360 - val_loss: 0.6648 - val_acc: 0.8174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8857 - acc: 0.7350\n",
      "Epoch 00442: val_loss did not improve from 0.66000\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.8857 - acc: 0.7350 - val_loss: 0.6602 - val_acc: 0.8223\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8851 - acc: 0.7364\n",
      "Epoch 00443: val_loss did not improve from 0.66000\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.8851 - acc: 0.7364 - val_loss: 0.6685 - val_acc: 0.8241\n",
      "Epoch 444/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8950 - acc: 0.7354\n",
      "Epoch 00444: val_loss improved from 0.66000 to 0.65975, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/444-0.6598.hdf5\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8950 - acc: 0.7353 - val_loss: 0.6598 - val_acc: 0.8251\n",
      "Epoch 445/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8868 - acc: 0.7364\n",
      "Epoch 00445: val_loss improved from 0.65975 to 0.65822, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/445-0.6582.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.8864 - acc: 0.7365 - val_loss: 0.6582 - val_acc: 0.8253\n",
      "Epoch 446/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8856 - acc: 0.7365\n",
      "Epoch 00446: val_loss did not improve from 0.65822\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8853 - acc: 0.7366 - val_loss: 0.6593 - val_acc: 0.8227\n",
      "Epoch 447/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8831 - acc: 0.7379\n",
      "Epoch 00447: val_loss improved from 0.65822 to 0.65654, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/447-0.6565.hdf5\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.8831 - acc: 0.7378 - val_loss: 0.6565 - val_acc: 0.8234\n",
      "Epoch 448/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8855 - acc: 0.7356\n",
      "Epoch 00448: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.8856 - acc: 0.7356 - val_loss: 0.6666 - val_acc: 0.8223\n",
      "Epoch 449/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8830 - acc: 0.7374\n",
      "Epoch 00449: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8830 - acc: 0.7374 - val_loss: 0.6607 - val_acc: 0.8232\n",
      "Epoch 450/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8820 - acc: 0.7378\n",
      "Epoch 00450: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.8817 - acc: 0.7378 - val_loss: 0.6573 - val_acc: 0.8267\n",
      "Epoch 451/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8879 - acc: 0.7357\n",
      "Epoch 00451: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.8880 - acc: 0.7357 - val_loss: 0.6598 - val_acc: 0.8213\n",
      "Epoch 452/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8861 - acc: 0.7373\n",
      "Epoch 00452: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.8865 - acc: 0.7372 - val_loss: 0.6605 - val_acc: 0.8227\n",
      "Epoch 453/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8824 - acc: 0.7385\n",
      "Epoch 00453: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.8822 - acc: 0.7385 - val_loss: 0.6587 - val_acc: 0.8253\n",
      "Epoch 454/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8810 - acc: 0.7377\n",
      "Epoch 00454: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.8810 - acc: 0.7376 - val_loss: 0.6579 - val_acc: 0.8272\n",
      "Epoch 455/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8837 - acc: 0.7348\n",
      "Epoch 00455: val_loss did not improve from 0.65654\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.8835 - acc: 0.7347 - val_loss: 0.6577 - val_acc: 0.8234\n",
      "Epoch 456/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8884 - acc: 0.7348\n",
      "Epoch 00456: val_loss improved from 0.65654 to 0.65326, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/456-0.6533.hdf5\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.8883 - acc: 0.7349 - val_loss: 0.6533 - val_acc: 0.8234\n",
      "Epoch 457/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8815 - acc: 0.7393\n",
      "Epoch 00457: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.8815 - acc: 0.7392 - val_loss: 0.6611 - val_acc: 0.8232\n",
      "Epoch 458/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.7354\n",
      "Epoch 00458: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.8849 - acc: 0.7354 - val_loss: 0.6638 - val_acc: 0.8230\n",
      "Epoch 459/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8840 - acc: 0.7356\n",
      "Epoch 00459: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.8839 - acc: 0.7356 - val_loss: 0.6585 - val_acc: 0.8239\n",
      "Epoch 460/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.7354\n",
      "Epoch 00460: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.8809 - acc: 0.7355 - val_loss: 0.6578 - val_acc: 0.8241\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8833 - acc: 0.7367\n",
      "Epoch 00461: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.8833 - acc: 0.7367 - val_loss: 0.6606 - val_acc: 0.8239\n",
      "Epoch 462/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8881 - acc: 0.7350\n",
      "Epoch 00462: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8883 - acc: 0.7350 - val_loss: 0.6631 - val_acc: 0.8244\n",
      "Epoch 463/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8834 - acc: 0.7368\n",
      "Epoch 00463: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8838 - acc: 0.7367 - val_loss: 0.6614 - val_acc: 0.8230\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8818 - acc: 0.7343\n",
      "Epoch 00464: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8818 - acc: 0.7343 - val_loss: 0.6614 - val_acc: 0.8244\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8894 - acc: 0.7346\n",
      "Epoch 00465: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8893 - acc: 0.7347 - val_loss: 0.6680 - val_acc: 0.8174\n",
      "Epoch 466/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8809 - acc: 0.7372\n",
      "Epoch 00466: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8809 - acc: 0.7371 - val_loss: 0.6655 - val_acc: 0.8176\n",
      "Epoch 467/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8735 - acc: 0.7383\n",
      "Epoch 00467: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.8737 - acc: 0.7383 - val_loss: 0.6536 - val_acc: 0.8262\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8790 - acc: 0.7399\n",
      "Epoch 00468: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.8790 - acc: 0.7399 - val_loss: 0.6548 - val_acc: 0.8223\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8794 - acc: 0.7383\n",
      "Epoch 00469: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8793 - acc: 0.7383 - val_loss: 0.6611 - val_acc: 0.8227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 470/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8793 - acc: 0.7385\n",
      "Epoch 00470: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8792 - acc: 0.7385 - val_loss: 0.6548 - val_acc: 0.8260\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8842 - acc: 0.7366\n",
      "Epoch 00471: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8841 - acc: 0.7366 - val_loss: 0.6649 - val_acc: 0.8244\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8781 - acc: 0.7362\n",
      "Epoch 00472: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8780 - acc: 0.7363 - val_loss: 0.6554 - val_acc: 0.8276\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8819 - acc: 0.7345\n",
      "Epoch 00473: val_loss did not improve from 0.65326\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8818 - acc: 0.7345 - val_loss: 0.6555 - val_acc: 0.8258\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8781 - acc: 0.7394\n",
      "Epoch 00474: val_loss improved from 0.65326 to 0.65107, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/474-0.6511.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8780 - acc: 0.7394 - val_loss: 0.6511 - val_acc: 0.8274\n",
      "Epoch 475/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8804 - acc: 0.7388\n",
      "Epoch 00475: val_loss did not improve from 0.65107\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8802 - acc: 0.7389 - val_loss: 0.6593 - val_acc: 0.8255\n",
      "Epoch 476/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8826 - acc: 0.7377\n",
      "Epoch 00476: val_loss did not improve from 0.65107\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8822 - acc: 0.7378 - val_loss: 0.6555 - val_acc: 0.8258\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8846 - acc: 0.7387\n",
      "Epoch 00477: val_loss did not improve from 0.65107\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8845 - acc: 0.7387 - val_loss: 0.6525 - val_acc: 0.8258\n",
      "Epoch 478/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8762 - acc: 0.7404\n",
      "Epoch 00478: val_loss did not improve from 0.65107\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.8762 - acc: 0.7405 - val_loss: 0.6517 - val_acc: 0.8244\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8765 - acc: 0.7374\n",
      "Epoch 00479: val_loss improved from 0.65107 to 0.65087, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/479-0.6509.hdf5\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.8765 - acc: 0.7374 - val_loss: 0.6509 - val_acc: 0.8281\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8797 - acc: 0.7378\n",
      "Epoch 00480: val_loss improved from 0.65087 to 0.64784, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/480-0.6478.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8797 - acc: 0.7378 - val_loss: 0.6478 - val_acc: 0.8288\n",
      "Epoch 481/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8786 - acc: 0.7377\n",
      "Epoch 00481: val_loss did not improve from 0.64784\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8781 - acc: 0.7378 - val_loss: 0.6502 - val_acc: 0.8274\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8814 - acc: 0.7380\n",
      "Epoch 00482: val_loss did not improve from 0.64784\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8815 - acc: 0.7380 - val_loss: 0.6581 - val_acc: 0.8241\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8675 - acc: 0.7409\n",
      "Epoch 00483: val_loss did not improve from 0.64784\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8675 - acc: 0.7409 - val_loss: 0.6491 - val_acc: 0.8297\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8704 - acc: 0.7390\n",
      "Epoch 00484: val_loss did not improve from 0.64784\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8705 - acc: 0.7389 - val_loss: 0.6511 - val_acc: 0.8260\n",
      "Epoch 485/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8742 - acc: 0.7393\n",
      "Epoch 00485: val_loss improved from 0.64784 to 0.64534, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_3_conv_checkpoint/485-0.6453.hdf5\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8740 - acc: 0.7393 - val_loss: 0.6453 - val_acc: 0.8295\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8762 - acc: 0.7371\n",
      "Epoch 00486: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8761 - acc: 0.7371 - val_loss: 0.6546 - val_acc: 0.8253\n",
      "Epoch 487/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8756 - acc: 0.7368\n",
      "Epoch 00487: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8753 - acc: 0.7368 - val_loss: 0.6545 - val_acc: 0.8281\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8767 - acc: 0.7376\n",
      "Epoch 00488: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8766 - acc: 0.7376 - val_loss: 0.6600 - val_acc: 0.8232\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8725 - acc: 0.7410\n",
      "Epoch 00489: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.8725 - acc: 0.7410 - val_loss: 0.6532 - val_acc: 0.8248\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8703 - acc: 0.7405\n",
      "Epoch 00490: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8704 - acc: 0.7406 - val_loss: 0.6475 - val_acc: 0.8293\n",
      "Epoch 491/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8755 - acc: 0.7368\n",
      "Epoch 00491: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8752 - acc: 0.7367 - val_loss: 0.6477 - val_acc: 0.8272\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8793 - acc: 0.7398\n",
      "Epoch 00492: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.8793 - acc: 0.7398 - val_loss: 0.6539 - val_acc: 0.8241\n",
      "Epoch 493/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8754 - acc: 0.7411\n",
      "Epoch 00493: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.8753 - acc: 0.7412 - val_loss: 0.6463 - val_acc: 0.8258\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8745 - acc: 0.7380\n",
      "Epoch 00494: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8744 - acc: 0.7381 - val_loss: 0.6528 - val_acc: 0.8241\n",
      "Epoch 495/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8754 - acc: 0.7376\n",
      "Epoch 00495: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.8755 - acc: 0.7376 - val_loss: 0.6602 - val_acc: 0.8230\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8709 - acc: 0.7414\n",
      "Epoch 00496: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.8709 - acc: 0.7413 - val_loss: 0.6502 - val_acc: 0.8255\n",
      "Epoch 497/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8761 - acc: 0.7375\n",
      "Epoch 00497: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.8758 - acc: 0.7376 - val_loss: 0.6510 - val_acc: 0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8733 - acc: 0.7407\n",
      "Epoch 00498: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.8732 - acc: 0.7407 - val_loss: 0.6513 - val_acc: 0.8265\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8724 - acc: 0.7396\n",
      "Epoch 00499: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.8723 - acc: 0.7396 - val_loss: 0.6509 - val_acc: 0.8258\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8760 - acc: 0.7385\n",
      "Epoch 00500: val_loss did not improve from 0.64534\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.8760 - acc: 0.7385 - val_loss: 0.6479 - val_acc: 0.8255\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 383us/sample - loss: 0.7135 - acc: 0.7940\n",
      "Loss: 0.7134613753355429 Accuracy: 0.79397714\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6871 - acc: 0.1213\n",
      "Epoch 00001: val_loss improved from inf to 2.53735, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/001-2.5373.hdf5\n",
      "36805/36805 [==============================] - 31s 853us/sample - loss: 2.6871 - acc: 0.1213 - val_loss: 2.5373 - val_acc: 0.2427\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.3904 - acc: 0.2281\n",
      "Epoch 00002: val_loss improved from 2.53735 to 2.14867, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/002-2.1487.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 2.3900 - acc: 0.2280 - val_loss: 2.1487 - val_acc: 0.3282\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1737 - acc: 0.2813\n",
      "Epoch 00003: val_loss improved from 2.14867 to 1.96702, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/003-1.9670.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 2.1737 - acc: 0.2813 - val_loss: 1.9670 - val_acc: 0.3918\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0536 - acc: 0.3170\n",
      "Epoch 00004: val_loss improved from 1.96702 to 1.85768, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/004-1.8577.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 2.0538 - acc: 0.3170 - val_loss: 1.8577 - val_acc: 0.4188\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9651 - acc: 0.3442\n",
      "Epoch 00005: val_loss improved from 1.85768 to 1.76638, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/005-1.7664.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.9650 - acc: 0.3442 - val_loss: 1.7664 - val_acc: 0.4524\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8953 - acc: 0.3662\n",
      "Epoch 00006: val_loss improved from 1.76638 to 1.70721, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/006-1.7072.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.8953 - acc: 0.3662 - val_loss: 1.7072 - val_acc: 0.4710\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8353 - acc: 0.3867\n",
      "Epoch 00007: val_loss improved from 1.70721 to 1.64287, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/007-1.6429.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.8353 - acc: 0.3867 - val_loss: 1.6429 - val_acc: 0.4943\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7875 - acc: 0.4023\n",
      "Epoch 00008: val_loss improved from 1.64287 to 1.60416, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/008-1.6042.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.7872 - acc: 0.4024 - val_loss: 1.6042 - val_acc: 0.5010\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7413 - acc: 0.4207\n",
      "Epoch 00009: val_loss improved from 1.60416 to 1.54915, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/009-1.5492.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.7415 - acc: 0.4206 - val_loss: 1.5492 - val_acc: 0.5285\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6976 - acc: 0.4399\n",
      "Epoch 00010: val_loss improved from 1.54915 to 1.49620, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/010-1.4962.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.6977 - acc: 0.4398 - val_loss: 1.4962 - val_acc: 0.5432\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6604 - acc: 0.4530\n",
      "Epoch 00011: val_loss improved from 1.49620 to 1.45608, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/011-1.4561.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.6603 - acc: 0.4530 - val_loss: 1.4561 - val_acc: 0.5663\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6131 - acc: 0.4698\n",
      "Epoch 00012: val_loss improved from 1.45608 to 1.41393, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/012-1.4139.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.6131 - acc: 0.4698 - val_loss: 1.4139 - val_acc: 0.5826\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5818 - acc: 0.4803\n",
      "Epoch 00013: val_loss improved from 1.41393 to 1.38742, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/013-1.3874.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.5819 - acc: 0.4803 - val_loss: 1.3874 - val_acc: 0.5837\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5464 - acc: 0.4940\n",
      "Epoch 00014: val_loss improved from 1.38742 to 1.34207, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/014-1.3421.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.5465 - acc: 0.4939 - val_loss: 1.3421 - val_acc: 0.6059\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5183 - acc: 0.5036\n",
      "Epoch 00015: val_loss improved from 1.34207 to 1.32260, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/015-1.3226.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.5182 - acc: 0.5037 - val_loss: 1.3226 - val_acc: 0.6007\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4958 - acc: 0.5142\n",
      "Epoch 00016: val_loss improved from 1.32260 to 1.28854, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/016-1.2885.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.4957 - acc: 0.5142 - val_loss: 1.2885 - val_acc: 0.6229\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4686 - acc: 0.5268\n",
      "Epoch 00017: val_loss improved from 1.28854 to 1.25840, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/017-1.2584.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.4680 - acc: 0.5270 - val_loss: 1.2584 - val_acc: 0.6252\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4422 - acc: 0.5353\n",
      "Epoch 00018: val_loss improved from 1.25840 to 1.23847, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/018-1.2385.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.4422 - acc: 0.5353 - val_loss: 1.2385 - val_acc: 0.6289\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4206 - acc: 0.5430\n",
      "Epoch 00019: val_loss improved from 1.23847 to 1.21292, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/019-1.2129.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.4207 - acc: 0.5430 - val_loss: 1.2129 - val_acc: 0.6380\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3928 - acc: 0.5548\n",
      "Epoch 00020: val_loss improved from 1.21292 to 1.18960, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/020-1.1896.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.3927 - acc: 0.5548 - val_loss: 1.1896 - val_acc: 0.6466\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3864 - acc: 0.5562\n",
      "Epoch 00021: val_loss improved from 1.18960 to 1.18066, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/021-1.1807.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.3865 - acc: 0.5562 - val_loss: 1.1807 - val_acc: 0.6459\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3582 - acc: 0.5676\n",
      "Epoch 00022: val_loss improved from 1.18066 to 1.16188, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/022-1.1619.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.3582 - acc: 0.5676 - val_loss: 1.1619 - val_acc: 0.6506\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3429 - acc: 0.5710\n",
      "Epoch 00023: val_loss did not improve from 1.16188\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.3436 - acc: 0.5708 - val_loss: 1.1643 - val_acc: 0.6564\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3313 - acc: 0.5764\n",
      "Epoch 00024: val_loss improved from 1.16188 to 1.11913, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/024-1.1191.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.3308 - acc: 0.5766 - val_loss: 1.1191 - val_acc: 0.6653\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3082 - acc: 0.5839\n",
      "Epoch 00025: val_loss improved from 1.11913 to 1.10820, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/025-1.1082.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.3082 - acc: 0.5840 - val_loss: 1.1082 - val_acc: 0.6755\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2955 - acc: 0.5881\n",
      "Epoch 00026: val_loss did not improve from 1.10820\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.2953 - acc: 0.5882 - val_loss: 1.1117 - val_acc: 0.6732\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2851 - acc: 0.5907\n",
      "Epoch 00027: val_loss improved from 1.10820 to 1.07891, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/027-1.0789.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 1.2852 - acc: 0.5907 - val_loss: 1.0789 - val_acc: 0.6809\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2713 - acc: 0.5967\n",
      "Epoch 00028: val_loss improved from 1.07891 to 1.07094, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/028-1.0709.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.2713 - acc: 0.5967 - val_loss: 1.0709 - val_acc: 0.6886\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2575 - acc: 0.6032\n",
      "Epoch 00029: val_loss improved from 1.07094 to 1.04258, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/029-1.0426.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.2574 - acc: 0.6032 - val_loss: 1.0426 - val_acc: 0.6914\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2455 - acc: 0.6068\n",
      "Epoch 00030: val_loss improved from 1.04258 to 1.04004, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/030-1.0400.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.2455 - acc: 0.6068 - val_loss: 1.0400 - val_acc: 0.6914\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2278 - acc: 0.6131\n",
      "Epoch 00031: val_loss improved from 1.04004 to 1.02289, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/031-1.0229.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.2278 - acc: 0.6132 - val_loss: 1.0229 - val_acc: 0.7000\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2226 - acc: 0.6139\n",
      "Epoch 00032: val_loss improved from 1.02289 to 1.01059, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/032-1.0106.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.2229 - acc: 0.6139 - val_loss: 1.0106 - val_acc: 0.7035\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2055 - acc: 0.6199\n",
      "Epoch 00033: val_loss improved from 1.01059 to 1.01057, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/033-1.0106.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.2050 - acc: 0.6201 - val_loss: 1.0106 - val_acc: 0.7030\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1931 - acc: 0.6244\n",
      "Epoch 00034: val_loss did not improve from 1.01057\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.1931 - acc: 0.6244 - val_loss: 1.0143 - val_acc: 0.7056\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1798 - acc: 0.6287\n",
      "Epoch 00035: val_loss improved from 1.01057 to 0.99105, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/035-0.9910.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.1798 - acc: 0.6287 - val_loss: 0.9910 - val_acc: 0.7156\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1775 - acc: 0.6291\n",
      "Epoch 00036: val_loss improved from 0.99105 to 0.97145, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/036-0.9714.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.1779 - acc: 0.6290 - val_loss: 0.9714 - val_acc: 0.7154\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1628 - acc: 0.6351\n",
      "Epoch 00037: val_loss did not improve from 0.97145\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.1628 - acc: 0.6351 - val_loss: 0.9719 - val_acc: 0.7198\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1572 - acc: 0.6355\n",
      "Epoch 00038: val_loss improved from 0.97145 to 0.95718, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/038-0.9572.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.1571 - acc: 0.6355 - val_loss: 0.9572 - val_acc: 0.7195\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1390 - acc: 0.6426\n",
      "Epoch 00039: val_loss improved from 0.95718 to 0.94655, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/039-0.9466.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.1390 - acc: 0.6427 - val_loss: 0.9466 - val_acc: 0.7240\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1397 - acc: 0.6424\n",
      "Epoch 00040: val_loss improved from 0.94655 to 0.93934, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/040-0.9393.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.1399 - acc: 0.6424 - val_loss: 0.9393 - val_acc: 0.7209\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1332 - acc: 0.6471\n",
      "Epoch 00041: val_loss improved from 0.93934 to 0.93283, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/041-0.9328.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.1331 - acc: 0.6471 - val_loss: 0.9328 - val_acc: 0.7235\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1207 - acc: 0.6503\n",
      "Epoch 00042: val_loss improved from 0.93283 to 0.92045, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/042-0.9205.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.1206 - acc: 0.6503 - val_loss: 0.9205 - val_acc: 0.7275\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1058 - acc: 0.6536\n",
      "Epoch 00043: val_loss improved from 0.92045 to 0.90845, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/043-0.9084.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.1058 - acc: 0.6536 - val_loss: 0.9084 - val_acc: 0.7361\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1002 - acc: 0.6567\n",
      "Epoch 00044: val_loss improved from 0.90845 to 0.90321, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/044-0.9032.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.1002 - acc: 0.6567 - val_loss: 0.9032 - val_acc: 0.7389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0970 - acc: 0.6549\n",
      "Epoch 00045: val_loss improved from 0.90321 to 0.89380, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/045-0.8938.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.0969 - acc: 0.6550 - val_loss: 0.8938 - val_acc: 0.7407\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0833 - acc: 0.6623\n",
      "Epoch 00046: val_loss did not improve from 0.89380\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.0833 - acc: 0.6623 - val_loss: 0.8939 - val_acc: 0.7275\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0874 - acc: 0.6626\n",
      "Epoch 00047: val_loss did not improve from 0.89380\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.0873 - acc: 0.6626 - val_loss: 0.8949 - val_acc: 0.7382\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0714 - acc: 0.6685\n",
      "Epoch 00048: val_loss improved from 0.89380 to 0.87590, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/048-0.8759.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.0708 - acc: 0.6686 - val_loss: 0.8759 - val_acc: 0.7393\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0707 - acc: 0.6675\n",
      "Epoch 00049: val_loss improved from 0.87590 to 0.87015, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/049-0.8702.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.0707 - acc: 0.6674 - val_loss: 0.8702 - val_acc: 0.7463\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0622 - acc: 0.6686\n",
      "Epoch 00050: val_loss did not improve from 0.87015\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.0622 - acc: 0.6686 - val_loss: 0.8722 - val_acc: 0.7466\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0488 - acc: 0.6731\n",
      "Epoch 00051: val_loss improved from 0.87015 to 0.86549, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/051-0.8655.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.0488 - acc: 0.6731 - val_loss: 0.8655 - val_acc: 0.7473\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0485 - acc: 0.6765\n",
      "Epoch 00052: val_loss improved from 0.86549 to 0.85685, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/052-0.8568.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.0485 - acc: 0.6765 - val_loss: 0.8568 - val_acc: 0.7438\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0415 - acc: 0.6787\n",
      "Epoch 00053: val_loss improved from 0.85685 to 0.85208, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/053-0.8521.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.0414 - acc: 0.6787 - val_loss: 0.8521 - val_acc: 0.7524\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0374 - acc: 0.6790\n",
      "Epoch 00054: val_loss improved from 0.85208 to 0.84412, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/054-0.8441.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.0372 - acc: 0.6791 - val_loss: 0.8441 - val_acc: 0.7545\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0286 - acc: 0.6819\n",
      "Epoch 00055: val_loss did not improve from 0.84412\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.0286 - acc: 0.6819 - val_loss: 0.8457 - val_acc: 0.7524\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0272 - acc: 0.6849\n",
      "Epoch 00056: val_loss improved from 0.84412 to 0.83087, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/056-0.8309.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 1.0271 - acc: 0.6849 - val_loss: 0.8309 - val_acc: 0.7554\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0179 - acc: 0.6838\n",
      "Epoch 00057: val_loss improved from 0.83087 to 0.82646, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/057-0.8265.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.0179 - acc: 0.6838 - val_loss: 0.8265 - val_acc: 0.7543\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0123 - acc: 0.6869\n",
      "Epoch 00058: val_loss improved from 0.82646 to 0.82219, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/058-0.8222.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.0124 - acc: 0.6869 - val_loss: 0.8222 - val_acc: 0.7594\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0116 - acc: 0.6892\n",
      "Epoch 00059: val_loss improved from 0.82219 to 0.81050, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/059-0.8105.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.0115 - acc: 0.6892 - val_loss: 0.8105 - val_acc: 0.7638\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0043 - acc: 0.6911\n",
      "Epoch 00060: val_loss improved from 0.81050 to 0.81041, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/060-0.8104.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.0043 - acc: 0.6912 - val_loss: 0.8104 - val_acc: 0.7626\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9957 - acc: 0.6916\n",
      "Epoch 00061: val_loss improved from 0.81041 to 0.80134, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/061-0.8013.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.9957 - acc: 0.6916 - val_loss: 0.8013 - val_acc: 0.7685\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9921 - acc: 0.6957\n",
      "Epoch 00062: val_loss did not improve from 0.80134\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.9922 - acc: 0.6957 - val_loss: 0.8176 - val_acc: 0.7668\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9890 - acc: 0.6955\n",
      "Epoch 00063: val_loss improved from 0.80134 to 0.79185, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/063-0.7919.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.9890 - acc: 0.6955 - val_loss: 0.7919 - val_acc: 0.7701\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9821 - acc: 0.6981\n",
      "Epoch 00064: val_loss did not improve from 0.79185\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.9819 - acc: 0.6983 - val_loss: 0.8000 - val_acc: 0.7636\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9806 - acc: 0.7016\n",
      "Epoch 00065: val_loss improved from 0.79185 to 0.78747, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/065-0.7875.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.9806 - acc: 0.7016 - val_loss: 0.7875 - val_acc: 0.7731\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9729 - acc: 0.7000\n",
      "Epoch 00066: val_loss improved from 0.78747 to 0.78485, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/066-0.7849.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.9728 - acc: 0.7001 - val_loss: 0.7849 - val_acc: 0.7752\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9693 - acc: 0.7057\n",
      "Epoch 00067: val_loss improved from 0.78485 to 0.77671, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/067-0.7767.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.9695 - acc: 0.7055 - val_loss: 0.7767 - val_acc: 0.7717\n",
      "Epoch 68/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9639 - acc: 0.7068\n",
      "Epoch 00068: val_loss did not improve from 0.77671\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.9640 - acc: 0.7068 - val_loss: 0.7837 - val_acc: 0.7736\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9549 - acc: 0.7062\n",
      "Epoch 00069: val_loss improved from 0.77671 to 0.76605, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/069-0.7660.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.9549 - acc: 0.7062 - val_loss: 0.7660 - val_acc: 0.7768\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9529 - acc: 0.7087\n",
      "Epoch 00070: val_loss did not improve from 0.76605\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.9529 - acc: 0.7086 - val_loss: 0.7736 - val_acc: 0.7775\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9519 - acc: 0.7082\n",
      "Epoch 00071: val_loss improved from 0.76605 to 0.76265, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/071-0.7627.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.9518 - acc: 0.7082 - val_loss: 0.7627 - val_acc: 0.7780\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9474 - acc: 0.7099\n",
      "Epoch 00072: val_loss improved from 0.76265 to 0.76046, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/072-0.7605.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.9473 - acc: 0.7099 - val_loss: 0.7605 - val_acc: 0.7822\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9506 - acc: 0.7113\n",
      "Epoch 00073: val_loss improved from 0.76046 to 0.75810, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/073-0.7581.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.9505 - acc: 0.7113 - val_loss: 0.7581 - val_acc: 0.7841\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9386 - acc: 0.7163\n",
      "Epoch 00074: val_loss improved from 0.75810 to 0.74759, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/074-0.7476.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.9385 - acc: 0.7162 - val_loss: 0.7476 - val_acc: 0.7831\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9369 - acc: 0.7165\n",
      "Epoch 00075: val_loss improved from 0.74759 to 0.74642, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/075-0.7464.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.9368 - acc: 0.7165 - val_loss: 0.7464 - val_acc: 0.7890\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9342 - acc: 0.7156\n",
      "Epoch 00076: val_loss did not improve from 0.74642\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.9342 - acc: 0.7156 - val_loss: 0.7501 - val_acc: 0.7850\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9313 - acc: 0.7164\n",
      "Epoch 00077: val_loss improved from 0.74642 to 0.74096, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/077-0.7410.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.9312 - acc: 0.7165 - val_loss: 0.7410 - val_acc: 0.7918\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9246 - acc: 0.7221\n",
      "Epoch 00078: val_loss improved from 0.74096 to 0.73715, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/078-0.7371.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.9246 - acc: 0.7221 - val_loss: 0.7371 - val_acc: 0.7899\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9254 - acc: 0.7197\n",
      "Epoch 00079: val_loss improved from 0.73715 to 0.73404, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/079-0.7340.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.9254 - acc: 0.7197 - val_loss: 0.7340 - val_acc: 0.7945\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9215 - acc: 0.7226\n",
      "Epoch 00080: val_loss did not improve from 0.73404\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.9218 - acc: 0.7225 - val_loss: 0.7438 - val_acc: 0.7852\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9139 - acc: 0.7226\n",
      "Epoch 00081: val_loss did not improve from 0.73404\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.9139 - acc: 0.7226 - val_loss: 0.7460 - val_acc: 0.7850\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9101 - acc: 0.7213\n",
      "Epoch 00082: val_loss improved from 0.73404 to 0.72927, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/082-0.7293.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.9103 - acc: 0.7213 - val_loss: 0.7293 - val_acc: 0.7964\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9067 - acc: 0.7252\n",
      "Epoch 00083: val_loss improved from 0.72927 to 0.72699, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/083-0.7270.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.9067 - acc: 0.7252 - val_loss: 0.7270 - val_acc: 0.7962\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9077 - acc: 0.7243\n",
      "Epoch 00084: val_loss improved from 0.72699 to 0.72149, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/084-0.7215.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.9077 - acc: 0.7243 - val_loss: 0.7215 - val_acc: 0.7985\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9030 - acc: 0.7279\n",
      "Epoch 00085: val_loss improved from 0.72149 to 0.71777, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/085-0.7178.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.9030 - acc: 0.7279 - val_loss: 0.7178 - val_acc: 0.7971\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8982 - acc: 0.7287\n",
      "Epoch 00086: val_loss improved from 0.71777 to 0.71122, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/086-0.7112.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8986 - acc: 0.7287 - val_loss: 0.7112 - val_acc: 0.7959\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8998 - acc: 0.7271\n",
      "Epoch 00087: val_loss did not improve from 0.71122\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8998 - acc: 0.7271 - val_loss: 0.7152 - val_acc: 0.7973\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8963 - acc: 0.7295\n",
      "Epoch 00088: val_loss did not improve from 0.71122\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8962 - acc: 0.7295 - val_loss: 0.7153 - val_acc: 0.7992\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8883 - acc: 0.7329\n",
      "Epoch 00089: val_loss improved from 0.71122 to 0.70400, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/089-0.7040.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8881 - acc: 0.7329 - val_loss: 0.7040 - val_acc: 0.7971\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8861 - acc: 0.7333\n",
      "Epoch 00090: val_loss improved from 0.70400 to 0.70264, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/090-0.7026.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8861 - acc: 0.7333 - val_loss: 0.7026 - val_acc: 0.8011\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8882 - acc: 0.7305\n",
      "Epoch 00091: val_loss did not improve from 0.70264\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8882 - acc: 0.7305 - val_loss: 0.7056 - val_acc: 0.8027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8775 - acc: 0.7338\n",
      "Epoch 00092: val_loss improved from 0.70264 to 0.70038, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/092-0.7004.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8775 - acc: 0.7338 - val_loss: 0.7004 - val_acc: 0.8041\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8756 - acc: 0.7342\n",
      "Epoch 00093: val_loss improved from 0.70038 to 0.69931, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/093-0.6993.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8759 - acc: 0.7342 - val_loss: 0.6993 - val_acc: 0.8057\n",
      "Epoch 94/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8786 - acc: 0.7342\n",
      "Epoch 00094: val_loss improved from 0.69931 to 0.69307, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/094-0.6931.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8786 - acc: 0.7343 - val_loss: 0.6931 - val_acc: 0.8097\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8704 - acc: 0.7380\n",
      "Epoch 00095: val_loss did not improve from 0.69307\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8705 - acc: 0.7380 - val_loss: 0.6937 - val_acc: 0.8043\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7377\n",
      "Epoch 00096: val_loss did not improve from 0.69307\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.8719 - acc: 0.7377 - val_loss: 0.6933 - val_acc: 0.8053\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8767 - acc: 0.7344\n",
      "Epoch 00097: val_loss did not improve from 0.69307\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.8767 - acc: 0.7344 - val_loss: 0.6935 - val_acc: 0.8067\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8717 - acc: 0.7352\n",
      "Epoch 00098: val_loss improved from 0.69307 to 0.69142, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/098-0.6914.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8717 - acc: 0.7353 - val_loss: 0.6914 - val_acc: 0.8111\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8623 - acc: 0.7380\n",
      "Epoch 00099: val_loss did not improve from 0.69142\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8623 - acc: 0.7380 - val_loss: 0.6939 - val_acc: 0.8060\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8666 - acc: 0.7393\n",
      "Epoch 00100: val_loss did not improve from 0.69142\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.8666 - acc: 0.7393 - val_loss: 0.7057 - val_acc: 0.8008\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8570 - acc: 0.7420\n",
      "Epoch 00101: val_loss improved from 0.69142 to 0.67445, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/101-0.6744.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8569 - acc: 0.7421 - val_loss: 0.6744 - val_acc: 0.8155\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8584 - acc: 0.7426\n",
      "Epoch 00102: val_loss did not improve from 0.67445\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8584 - acc: 0.7426 - val_loss: 0.6774 - val_acc: 0.8116\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8591 - acc: 0.7422\n",
      "Epoch 00103: val_loss did not improve from 0.67445\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.8591 - acc: 0.7422 - val_loss: 0.6776 - val_acc: 0.8092\n",
      "Epoch 104/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8499 - acc: 0.7438\n",
      "Epoch 00104: val_loss improved from 0.67445 to 0.67098, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/104-0.6710.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.8500 - acc: 0.7438 - val_loss: 0.6710 - val_acc: 0.8127\n",
      "Epoch 105/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8554 - acc: 0.7426\n",
      "Epoch 00105: val_loss improved from 0.67098 to 0.66790, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/105-0.6679.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8549 - acc: 0.7426 - val_loss: 0.6679 - val_acc: 0.8127\n",
      "Epoch 106/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8522 - acc: 0.7428\n",
      "Epoch 00106: val_loss did not improve from 0.66790\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8518 - acc: 0.7429 - val_loss: 0.6681 - val_acc: 0.8150\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8439 - acc: 0.7454\n",
      "Epoch 00107: val_loss improved from 0.66790 to 0.66318, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/107-0.6632.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8439 - acc: 0.7454 - val_loss: 0.6632 - val_acc: 0.8197\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8426 - acc: 0.7453\n",
      "Epoch 00108: val_loss did not improve from 0.66318\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8427 - acc: 0.7452 - val_loss: 0.6718 - val_acc: 0.8178\n",
      "Epoch 109/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8423 - acc: 0.7469\n",
      "Epoch 00109: val_loss improved from 0.66318 to 0.66054, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/109-0.6605.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.8423 - acc: 0.7469 - val_loss: 0.6605 - val_acc: 0.8174\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8403 - acc: 0.7494\n",
      "Epoch 00110: val_loss did not improve from 0.66054\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.8403 - acc: 0.7495 - val_loss: 0.6653 - val_acc: 0.8192\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8323 - acc: 0.7487\n",
      "Epoch 00111: val_loss improved from 0.66054 to 0.64850, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/111-0.6485.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8322 - acc: 0.7488 - val_loss: 0.6485 - val_acc: 0.8199\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8390 - acc: 0.7474\n",
      "Epoch 00112: val_loss did not improve from 0.64850\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8387 - acc: 0.7475 - val_loss: 0.6660 - val_acc: 0.8181\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8341 - acc: 0.7514\n",
      "Epoch 00113: val_loss did not improve from 0.64850\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8341 - acc: 0.7514 - val_loss: 0.6646 - val_acc: 0.8143\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8323 - acc: 0.7504\n",
      "Epoch 00114: val_loss did not improve from 0.64850\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8322 - acc: 0.7504 - val_loss: 0.6497 - val_acc: 0.8185\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8287 - acc: 0.7502\n",
      "Epoch 00115: val_loss did not improve from 0.64850\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.8289 - acc: 0.7502 - val_loss: 0.6528 - val_acc: 0.8192\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8322 - acc: 0.7511\n",
      "Epoch 00116: val_loss did not improve from 0.64850\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.8323 - acc: 0.7511 - val_loss: 0.6596 - val_acc: 0.8197\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8270 - acc: 0.7516\n",
      "Epoch 00117: val_loss did not improve from 0.64850\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.8269 - acc: 0.7517 - val_loss: 0.6541 - val_acc: 0.8192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8231 - acc: 0.7541\n",
      "Epoch 00118: val_loss improved from 0.64850 to 0.64014, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/118-0.6401.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.8232 - acc: 0.7541 - val_loss: 0.6401 - val_acc: 0.8232\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8276 - acc: 0.7546\n",
      "Epoch 00119: val_loss did not improve from 0.64014\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8279 - acc: 0.7544 - val_loss: 0.6551 - val_acc: 0.8188\n",
      "Epoch 120/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8183 - acc: 0.7556\n",
      "Epoch 00120: val_loss improved from 0.64014 to 0.63993, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/120-0.6399.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8183 - acc: 0.7556 - val_loss: 0.6399 - val_acc: 0.8253\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8157 - acc: 0.7580\n",
      "Epoch 00121: val_loss did not improve from 0.63993\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8157 - acc: 0.7580 - val_loss: 0.6444 - val_acc: 0.8274\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8116 - acc: 0.7549\n",
      "Epoch 00122: val_loss did not improve from 0.63993\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.8115 - acc: 0.7549 - val_loss: 0.6402 - val_acc: 0.8267\n",
      "Epoch 123/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8157 - acc: 0.7579\n",
      "Epoch 00123: val_loss improved from 0.63993 to 0.63306, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/123-0.6331.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.8160 - acc: 0.7579 - val_loss: 0.6331 - val_acc: 0.8244\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8137 - acc: 0.7569\n",
      "Epoch 00124: val_loss did not improve from 0.63306\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8136 - acc: 0.7569 - val_loss: 0.6373 - val_acc: 0.8281\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8042 - acc: 0.7595\n",
      "Epoch 00125: val_loss did not improve from 0.63306\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8042 - acc: 0.7595 - val_loss: 0.6427 - val_acc: 0.8251\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8129 - acc: 0.7569\n",
      "Epoch 00126: val_loss improved from 0.63306 to 0.63284, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/126-0.6328.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8131 - acc: 0.7569 - val_loss: 0.6328 - val_acc: 0.8255\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8038 - acc: 0.7586\n",
      "Epoch 00127: val_loss improved from 0.63284 to 0.63233, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/127-0.6323.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.8038 - acc: 0.7586 - val_loss: 0.6323 - val_acc: 0.8300\n",
      "Epoch 128/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8035 - acc: 0.7589\n",
      "Epoch 00128: val_loss improved from 0.63233 to 0.62810, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/128-0.6281.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.8035 - acc: 0.7589 - val_loss: 0.6281 - val_acc: 0.8332\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8014 - acc: 0.7590\n",
      "Epoch 00129: val_loss did not improve from 0.62810\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8013 - acc: 0.7590 - val_loss: 0.6384 - val_acc: 0.8255\n",
      "Epoch 130/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8038 - acc: 0.7597\n",
      "Epoch 00130: val_loss did not improve from 0.62810\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.8039 - acc: 0.7596 - val_loss: 0.6299 - val_acc: 0.8290\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7967 - acc: 0.7621\n",
      "Epoch 00131: val_loss did not improve from 0.62810\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7967 - acc: 0.7622 - val_loss: 0.6301 - val_acc: 0.8272\n",
      "Epoch 132/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8012 - acc: 0.7626\n",
      "Epoch 00132: val_loss improved from 0.62810 to 0.61740, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/132-0.6174.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8013 - acc: 0.7626 - val_loss: 0.6174 - val_acc: 0.8323\n",
      "Epoch 133/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7951 - acc: 0.7624\n",
      "Epoch 00133: val_loss improved from 0.61740 to 0.61623, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/133-0.6162.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7952 - acc: 0.7624 - val_loss: 0.6162 - val_acc: 0.8302\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7948 - acc: 0.7622\n",
      "Epoch 00134: val_loss did not improve from 0.61623\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7948 - acc: 0.7622 - val_loss: 0.6213 - val_acc: 0.8304\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7908 - acc: 0.7639\n",
      "Epoch 00135: val_loss did not improve from 0.61623\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7907 - acc: 0.7639 - val_loss: 0.6233 - val_acc: 0.8309\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7936 - acc: 0.7625\n",
      "Epoch 00136: val_loss improved from 0.61623 to 0.61187, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/136-0.6119.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7937 - acc: 0.7625 - val_loss: 0.6119 - val_acc: 0.8360\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7941 - acc: 0.7646\n",
      "Epoch 00137: val_loss did not improve from 0.61187\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7941 - acc: 0.7646 - val_loss: 0.6165 - val_acc: 0.8316\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7919 - acc: 0.7646\n",
      "Epoch 00138: val_loss did not improve from 0.61187\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7920 - acc: 0.7647 - val_loss: 0.6220 - val_acc: 0.8290\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7858 - acc: 0.7641\n",
      "Epoch 00139: val_loss improved from 0.61187 to 0.61094, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/139-0.6109.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7859 - acc: 0.7641 - val_loss: 0.6109 - val_acc: 0.8358\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7859 - acc: 0.7683\n",
      "Epoch 00140: val_loss did not improve from 0.61094\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7858 - acc: 0.7683 - val_loss: 0.6118 - val_acc: 0.8311\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7824 - acc: 0.7654\n",
      "Epoch 00141: val_loss did not improve from 0.61094\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7824 - acc: 0.7654 - val_loss: 0.6131 - val_acc: 0.8339\n",
      "Epoch 142/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7805 - acc: 0.7701\n",
      "Epoch 00142: val_loss improved from 0.61094 to 0.60824, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/142-0.6082.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7811 - acc: 0.7700 - val_loss: 0.6082 - val_acc: 0.8341\n",
      "Epoch 143/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7782 - acc: 0.7679\n",
      "Epoch 00143: val_loss improved from 0.60824 to 0.60062, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/143-0.6006.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7781 - acc: 0.7679 - val_loss: 0.6006 - val_acc: 0.8358\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7809 - acc: 0.7684\n",
      "Epoch 00144: val_loss did not improve from 0.60062\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7809 - acc: 0.7684 - val_loss: 0.6152 - val_acc: 0.8311\n",
      "Epoch 145/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7790 - acc: 0.7686\n",
      "Epoch 00145: val_loss did not improve from 0.60062\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7789 - acc: 0.7685 - val_loss: 0.6156 - val_acc: 0.8351\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7783 - acc: 0.7685\n",
      "Epoch 00146: val_loss did not improve from 0.60062\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.7785 - acc: 0.7685 - val_loss: 0.6071 - val_acc: 0.8360\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7812 - acc: 0.7674\n",
      "Epoch 00147: val_loss did not improve from 0.60062\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7811 - acc: 0.7674 - val_loss: 0.6039 - val_acc: 0.8390\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7688 - acc: 0.7716\n",
      "Epoch 00148: val_loss did not improve from 0.60062\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.7688 - acc: 0.7715 - val_loss: 0.6108 - val_acc: 0.8355\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.7705\n",
      "Epoch 00149: val_loss improved from 0.60062 to 0.59613, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/149-0.5961.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.7699 - acc: 0.7705 - val_loss: 0.5961 - val_acc: 0.8395\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7663 - acc: 0.7712\n",
      "Epoch 00150: val_loss improved from 0.59613 to 0.59481, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/150-0.5948.hdf5\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7663 - acc: 0.7712 - val_loss: 0.5948 - val_acc: 0.8416\n",
      "Epoch 151/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7688 - acc: 0.7719\n",
      "Epoch 00151: val_loss improved from 0.59481 to 0.58950, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/151-0.5895.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7685 - acc: 0.7719 - val_loss: 0.5895 - val_acc: 0.8393\n",
      "Epoch 152/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7622 - acc: 0.7727\n",
      "Epoch 00152: val_loss did not improve from 0.58950\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7621 - acc: 0.7727 - val_loss: 0.5985 - val_acc: 0.8362\n",
      "Epoch 153/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7681 - acc: 0.7772\n",
      "Epoch 00153: val_loss did not improve from 0.58950\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7679 - acc: 0.7772 - val_loss: 0.5907 - val_acc: 0.8404\n",
      "Epoch 154/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7669 - acc: 0.7730\n",
      "Epoch 00154: val_loss improved from 0.58950 to 0.58908, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/154-0.5891.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.7671 - acc: 0.7731 - val_loss: 0.5891 - val_acc: 0.8449\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7637 - acc: 0.7744\n",
      "Epoch 00155: val_loss improved from 0.58908 to 0.58848, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/155-0.5885.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7639 - acc: 0.7744 - val_loss: 0.5885 - val_acc: 0.8411\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7620 - acc: 0.7743\n",
      "Epoch 00156: val_loss did not improve from 0.58848\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.7620 - acc: 0.7744 - val_loss: 0.5945 - val_acc: 0.8346\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7590 - acc: 0.7741\n",
      "Epoch 00157: val_loss did not improve from 0.58848\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7589 - acc: 0.7741 - val_loss: 0.5952 - val_acc: 0.8390\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7609 - acc: 0.7752\n",
      "Epoch 00158: val_loss improved from 0.58848 to 0.58684, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/158-0.5868.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7609 - acc: 0.7752 - val_loss: 0.5868 - val_acc: 0.8428\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7545 - acc: 0.7756\n",
      "Epoch 00159: val_loss improved from 0.58684 to 0.58330, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/159-0.5833.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7544 - acc: 0.7756 - val_loss: 0.5833 - val_acc: 0.8465\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7581 - acc: 0.7738\n",
      "Epoch 00160: val_loss improved from 0.58330 to 0.58189, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/160-0.5819.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7580 - acc: 0.7738 - val_loss: 0.5819 - val_acc: 0.8430\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7460 - acc: 0.7794\n",
      "Epoch 00161: val_loss improved from 0.58189 to 0.57873, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/161-0.5787.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.7460 - acc: 0.7795 - val_loss: 0.5787 - val_acc: 0.8425\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7554 - acc: 0.7768\n",
      "Epoch 00162: val_loss did not improve from 0.57873\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7553 - acc: 0.7768 - val_loss: 0.5863 - val_acc: 0.8428\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7503 - acc: 0.7783\n",
      "Epoch 00163: val_loss did not improve from 0.57873\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7503 - acc: 0.7783 - val_loss: 0.5851 - val_acc: 0.8453\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7464 - acc: 0.7781\n",
      "Epoch 00164: val_loss did not improve from 0.57873\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7464 - acc: 0.7781 - val_loss: 0.5817 - val_acc: 0.8423\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7475 - acc: 0.7779\n",
      "Epoch 00165: val_loss improved from 0.57873 to 0.57282, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/165-0.5728.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7475 - acc: 0.7779 - val_loss: 0.5728 - val_acc: 0.8456\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7476 - acc: 0.7771\n",
      "Epoch 00166: val_loss did not improve from 0.57282\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7476 - acc: 0.7771 - val_loss: 0.5813 - val_acc: 0.8470\n",
      "Epoch 167/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7440 - acc: 0.7774\n",
      "Epoch 00167: val_loss improved from 0.57282 to 0.57276, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/167-0.5728.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7446 - acc: 0.7774 - val_loss: 0.5728 - val_acc: 0.8472\n",
      "Epoch 168/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7462 - acc: 0.7796\n",
      "Epoch 00168: val_loss did not improve from 0.57276\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7462 - acc: 0.7797 - val_loss: 0.5765 - val_acc: 0.8474\n",
      "Epoch 169/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7478 - acc: 0.7800\n",
      "Epoch 00169: val_loss did not improve from 0.57276\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.7487 - acc: 0.7798 - val_loss: 0.5738 - val_acc: 0.8453\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7391 - acc: 0.7802\n",
      "Epoch 00170: val_loss did not improve from 0.57276\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.7391 - acc: 0.7802 - val_loss: 0.5759 - val_acc: 0.8458\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7439 - acc: 0.7784\n",
      "Epoch 00171: val_loss did not improve from 0.57276\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7440 - acc: 0.7784 - val_loss: 0.5799 - val_acc: 0.8451\n",
      "Epoch 172/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7375 - acc: 0.7782\n",
      "Epoch 00172: val_loss improved from 0.57276 to 0.56591, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/172-0.5659.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7374 - acc: 0.7782 - val_loss: 0.5659 - val_acc: 0.8495\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7376 - acc: 0.7805\n",
      "Epoch 00173: val_loss did not improve from 0.56591\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7375 - acc: 0.7805 - val_loss: 0.5672 - val_acc: 0.8500\n",
      "Epoch 174/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7376 - acc: 0.7813\n",
      "Epoch 00174: val_loss did not improve from 0.56591\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7376 - acc: 0.7812 - val_loss: 0.5704 - val_acc: 0.8498\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7304 - acc: 0.7834\n",
      "Epoch 00175: val_loss improved from 0.56591 to 0.56287, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/175-0.5629.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7303 - acc: 0.7835 - val_loss: 0.5629 - val_acc: 0.8484\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7330 - acc: 0.7832\n",
      "Epoch 00176: val_loss did not improve from 0.56287\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7331 - acc: 0.7831 - val_loss: 0.5736 - val_acc: 0.8432\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7324 - acc: 0.7848\n",
      "Epoch 00177: val_loss did not improve from 0.56287\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7323 - acc: 0.7848 - val_loss: 0.5741 - val_acc: 0.8449\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7316 - acc: 0.7825\n",
      "Epoch 00178: val_loss did not improve from 0.56287\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7316 - acc: 0.7825 - val_loss: 0.5679 - val_acc: 0.8442\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7303 - acc: 0.7859\n",
      "Epoch 00179: val_loss improved from 0.56287 to 0.55389, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/179-0.5539.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7302 - acc: 0.7860 - val_loss: 0.5539 - val_acc: 0.8498\n",
      "Epoch 180/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7286 - acc: 0.7859\n",
      "Epoch 00180: val_loss did not improve from 0.55389\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7289 - acc: 0.7859 - val_loss: 0.5620 - val_acc: 0.8479\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7290 - acc: 0.7841\n",
      "Epoch 00181: val_loss did not improve from 0.55389\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7291 - acc: 0.7841 - val_loss: 0.5613 - val_acc: 0.8514\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7194 - acc: 0.7884\n",
      "Epoch 00182: val_loss improved from 0.55389 to 0.55043, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/182-0.5504.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7194 - acc: 0.7884 - val_loss: 0.5504 - val_acc: 0.8537\n",
      "Epoch 183/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7248 - acc: 0.7857\n",
      "Epoch 00183: val_loss did not improve from 0.55043\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7247 - acc: 0.7857 - val_loss: 0.5637 - val_acc: 0.8495\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7222 - acc: 0.7843\n",
      "Epoch 00184: val_loss did not improve from 0.55043\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7221 - acc: 0.7843 - val_loss: 0.5533 - val_acc: 0.8530\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7176 - acc: 0.7893\n",
      "Epoch 00185: val_loss did not improve from 0.55043\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7176 - acc: 0.7893 - val_loss: 0.5605 - val_acc: 0.8477\n",
      "Epoch 186/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7207 - acc: 0.7884\n",
      "Epoch 00186: val_loss did not improve from 0.55043\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7203 - acc: 0.7886 - val_loss: 0.5715 - val_acc: 0.8472\n",
      "Epoch 187/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7185 - acc: 0.7875\n",
      "Epoch 00187: val_loss improved from 0.55043 to 0.54648, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/187-0.5465.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.7185 - acc: 0.7874 - val_loss: 0.5465 - val_acc: 0.8549\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7173 - acc: 0.7864\n",
      "Epoch 00188: val_loss did not improve from 0.54648\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.7173 - acc: 0.7864 - val_loss: 0.5466 - val_acc: 0.8526\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7186 - acc: 0.7877\n",
      "Epoch 00189: val_loss improved from 0.54648 to 0.54575, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/189-0.5457.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7187 - acc: 0.7877 - val_loss: 0.5457 - val_acc: 0.8560\n",
      "Epoch 190/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7126 - acc: 0.7883\n",
      "Epoch 00190: val_loss improved from 0.54575 to 0.53934, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/190-0.5393.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7128 - acc: 0.7884 - val_loss: 0.5393 - val_acc: 0.8553\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7146 - acc: 0.7900\n",
      "Epoch 00191: val_loss did not improve from 0.53934\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7146 - acc: 0.7900 - val_loss: 0.5446 - val_acc: 0.8532\n",
      "Epoch 192/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7155 - acc: 0.7885\n",
      "Epoch 00192: val_loss improved from 0.53934 to 0.53901, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/192-0.5390.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7151 - acc: 0.7886 - val_loss: 0.5390 - val_acc: 0.8532\n",
      "Epoch 193/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7096 - acc: 0.7896- ETA: 0s - loss: 0.7082 - acc\n",
      "Epoch 00193: val_loss did not improve from 0.53901\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7099 - acc: 0.7895 - val_loss: 0.5572 - val_acc: 0.8442\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7115 - acc: 0.7876\n",
      "Epoch 00194: val_loss did not improve from 0.53901\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.7114 - acc: 0.7875 - val_loss: 0.5537 - val_acc: 0.8528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7130 - acc: 0.7909\n",
      "Epoch 00195: val_loss did not improve from 0.53901\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7130 - acc: 0.7909 - val_loss: 0.5470 - val_acc: 0.8553\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7116 - acc: 0.7884\n",
      "Epoch 00196: val_loss did not improve from 0.53901\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7115 - acc: 0.7884 - val_loss: 0.5469 - val_acc: 0.8523\n",
      "Epoch 197/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7063 - acc: 0.7916\n",
      "Epoch 00197: val_loss did not improve from 0.53901\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7057 - acc: 0.7919 - val_loss: 0.5466 - val_acc: 0.8565\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7060 - acc: 0.7898\n",
      "Epoch 00198: val_loss improved from 0.53901 to 0.53204, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/198-0.5320.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.7061 - acc: 0.7897 - val_loss: 0.5320 - val_acc: 0.8549\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7073 - acc: 0.7928\n",
      "Epoch 00199: val_loss did not improve from 0.53204\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7073 - acc: 0.7928 - val_loss: 0.5398 - val_acc: 0.8542\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7062 - acc: 0.7895\n",
      "Epoch 00200: val_loss did not improve from 0.53204\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7061 - acc: 0.7896 - val_loss: 0.5351 - val_acc: 0.8553\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6960 - acc: 0.7954\n",
      "Epoch 00201: val_loss did not improve from 0.53204\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6960 - acc: 0.7954 - val_loss: 0.5350 - val_acc: 0.8581\n",
      "Epoch 202/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7045 - acc: 0.7917\n",
      "Epoch 00202: val_loss improved from 0.53204 to 0.53091, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/202-0.5309.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7046 - acc: 0.7917 - val_loss: 0.5309 - val_acc: 0.8556\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6982 - acc: 0.7940\n",
      "Epoch 00203: val_loss did not improve from 0.53091\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6982 - acc: 0.7940 - val_loss: 0.5372 - val_acc: 0.8577\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6976 - acc: 0.7924\n",
      "Epoch 00204: val_loss did not improve from 0.53091\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6977 - acc: 0.7924 - val_loss: 0.5322 - val_acc: 0.8595\n",
      "Epoch 205/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6963 - acc: 0.7933\n",
      "Epoch 00205: val_loss did not improve from 0.53091\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6963 - acc: 0.7933 - val_loss: 0.5324 - val_acc: 0.8586\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6948 - acc: 0.7958\n",
      "Epoch 00206: val_loss did not improve from 0.53091\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.6948 - acc: 0.7958 - val_loss: 0.5433 - val_acc: 0.8521\n",
      "Epoch 207/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6950 - acc: 0.7946\n",
      "Epoch 00207: val_loss improved from 0.53091 to 0.52467, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/207-0.5247.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6955 - acc: 0.7946 - val_loss: 0.5247 - val_acc: 0.8595\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7001 - acc: 0.7937\n",
      "Epoch 00208: val_loss did not improve from 0.52467\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7002 - acc: 0.7936 - val_loss: 0.5354 - val_acc: 0.8565\n",
      "Epoch 209/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6914 - acc: 0.7980\n",
      "Epoch 00209: val_loss did not improve from 0.52467\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6913 - acc: 0.7980 - val_loss: 0.5281 - val_acc: 0.8542\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6889 - acc: 0.7961\n",
      "Epoch 00210: val_loss improved from 0.52467 to 0.52328, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/210-0.5233.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6888 - acc: 0.7961 - val_loss: 0.5233 - val_acc: 0.8598\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6830 - acc: 0.7978\n",
      "Epoch 00211: val_loss improved from 0.52328 to 0.51852, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/211-0.5185.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6829 - acc: 0.7978 - val_loss: 0.5185 - val_acc: 0.8626\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6898 - acc: 0.7955\n",
      "Epoch 00212: val_loss did not improve from 0.51852\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6898 - acc: 0.7955 - val_loss: 0.5366 - val_acc: 0.8563\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6824 - acc: 0.7983\n",
      "Epoch 00213: val_loss did not improve from 0.51852\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6824 - acc: 0.7983 - val_loss: 0.5231 - val_acc: 0.8588\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6889 - acc: 0.7959\n",
      "Epoch 00214: val_loss improved from 0.51852 to 0.51599, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/214-0.5160.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6889 - acc: 0.7959 - val_loss: 0.5160 - val_acc: 0.8600\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6864 - acc: 0.7999\n",
      "Epoch 00215: val_loss did not improve from 0.51599\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6866 - acc: 0.7998 - val_loss: 0.5312 - val_acc: 0.8577\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6807 - acc: 0.7987\n",
      "Epoch 00216: val_loss did not improve from 0.51599\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6807 - acc: 0.7988 - val_loss: 0.5202 - val_acc: 0.8600\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6856 - acc: 0.7990\n",
      "Epoch 00217: val_loss did not improve from 0.51599\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6856 - acc: 0.7990 - val_loss: 0.5195 - val_acc: 0.8637\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6891 - acc: 0.7944\n",
      "Epoch 00218: val_loss did not improve from 0.51599\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6890 - acc: 0.7945 - val_loss: 0.5182 - val_acc: 0.8600\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6823 - acc: 0.7986\n",
      "Epoch 00219: val_loss did not improve from 0.51599\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6823 - acc: 0.7985 - val_loss: 0.5285 - val_acc: 0.8598\n",
      "Epoch 220/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6810 - acc: 0.7984\n",
      "Epoch 00220: val_loss improved from 0.51599 to 0.51312, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/220-0.5131.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6809 - acc: 0.7983 - val_loss: 0.5131 - val_acc: 0.8628\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6785 - acc: 0.7998\n",
      "Epoch 00221: val_loss did not improve from 0.51312\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6784 - acc: 0.7999 - val_loss: 0.5179 - val_acc: 0.8637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 222/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6759 - acc: 0.8005\n",
      "Epoch 00222: val_loss improved from 0.51312 to 0.51015, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/222-0.5102.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6760 - acc: 0.8005 - val_loss: 0.5102 - val_acc: 0.8644\n",
      "Epoch 223/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6720 - acc: 0.8025\n",
      "Epoch 00223: val_loss improved from 0.51015 to 0.50841, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/223-0.5084.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6720 - acc: 0.8025 - val_loss: 0.5084 - val_acc: 0.8661\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6737 - acc: 0.8040\n",
      "Epoch 00224: val_loss did not improve from 0.50841\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6738 - acc: 0.8039 - val_loss: 0.5143 - val_acc: 0.8619\n",
      "Epoch 225/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6756 - acc: 0.8004\n",
      "Epoch 00225: val_loss did not improve from 0.50841\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6753 - acc: 0.8005 - val_loss: 0.5104 - val_acc: 0.8649\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6692 - acc: 0.8032\n",
      "Epoch 00226: val_loss did not improve from 0.50841\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.6691 - acc: 0.8032 - val_loss: 0.5230 - val_acc: 0.8570\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6723 - acc: 0.8020\n",
      "Epoch 00227: val_loss did not improve from 0.50841\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6723 - acc: 0.8020 - val_loss: 0.5124 - val_acc: 0.8621\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6721 - acc: 0.8001\n",
      "Epoch 00228: val_loss improved from 0.50841 to 0.50575, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/228-0.5058.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6720 - acc: 0.8001 - val_loss: 0.5058 - val_acc: 0.8679\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6691 - acc: 0.8017\n",
      "Epoch 00229: val_loss improved from 0.50575 to 0.50426, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/229-0.5043.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6691 - acc: 0.8017 - val_loss: 0.5043 - val_acc: 0.8658\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6702 - acc: 0.8029\n",
      "Epoch 00230: val_loss did not improve from 0.50426\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6703 - acc: 0.8029 - val_loss: 0.5108 - val_acc: 0.8593\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6702 - acc: 0.8023\n",
      "Epoch 00231: val_loss did not improve from 0.50426\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6703 - acc: 0.8023 - val_loss: 0.5175 - val_acc: 0.8600\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6697 - acc: 0.8034\n",
      "Epoch 00232: val_loss improved from 0.50426 to 0.49957, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/232-0.4996.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.6697 - acc: 0.8034 - val_loss: 0.4996 - val_acc: 0.8670\n",
      "Epoch 233/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6672 - acc: 0.8042\n",
      "Epoch 00233: val_loss did not improve from 0.49957\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6673 - acc: 0.8042 - val_loss: 0.5061 - val_acc: 0.8654\n",
      "Epoch 234/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.8068\n",
      "Epoch 00234: val_loss did not improve from 0.49957\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6591 - acc: 0.8067 - val_loss: 0.5125 - val_acc: 0.8630\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6685 - acc: 0.8042\n",
      "Epoch 00235: val_loss did not improve from 0.49957\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6686 - acc: 0.8042 - val_loss: 0.5074 - val_acc: 0.8644\n",
      "Epoch 236/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6677 - acc: 0.8029\n",
      "Epoch 00236: val_loss did not improve from 0.49957\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6681 - acc: 0.8028 - val_loss: 0.5047 - val_acc: 0.8656\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6616 - acc: 0.8043\n",
      "Epoch 00237: val_loss did not improve from 0.49957\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6617 - acc: 0.8042 - val_loss: 0.5015 - val_acc: 0.8658\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6608 - acc: 0.8032\n",
      "Epoch 00238: val_loss improved from 0.49957 to 0.49716, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/238-0.4972.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6607 - acc: 0.8032 - val_loss: 0.4972 - val_acc: 0.8654\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6556 - acc: 0.8069\n",
      "Epoch 00239: val_loss did not improve from 0.49716\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6556 - acc: 0.8068 - val_loss: 0.5003 - val_acc: 0.8654\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6584 - acc: 0.8062\n",
      "Epoch 00240: val_loss did not improve from 0.49716\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.6583 - acc: 0.8062 - val_loss: 0.5050 - val_acc: 0.8644\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6549 - acc: 0.8061\n",
      "Epoch 00241: val_loss did not improve from 0.49716\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6549 - acc: 0.8061 - val_loss: 0.5029 - val_acc: 0.8656\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6634 - acc: 0.8042\n",
      "Epoch 00242: val_loss did not improve from 0.49716\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6634 - acc: 0.8042 - val_loss: 0.5000 - val_acc: 0.8665\n",
      "Epoch 243/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6537 - acc: 0.8078\n",
      "Epoch 00243: val_loss improved from 0.49716 to 0.48553, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/243-0.4855.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6538 - acc: 0.8079 - val_loss: 0.4855 - val_acc: 0.8689\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6557 - acc: 0.8068\n",
      "Epoch 00244: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6557 - acc: 0.8068 - val_loss: 0.5054 - val_acc: 0.8663\n",
      "Epoch 245/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6539 - acc: 0.8072\n",
      "Epoch 00245: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.6539 - acc: 0.8070 - val_loss: 0.4992 - val_acc: 0.8670\n",
      "Epoch 246/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6553 - acc: 0.8058\n",
      "Epoch 00246: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.6554 - acc: 0.8057 - val_loss: 0.4944 - val_acc: 0.8668\n",
      "Epoch 247/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6496 - acc: 0.8100\n",
      "Epoch 00247: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.6492 - acc: 0.8101 - val_loss: 0.4882 - val_acc: 0.8724\n",
      "Epoch 248/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6492 - acc: 0.8072\n",
      "Epoch 00248: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.6492 - acc: 0.8073 - val_loss: 0.4938 - val_acc: 0.8663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6470 - acc: 0.8086\n",
      "Epoch 00249: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.6473 - acc: 0.8084 - val_loss: 0.4881 - val_acc: 0.8682\n",
      "Epoch 250/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6531 - acc: 0.8080\n",
      "Epoch 00250: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6536 - acc: 0.8079 - val_loss: 0.4858 - val_acc: 0.8689\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6506 - acc: 0.8088- ETA: 2\n",
      "Epoch 00251: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.6505 - acc: 0.8088 - val_loss: 0.4880 - val_acc: 0.8686\n",
      "Epoch 252/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.8081\n",
      "Epoch 00252: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6461 - acc: 0.8080 - val_loss: 0.4989 - val_acc: 0.8658\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6469 - acc: 0.8059\n",
      "Epoch 00253: val_loss did not improve from 0.48553\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.6468 - acc: 0.8059 - val_loss: 0.4929 - val_acc: 0.8649\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6472 - acc: 0.8098\n",
      "Epoch 00254: val_loss improved from 0.48553 to 0.48353, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/254-0.4835.hdf5\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6472 - acc: 0.8098 - val_loss: 0.4835 - val_acc: 0.8735\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6401 - acc: 0.8106\n",
      "Epoch 00255: val_loss did not improve from 0.48353\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.6400 - acc: 0.8106 - val_loss: 0.4850 - val_acc: 0.8717\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6429 - acc: 0.8111\n",
      "Epoch 00256: val_loss did not improve from 0.48353\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6428 - acc: 0.8111 - val_loss: 0.4974 - val_acc: 0.8684\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6433 - acc: 0.8127\n",
      "Epoch 00257: val_loss did not improve from 0.48353\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.6432 - acc: 0.8127 - val_loss: 0.4836 - val_acc: 0.8700\n",
      "Epoch 258/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6420 - acc: 0.8106\n",
      "Epoch 00258: val_loss improved from 0.48353 to 0.48050, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/258-0.4805.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.6417 - acc: 0.8108 - val_loss: 0.4805 - val_acc: 0.8740\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6398 - acc: 0.8115\n",
      "Epoch 00259: val_loss did not improve from 0.48050\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.6398 - acc: 0.8115 - val_loss: 0.4849 - val_acc: 0.8740\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6399 - acc: 0.8107\n",
      "Epoch 00260: val_loss improved from 0.48050 to 0.47779, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/260-0.4778.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.6399 - acc: 0.8107 - val_loss: 0.4778 - val_acc: 0.8726\n",
      "Epoch 261/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6378 - acc: 0.8112\n",
      "Epoch 00261: val_loss improved from 0.47779 to 0.47707, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/261-0.4771.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.6377 - acc: 0.8112 - val_loss: 0.4771 - val_acc: 0.8721\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6388 - acc: 0.8114\n",
      "Epoch 00262: val_loss did not improve from 0.47707\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.6388 - acc: 0.8114 - val_loss: 0.4809 - val_acc: 0.8717\n",
      "Epoch 263/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6339 - acc: 0.8124\n",
      "Epoch 00263: val_loss did not improve from 0.47707\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.6340 - acc: 0.8123 - val_loss: 0.4795 - val_acc: 0.8751\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6394 - acc: 0.8143\n",
      "Epoch 00264: val_loss did not improve from 0.47707\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.6394 - acc: 0.8143 - val_loss: 0.4903 - val_acc: 0.8730\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6371 - acc: 0.8115\n",
      "Epoch 00265: val_loss did not improve from 0.47707\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6371 - acc: 0.8115 - val_loss: 0.4920 - val_acc: 0.8730\n",
      "Epoch 266/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6296 - acc: 0.8133\n",
      "Epoch 00266: val_loss did not improve from 0.47707\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6295 - acc: 0.8133 - val_loss: 0.4808 - val_acc: 0.8712\n",
      "Epoch 267/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6312 - acc: 0.8120\n",
      "Epoch 00267: val_loss improved from 0.47707 to 0.47607, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/267-0.4761.hdf5\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.6312 - acc: 0.8120 - val_loss: 0.4761 - val_acc: 0.8698\n",
      "Epoch 268/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6340 - acc: 0.8124\n",
      "Epoch 00268: val_loss did not improve from 0.47607\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6341 - acc: 0.8122 - val_loss: 0.4845 - val_acc: 0.8747\n",
      "Epoch 269/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6330 - acc: 0.8141\n",
      "Epoch 00269: val_loss did not improve from 0.47607\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6329 - acc: 0.8141 - val_loss: 0.4895 - val_acc: 0.8707\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6322 - acc: 0.8148\n",
      "Epoch 00270: val_loss did not improve from 0.47607\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6323 - acc: 0.8147 - val_loss: 0.4791 - val_acc: 0.8730\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6316 - acc: 0.8138\n",
      "Epoch 00271: val_loss did not improve from 0.47607\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.6316 - acc: 0.8137 - val_loss: 0.4775 - val_acc: 0.8775\n",
      "Epoch 272/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6375 - acc: 0.8117\n",
      "Epoch 00272: val_loss did not improve from 0.47607\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.6375 - acc: 0.8117 - val_loss: 0.4857 - val_acc: 0.8684\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6286 - acc: 0.8147\n",
      "Epoch 00273: val_loss improved from 0.47607 to 0.47476, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/273-0.4748.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.6286 - acc: 0.8147 - val_loss: 0.4748 - val_acc: 0.8749\n",
      "Epoch 274/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6292 - acc: 0.8148\n",
      "Epoch 00274: val_loss improved from 0.47476 to 0.47131, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/274-0.4713.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.6295 - acc: 0.8148 - val_loss: 0.4713 - val_acc: 0.8742\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.8140\n",
      "Epoch 00275: val_loss did not improve from 0.47131\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.6309 - acc: 0.8140 - val_loss: 0.4745 - val_acc: 0.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6298 - acc: 0.8145\n",
      "Epoch 00276: val_loss improved from 0.47131 to 0.46957, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/276-0.4696.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.6298 - acc: 0.8145 - val_loss: 0.4696 - val_acc: 0.8782\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6230 - acc: 0.8169\n",
      "Epoch 00277: val_loss improved from 0.46957 to 0.46508, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/277-0.4651.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6229 - acc: 0.8169 - val_loss: 0.4651 - val_acc: 0.8772\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6243 - acc: 0.8171\n",
      "Epoch 00278: val_loss did not improve from 0.46508\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.6243 - acc: 0.8171 - val_loss: 0.4706 - val_acc: 0.8761\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6254 - acc: 0.8141\n",
      "Epoch 00279: val_loss did not improve from 0.46508\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6254 - acc: 0.8141 - val_loss: 0.4723 - val_acc: 0.8733\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6223 - acc: 0.8164\n",
      "Epoch 00280: val_loss did not improve from 0.46508\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6223 - acc: 0.8164 - val_loss: 0.4764 - val_acc: 0.8751\n",
      "Epoch 281/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6263 - acc: 0.8151\n",
      "Epoch 00281: val_loss did not improve from 0.46508\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6264 - acc: 0.8151 - val_loss: 0.4752 - val_acc: 0.8749\n",
      "Epoch 282/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6283 - acc: 0.8146\n",
      "Epoch 00282: val_loss did not improve from 0.46508\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.6283 - acc: 0.8145 - val_loss: 0.4739 - val_acc: 0.8712\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6174 - acc: 0.8182\n",
      "Epoch 00283: val_loss improved from 0.46508 to 0.46465, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/283-0.4647.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.6174 - acc: 0.8183 - val_loss: 0.4647 - val_acc: 0.8751\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6199 - acc: 0.8176\n",
      "Epoch 00284: val_loss did not improve from 0.46465\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6199 - acc: 0.8177 - val_loss: 0.4650 - val_acc: 0.8761\n",
      "Epoch 285/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6188 - acc: 0.8171\n",
      "Epoch 00285: val_loss improved from 0.46465 to 0.46262, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/285-0.4626.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6185 - acc: 0.8172 - val_loss: 0.4626 - val_acc: 0.8768\n",
      "Epoch 286/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.8183\n",
      "Epoch 00286: val_loss improved from 0.46262 to 0.45940, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/286-0.4594.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.6148 - acc: 0.8184 - val_loss: 0.4594 - val_acc: 0.8777\n",
      "Epoch 287/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6158 - acc: 0.8171\n",
      "Epoch 00287: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.6158 - acc: 0.8171 - val_loss: 0.4664 - val_acc: 0.8758\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6177 - acc: 0.8171\n",
      "Epoch 00288: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6176 - acc: 0.8171 - val_loss: 0.4658 - val_acc: 0.8772\n",
      "Epoch 289/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.8184\n",
      "Epoch 00289: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6161 - acc: 0.8184 - val_loss: 0.4766 - val_acc: 0.8728\n",
      "Epoch 290/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6139 - acc: 0.8195\n",
      "Epoch 00290: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.6139 - acc: 0.8194 - val_loss: 0.4633 - val_acc: 0.8784\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6153 - acc: 0.8198\n",
      "Epoch 00291: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6153 - acc: 0.8198 - val_loss: 0.4669 - val_acc: 0.8777\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.8191\n",
      "Epoch 00292: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6097 - acc: 0.8191 - val_loss: 0.4618 - val_acc: 0.8765\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.8199\n",
      "Epoch 00293: val_loss did not improve from 0.45940\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6110 - acc: 0.8199 - val_loss: 0.4684 - val_acc: 0.8756\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6082 - acc: 0.8205\n",
      "Epoch 00294: val_loss improved from 0.45940 to 0.45818, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/294-0.4582.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6082 - acc: 0.8205 - val_loss: 0.4582 - val_acc: 0.8791\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6084 - acc: 0.8210\n",
      "Epoch 00295: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6085 - acc: 0.8210 - val_loss: 0.4637 - val_acc: 0.8821\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.8180\n",
      "Epoch 00296: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.6120 - acc: 0.8180 - val_loss: 0.4608 - val_acc: 0.8810\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6087 - acc: 0.8206\n",
      "Epoch 00297: val_loss did not improve from 0.45818\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.6088 - acc: 0.8206 - val_loss: 0.4615 - val_acc: 0.8775\n",
      "Epoch 298/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6116 - acc: 0.8197\n",
      "Epoch 00298: val_loss improved from 0.45818 to 0.45589, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/298-0.4559.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6118 - acc: 0.8197 - val_loss: 0.4559 - val_acc: 0.8768\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6070 - acc: 0.8190\n",
      "Epoch 00299: val_loss did not improve from 0.45589\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.6071 - acc: 0.8190 - val_loss: 0.4573 - val_acc: 0.8770\n",
      "Epoch 300/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6061 - acc: 0.8192\n",
      "Epoch 00300: val_loss improved from 0.45589 to 0.45522, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/300-0.4552.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.6060 - acc: 0.8193 - val_loss: 0.4552 - val_acc: 0.8798\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8181\n",
      "Epoch 00301: val_loss improved from 0.45522 to 0.45367, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/301-0.4537.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.6031 - acc: 0.8181 - val_loss: 0.4537 - val_acc: 0.8796\n",
      "Epoch 302/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6038 - acc: 0.8226\n",
      "Epoch 00302: val_loss did not improve from 0.45367\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6037 - acc: 0.8226 - val_loss: 0.4596 - val_acc: 0.8810\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.8211\n",
      "Epoch 00303: val_loss improved from 0.45367 to 0.45196, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/303-0.4520.hdf5\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6043 - acc: 0.8211 - val_loss: 0.4520 - val_acc: 0.8789\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6015 - acc: 0.8217\n",
      "Epoch 00304: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6015 - acc: 0.8217 - val_loss: 0.4596 - val_acc: 0.8770\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6081 - acc: 0.8213\n",
      "Epoch 00305: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.6080 - acc: 0.8214 - val_loss: 0.4610 - val_acc: 0.8782\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6049 - acc: 0.8210\n",
      "Epoch 00306: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.6049 - acc: 0.8210 - val_loss: 0.4540 - val_acc: 0.8786\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.8218\n",
      "Epoch 00307: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.6023 - acc: 0.8218 - val_loss: 0.4678 - val_acc: 0.8777\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6030 - acc: 0.8216\n",
      "Epoch 00308: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.6030 - acc: 0.8216 - val_loss: 0.4552 - val_acc: 0.8805\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5987 - acc: 0.8225\n",
      "Epoch 00309: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.5987 - acc: 0.8225 - val_loss: 0.4625 - val_acc: 0.8765\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.8225\n",
      "Epoch 00310: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.5996 - acc: 0.8225 - val_loss: 0.4531 - val_acc: 0.8784\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5995 - acc: 0.8220\n",
      "Epoch 00311: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5994 - acc: 0.8220 - val_loss: 0.4537 - val_acc: 0.8786\n",
      "Epoch 312/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5979 - acc: 0.8214\n",
      "Epoch 00312: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.5977 - acc: 0.8215 - val_loss: 0.4532 - val_acc: 0.8805\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5981 - acc: 0.8244\n",
      "Epoch 00313: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.5981 - acc: 0.8244 - val_loss: 0.4583 - val_acc: 0.8800\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5990 - acc: 0.8233\n",
      "Epoch 00314: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.5992 - acc: 0.8233 - val_loss: 0.4521 - val_acc: 0.8793\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5952 - acc: 0.8238\n",
      "Epoch 00315: val_loss did not improve from 0.45196\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.5951 - acc: 0.8238 - val_loss: 0.4551 - val_acc: 0.8826\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6000 - acc: 0.8218\n",
      "Epoch 00316: val_loss improved from 0.45196 to 0.44493, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/316-0.4449.hdf5\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.6000 - acc: 0.8218 - val_loss: 0.4449 - val_acc: 0.8828\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.8231\n",
      "Epoch 00317: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.5996 - acc: 0.8231 - val_loss: 0.4521 - val_acc: 0.8817\n",
      "Epoch 318/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5958 - acc: 0.8243\n",
      "Epoch 00318: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 30s 804us/sample - loss: 0.5962 - acc: 0.8242 - val_loss: 0.4547 - val_acc: 0.8800\n",
      "Epoch 319/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5957 - acc: 0.8213\n",
      "Epoch 00319: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5958 - acc: 0.8213 - val_loss: 0.4493 - val_acc: 0.8852\n",
      "Epoch 320/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5963 - acc: 0.8244\n",
      "Epoch 00320: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5962 - acc: 0.8245 - val_loss: 0.4472 - val_acc: 0.8854\n",
      "Epoch 321/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5992 - acc: 0.8225\n",
      "Epoch 00321: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5991 - acc: 0.8225 - val_loss: 0.4500 - val_acc: 0.8784\n",
      "Epoch 322/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.8254\n",
      "Epoch 00322: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5896 - acc: 0.8254 - val_loss: 0.4481 - val_acc: 0.8835\n",
      "Epoch 323/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5915 - acc: 0.8246\n",
      "Epoch 00323: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5922 - acc: 0.8246 - val_loss: 0.4459 - val_acc: 0.8866\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5876 - acc: 0.8261\n",
      "Epoch 00324: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5876 - acc: 0.8261 - val_loss: 0.4483 - val_acc: 0.8810\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5934 - acc: 0.8256\n",
      "Epoch 00325: val_loss did not improve from 0.44493\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5933 - acc: 0.8256 - val_loss: 0.4511 - val_acc: 0.8807\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5851 - acc: 0.8261\n",
      "Epoch 00326: val_loss improved from 0.44493 to 0.44427, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/326-0.4443.hdf5\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.5852 - acc: 0.8261 - val_loss: 0.4443 - val_acc: 0.8842\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5892 - acc: 0.8260\n",
      "Epoch 00327: val_loss did not improve from 0.44427\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5892 - acc: 0.8260 - val_loss: 0.4482 - val_acc: 0.8807\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5926 - acc: 0.8241\n",
      "Epoch 00328: val_loss improved from 0.44427 to 0.44063, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/328-0.4406.hdf5\n",
      "36805/36805 [==============================] - 30s 805us/sample - loss: 0.5926 - acc: 0.8241 - val_loss: 0.4406 - val_acc: 0.8817\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5875 - acc: 0.8247\n",
      "Epoch 00329: val_loss did not improve from 0.44063\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5875 - acc: 0.8247 - val_loss: 0.4433 - val_acc: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5878 - acc: 0.8257\n",
      "Epoch 00330: val_loss improved from 0.44063 to 0.43642, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/330-0.4364.hdf5\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5878 - acc: 0.8257 - val_loss: 0.4364 - val_acc: 0.8840\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5791 - acc: 0.8273\n",
      "Epoch 00331: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5791 - acc: 0.8273 - val_loss: 0.4401 - val_acc: 0.8852\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5810 - acc: 0.8271\n",
      "Epoch 00332: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5810 - acc: 0.8271 - val_loss: 0.4415 - val_acc: 0.8840\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5884 - acc: 0.8259\n",
      "Epoch 00333: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5883 - acc: 0.8259 - val_loss: 0.4491 - val_acc: 0.8819\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5761 - acc: 0.8284\n",
      "Epoch 00334: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.5761 - acc: 0.8284 - val_loss: 0.4364 - val_acc: 0.8826\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5803 - acc: 0.8263\n",
      "Epoch 00335: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5803 - acc: 0.8263 - val_loss: 0.4383 - val_acc: 0.8849\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5824 - acc: 0.8297\n",
      "Epoch 00336: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5823 - acc: 0.8298 - val_loss: 0.4447 - val_acc: 0.8835\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5804 - acc: 0.8279\n",
      "Epoch 00337: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5804 - acc: 0.8279 - val_loss: 0.4482 - val_acc: 0.8810\n",
      "Epoch 338/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5802 - acc: 0.8291\n",
      "Epoch 00338: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5801 - acc: 0.8292 - val_loss: 0.4451 - val_acc: 0.8828\n",
      "Epoch 339/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.8262\n",
      "Epoch 00339: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5853 - acc: 0.8261 - val_loss: 0.4422 - val_acc: 0.8807\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5846 - acc: 0.8263\n",
      "Epoch 00340: val_loss did not improve from 0.43642\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.5845 - acc: 0.8263 - val_loss: 0.4381 - val_acc: 0.8845\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5749 - acc: 0.8307\n",
      "Epoch 00341: val_loss improved from 0.43642 to 0.43394, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/341-0.4339.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5748 - acc: 0.8307 - val_loss: 0.4339 - val_acc: 0.8856\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5781 - acc: 0.8301\n",
      "Epoch 00342: val_loss did not improve from 0.43394\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.5781 - acc: 0.8301 - val_loss: 0.4376 - val_acc: 0.8840\n",
      "Epoch 343/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5782 - acc: 0.8297\n",
      "Epoch 00343: val_loss did not improve from 0.43394\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.5785 - acc: 0.8296 - val_loss: 0.4360 - val_acc: 0.8854\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5775 - acc: 0.8307\n",
      "Epoch 00344: val_loss did not improve from 0.43394\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.5775 - acc: 0.8307 - val_loss: 0.4384 - val_acc: 0.8842\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5781 - acc: 0.8286\n",
      "Epoch 00345: val_loss improved from 0.43394 to 0.43390, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/345-0.4339.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.5781 - acc: 0.8285 - val_loss: 0.4339 - val_acc: 0.8852\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.8303\n",
      "Epoch 00346: val_loss did not improve from 0.43390\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.5729 - acc: 0.8303 - val_loss: 0.4356 - val_acc: 0.8840\n",
      "Epoch 347/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.8296\n",
      "Epoch 00347: val_loss did not improve from 0.43390\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5762 - acc: 0.8297 - val_loss: 0.4377 - val_acc: 0.8840\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5745 - acc: 0.8304\n",
      "Epoch 00348: val_loss did not improve from 0.43390\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5745 - acc: 0.8304 - val_loss: 0.4386 - val_acc: 0.8833\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5799 - acc: 0.8288\n",
      "Epoch 00349: val_loss did not improve from 0.43390\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5799 - acc: 0.8288 - val_loss: 0.4377 - val_acc: 0.8840\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5716 - acc: 0.8330\n",
      "Epoch 00350: val_loss improved from 0.43390 to 0.43318, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/350-0.4332.hdf5\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.5716 - acc: 0.8330 - val_loss: 0.4332 - val_acc: 0.8824\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5669 - acc: 0.8309\n",
      "Epoch 00351: val_loss did not improve from 0.43318\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.5669 - acc: 0.8309 - val_loss: 0.4407 - val_acc: 0.8824\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5763 - acc: 0.8287\n",
      "Epoch 00352: val_loss did not improve from 0.43318\n",
      "36805/36805 [==============================] - 30s 803us/sample - loss: 0.5764 - acc: 0.8287 - val_loss: 0.4367 - val_acc: 0.8819\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5726 - acc: 0.8301\n",
      "Epoch 00353: val_loss did not improve from 0.43318\n",
      "36805/36805 [==============================] - 30s 806us/sample - loss: 0.5725 - acc: 0.8301 - val_loss: 0.4512 - val_acc: 0.8835\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5694 - acc: 0.8304\n",
      "Epoch 00354: val_loss improved from 0.43318 to 0.43121, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/354-0.4312.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5694 - acc: 0.8304 - val_loss: 0.4312 - val_acc: 0.8852\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.8314\n",
      "Epoch 00355: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.5708 - acc: 0.8314 - val_loss: 0.4356 - val_acc: 0.8873\n",
      "Epoch 356/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5660 - acc: 0.8322\n",
      "Epoch 00356: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.5666 - acc: 0.8320 - val_loss: 0.4419 - val_acc: 0.8826\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.8280\n",
      "Epoch 00357: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.5789 - acc: 0.8280 - val_loss: 0.4315 - val_acc: 0.8856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5714 - acc: 0.8297\n",
      "Epoch 00358: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5714 - acc: 0.8296 - val_loss: 0.4358 - val_acc: 0.8845\n",
      "Epoch 359/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5692 - acc: 0.8314\n",
      "Epoch 00359: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5692 - acc: 0.8314 - val_loss: 0.4340 - val_acc: 0.8854\n",
      "Epoch 360/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5694 - acc: 0.8327\n",
      "Epoch 00360: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.5691 - acc: 0.8328 - val_loss: 0.4334 - val_acc: 0.8868\n",
      "Epoch 361/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5626 - acc: 0.8325\n",
      "Epoch 00361: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5625 - acc: 0.8324 - val_loss: 0.4434 - val_acc: 0.8817\n",
      "Epoch 362/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8319\n",
      "Epoch 00362: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5699 - acc: 0.8320 - val_loss: 0.4335 - val_acc: 0.8882\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5722 - acc: 0.8310\n",
      "Epoch 00363: val_loss did not improve from 0.43121\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5722 - acc: 0.8309 - val_loss: 0.4413 - val_acc: 0.8880\n",
      "Epoch 364/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5602 - acc: 0.8321\n",
      "Epoch 00364: val_loss improved from 0.43121 to 0.43033, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/364-0.4303.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5604 - acc: 0.8321 - val_loss: 0.4303 - val_acc: 0.8877\n",
      "Epoch 365/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5590 - acc: 0.8350\n",
      "Epoch 00365: val_loss did not improve from 0.43033\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5588 - acc: 0.8350 - val_loss: 0.4350 - val_acc: 0.8880\n",
      "Epoch 366/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5669 - acc: 0.8332\n",
      "Epoch 00366: val_loss improved from 0.43033 to 0.42788, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/366-0.4279.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5666 - acc: 0.8333 - val_loss: 0.4279 - val_acc: 0.8868\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5672 - acc: 0.8335\n",
      "Epoch 00367: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5672 - acc: 0.8335 - val_loss: 0.4297 - val_acc: 0.8873\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5661 - acc: 0.8338\n",
      "Epoch 00368: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5660 - acc: 0.8338 - val_loss: 0.4305 - val_acc: 0.8875\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5685 - acc: 0.8301\n",
      "Epoch 00369: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5684 - acc: 0.8301 - val_loss: 0.4347 - val_acc: 0.8845\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5644 - acc: 0.8327\n",
      "Epoch 00370: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5644 - acc: 0.8327 - val_loss: 0.4337 - val_acc: 0.8873\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5615 - acc: 0.8348\n",
      "Epoch 00371: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5615 - acc: 0.8348 - val_loss: 0.4396 - val_acc: 0.8838\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.8348\n",
      "Epoch 00372: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5621 - acc: 0.8348 - val_loss: 0.4293 - val_acc: 0.8852\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.8345\n",
      "Epoch 00373: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5613 - acc: 0.8345 - val_loss: 0.4366 - val_acc: 0.8863\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5591 - acc: 0.8336\n",
      "Epoch 00374: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5592 - acc: 0.8335 - val_loss: 0.4328 - val_acc: 0.8856\n",
      "Epoch 375/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5576 - acc: 0.8352\n",
      "Epoch 00375: val_loss did not improve from 0.42788\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5577 - acc: 0.8352 - val_loss: 0.4282 - val_acc: 0.8847\n",
      "Epoch 376/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5574 - acc: 0.8348\n",
      "Epoch 00376: val_loss improved from 0.42788 to 0.42659, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/376-0.4266.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5573 - acc: 0.8348 - val_loss: 0.4266 - val_acc: 0.8905\n",
      "Epoch 377/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5566 - acc: 0.8341\n",
      "Epoch 00377: val_loss did not improve from 0.42659\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5564 - acc: 0.8342 - val_loss: 0.4308 - val_acc: 0.8821\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5559 - acc: 0.8348\n",
      "Epoch 00378: val_loss did not improve from 0.42659\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5559 - acc: 0.8348 - val_loss: 0.4301 - val_acc: 0.8866\n",
      "Epoch 379/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5589 - acc: 0.8348\n",
      "Epoch 00379: val_loss did not improve from 0.42659\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5588 - acc: 0.8349 - val_loss: 0.4288 - val_acc: 0.8840\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5623 - acc: 0.8326\n",
      "Epoch 00380: val_loss improved from 0.42659 to 0.42604, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/380-0.4260.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5623 - acc: 0.8327 - val_loss: 0.4260 - val_acc: 0.8866\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5575 - acc: 0.8348\n",
      "Epoch 00381: val_loss did not improve from 0.42604\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5575 - acc: 0.8348 - val_loss: 0.4267 - val_acc: 0.8868\n",
      "Epoch 382/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5551 - acc: 0.8358\n",
      "Epoch 00382: val_loss did not improve from 0.42604\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5549 - acc: 0.8358 - val_loss: 0.4300 - val_acc: 0.8852\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5536 - acc: 0.8359\n",
      "Epoch 00383: val_loss did not improve from 0.42604\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5536 - acc: 0.8359 - val_loss: 0.4277 - val_acc: 0.8898\n",
      "Epoch 384/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5537 - acc: 0.8334\n",
      "Epoch 00384: val_loss did not improve from 0.42604\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5536 - acc: 0.8334 - val_loss: 0.4299 - val_acc: 0.8880\n",
      "Epoch 385/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5567 - acc: 0.8339\n",
      "Epoch 00385: val_loss did not improve from 0.42604\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5565 - acc: 0.8340 - val_loss: 0.4305 - val_acc: 0.8856\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5572 - acc: 0.8340\n",
      "Epoch 00386: val_loss did not improve from 0.42604\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5571 - acc: 0.8340 - val_loss: 0.4381 - val_acc: 0.8838\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5523 - acc: 0.8364\n",
      "Epoch 00387: val_loss improved from 0.42604 to 0.42603, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/387-0.4260.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5523 - acc: 0.8363 - val_loss: 0.4260 - val_acc: 0.8901\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5569 - acc: 0.8342\n",
      "Epoch 00388: val_loss did not improve from 0.42603\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5568 - acc: 0.8342 - val_loss: 0.4328 - val_acc: 0.8859\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.8352\n",
      "Epoch 00389: val_loss improved from 0.42603 to 0.42203, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/389-0.4220.hdf5\n",
      "36805/36805 [==============================] - 30s 802us/sample - loss: 0.5540 - acc: 0.8352 - val_loss: 0.4220 - val_acc: 0.8901\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5497 - acc: 0.8366\n",
      "Epoch 00390: val_loss did not improve from 0.42203\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5499 - acc: 0.8366 - val_loss: 0.4225 - val_acc: 0.8889\n",
      "Epoch 391/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5551 - acc: 0.8346\n",
      "Epoch 00391: val_loss did not improve from 0.42203\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5548 - acc: 0.8347 - val_loss: 0.4358 - val_acc: 0.8868\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5533 - acc: 0.8366\n",
      "Epoch 00392: val_loss did not improve from 0.42203\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5533 - acc: 0.8366 - val_loss: 0.4312 - val_acc: 0.8859\n",
      "Epoch 393/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.8352\n",
      "Epoch 00393: val_loss did not improve from 0.42203\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5538 - acc: 0.8353 - val_loss: 0.4235 - val_acc: 0.8849\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.8371\n",
      "Epoch 00394: val_loss did not improve from 0.42203\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5506 - acc: 0.8370 - val_loss: 0.4230 - val_acc: 0.8889\n",
      "Epoch 395/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5480 - acc: 0.8356\n",
      "Epoch 00395: val_loss did not improve from 0.42203\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.5478 - acc: 0.8356 - val_loss: 0.4238 - val_acc: 0.8894\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.8372\n",
      "Epoch 00396: val_loss improved from 0.42203 to 0.42011, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/396-0.4201.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5484 - acc: 0.8372 - val_loss: 0.4201 - val_acc: 0.8896\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5483 - acc: 0.8373\n",
      "Epoch 00397: val_loss did not improve from 0.42011\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5484 - acc: 0.8373 - val_loss: 0.4263 - val_acc: 0.8891\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5442 - acc: 0.8384\n",
      "Epoch 00398: val_loss did not improve from 0.42011\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5442 - acc: 0.8384 - val_loss: 0.4284 - val_acc: 0.8861\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5464 - acc: 0.8370\n",
      "Epoch 00399: val_loss did not improve from 0.42011\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5464 - acc: 0.8370 - val_loss: 0.4244 - val_acc: 0.8887\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5491 - acc: 0.8390\n",
      "Epoch 00400: val_loss did not improve from 0.42011\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.5491 - acc: 0.8390 - val_loss: 0.4235 - val_acc: 0.8887\n",
      "Epoch 401/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5444 - acc: 0.8380\n",
      "Epoch 00401: val_loss did not improve from 0.42011\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5450 - acc: 0.8378 - val_loss: 0.4225 - val_acc: 0.8894\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5431 - acc: 0.8365\n",
      "Epoch 00402: val_loss improved from 0.42011 to 0.41864, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/402-0.4186.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5431 - acc: 0.8365 - val_loss: 0.4186 - val_acc: 0.8891\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5440 - acc: 0.8395\n",
      "Epoch 00403: val_loss improved from 0.41864 to 0.41855, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/403-0.4185.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5441 - acc: 0.8394 - val_loss: 0.4185 - val_acc: 0.8901\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5459 - acc: 0.8362\n",
      "Epoch 00404: val_loss did not improve from 0.41855\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5459 - acc: 0.8362 - val_loss: 0.4325 - val_acc: 0.8898\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5439 - acc: 0.8391\n",
      "Epoch 00405: val_loss improved from 0.41855 to 0.41808, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/405-0.4181.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5442 - acc: 0.8391 - val_loss: 0.4181 - val_acc: 0.8889\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5503 - acc: 0.8359\n",
      "Epoch 00406: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5504 - acc: 0.8359 - val_loss: 0.4298 - val_acc: 0.8882\n",
      "Epoch 407/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5429 - acc: 0.8381\n",
      "Epoch 00407: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5428 - acc: 0.8381 - val_loss: 0.4214 - val_acc: 0.8877\n",
      "Epoch 408/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5419 - acc: 0.8386\n",
      "Epoch 00408: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5421 - acc: 0.8386 - val_loss: 0.4286 - val_acc: 0.8868\n",
      "Epoch 409/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5340 - acc: 0.8417\n",
      "Epoch 00409: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5351 - acc: 0.8415 - val_loss: 0.4181 - val_acc: 0.8912\n",
      "Epoch 410/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.8396\n",
      "Epoch 00410: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5385 - acc: 0.8395 - val_loss: 0.4243 - val_acc: 0.8884\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5496 - acc: 0.8348\n",
      "Epoch 00411: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5496 - acc: 0.8348 - val_loss: 0.4201 - val_acc: 0.8873\n",
      "Epoch 412/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.8388\n",
      "Epoch 00412: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5395 - acc: 0.8389 - val_loss: 0.4366 - val_acc: 0.8856\n",
      "Epoch 413/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5439 - acc: 0.8386\n",
      "Epoch 00413: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5439 - acc: 0.8387 - val_loss: 0.4251 - val_acc: 0.8842\n",
      "Epoch 414/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5467 - acc: 0.8354\n",
      "Epoch 00414: val_loss did not improve from 0.41808\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5464 - acc: 0.8355 - val_loss: 0.4295 - val_acc: 0.8868\n",
      "Epoch 415/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5406 - acc: 0.8393\n",
      "Epoch 00415: val_loss improved from 0.41808 to 0.41486, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/415-0.4149.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5407 - acc: 0.8392 - val_loss: 0.4149 - val_acc: 0.8912\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5417 - acc: 0.8399\n",
      "Epoch 00416: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.5416 - acc: 0.8399 - val_loss: 0.4275 - val_acc: 0.8912\n",
      "Epoch 417/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.8397\n",
      "Epoch 00417: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5403 - acc: 0.8396 - val_loss: 0.4210 - val_acc: 0.8898\n",
      "Epoch 418/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.8406\n",
      "Epoch 00418: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5361 - acc: 0.8407 - val_loss: 0.4173 - val_acc: 0.8884\n",
      "Epoch 419/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5340 - acc: 0.8396\n",
      "Epoch 00419: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5339 - acc: 0.8396 - val_loss: 0.4195 - val_acc: 0.8887\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5396 - acc: 0.8409\n",
      "Epoch 00420: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.5396 - acc: 0.8409 - val_loss: 0.4204 - val_acc: 0.8889\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.8380\n",
      "Epoch 00421: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5401 - acc: 0.8381 - val_loss: 0.4167 - val_acc: 0.8877\n",
      "Epoch 422/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5357 - acc: 0.8399\n",
      "Epoch 00422: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5359 - acc: 0.8397 - val_loss: 0.4172 - val_acc: 0.8910\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5386 - acc: 0.8410\n",
      "Epoch 00423: val_loss did not improve from 0.41486\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5385 - acc: 0.8410 - val_loss: 0.4161 - val_acc: 0.8908\n",
      "Epoch 424/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5315 - acc: 0.8412\n",
      "Epoch 00424: val_loss improved from 0.41486 to 0.41435, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/424-0.4144.hdf5\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5317 - acc: 0.8411 - val_loss: 0.4144 - val_acc: 0.8896\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5320 - acc: 0.8425\n",
      "Epoch 00425: val_loss did not improve from 0.41435\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5319 - acc: 0.8425 - val_loss: 0.4210 - val_acc: 0.8915\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5324 - acc: 0.8420\n",
      "Epoch 00426: val_loss did not improve from 0.41435\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.5323 - acc: 0.8420 - val_loss: 0.4190 - val_acc: 0.8942\n",
      "Epoch 427/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5351 - acc: 0.8415\n",
      "Epoch 00427: val_loss improved from 0.41435 to 0.41431, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/427-0.4143.hdf5\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5348 - acc: 0.8415 - val_loss: 0.4143 - val_acc: 0.8894\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5363 - acc: 0.8388\n",
      "Epoch 00428: val_loss did not improve from 0.41431\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5363 - acc: 0.8388 - val_loss: 0.4193 - val_acc: 0.8910\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5341 - acc: 0.8397\n",
      "Epoch 00429: val_loss did not improve from 0.41431\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5340 - acc: 0.8398 - val_loss: 0.4183 - val_acc: 0.8931\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5330 - acc: 0.8424\n",
      "Epoch 00430: val_loss did not improve from 0.41431\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5330 - acc: 0.8425 - val_loss: 0.4161 - val_acc: 0.8901\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.8442\n",
      "Epoch 00431: val_loss did not improve from 0.41431\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5284 - acc: 0.8442 - val_loss: 0.4204 - val_acc: 0.8877\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5307 - acc: 0.8411\n",
      "Epoch 00432: val_loss did not improve from 0.41431\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5307 - acc: 0.8410 - val_loss: 0.4202 - val_acc: 0.8910\n",
      "Epoch 433/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5398 - acc: 0.8412\n",
      "Epoch 00433: val_loss did not improve from 0.41431\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5401 - acc: 0.8411 - val_loss: 0.4188 - val_acc: 0.8912\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5328 - acc: 0.8424\n",
      "Epoch 00434: val_loss improved from 0.41431 to 0.41324, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/434-0.4132.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5328 - acc: 0.8425 - val_loss: 0.4132 - val_acc: 0.8901\n",
      "Epoch 435/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.8429\n",
      "Epoch 00435: val_loss did not improve from 0.41324\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.5259 - acc: 0.8429 - val_loss: 0.4139 - val_acc: 0.8905\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5252 - acc: 0.8453\n",
      "Epoch 00436: val_loss did not improve from 0.41324\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5254 - acc: 0.8452 - val_loss: 0.4185 - val_acc: 0.8896\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5254 - acc: 0.8445\n",
      "Epoch 00437: val_loss did not improve from 0.41324\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5254 - acc: 0.8445 - val_loss: 0.4138 - val_acc: 0.8898\n",
      "Epoch 438/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5267 - acc: 0.8430\n",
      "Epoch 00438: val_loss improved from 0.41324 to 0.40979, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/438-0.4098.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5268 - acc: 0.8430 - val_loss: 0.4098 - val_acc: 0.8903\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5322 - acc: 0.8417\n",
      "Epoch 00439: val_loss improved from 0.40979 to 0.40974, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/439-0.4097.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5322 - acc: 0.8417 - val_loss: 0.4097 - val_acc: 0.8908\n",
      "Epoch 440/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.8437\n",
      "Epoch 00440: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5250 - acc: 0.8436 - val_loss: 0.4173 - val_acc: 0.8880\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5269 - acc: 0.8439\n",
      "Epoch 00441: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5268 - acc: 0.8439 - val_loss: 0.4104 - val_acc: 0.8917\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5230 - acc: 0.8435\n",
      "Epoch 00442: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5229 - acc: 0.8435 - val_loss: 0.4177 - val_acc: 0.8889\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5277 - acc: 0.8418\n",
      "Epoch 00443: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5276 - acc: 0.8418 - val_loss: 0.4150 - val_acc: 0.8903\n",
      "Epoch 444/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5241 - acc: 0.8449\n",
      "Epoch 00444: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5243 - acc: 0.8449 - val_loss: 0.4228 - val_acc: 0.8915\n",
      "Epoch 445/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5327 - acc: 0.8418\n",
      "Epoch 00445: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5325 - acc: 0.8418 - val_loss: 0.4186 - val_acc: 0.8908\n",
      "Epoch 446/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5251 - acc: 0.8410\n",
      "Epoch 00446: val_loss did not improve from 0.40974\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5253 - acc: 0.8411 - val_loss: 0.4148 - val_acc: 0.8919\n",
      "Epoch 447/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5287 - acc: 0.8422\n",
      "Epoch 00447: val_loss improved from 0.40974 to 0.40890, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/447-0.4089.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5289 - acc: 0.8422 - val_loss: 0.4089 - val_acc: 0.8919\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.8426\n",
      "Epoch 00448: val_loss did not improve from 0.40890\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5201 - acc: 0.8425 - val_loss: 0.4135 - val_acc: 0.8912\n",
      "Epoch 449/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5266 - acc: 0.8404\n",
      "Epoch 00449: val_loss improved from 0.40890 to 0.40678, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/449-0.4068.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5264 - acc: 0.8405 - val_loss: 0.4068 - val_acc: 0.8919\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5214 - acc: 0.8449\n",
      "Epoch 00450: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5214 - acc: 0.8449 - val_loss: 0.4131 - val_acc: 0.8891\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5282 - acc: 0.8439\n",
      "Epoch 00451: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5282 - acc: 0.8439 - val_loss: 0.4139 - val_acc: 0.8896\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.8444\n",
      "Epoch 00452: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5243 - acc: 0.8444 - val_loss: 0.4144 - val_acc: 0.8935\n",
      "Epoch 453/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5197 - acc: 0.8460\n",
      "Epoch 00453: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5195 - acc: 0.8460 - val_loss: 0.4171 - val_acc: 0.8908\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5220 - acc: 0.8439\n",
      "Epoch 00454: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5220 - acc: 0.8439 - val_loss: 0.4175 - val_acc: 0.8912\n",
      "Epoch 455/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.8436\n",
      "Epoch 00455: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5202 - acc: 0.8436 - val_loss: 0.4097 - val_acc: 0.8942\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5199 - acc: 0.8454\n",
      "Epoch 00456: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5199 - acc: 0.8453 - val_loss: 0.4096 - val_acc: 0.8915\n",
      "Epoch 457/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5195 - acc: 0.8446\n",
      "Epoch 00457: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5198 - acc: 0.8445 - val_loss: 0.4095 - val_acc: 0.8919\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5222 - acc: 0.8427\n",
      "Epoch 00458: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5223 - acc: 0.8427 - val_loss: 0.4107 - val_acc: 0.8917\n",
      "Epoch 459/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5226 - acc: 0.8447\n",
      "Epoch 00459: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5233 - acc: 0.8446 - val_loss: 0.4124 - val_acc: 0.8905\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5217 - acc: 0.8456\n",
      "Epoch 00460: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5217 - acc: 0.8456 - val_loss: 0.4187 - val_acc: 0.8877\n",
      "Epoch 461/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5162 - acc: 0.8463\n",
      "Epoch 00461: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5159 - acc: 0.8464 - val_loss: 0.4112 - val_acc: 0.8903\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5157 - acc: 0.8438\n",
      "Epoch 00462: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5156 - acc: 0.8438 - val_loss: 0.4084 - val_acc: 0.8915\n",
      "Epoch 463/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5194 - acc: 0.8442\n",
      "Epoch 00463: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5192 - acc: 0.8442 - val_loss: 0.4130 - val_acc: 0.8908\n",
      "Epoch 464/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5137 - acc: 0.8448\n",
      "Epoch 00464: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5138 - acc: 0.8448 - val_loss: 0.4134 - val_acc: 0.8917\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.8483\n",
      "Epoch 00465: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5154 - acc: 0.8483 - val_loss: 0.4219 - val_acc: 0.8917\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5171 - acc: 0.8442\n",
      "Epoch 00466: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5172 - acc: 0.8441 - val_loss: 0.4125 - val_acc: 0.8919\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5132 - acc: 0.8482\n",
      "Epoch 00467: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5132 - acc: 0.8482 - val_loss: 0.4145 - val_acc: 0.8891\n",
      "Epoch 468/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8467\n",
      "Epoch 00468: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5142 - acc: 0.8467 - val_loss: 0.4154 - val_acc: 0.8912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5137 - acc: 0.8472\n",
      "Epoch 00469: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5137 - acc: 0.8472 - val_loss: 0.4085 - val_acc: 0.8903\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5141 - acc: 0.8445\n",
      "Epoch 00470: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5140 - acc: 0.8445 - val_loss: 0.4077 - val_acc: 0.8959\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5109 - acc: 0.8443\n",
      "Epoch 00471: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 801us/sample - loss: 0.5109 - acc: 0.8443 - val_loss: 0.4114 - val_acc: 0.8924\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5153 - acc: 0.8457\n",
      "Epoch 00472: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5152 - acc: 0.8457 - val_loss: 0.4109 - val_acc: 0.8935\n",
      "Epoch 473/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5152 - acc: 0.8453\n",
      "Epoch 00473: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.5149 - acc: 0.8454 - val_loss: 0.4078 - val_acc: 0.8901\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5167 - acc: 0.8463\n",
      "Epoch 00474: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.5167 - acc: 0.8463 - val_loss: 0.4125 - val_acc: 0.8931\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5181 - acc: 0.8452\n",
      "Epoch 00475: val_loss did not improve from 0.40678\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.5181 - acc: 0.8452 - val_loss: 0.4187 - val_acc: 0.8889\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5102 - acc: 0.8475\n",
      "Epoch 00476: val_loss improved from 0.40678 to 0.40534, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/476-0.4053.hdf5\n",
      "36805/36805 [==============================] - 29s 799us/sample - loss: 0.5103 - acc: 0.8474 - val_loss: 0.4053 - val_acc: 0.8910\n",
      "Epoch 477/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5131 - acc: 0.8474\n",
      "Epoch 00477: val_loss did not improve from 0.40534\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5133 - acc: 0.8474 - val_loss: 0.4115 - val_acc: 0.8891\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5047 - acc: 0.8467\n",
      "Epoch 00478: val_loss did not improve from 0.40534\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5047 - acc: 0.8467 - val_loss: 0.4103 - val_acc: 0.8905\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.8467\n",
      "Epoch 00479: val_loss did not improve from 0.40534\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5118 - acc: 0.8467 - val_loss: 0.4241 - val_acc: 0.8928\n",
      "Epoch 480/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5125 - acc: 0.8473\n",
      "Epoch 00480: val_loss did not improve from 0.40534\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 0.5122 - acc: 0.8474 - val_loss: 0.4083 - val_acc: 0.8956\n",
      "Epoch 481/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5085 - acc: 0.8461\n",
      "Epoch 00481: val_loss did not improve from 0.40534\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5083 - acc: 0.8461 - val_loss: 0.4208 - val_acc: 0.8921\n",
      "Epoch 482/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5097 - acc: 0.8492\n",
      "Epoch 00482: val_loss improved from 0.40534 to 0.40532, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/482-0.4053.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5098 - acc: 0.8491 - val_loss: 0.4053 - val_acc: 0.8938\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5064 - acc: 0.8465\n",
      "Epoch 00483: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.5064 - acc: 0.8465 - val_loss: 0.4126 - val_acc: 0.8935\n",
      "Epoch 484/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.8491\n",
      "Epoch 00484: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.5068 - acc: 0.8491 - val_loss: 0.4114 - val_acc: 0.8919\n",
      "Epoch 485/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5087 - acc: 0.8470\n",
      "Epoch 00485: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5091 - acc: 0.8469 - val_loss: 0.4095 - val_acc: 0.8961\n",
      "Epoch 486/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5063 - acc: 0.8475\n",
      "Epoch 00486: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.5060 - acc: 0.8475 - val_loss: 0.4115 - val_acc: 0.8956\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5142 - acc: 0.8465\n",
      "Epoch 00487: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.5142 - acc: 0.8465 - val_loss: 0.4082 - val_acc: 0.8912\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5089 - acc: 0.8479\n",
      "Epoch 00488: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.5089 - acc: 0.8479 - val_loss: 0.4054 - val_acc: 0.8919\n",
      "Epoch 489/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5100 - acc: 0.8467\n",
      "Epoch 00489: val_loss did not improve from 0.40532\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.5100 - acc: 0.8467 - val_loss: 0.4099 - val_acc: 0.8921\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5074 - acc: 0.8468\n",
      "Epoch 00490: val_loss improved from 0.40532 to 0.40251, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/490-0.4025.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.5079 - acc: 0.8468 - val_loss: 0.4025 - val_acc: 0.8933\n",
      "Epoch 491/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.8479\n",
      "Epoch 00491: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.5066 - acc: 0.8480 - val_loss: 0.4126 - val_acc: 0.8940\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.8475\n",
      "Epoch 00492: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 797us/sample - loss: 0.5049 - acc: 0.8475 - val_loss: 0.4049 - val_acc: 0.8940\n",
      "Epoch 493/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5076 - acc: 0.8488\n",
      "Epoch 00493: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 0.5079 - acc: 0.8486 - val_loss: 0.4100 - val_acc: 0.8917\n",
      "Epoch 494/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5087 - acc: 0.8495\n",
      "Epoch 00494: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 791us/sample - loss: 0.5086 - acc: 0.8494 - val_loss: 0.4062 - val_acc: 0.8966\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.8501\n",
      "Epoch 00495: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 796us/sample - loss: 0.5035 - acc: 0.8500 - val_loss: 0.4049 - val_acc: 0.8938\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5046 - acc: 0.8481\n",
      "Epoch 00496: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.5046 - acc: 0.8481 - val_loss: 0.4108 - val_acc: 0.8931\n",
      "Epoch 497/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5038 - acc: 0.8485\n",
      "Epoch 00497: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 794us/sample - loss: 0.5037 - acc: 0.8485 - val_loss: 0.4049 - val_acc: 0.8952\n",
      "Epoch 498/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.8487\n",
      "Epoch 00498: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.5047 - acc: 0.8487 - val_loss: 0.4155 - val_acc: 0.8915\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.8489\n",
      "Epoch 00499: val_loss did not improve from 0.40251\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.5025 - acc: 0.8489 - val_loss: 0.4051 - val_acc: 0.8905\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.8477\n",
      "Epoch 00500: val_loss improved from 0.40251 to 0.39998, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_4_conv_checkpoint/500-0.4000.hdf5\n",
      "36805/36805 [==============================] - 29s 800us/sample - loss: 0.5062 - acc: 0.8477 - val_loss: 0.4000 - val_acc: 0.8963\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 382us/sample - loss: 0.4633 - acc: 0.8665\n",
      "Loss: 0.4633347888849482 Accuracy: 0.866459\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.5803 - acc: 0.1586\n",
      "Epoch 00001: val_loss improved from inf to 2.16382, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/001-2.1638.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 2.5800 - acc: 0.1587 - val_loss: 2.1638 - val_acc: 0.3501\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1127 - acc: 0.3047- ETA: 0s - loss: 2.1156 - acc:\n",
      "Epoch 00002: val_loss improved from 2.16382 to 1.86051, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/002-1.8605.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 2.1126 - acc: 0.3048 - val_loss: 1.8605 - val_acc: 0.4095\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9181 - acc: 0.3680\n",
      "Epoch 00003: val_loss improved from 1.86051 to 1.67803, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/003-1.6780.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.9182 - acc: 0.3680 - val_loss: 1.6780 - val_acc: 0.4780\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7733 - acc: 0.4173\n",
      "Epoch 00004: val_loss improved from 1.67803 to 1.53590, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/004-1.5359.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.7732 - acc: 0.4173 - val_loss: 1.5359 - val_acc: 0.5288\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6554 - acc: 0.4596\n",
      "Epoch 00005: val_loss improved from 1.53590 to 1.44151, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/005-1.4415.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.6554 - acc: 0.4596 - val_loss: 1.4415 - val_acc: 0.5523\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5735 - acc: 0.4891\n",
      "Epoch 00006: val_loss improved from 1.44151 to 1.35632, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/006-1.3563.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 1.5735 - acc: 0.4891 - val_loss: 1.3563 - val_acc: 0.5980\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4919 - acc: 0.5182\n",
      "Epoch 00007: val_loss improved from 1.35632 to 1.29547, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/007-1.2955.hdf5\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 1.4919 - acc: 0.5182 - val_loss: 1.2955 - val_acc: 0.6205\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4331 - acc: 0.5401\n",
      "Epoch 00008: val_loss improved from 1.29547 to 1.23792, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/008-1.2379.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.4334 - acc: 0.5400 - val_loss: 1.2379 - val_acc: 0.6315\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3738 - acc: 0.5636\n",
      "Epoch 00009: val_loss improved from 1.23792 to 1.15665, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/009-1.1566.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 1.3738 - acc: 0.5636 - val_loss: 1.1566 - val_acc: 0.6564\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3192 - acc: 0.5807\n",
      "Epoch 00010: val_loss improved from 1.15665 to 1.10444, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/010-1.1044.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.3191 - acc: 0.5807 - val_loss: 1.1044 - val_acc: 0.6646\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2644 - acc: 0.6019\n",
      "Epoch 00011: val_loss improved from 1.10444 to 1.05490, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/011-1.0549.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.2644 - acc: 0.6019 - val_loss: 1.0549 - val_acc: 0.6928\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2240 - acc: 0.6181\n",
      "Epoch 00012: val_loss improved from 1.05490 to 1.02417, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/012-1.0242.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.2239 - acc: 0.6181 - val_loss: 1.0242 - val_acc: 0.6956\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1847 - acc: 0.6304\n",
      "Epoch 00013: val_loss improved from 1.02417 to 0.98155, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/013-0.9815.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.1847 - acc: 0.6304 - val_loss: 0.9815 - val_acc: 0.7209\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1465 - acc: 0.6438\n",
      "Epoch 00014: val_loss improved from 0.98155 to 0.93528, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/014-0.9353.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.1464 - acc: 0.6438 - val_loss: 0.9353 - val_acc: 0.7347\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1138 - acc: 0.6560\n",
      "Epoch 00015: val_loss improved from 0.93528 to 0.91117, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/015-0.9112.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.1138 - acc: 0.6560 - val_loss: 0.9112 - val_acc: 0.7405\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0815 - acc: 0.6687\n",
      "Epoch 00016: val_loss improved from 0.91117 to 0.86444, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/016-0.8644.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.0815 - acc: 0.6687 - val_loss: 0.8644 - val_acc: 0.7536\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0513 - acc: 0.6801\n",
      "Epoch 00017: val_loss improved from 0.86444 to 0.85427, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/017-0.8543.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 1.0513 - acc: 0.6800 - val_loss: 0.8543 - val_acc: 0.7524\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0166 - acc: 0.6928\n",
      "Epoch 00018: val_loss improved from 0.85427 to 0.82696, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/018-0.8270.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.0166 - acc: 0.6928 - val_loss: 0.8270 - val_acc: 0.7631\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9960 - acc: 0.7031\n",
      "Epoch 00019: val_loss improved from 0.82696 to 0.80451, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/019-0.8045.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.9959 - acc: 0.7031 - val_loss: 0.8045 - val_acc: 0.7764\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9687 - acc: 0.7081\n",
      "Epoch 00020: val_loss improved from 0.80451 to 0.78066, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/020-0.7807.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.9687 - acc: 0.7081 - val_loss: 0.7807 - val_acc: 0.7743\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9451 - acc: 0.7180\n",
      "Epoch 00021: val_loss improved from 0.78066 to 0.74595, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/021-0.7460.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.9450 - acc: 0.7180 - val_loss: 0.7460 - val_acc: 0.7845\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9208 - acc: 0.7263\n",
      "Epoch 00022: val_loss did not improve from 0.74595\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.9206 - acc: 0.7264 - val_loss: 0.7483 - val_acc: 0.7885\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8999 - acc: 0.7316\n",
      "Epoch 00023: val_loss improved from 0.74595 to 0.70315, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/023-0.7031.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8998 - acc: 0.7316 - val_loss: 0.7031 - val_acc: 0.7957\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8750 - acc: 0.7389\n",
      "Epoch 00024: val_loss improved from 0.70315 to 0.69434, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/024-0.6943.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.8750 - acc: 0.7389 - val_loss: 0.6943 - val_acc: 0.7962\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8584 - acc: 0.7478\n",
      "Epoch 00025: val_loss improved from 0.69434 to 0.66554, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/025-0.6655.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.8584 - acc: 0.7478 - val_loss: 0.6655 - val_acc: 0.8090\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8399 - acc: 0.7539\n",
      "Epoch 00026: val_loss did not improve from 0.66554\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.8400 - acc: 0.7538 - val_loss: 0.6692 - val_acc: 0.8113\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8323 - acc: 0.7546\n",
      "Epoch 00027: val_loss improved from 0.66554 to 0.64750, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/027-0.6475.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.8322 - acc: 0.7546 - val_loss: 0.6475 - val_acc: 0.8223\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8099 - acc: 0.7636\n",
      "Epoch 00028: val_loss improved from 0.64750 to 0.64025, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/028-0.6403.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.8099 - acc: 0.7636 - val_loss: 0.6403 - val_acc: 0.8183\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7974 - acc: 0.7664\n",
      "Epoch 00029: val_loss improved from 0.64025 to 0.62760, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/029-0.6276.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7973 - acc: 0.7665 - val_loss: 0.6276 - val_acc: 0.8192\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7798 - acc: 0.7722\n",
      "Epoch 00030: val_loss improved from 0.62760 to 0.60965, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/030-0.6096.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7798 - acc: 0.7722 - val_loss: 0.6096 - val_acc: 0.8330\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7623 - acc: 0.7762\n",
      "Epoch 00031: val_loss improved from 0.60965 to 0.59035, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/031-0.5903.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7623 - acc: 0.7762 - val_loss: 0.5903 - val_acc: 0.8360\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7520 - acc: 0.7814\n",
      "Epoch 00032: val_loss improved from 0.59035 to 0.57323, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/032-0.5732.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.7520 - acc: 0.7814 - val_loss: 0.5732 - val_acc: 0.8372\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7408 - acc: 0.7817\n",
      "Epoch 00033: val_loss improved from 0.57323 to 0.56141, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/033-0.5614.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.7408 - acc: 0.7816 - val_loss: 0.5614 - val_acc: 0.8439\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7271 - acc: 0.7871\n",
      "Epoch 00034: val_loss improved from 0.56141 to 0.55172, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/034-0.5517.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7271 - acc: 0.7871 - val_loss: 0.5517 - val_acc: 0.8402\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7147 - acc: 0.7921\n",
      "Epoch 00035: val_loss improved from 0.55172 to 0.53526, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/035-0.5353.hdf5\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.7147 - acc: 0.7921 - val_loss: 0.5353 - val_acc: 0.8516\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7016 - acc: 0.7948\n",
      "Epoch 00036: val_loss improved from 0.53526 to 0.52938, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/036-0.5294.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.7016 - acc: 0.7948 - val_loss: 0.5294 - val_acc: 0.8530\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6943 - acc: 0.7988\n",
      "Epoch 00037: val_loss improved from 0.52938 to 0.51750, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/037-0.5175.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6943 - acc: 0.7988 - val_loss: 0.5175 - val_acc: 0.8528\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.7993\n",
      "Epoch 00038: val_loss did not improve from 0.51750\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6903 - acc: 0.7992 - val_loss: 0.5271 - val_acc: 0.8542\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6695 - acc: 0.8042\n",
      "Epoch 00039: val_loss did not improve from 0.51750\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6696 - acc: 0.8042 - val_loss: 0.5243 - val_acc: 0.8521\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6680 - acc: 0.8072\n",
      "Epoch 00040: val_loss improved from 0.51750 to 0.50140, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/040-0.5014.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6679 - acc: 0.8072 - val_loss: 0.5014 - val_acc: 0.8560\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6579 - acc: 0.8107\n",
      "Epoch 00041: val_loss did not improve from 0.50140\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6579 - acc: 0.8107 - val_loss: 0.5041 - val_acc: 0.8565\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6465 - acc: 0.8135\n",
      "Epoch 00042: val_loss improved from 0.50140 to 0.47985, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/042-0.4798.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.6465 - acc: 0.8135 - val_loss: 0.4798 - val_acc: 0.8712\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6388 - acc: 0.8145\n",
      "Epoch 00043: val_loss improved from 0.47985 to 0.47442, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/043-0.4744.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6388 - acc: 0.8145 - val_loss: 0.4744 - val_acc: 0.8684\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6254 - acc: 0.8186\n",
      "Epoch 00044: val_loss improved from 0.47442 to 0.45957, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/044-0.4596.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.6254 - acc: 0.8186 - val_loss: 0.4596 - val_acc: 0.8721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6230 - acc: 0.8195\n",
      "Epoch 00045: val_loss did not improve from 0.45957\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6230 - acc: 0.8195 - val_loss: 0.4807 - val_acc: 0.8642\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6144 - acc: 0.8244\n",
      "Epoch 00046: val_loss improved from 0.45957 to 0.45746, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/046-0.4575.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.6143 - acc: 0.8244 - val_loss: 0.4575 - val_acc: 0.8724\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6162 - acc: 0.8206\n",
      "Epoch 00047: val_loss did not improve from 0.45746\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.6161 - acc: 0.8206 - val_loss: 0.4882 - val_acc: 0.8614\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.8260\n",
      "Epoch 00048: val_loss improved from 0.45746 to 0.44592, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/048-0.4459.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.6023 - acc: 0.8261 - val_loss: 0.4459 - val_acc: 0.8756\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5886 - acc: 0.8309\n",
      "Epoch 00049: val_loss improved from 0.44592 to 0.44527, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/049-0.4453.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5885 - acc: 0.8309 - val_loss: 0.4453 - val_acc: 0.8833\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5963 - acc: 0.8273\n",
      "Epoch 00050: val_loss improved from 0.44527 to 0.42762, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/050-0.4276.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5963 - acc: 0.8273 - val_loss: 0.4276 - val_acc: 0.8789\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5771 - acc: 0.8330- ET\n",
      "Epoch 00051: val_loss improved from 0.42762 to 0.42524, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/051-0.4252.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.5771 - acc: 0.8330 - val_loss: 0.4252 - val_acc: 0.8847\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5768 - acc: 0.8336\n",
      "Epoch 00052: val_loss improved from 0.42524 to 0.41787, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/052-0.4179.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5768 - acc: 0.8336 - val_loss: 0.4179 - val_acc: 0.8887\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5670 - acc: 0.8363\n",
      "Epoch 00053: val_loss did not improve from 0.41787\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.5669 - acc: 0.8363 - val_loss: 0.4190 - val_acc: 0.8873\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5527 - acc: 0.8386\n",
      "Epoch 00054: val_loss improved from 0.41787 to 0.41183, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/054-0.4118.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5526 - acc: 0.8386 - val_loss: 0.4118 - val_acc: 0.8870\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5550 - acc: 0.8386\n",
      "Epoch 00055: val_loss improved from 0.41183 to 0.40534, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/055-0.4053.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5551 - acc: 0.8386 - val_loss: 0.4053 - val_acc: 0.8887\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5527 - acc: 0.8390\n",
      "Epoch 00056: val_loss did not improve from 0.40534\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5526 - acc: 0.8390 - val_loss: 0.4128 - val_acc: 0.8817\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5399 - acc: 0.8435\n",
      "Epoch 00057: val_loss improved from 0.40534 to 0.39672, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/057-0.3967.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5399 - acc: 0.8435 - val_loss: 0.3967 - val_acc: 0.8894\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5419 - acc: 0.8442\n",
      "Epoch 00058: val_loss did not improve from 0.39672\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5420 - acc: 0.8443 - val_loss: 0.4392 - val_acc: 0.8754\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5329 - acc: 0.8459\n",
      "Epoch 00059: val_loss improved from 0.39672 to 0.38587, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/059-0.3859.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.5329 - acc: 0.8459 - val_loss: 0.3859 - val_acc: 0.8935\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5322 - acc: 0.8461\n",
      "Epoch 00060: val_loss did not improve from 0.38587\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.5321 - acc: 0.8461 - val_loss: 0.3860 - val_acc: 0.8970\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5206 - acc: 0.8500\n",
      "Epoch 00061: val_loss did not improve from 0.38587\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5206 - acc: 0.8500 - val_loss: 0.3921 - val_acc: 0.8877\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5176 - acc: 0.8503\n",
      "Epoch 00062: val_loss improved from 0.38587 to 0.38200, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/062-0.3820.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.5179 - acc: 0.8503 - val_loss: 0.3820 - val_acc: 0.8982\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5138 - acc: 0.8514\n",
      "Epoch 00063: val_loss did not improve from 0.38200\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.5137 - acc: 0.8514 - val_loss: 0.3850 - val_acc: 0.8952\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5039 - acc: 0.8538\n",
      "Epoch 00064: val_loss improved from 0.38200 to 0.36397, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/064-0.3640.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.5042 - acc: 0.8537 - val_loss: 0.3640 - val_acc: 0.9003\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5098 - acc: 0.8520\n",
      "Epoch 00065: val_loss did not improve from 0.36397\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.5098 - acc: 0.8520 - val_loss: 0.3848 - val_acc: 0.8980\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.8562\n",
      "Epoch 00066: val_loss did not improve from 0.36397\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.5000 - acc: 0.8561 - val_loss: 0.3663 - val_acc: 0.9008\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4887 - acc: 0.8572\n",
      "Epoch 00067: val_loss improved from 0.36397 to 0.36053, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/067-0.3605.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4887 - acc: 0.8571 - val_loss: 0.3605 - val_acc: 0.9019\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8559\n",
      "Epoch 00068: val_loss improved from 0.36053 to 0.35948, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/068-0.3595.hdf5\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.4927 - acc: 0.8559 - val_loss: 0.3595 - val_acc: 0.8987\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4844 - acc: 0.8600\n",
      "Epoch 00069: val_loss improved from 0.35948 to 0.35006, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/069-0.3501.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4844 - acc: 0.8600 - val_loss: 0.3501 - val_acc: 0.9047\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4822 - acc: 0.8614\n",
      "Epoch 00070: val_loss improved from 0.35006 to 0.34909, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/070-0.3491.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4822 - acc: 0.8614 - val_loss: 0.3491 - val_acc: 0.9045\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4756 - acc: 0.8610\n",
      "Epoch 00071: val_loss did not improve from 0.34909\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.4755 - acc: 0.8610 - val_loss: 0.3533 - val_acc: 0.9008\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8629\n",
      "Epoch 00072: val_loss did not improve from 0.34909\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.4725 - acc: 0.8629 - val_loss: 0.3574 - val_acc: 0.9005\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4679 - acc: 0.8634\n",
      "Epoch 00073: val_loss improved from 0.34909 to 0.34210, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/073-0.3421.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4679 - acc: 0.8634 - val_loss: 0.3421 - val_acc: 0.9036\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.8643\n",
      "Epoch 00074: val_loss did not improve from 0.34210\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.4666 - acc: 0.8643 - val_loss: 0.3506 - val_acc: 0.9038\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8638\n",
      "Epoch 00075: val_loss did not improve from 0.34210\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.4670 - acc: 0.8637 - val_loss: 0.3544 - val_acc: 0.9022\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4654 - acc: 0.8649\n",
      "Epoch 00076: val_loss did not improve from 0.34210\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.4653 - acc: 0.8649 - val_loss: 0.3456 - val_acc: 0.9033\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4568 - acc: 0.8695\n",
      "Epoch 00077: val_loss improved from 0.34210 to 0.32698, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/077-0.3270.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4570 - acc: 0.8694 - val_loss: 0.3270 - val_acc: 0.9092\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8661\n",
      "Epoch 00078: val_loss did not improve from 0.32698\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.4594 - acc: 0.8661 - val_loss: 0.3638 - val_acc: 0.9022\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8691\n",
      "Epoch 00079: val_loss did not improve from 0.32698\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.4494 - acc: 0.8691 - val_loss: 0.3324 - val_acc: 0.9089\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8680\n",
      "Epoch 00080: val_loss improved from 0.32698 to 0.32630, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/080-0.3263.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.4498 - acc: 0.8680 - val_loss: 0.3263 - val_acc: 0.9108\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4450 - acc: 0.8687\n",
      "Epoch 00081: val_loss did not improve from 0.32630\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.4450 - acc: 0.8687 - val_loss: 0.3267 - val_acc: 0.9178\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8704\n",
      "Epoch 00082: val_loss improved from 0.32630 to 0.31868, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/082-0.3187.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.4451 - acc: 0.8704 - val_loss: 0.3187 - val_acc: 0.9131\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4355 - acc: 0.8735\n",
      "Epoch 00083: val_loss improved from 0.31868 to 0.31847, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/083-0.3185.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.4354 - acc: 0.8735 - val_loss: 0.3185 - val_acc: 0.9136\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4423 - acc: 0.8713\n",
      "Epoch 00084: val_loss improved from 0.31847 to 0.31231, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/084-0.3123.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.4423 - acc: 0.8713 - val_loss: 0.3123 - val_acc: 0.9140\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8728\n",
      "Epoch 00085: val_loss did not improve from 0.31231\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4329 - acc: 0.8728 - val_loss: 0.3168 - val_acc: 0.9126\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4316 - acc: 0.8742\n",
      "Epoch 00086: val_loss did not improve from 0.31231\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4315 - acc: 0.8742 - val_loss: 0.3294 - val_acc: 0.9068\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8748- ETA: 0s - loss: 0.4316 - acc: \n",
      "Epoch 00087: val_loss did not improve from 0.31231\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.4320 - acc: 0.8747 - val_loss: 0.3186 - val_acc: 0.9115\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4265 - acc: 0.8755\n",
      "Epoch 00088: val_loss did not improve from 0.31231\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.4266 - acc: 0.8754 - val_loss: 0.3159 - val_acc: 0.9138\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4214 - acc: 0.8778\n",
      "Epoch 00089: val_loss improved from 0.31231 to 0.31165, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/089-0.3116.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.4214 - acc: 0.8778 - val_loss: 0.3116 - val_acc: 0.9154\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4159 - acc: 0.8775\n",
      "Epoch 00090: val_loss did not improve from 0.31165\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4159 - acc: 0.8775 - val_loss: 0.3332 - val_acc: 0.9099\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4223 - acc: 0.8761\n",
      "Epoch 00091: val_loss improved from 0.31165 to 0.30342, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/091-0.3034.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4222 - acc: 0.8762 - val_loss: 0.3034 - val_acc: 0.9164\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4189 - acc: 0.8766\n",
      "Epoch 00092: val_loss did not improve from 0.30342\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4190 - acc: 0.8766 - val_loss: 0.3081 - val_acc: 0.9152\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8778\n",
      "Epoch 00093: val_loss improved from 0.30342 to 0.29514, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/093-0.2951.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4170 - acc: 0.8778 - val_loss: 0.2951 - val_acc: 0.9196\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8792\n",
      "Epoch 00094: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4054 - acc: 0.8791 - val_loss: 0.3033 - val_acc: 0.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8811\n",
      "Epoch 00095: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4085 - acc: 0.8811 - val_loss: 0.3040 - val_acc: 0.9196\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4078 - acc: 0.8813\n",
      "Epoch 00096: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4077 - acc: 0.8813 - val_loss: 0.2985 - val_acc: 0.9194\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3958 - acc: 0.8829\n",
      "Epoch 00097: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3958 - acc: 0.8829 - val_loss: 0.3036 - val_acc: 0.9159\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.8823\n",
      "Epoch 00098: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.4049 - acc: 0.8824 - val_loss: 0.3007 - val_acc: 0.9180\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3963 - acc: 0.8840\n",
      "Epoch 00099: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3963 - acc: 0.8840 - val_loss: 0.3008 - val_acc: 0.9187\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8838\n",
      "Epoch 00100: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3987 - acc: 0.8838 - val_loss: 0.3028 - val_acc: 0.9201\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3907 - acc: 0.8852\n",
      "Epoch 00101: val_loss did not improve from 0.29514\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3907 - acc: 0.8852 - val_loss: 0.2965 - val_acc: 0.9187\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8874\n",
      "Epoch 00102: val_loss improved from 0.29514 to 0.28954, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/102-0.2895.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3853 - acc: 0.8874 - val_loss: 0.2895 - val_acc: 0.9227\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3889 - acc: 0.8838\n",
      "Epoch 00103: val_loss did not improve from 0.28954\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3889 - acc: 0.8838 - val_loss: 0.2932 - val_acc: 0.9194\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8863\n",
      "Epoch 00104: val_loss did not improve from 0.28954\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3856 - acc: 0.8863 - val_loss: 0.2932 - val_acc: 0.9222\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8846\n",
      "Epoch 00105: val_loss did not improve from 0.28954\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3853 - acc: 0.8847 - val_loss: 0.2945 - val_acc: 0.9187\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8871\n",
      "Epoch 00106: val_loss improved from 0.28954 to 0.28524, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/106-0.2852.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3798 - acc: 0.8871 - val_loss: 0.2852 - val_acc: 0.9227\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3812 - acc: 0.8860\n",
      "Epoch 00107: val_loss did not improve from 0.28524\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3811 - acc: 0.8860 - val_loss: 0.2931 - val_acc: 0.9199\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8884\n",
      "Epoch 00108: val_loss did not improve from 0.28524\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.3813 - acc: 0.8884 - val_loss: 0.2997 - val_acc: 0.9189\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3775 - acc: 0.8860\n",
      "Epoch 00109: val_loss did not improve from 0.28524\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3775 - acc: 0.8860 - val_loss: 0.2863 - val_acc: 0.9248\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3752 - acc: 0.8897\n",
      "Epoch 00110: val_loss improved from 0.28524 to 0.27590, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/110-0.2759.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3752 - acc: 0.8897 - val_loss: 0.2759 - val_acc: 0.9241\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3747 - acc: 0.8898\n",
      "Epoch 00111: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3747 - acc: 0.8899 - val_loss: 0.2777 - val_acc: 0.9243\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3693 - acc: 0.8892\n",
      "Epoch 00112: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3692 - acc: 0.8892 - val_loss: 0.2881 - val_acc: 0.9206\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3722 - acc: 0.8883\n",
      "Epoch 00113: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3721 - acc: 0.8884 - val_loss: 0.2785 - val_acc: 0.9199\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3668 - acc: 0.8905\n",
      "Epoch 00114: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3667 - acc: 0.8905 - val_loss: 0.2838 - val_acc: 0.9189\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3662 - acc: 0.8904\n",
      "Epoch 00115: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3662 - acc: 0.8904 - val_loss: 0.2790 - val_acc: 0.9231\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3618 - acc: 0.8933\n",
      "Epoch 00116: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.3617 - acc: 0.8933 - val_loss: 0.2879 - val_acc: 0.9196\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3606 - acc: 0.8917\n",
      "Epoch 00117: val_loss did not improve from 0.27590\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3606 - acc: 0.8917 - val_loss: 0.2777 - val_acc: 0.9257\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3558 - acc: 0.8947\n",
      "Epoch 00118: val_loss improved from 0.27590 to 0.27128, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/118-0.2713.hdf5\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3559 - acc: 0.8947 - val_loss: 0.2713 - val_acc: 0.9222\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3601 - acc: 0.8934\n",
      "Epoch 00119: val_loss did not improve from 0.27128\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3601 - acc: 0.8934 - val_loss: 0.2769 - val_acc: 0.9236\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3554 - acc: 0.8958\n",
      "Epoch 00120: val_loss did not improve from 0.27128\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3555 - acc: 0.8958 - val_loss: 0.2848 - val_acc: 0.9220\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3577 - acc: 0.8921\n",
      "Epoch 00121: val_loss did not improve from 0.27128\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.3578 - acc: 0.8921 - val_loss: 0.2862 - val_acc: 0.9213\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8949\n",
      "Epoch 00122: val_loss did not improve from 0.27128\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3585 - acc: 0.8950 - val_loss: 0.2733 - val_acc: 0.9241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8951\n",
      "Epoch 00123: val_loss did not improve from 0.27128\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3532 - acc: 0.8952 - val_loss: 0.2821 - val_acc: 0.9243\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.8957\n",
      "Epoch 00124: val_loss improved from 0.27128 to 0.26236, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/124-0.2624.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3506 - acc: 0.8957 - val_loss: 0.2624 - val_acc: 0.9278\n",
      "Epoch 125/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3468 - acc: 0.8959\n",
      "Epoch 00125: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3470 - acc: 0.8958 - val_loss: 0.2711 - val_acc: 0.9269\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.8964\n",
      "Epoch 00126: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3493 - acc: 0.8964 - val_loss: 0.2651 - val_acc: 0.9245\n",
      "Epoch 127/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8975\n",
      "Epoch 00127: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3394 - acc: 0.8975 - val_loss: 0.2811 - val_acc: 0.9208\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.8975\n",
      "Epoch 00128: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3445 - acc: 0.8975 - val_loss: 0.2817 - val_acc: 0.9213\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.8980\n",
      "Epoch 00129: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3393 - acc: 0.8980 - val_loss: 0.2710 - val_acc: 0.9259\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8989\n",
      "Epoch 00130: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.3398 - acc: 0.8989 - val_loss: 0.2669 - val_acc: 0.9285\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.8972\n",
      "Epoch 00131: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3374 - acc: 0.8972 - val_loss: 0.2633 - val_acc: 0.9241\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8999\n",
      "Epoch 00132: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3355 - acc: 0.8999 - val_loss: 0.2655 - val_acc: 0.9290\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3346 - acc: 0.8992\n",
      "Epoch 00133: val_loss did not improve from 0.26236\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3346 - acc: 0.8991 - val_loss: 0.2671 - val_acc: 0.9271\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8983\n",
      "Epoch 00134: val_loss improved from 0.26236 to 0.25472, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/134-0.2547.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3344 - acc: 0.8983 - val_loss: 0.2547 - val_acc: 0.9280\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.9005\n",
      "Epoch 00135: val_loss did not improve from 0.25472\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3297 - acc: 0.9006 - val_loss: 0.2615 - val_acc: 0.9248\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.9028\n",
      "Epoch 00136: val_loss did not improve from 0.25472\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3338 - acc: 0.9028 - val_loss: 0.2636 - val_acc: 0.9273\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.9016\n",
      "Epoch 00137: val_loss did not improve from 0.25472\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3283 - acc: 0.9016 - val_loss: 0.2805 - val_acc: 0.9269\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3312 - acc: 0.9019\n",
      "Epoch 00138: val_loss did not improve from 0.25472\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3312 - acc: 0.9019 - val_loss: 0.2597 - val_acc: 0.9273\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.9024\n",
      "Epoch 00139: val_loss did not improve from 0.25472\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3298 - acc: 0.9024 - val_loss: 0.2688 - val_acc: 0.9283\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.9048\n",
      "Epoch 00140: val_loss did not improve from 0.25472\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3198 - acc: 0.9048 - val_loss: 0.2548 - val_acc: 0.9299\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.9024\n",
      "Epoch 00141: val_loss improved from 0.25472 to 0.25352, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/141-0.2535.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3250 - acc: 0.9024 - val_loss: 0.2535 - val_acc: 0.9297\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.9038\n",
      "Epoch 00142: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3218 - acc: 0.9037 - val_loss: 0.2578 - val_acc: 0.9269\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3287 - acc: 0.9013\n",
      "Epoch 00143: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3287 - acc: 0.9013 - val_loss: 0.2603 - val_acc: 0.9290\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.9040\n",
      "Epoch 00144: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3221 - acc: 0.9040 - val_loss: 0.2680 - val_acc: 0.9280\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.9032\n",
      "Epoch 00145: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3189 - acc: 0.9032 - val_loss: 0.2566 - val_acc: 0.9255\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3199 - acc: 0.9021\n",
      "Epoch 00146: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3201 - acc: 0.9021 - val_loss: 0.2600 - val_acc: 0.9304\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3198 - acc: 0.9027\n",
      "Epoch 00147: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3198 - acc: 0.9027 - val_loss: 0.2603 - val_acc: 0.9280\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9036\n",
      "Epoch 00148: val_loss did not improve from 0.25352\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3164 - acc: 0.9036 - val_loss: 0.2634 - val_acc: 0.9266\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9055\n",
      "Epoch 00149: val_loss improved from 0.25352 to 0.25043, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/149-0.2504.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3095 - acc: 0.9055 - val_loss: 0.2504 - val_acc: 0.9285\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.9055\n",
      "Epoch 00150: val_loss did not improve from 0.25043\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.3124 - acc: 0.9055 - val_loss: 0.2582 - val_acc: 0.9271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3130 - acc: 0.9048\n",
      "Epoch 00151: val_loss did not improve from 0.25043\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3130 - acc: 0.9048 - val_loss: 0.2671 - val_acc: 0.9278\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3069 - acc: 0.9073\n",
      "Epoch 00152: val_loss did not improve from 0.25043\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3069 - acc: 0.9073 - val_loss: 0.2603 - val_acc: 0.9324\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3062 - acc: 0.9069\n",
      "Epoch 00153: val_loss did not improve from 0.25043\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.3062 - acc: 0.9069 - val_loss: 0.2635 - val_acc: 0.9266\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3105 - acc: 0.9062\n",
      "Epoch 00154: val_loss improved from 0.25043 to 0.24589, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/154-0.2459.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.3105 - acc: 0.9062 - val_loss: 0.2459 - val_acc: 0.9341\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.9065\n",
      "Epoch 00155: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3104 - acc: 0.9066 - val_loss: 0.2697 - val_acc: 0.9248\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9055\n",
      "Epoch 00156: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3068 - acc: 0.9055 - val_loss: 0.2571 - val_acc: 0.9315\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.9080\n",
      "Epoch 00157: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3063 - acc: 0.9080 - val_loss: 0.2551 - val_acc: 0.9311\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.9074\n",
      "Epoch 00158: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.3060 - acc: 0.9074 - val_loss: 0.2600 - val_acc: 0.9262\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.9093\n",
      "Epoch 00159: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2990 - acc: 0.9093 - val_loss: 0.2596 - val_acc: 0.9299\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9065\n",
      "Epoch 00160: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3054 - acc: 0.9065 - val_loss: 0.2503 - val_acc: 0.9299\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.9083\n",
      "Epoch 00161: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3009 - acc: 0.9083 - val_loss: 0.2470 - val_acc: 0.9308\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3028 - acc: 0.9092\n",
      "Epoch 00162: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.3028 - acc: 0.9092 - val_loss: 0.2589 - val_acc: 0.9264\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3013 - acc: 0.9096\n",
      "Epoch 00163: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.3013 - acc: 0.9096 - val_loss: 0.2494 - val_acc: 0.9329\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2961 - acc: 0.9100\n",
      "Epoch 00164: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2960 - acc: 0.9100 - val_loss: 0.2717 - val_acc: 0.9234\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9089\n",
      "Epoch 00165: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2966 - acc: 0.9089 - val_loss: 0.2578 - val_acc: 0.9266\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.9098\n",
      "Epoch 00166: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2966 - acc: 0.9098 - val_loss: 0.2472 - val_acc: 0.9271\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9102\n",
      "Epoch 00167: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2939 - acc: 0.9102 - val_loss: 0.2465 - val_acc: 0.9322\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2991 - acc: 0.9087\n",
      "Epoch 00168: val_loss did not improve from 0.24589\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2991 - acc: 0.9087 - val_loss: 0.2470 - val_acc: 0.9336\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2923 - acc: 0.9108\n",
      "Epoch 00169: val_loss improved from 0.24589 to 0.24159, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/169-0.2416.hdf5\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2923 - acc: 0.9108 - val_loss: 0.2416 - val_acc: 0.9336\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.9102\n",
      "Epoch 00170: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2911 - acc: 0.9102 - val_loss: 0.2536 - val_acc: 0.9327\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9123\n",
      "Epoch 00171: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2937 - acc: 0.9122 - val_loss: 0.2494 - val_acc: 0.9320\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9111\n",
      "Epoch 00172: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.2890 - acc: 0.9111 - val_loss: 0.2516 - val_acc: 0.9320\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.9125\n",
      "Epoch 00173: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2885 - acc: 0.9125 - val_loss: 0.2559 - val_acc: 0.9276\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9121\n",
      "Epoch 00174: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.2937 - acc: 0.9121 - val_loss: 0.2479 - val_acc: 0.9322\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.9122\n",
      "Epoch 00175: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2886 - acc: 0.9122 - val_loss: 0.2440 - val_acc: 0.9341\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2846 - acc: 0.9121\n",
      "Epoch 00176: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2846 - acc: 0.9121 - val_loss: 0.2423 - val_acc: 0.9329\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9115\n",
      "Epoch 00177: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2883 - acc: 0.9115 - val_loss: 0.2435 - val_acc: 0.9290\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2835 - acc: 0.9132- ETA: 0s - loss: 0.2822 \n",
      "Epoch 00178: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2835 - acc: 0.9132 - val_loss: 0.2454 - val_acc: 0.9320\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.9158\n",
      "Epoch 00179: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2763 - acc: 0.9158 - val_loss: 0.2440 - val_acc: 0.9324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.9131\n",
      "Epoch 00180: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2839 - acc: 0.9131 - val_loss: 0.2451 - val_acc: 0.9306\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.9158\n",
      "Epoch 00181: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2785 - acc: 0.9158 - val_loss: 0.2420 - val_acc: 0.9350\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2812 - acc: 0.9135\n",
      "Epoch 00182: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2812 - acc: 0.9135 - val_loss: 0.2467 - val_acc: 0.9355\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9165\n",
      "Epoch 00183: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2810 - acc: 0.9165 - val_loss: 0.2420 - val_acc: 0.9338\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9169\n",
      "Epoch 00184: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2790 - acc: 0.9169 - val_loss: 0.2442 - val_acc: 0.9373\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2741 - acc: 0.9173\n",
      "Epoch 00185: val_loss did not improve from 0.24159\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2740 - acc: 0.9173 - val_loss: 0.2430 - val_acc: 0.9364\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2761 - acc: 0.9149\n",
      "Epoch 00186: val_loss improved from 0.24159 to 0.23988, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/186-0.2399.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2761 - acc: 0.9149 - val_loss: 0.2399 - val_acc: 0.9320\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2710 - acc: 0.9179\n",
      "Epoch 00187: val_loss did not improve from 0.23988\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.2710 - acc: 0.9179 - val_loss: 0.2520 - val_acc: 0.9334\n",
      "Epoch 188/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.9153\n",
      "Epoch 00188: val_loss improved from 0.23988 to 0.23714, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/188-0.2371.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2738 - acc: 0.9153 - val_loss: 0.2371 - val_acc: 0.9345\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.9148\n",
      "Epoch 00189: val_loss did not improve from 0.23714\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2722 - acc: 0.9148 - val_loss: 0.2372 - val_acc: 0.9364\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.9169\n",
      "Epoch 00190: val_loss did not improve from 0.23714\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2722 - acc: 0.9169 - val_loss: 0.2412 - val_acc: 0.9338\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2733 - acc: 0.9186\n",
      "Epoch 00191: val_loss improved from 0.23714 to 0.23689, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/191-0.2369.hdf5\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2732 - acc: 0.9186 - val_loss: 0.2369 - val_acc: 0.9366\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.9165\n",
      "Epoch 00192: val_loss did not improve from 0.23689\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2679 - acc: 0.9166 - val_loss: 0.2455 - val_acc: 0.9338\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2674 - acc: 0.9200\n",
      "Epoch 00193: val_loss did not improve from 0.23689\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.2674 - acc: 0.9200 - val_loss: 0.2601 - val_acc: 0.9285\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2703 - acc: 0.9175\n",
      "Epoch 00194: val_loss improved from 0.23689 to 0.23304, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/194-0.2330.hdf5\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2703 - acc: 0.9175 - val_loss: 0.2330 - val_acc: 0.9362\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2666 - acc: 0.9195\n",
      "Epoch 00195: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2666 - acc: 0.9195 - val_loss: 0.2411 - val_acc: 0.9320\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.9175\n",
      "Epoch 00196: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2661 - acc: 0.9175 - val_loss: 0.2427 - val_acc: 0.9334\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.9189\n",
      "Epoch 00197: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2657 - acc: 0.9188 - val_loss: 0.2390 - val_acc: 0.9336\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2685 - acc: 0.9173\n",
      "Epoch 00198: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2685 - acc: 0.9173 - val_loss: 0.2331 - val_acc: 0.9357\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9190\n",
      "Epoch 00199: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2619 - acc: 0.9190 - val_loss: 0.2428 - val_acc: 0.9355\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2656 - acc: 0.9180\n",
      "Epoch 00200: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2655 - acc: 0.9180 - val_loss: 0.2344 - val_acc: 0.9362\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2684 - acc: 0.9186\n",
      "Epoch 00201: val_loss did not improve from 0.23304\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2684 - acc: 0.9186 - val_loss: 0.2351 - val_acc: 0.9334\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9196\n",
      "Epoch 00202: val_loss improved from 0.23304 to 0.23290, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/202-0.2329.hdf5\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2623 - acc: 0.9196 - val_loss: 0.2329 - val_acc: 0.9362\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9213\n",
      "Epoch 00203: val_loss improved from 0.23290 to 0.23086, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/203-0.2309.hdf5\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2599 - acc: 0.9213 - val_loss: 0.2309 - val_acc: 0.9357\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.9189\n",
      "Epoch 00204: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2621 - acc: 0.9190 - val_loss: 0.2347 - val_acc: 0.9348\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9210\n",
      "Epoch 00205: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2560 - acc: 0.9210 - val_loss: 0.2402 - val_acc: 0.9366\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9198\n",
      "Epoch 00206: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2577 - acc: 0.9198 - val_loss: 0.2454 - val_acc: 0.9350\n",
      "Epoch 207/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.9215\n",
      "Epoch 00207: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2570 - acc: 0.9215 - val_loss: 0.2330 - val_acc: 0.9378\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9211\n",
      "Epoch 00208: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2595 - acc: 0.9212 - val_loss: 0.2352 - val_acc: 0.9352\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9220\n",
      "Epoch 00209: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2560 - acc: 0.9220 - val_loss: 0.2367 - val_acc: 0.9350\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2541 - acc: 0.9217\n",
      "Epoch 00210: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2541 - acc: 0.9217 - val_loss: 0.2412 - val_acc: 0.9357\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2556 - acc: 0.9207\n",
      "Epoch 00211: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2556 - acc: 0.9207 - val_loss: 0.2359 - val_acc: 0.9355\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9207\n",
      "Epoch 00212: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2567 - acc: 0.9207 - val_loss: 0.2443 - val_acc: 0.9345\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2544 - acc: 0.9219\n",
      "Epoch 00213: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2544 - acc: 0.9219 - val_loss: 0.2432 - val_acc: 0.9369\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9215\n",
      "Epoch 00214: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2533 - acc: 0.9215 - val_loss: 0.2409 - val_acc: 0.9334\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2527 - acc: 0.9220\n",
      "Epoch 00215: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2527 - acc: 0.9220 - val_loss: 0.2329 - val_acc: 0.9362\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.9204\n",
      "Epoch 00216: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 825us/sample - loss: 0.2572 - acc: 0.9204 - val_loss: 0.2457 - val_acc: 0.9338\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.9235- ET\n",
      "Epoch 00217: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2506 - acc: 0.9235 - val_loss: 0.2399 - val_acc: 0.9357\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2499 - acc: 0.9228\n",
      "Epoch 00218: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2499 - acc: 0.9228 - val_loss: 0.2355 - val_acc: 0.9380\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9218\n",
      "Epoch 00219: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2529 - acc: 0.9217 - val_loss: 0.2408 - val_acc: 0.9352\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9237\n",
      "Epoch 00220: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2473 - acc: 0.9237 - val_loss: 0.2349 - val_acc: 0.9362\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9212\n",
      "Epoch 00221: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2525 - acc: 0.9212 - val_loss: 0.2401 - val_acc: 0.9345\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9228\n",
      "Epoch 00222: val_loss did not improve from 0.23086\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2484 - acc: 0.9228 - val_loss: 0.2405 - val_acc: 0.9383\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9236\n",
      "Epoch 00223: val_loss improved from 0.23086 to 0.22592, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_5_conv_checkpoint/223-0.2259.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2492 - acc: 0.9236 - val_loss: 0.2259 - val_acc: 0.9394\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9240\n",
      "Epoch 00224: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2462 - acc: 0.9239 - val_loss: 0.2401 - val_acc: 0.9364\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2428 - acc: 0.9256\n",
      "Epoch 00225: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2428 - acc: 0.9256 - val_loss: 0.2414 - val_acc: 0.9385\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2435 - acc: 0.9222\n",
      "Epoch 00226: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2435 - acc: 0.9222 - val_loss: 0.2314 - val_acc: 0.9352\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2425 - acc: 0.9252\n",
      "Epoch 00227: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2425 - acc: 0.9252 - val_loss: 0.2340 - val_acc: 0.9385\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9237\n",
      "Epoch 00228: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2456 - acc: 0.9237 - val_loss: 0.2467 - val_acc: 0.9336\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9257\n",
      "Epoch 00229: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2393 - acc: 0.9257 - val_loss: 0.2356 - val_acc: 0.9364\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9255\n",
      "Epoch 00230: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2461 - acc: 0.9255 - val_loss: 0.2471 - val_acc: 0.9331\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9253\n",
      "Epoch 00231: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2445 - acc: 0.9253 - val_loss: 0.2368 - val_acc: 0.9373\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2413 - acc: 0.9243\n",
      "Epoch 00232: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2412 - acc: 0.9243 - val_loss: 0.2343 - val_acc: 0.9387\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2397 - acc: 0.9256\n",
      "Epoch 00233: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2397 - acc: 0.9256 - val_loss: 0.2399 - val_acc: 0.9390\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9240\n",
      "Epoch 00234: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2443 - acc: 0.9241 - val_loss: 0.2297 - val_acc: 0.9408\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2388 - acc: 0.9256\n",
      "Epoch 00235: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2389 - acc: 0.9256 - val_loss: 0.2359 - val_acc: 0.9362\n",
      "Epoch 236/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.9270\n",
      "Epoch 00236: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2336 - acc: 0.9270 - val_loss: 0.2356 - val_acc: 0.9387\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.9262\n",
      "Epoch 00237: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2347 - acc: 0.9263 - val_loss: 0.2327 - val_acc: 0.9376\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.9252\n",
      "Epoch 00238: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2389 - acc: 0.9252 - val_loss: 0.2428 - val_acc: 0.9357\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2341 - acc: 0.9271\n",
      "Epoch 00239: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2341 - acc: 0.9271 - val_loss: 0.2401 - val_acc: 0.9357\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2335 - acc: 0.9287\n",
      "Epoch 00240: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2334 - acc: 0.9287 - val_loss: 0.2357 - val_acc: 0.9327\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9276\n",
      "Epoch 00241: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2328 - acc: 0.9276 - val_loss: 0.2379 - val_acc: 0.9369\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9281\n",
      "Epoch 00242: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.2304 - acc: 0.9281 - val_loss: 0.2745 - val_acc: 0.9290\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2325 - acc: 0.9253\n",
      "Epoch 00243: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2325 - acc: 0.9253 - val_loss: 0.2402 - val_acc: 0.9338\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9262\n",
      "Epoch 00244: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2361 - acc: 0.9262 - val_loss: 0.2392 - val_acc: 0.9366\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9280\n",
      "Epoch 00245: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2304 - acc: 0.9280 - val_loss: 0.2344 - val_acc: 0.9390\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2296 - acc: 0.9283\n",
      "Epoch 00246: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2296 - acc: 0.9284 - val_loss: 0.2465 - val_acc: 0.9338\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9279\n",
      "Epoch 00247: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2291 - acc: 0.9278 - val_loss: 0.2345 - val_acc: 0.9394\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9294\n",
      "Epoch 00248: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 822us/sample - loss: 0.2277 - acc: 0.9294 - val_loss: 0.2339 - val_acc: 0.9411\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2239 - acc: 0.9304\n",
      "Epoch 00249: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 823us/sample - loss: 0.2239 - acc: 0.9304 - val_loss: 0.2290 - val_acc: 0.9371\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9297\n",
      "Epoch 00250: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2247 - acc: 0.9297 - val_loss: 0.2378 - val_acc: 0.9383\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9298\n",
      "Epoch 00251: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.2294 - acc: 0.9298 - val_loss: 0.2378 - val_acc: 0.9378\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9292\n",
      "Epoch 00252: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2261 - acc: 0.9292 - val_loss: 0.2397 - val_acc: 0.9394\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2286 - acc: 0.9280\n",
      "Epoch 00253: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2286 - acc: 0.9281 - val_loss: 0.2537 - val_acc: 0.9331\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9289\n",
      "Epoch 00254: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2261 - acc: 0.9288 - val_loss: 0.2394 - val_acc: 0.9355\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9280\n",
      "Epoch 00255: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2299 - acc: 0.9280 - val_loss: 0.2339 - val_acc: 0.9369\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9284\n",
      "Epoch 00256: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2291 - acc: 0.9284 - val_loss: 0.2366 - val_acc: 0.9369\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9295\n",
      "Epoch 00257: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2228 - acc: 0.9295 - val_loss: 0.2523 - val_acc: 0.9345\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9295\n",
      "Epoch 00258: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2275 - acc: 0.9295 - val_loss: 0.2285 - val_acc: 0.9392\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9296\n",
      "Epoch 00259: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2226 - acc: 0.9297 - val_loss: 0.2348 - val_acc: 0.9408\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2228 - acc: 0.9299\n",
      "Epoch 00260: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2228 - acc: 0.9299 - val_loss: 0.2379 - val_acc: 0.9357\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9300\n",
      "Epoch 00261: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2210 - acc: 0.9300 - val_loss: 0.2429 - val_acc: 0.9373\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9301\n",
      "Epoch 00262: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2216 - acc: 0.9301 - val_loss: 0.2455 - val_acc: 0.9336\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9307\n",
      "Epoch 00263: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2191 - acc: 0.9307 - val_loss: 0.2428 - val_acc: 0.9387\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9318\n",
      "Epoch 00264: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2164 - acc: 0.9318 - val_loss: 0.2314 - val_acc: 0.9399\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9295\n",
      "Epoch 00265: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2256 - acc: 0.9295 - val_loss: 0.2457 - val_acc: 0.9390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9326\n",
      "Epoch 00266: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2178 - acc: 0.9326 - val_loss: 0.2439 - val_acc: 0.9385\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2176 - acc: 0.9316\n",
      "Epoch 00267: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2176 - acc: 0.9316 - val_loss: 0.2323 - val_acc: 0.9394\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.9323\n",
      "Epoch 00268: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.2153 - acc: 0.9323 - val_loss: 0.2341 - val_acc: 0.9387\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2171 - acc: 0.9309\n",
      "Epoch 00269: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2170 - acc: 0.9309 - val_loss: 0.2398 - val_acc: 0.9390\n",
      "Epoch 270/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9320\n",
      "Epoch 00270: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2139 - acc: 0.9320 - val_loss: 0.2540 - val_acc: 0.9357\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9335\n",
      "Epoch 00271: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2158 - acc: 0.9335 - val_loss: 0.2347 - val_acc: 0.9406\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9332\n",
      "Epoch 00272: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.2151 - acc: 0.9332 - val_loss: 0.2330 - val_acc: 0.9373\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9323\n",
      "Epoch 00273: val_loss did not improve from 0.22592\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.2154 - acc: 0.9323 - val_loss: 0.2428 - val_acc: 0.9322\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 396us/sample - loss: 0.2775 - acc: 0.9192\n",
      "Loss: 0.2775282277496433 Accuracy: 0.9192108\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4646 - acc: 0.1887\n",
      "Epoch 00001: val_loss improved from inf to 1.92446, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/001-1.9245.hdf5\n",
      "36805/36805 [==============================] - 34s 935us/sample - loss: 2.4645 - acc: 0.1888 - val_loss: 1.9245 - val_acc: 0.4051\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8992 - acc: 0.3699\n",
      "Epoch 00002: val_loss improved from 1.92446 to 1.60049, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/002-1.6005.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 1.8992 - acc: 0.3699 - val_loss: 1.6005 - val_acc: 0.5085\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6580 - acc: 0.4617\n",
      "Epoch 00003: val_loss improved from 1.60049 to 1.36210, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/003-1.3621.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 1.6580 - acc: 0.4618 - val_loss: 1.3621 - val_acc: 0.5931\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4851 - acc: 0.5215\n",
      "Epoch 00004: val_loss improved from 1.36210 to 1.18739, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/004-1.1874.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 1.4852 - acc: 0.5215 - val_loss: 1.1874 - val_acc: 0.6478\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3412 - acc: 0.5760\n",
      "Epoch 00005: val_loss improved from 1.18739 to 1.07033, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/005-1.0703.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 1.3412 - acc: 0.5760 - val_loss: 1.0703 - val_acc: 0.6907\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.6184\n",
      "Epoch 00006: val_loss improved from 1.07033 to 0.93300, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/006-0.9330.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 1.2186 - acc: 0.6184 - val_loss: 0.9330 - val_acc: 0.7345\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1193 - acc: 0.6523\n",
      "Epoch 00007: val_loss improved from 0.93300 to 0.87373, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/007-0.8737.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 1.1192 - acc: 0.6524 - val_loss: 0.8737 - val_acc: 0.7461\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0332 - acc: 0.6810\n",
      "Epoch 00008: val_loss improved from 0.87373 to 0.77349, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/008-0.7735.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 1.0331 - acc: 0.6810 - val_loss: 0.7735 - val_acc: 0.7831\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9649 - acc: 0.7056\n",
      "Epoch 00009: val_loss improved from 0.77349 to 0.71636, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/009-0.7164.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.9649 - acc: 0.7056 - val_loss: 0.7164 - val_acc: 0.8039\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9064 - acc: 0.7242\n",
      "Epoch 00010: val_loss improved from 0.71636 to 0.68649, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/010-0.6865.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.9064 - acc: 0.7242 - val_loss: 0.6865 - val_acc: 0.8102\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8541 - acc: 0.7438\n",
      "Epoch 00011: val_loss improved from 0.68649 to 0.64540, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/011-0.6454.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.8543 - acc: 0.7438 - val_loss: 0.6454 - val_acc: 0.8237\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8007 - acc: 0.7589\n",
      "Epoch 00012: val_loss improved from 0.64540 to 0.58140, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/012-0.5814.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.8007 - acc: 0.7589 - val_loss: 0.5814 - val_acc: 0.8418\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7632 - acc: 0.7697\n",
      "Epoch 00013: val_loss improved from 0.58140 to 0.55569, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/013-0.5557.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.7633 - acc: 0.7697 - val_loss: 0.5557 - val_acc: 0.8435\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7214 - acc: 0.7851\n",
      "Epoch 00014: val_loss improved from 0.55569 to 0.53696, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/014-0.5370.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.7214 - acc: 0.7850 - val_loss: 0.5370 - val_acc: 0.8446\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6893 - acc: 0.7936\n",
      "Epoch 00015: val_loss did not improve from 0.53696\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.6893 - acc: 0.7936 - val_loss: 0.5463 - val_acc: 0.8449\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6623 - acc: 0.8020\n",
      "Epoch 00016: val_loss improved from 0.53696 to 0.49076, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/016-0.4908.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.6622 - acc: 0.8021 - val_loss: 0.4908 - val_acc: 0.8607\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6313 - acc: 0.8123\n",
      "Epoch 00017: val_loss improved from 0.49076 to 0.45084, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/017-0.4508.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.6313 - acc: 0.8123 - val_loss: 0.4508 - val_acc: 0.8758\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6092 - acc: 0.8188\n",
      "Epoch 00018: val_loss did not improve from 0.45084\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.6093 - acc: 0.8188 - val_loss: 0.4586 - val_acc: 0.8779\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5868 - acc: 0.8246\n",
      "Epoch 00019: val_loss improved from 0.45084 to 0.39579, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/019-0.3958.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.5869 - acc: 0.8246 - val_loss: 0.3958 - val_acc: 0.8977\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.8313\n",
      "Epoch 00020: val_loss did not improve from 0.39579\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.5641 - acc: 0.8313 - val_loss: 0.4410 - val_acc: 0.8710\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5499 - acc: 0.8361\n",
      "Epoch 00021: val_loss improved from 0.39579 to 0.37984, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/021-0.3798.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.5501 - acc: 0.8361 - val_loss: 0.3798 - val_acc: 0.8942\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.8414\n",
      "Epoch 00022: val_loss improved from 0.37984 to 0.34812, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/022-0.3481.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.5243 - acc: 0.8414 - val_loss: 0.3481 - val_acc: 0.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.8482\n",
      "Epoch 00023: val_loss did not improve from 0.34812\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.5148 - acc: 0.8483 - val_loss: 0.3807 - val_acc: 0.8973\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8535\n",
      "Epoch 00024: val_loss did not improve from 0.34812\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.4942 - acc: 0.8536 - val_loss: 0.3563 - val_acc: 0.9005\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8571\n",
      "Epoch 00025: val_loss improved from 0.34812 to 0.33890, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/025-0.3389.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.4812 - acc: 0.8571 - val_loss: 0.3389 - val_acc: 0.9061\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.8622\n",
      "Epoch 00026: val_loss improved from 0.33890 to 0.31004, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/026-0.3100.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.4639 - acc: 0.8622 - val_loss: 0.3100 - val_acc: 0.9154\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4507 - acc: 0.8643\n",
      "Epoch 00027: val_loss improved from 0.31004 to 0.30032, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/027-0.3003.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.4507 - acc: 0.8643 - val_loss: 0.3003 - val_acc: 0.9161\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8659\n",
      "Epoch 00028: val_loss improved from 0.30032 to 0.30019, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/028-0.3002.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.4409 - acc: 0.8659 - val_loss: 0.3002 - val_acc: 0.9206\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8721\n",
      "Epoch 00029: val_loss improved from 0.30019 to 0.29910, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/029-0.2991.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.4306 - acc: 0.8721 - val_loss: 0.2991 - val_acc: 0.9187\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8733\n",
      "Epoch 00030: val_loss improved from 0.29910 to 0.28069, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/030-0.2807.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.4232 - acc: 0.8734 - val_loss: 0.2807 - val_acc: 0.9238\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4100 - acc: 0.8780\n",
      "Epoch 00031: val_loss improved from 0.28069 to 0.27208, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/031-0.2721.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.4100 - acc: 0.8780 - val_loss: 0.2721 - val_acc: 0.9248\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8810\n",
      "Epoch 00032: val_loss did not improve from 0.27208\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.3992 - acc: 0.8810 - val_loss: 0.2766 - val_acc: 0.9238\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3925 - acc: 0.8817\n",
      "Epoch 00033: val_loss improved from 0.27208 to 0.25970, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/033-0.2597.hdf5\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.3925 - acc: 0.8817 - val_loss: 0.2597 - val_acc: 0.9299\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3855 - acc: 0.8839\n",
      "Epoch 00034: val_loss did not improve from 0.25970\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.3854 - acc: 0.8839 - val_loss: 0.2812 - val_acc: 0.9168\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3732 - acc: 0.8873\n",
      "Epoch 00035: val_loss improved from 0.25970 to 0.24950, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/035-0.2495.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3731 - acc: 0.8873 - val_loss: 0.2495 - val_acc: 0.9306\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3718 - acc: 0.8879\n",
      "Epoch 00036: val_loss improved from 0.24950 to 0.24373, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/036-0.2437.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3718 - acc: 0.8879 - val_loss: 0.2437 - val_acc: 0.9299\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3611 - acc: 0.8913\n",
      "Epoch 00037: val_loss did not improve from 0.24373\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.3613 - acc: 0.8913 - val_loss: 0.2615 - val_acc: 0.9262\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3564 - acc: 0.8930\n",
      "Epoch 00038: val_loss did not improve from 0.24373\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.3564 - acc: 0.8931 - val_loss: 0.2783 - val_acc: 0.9196\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3433 - acc: 0.8985\n",
      "Epoch 00039: val_loss improved from 0.24373 to 0.23381, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/039-0.2338.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.3433 - acc: 0.8984 - val_loss: 0.2338 - val_acc: 0.9348\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8962\n",
      "Epoch 00040: val_loss did not improve from 0.23381\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.3425 - acc: 0.8962 - val_loss: 0.2342 - val_acc: 0.9317\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.8998\n",
      "Epoch 00041: val_loss improved from 0.23381 to 0.22385, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/041-0.2239.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3349 - acc: 0.8998 - val_loss: 0.2239 - val_acc: 0.9364\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.8985\n",
      "Epoch 00042: val_loss improved from 0.22385 to 0.21633, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/042-0.2163.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3327 - acc: 0.8985 - val_loss: 0.2163 - val_acc: 0.9378\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3253 - acc: 0.9013\n",
      "Epoch 00043: val_loss did not improve from 0.21633\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3253 - acc: 0.9013 - val_loss: 0.2366 - val_acc: 0.9341\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.9026\n",
      "Epoch 00044: val_loss improved from 0.21633 to 0.20957, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/044-0.2096.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3177 - acc: 0.9026 - val_loss: 0.2096 - val_acc: 0.9418\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.9038\n",
      "Epoch 00045: val_loss did not improve from 0.20957\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3157 - acc: 0.9038 - val_loss: 0.2176 - val_acc: 0.9415\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3083 - acc: 0.9072\n",
      "Epoch 00046: val_loss improved from 0.20957 to 0.20865, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/046-0.2086.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.3083 - acc: 0.9072 - val_loss: 0.2086 - val_acc: 0.9392\n",
      "Epoch 47/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.9072\n",
      "Epoch 00047: val_loss did not improve from 0.20865\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.3074 - acc: 0.9072 - val_loss: 0.2383 - val_acc: 0.9306\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.9094\n",
      "Epoch 00048: val_loss improved from 0.20865 to 0.20171, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/048-0.2017.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.2988 - acc: 0.9094 - val_loss: 0.2017 - val_acc: 0.9425\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9109\n",
      "Epoch 00049: val_loss improved from 0.20171 to 0.19634, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/049-0.1963.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2936 - acc: 0.9109 - val_loss: 0.1963 - val_acc: 0.9439\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9125\n",
      "Epoch 00050: val_loss did not improve from 0.19634\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2879 - acc: 0.9125 - val_loss: 0.1970 - val_acc: 0.9436\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.9111\n",
      "Epoch 00051: val_loss did not improve from 0.19634\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2892 - acc: 0.9111 - val_loss: 0.2159 - val_acc: 0.9364\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2797 - acc: 0.9150\n",
      "Epoch 00052: val_loss improved from 0.19634 to 0.19054, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/052-0.1905.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2798 - acc: 0.9150 - val_loss: 0.1905 - val_acc: 0.9490\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.9144\n",
      "Epoch 00053: val_loss did not improve from 0.19054\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2759 - acc: 0.9144 - val_loss: 0.2061 - val_acc: 0.9380\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9171\n",
      "Epoch 00054: val_loss improved from 0.19054 to 0.18750, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/054-0.1875.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2726 - acc: 0.9171 - val_loss: 0.1875 - val_acc: 0.9464\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2684 - acc: 0.9174\n",
      "Epoch 00055: val_loss improved from 0.18750 to 0.18560, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/055-0.1856.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2684 - acc: 0.9174 - val_loss: 0.1856 - val_acc: 0.9462\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9170\n",
      "Epoch 00056: val_loss did not improve from 0.18560\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2678 - acc: 0.9170 - val_loss: 0.1981 - val_acc: 0.9455\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9180\n",
      "Epoch 00057: val_loss improved from 0.18560 to 0.17979, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/057-0.1798.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2663 - acc: 0.9180 - val_loss: 0.1798 - val_acc: 0.9471\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9194\n",
      "Epoch 00058: val_loss did not improve from 0.17979\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2599 - acc: 0.9194 - val_loss: 0.1918 - val_acc: 0.9446\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2600 - acc: 0.9203\n",
      "Epoch 00059: val_loss did not improve from 0.17979\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2600 - acc: 0.9203 - val_loss: 0.1959 - val_acc: 0.9427\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9229\n",
      "Epoch 00060: val_loss improved from 0.17979 to 0.17625, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/060-0.1763.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2528 - acc: 0.9229 - val_loss: 0.1763 - val_acc: 0.9497\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9241\n",
      "Epoch 00061: val_loss did not improve from 0.17625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2473 - acc: 0.9241 - val_loss: 0.1790 - val_acc: 0.9483\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9243\n",
      "Epoch 00062: val_loss did not improve from 0.17625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.2473 - acc: 0.9243 - val_loss: 0.1775 - val_acc: 0.9485\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9252\n",
      "Epoch 00063: val_loss did not improve from 0.17625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2461 - acc: 0.9251 - val_loss: 0.1773 - val_acc: 0.9483\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9258\n",
      "Epoch 00064: val_loss did not improve from 0.17625\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2378 - acc: 0.9258 - val_loss: 0.1792 - val_acc: 0.9499\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2387 - acc: 0.9261\n",
      "Epoch 00065: val_loss improved from 0.17625 to 0.17003, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/065-0.1700.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2387 - acc: 0.9261 - val_loss: 0.1700 - val_acc: 0.9513\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9273\n",
      "Epoch 00066: val_loss improved from 0.17003 to 0.16759, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/066-0.1676.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2359 - acc: 0.9273 - val_loss: 0.1676 - val_acc: 0.9532\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9266\n",
      "Epoch 00067: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.2371 - acc: 0.9266 - val_loss: 0.1727 - val_acc: 0.9497\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9296\n",
      "Epoch 00068: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2284 - acc: 0.9296 - val_loss: 0.1857 - val_acc: 0.9450\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2306 - acc: 0.9285\n",
      "Epoch 00069: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2306 - acc: 0.9285 - val_loss: 0.1778 - val_acc: 0.9460\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9318\n",
      "Epoch 00070: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2232 - acc: 0.9318 - val_loss: 0.1703 - val_acc: 0.9502\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2250 - acc: 0.9285\n",
      "Epoch 00071: val_loss improved from 0.16759 to 0.16746, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/071-0.1675.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.2250 - acc: 0.9285 - val_loss: 0.1675 - val_acc: 0.9515\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9309\n",
      "Epoch 00072: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.2221 - acc: 0.9309 - val_loss: 0.1724 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9324\n",
      "Epoch 00073: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2187 - acc: 0.9324 - val_loss: 0.1702 - val_acc: 0.9529\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9329\n",
      "Epoch 00074: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.2195 - acc: 0.9328 - val_loss: 0.1752 - val_acc: 0.9464\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2172 - acc: 0.9312\n",
      "Epoch 00075: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.2172 - acc: 0.9312 - val_loss: 0.1676 - val_acc: 0.9553\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9326\n",
      "Epoch 00076: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2102 - acc: 0.9326 - val_loss: 0.1693 - val_acc: 0.9539\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9343\n",
      "Epoch 00077: val_loss improved from 0.16746 to 0.16104, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/077-0.1610.hdf5\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.2091 - acc: 0.9344 - val_loss: 0.1610 - val_acc: 0.9520\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9365\n",
      "Epoch 00078: val_loss improved from 0.16104 to 0.15490, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/078-0.1549.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.2057 - acc: 0.9365 - val_loss: 0.1549 - val_acc: 0.9562\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9365\n",
      "Epoch 00079: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.2054 - acc: 0.9365 - val_loss: 0.1658 - val_acc: 0.9539\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9367\n",
      "Epoch 00080: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2055 - acc: 0.9367 - val_loss: 0.1658 - val_acc: 0.9548\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9387\n",
      "Epoch 00081: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1993 - acc: 0.9387 - val_loss: 0.1742 - val_acc: 0.9492\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9367\n",
      "Epoch 00082: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.2022 - acc: 0.9367 - val_loss: 0.1555 - val_acc: 0.9564\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9383\n",
      "Epoch 00083: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1976 - acc: 0.9383 - val_loss: 0.1566 - val_acc: 0.9557\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9409\n",
      "Epoch 00084: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1917 - acc: 0.9409 - val_loss: 0.1562 - val_acc: 0.9571\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9386\n",
      "Epoch 00085: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1939 - acc: 0.9386 - val_loss: 0.1603 - val_acc: 0.9546\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9391\n",
      "Epoch 00086: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1925 - acc: 0.9391 - val_loss: 0.1578 - val_acc: 0.9546\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9404\n",
      "Epoch 00087: val_loss did not improve from 0.15490\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1905 - acc: 0.9404 - val_loss: 0.1702 - val_acc: 0.9490\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9418\n",
      "Epoch 00088: val_loss improved from 0.15490 to 0.15346, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/088-0.1535.hdf5\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1862 - acc: 0.9419 - val_loss: 0.1535 - val_acc: 0.9569\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9395\n",
      "Epoch 00089: val_loss did not improve from 0.15346\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1865 - acc: 0.9395 - val_loss: 0.1558 - val_acc: 0.9583\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9419\n",
      "Epoch 00090: val_loss did not improve from 0.15346\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1851 - acc: 0.9419 - val_loss: 0.1587 - val_acc: 0.9546\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9418\n",
      "Epoch 00091: val_loss improved from 0.15346 to 0.15233, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/091-0.1523.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1846 - acc: 0.9418 - val_loss: 0.1523 - val_acc: 0.9585\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9415\n",
      "Epoch 00092: val_loss did not improve from 0.15233\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1842 - acc: 0.9415 - val_loss: 0.1545 - val_acc: 0.9567\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9451\n",
      "Epoch 00093: val_loss improved from 0.15233 to 0.15207, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/093-0.1521.hdf5\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.1727 - acc: 0.9451 - val_loss: 0.1521 - val_acc: 0.9564\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9463\n",
      "Epoch 00094: val_loss did not improve from 0.15207\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1703 - acc: 0.9463 - val_loss: 0.1549 - val_acc: 0.9560\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9447\n",
      "Epoch 00095: val_loss did not improve from 0.15207\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1775 - acc: 0.9447 - val_loss: 0.1649 - val_acc: 0.9502\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9433\n",
      "Epoch 00096: val_loss did not improve from 0.15207\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1766 - acc: 0.9433 - val_loss: 0.1578 - val_acc: 0.9557\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9460\n",
      "Epoch 00097: val_loss did not improve from 0.15207\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1740 - acc: 0.9459 - val_loss: 0.1611 - val_acc: 0.9564\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1753 - acc: 0.9443\n",
      "Epoch 00098: val_loss did not improve from 0.15207\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1753 - acc: 0.9443 - val_loss: 0.1536 - val_acc: 0.9581\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9465\n",
      "Epoch 00099: val_loss improved from 0.15207 to 0.14239, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/099-0.1424.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1675 - acc: 0.9465 - val_loss: 0.1424 - val_acc: 0.9609\n",
      "Epoch 100/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9447\n",
      "Epoch 00100: val_loss did not improve from 0.14239\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1728 - acc: 0.9447 - val_loss: 0.1522 - val_acc: 0.9571\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9465\n",
      "Epoch 00101: val_loss did not improve from 0.14239\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1653 - acc: 0.9465 - val_loss: 0.1544 - val_acc: 0.9543\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9435\n",
      "Epoch 00102: val_loss improved from 0.14239 to 0.14040, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/102-0.1404.hdf5\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1781 - acc: 0.9435 - val_loss: 0.1404 - val_acc: 0.9613\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9488\n",
      "Epoch 00103: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1614 - acc: 0.9487 - val_loss: 0.1521 - val_acc: 0.9590\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9479\n",
      "Epoch 00104: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1626 - acc: 0.9479 - val_loss: 0.1522 - val_acc: 0.9574\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9474\n",
      "Epoch 00105: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 838us/sample - loss: 0.1622 - acc: 0.9474 - val_loss: 0.1477 - val_acc: 0.9595\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9501\n",
      "Epoch 00106: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1558 - acc: 0.9501 - val_loss: 0.1460 - val_acc: 0.9616\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9505\n",
      "Epoch 00107: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1565 - acc: 0.9506 - val_loss: 0.1457 - val_acc: 0.9597\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9487\n",
      "Epoch 00108: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1554 - acc: 0.9487 - val_loss: 0.1662 - val_acc: 0.9555\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9479\n",
      "Epoch 00109: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1605 - acc: 0.9479 - val_loss: 0.1482 - val_acc: 0.9592\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9501\n",
      "Epoch 00110: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1555 - acc: 0.9500 - val_loss: 0.1574 - val_acc: 0.9564\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9499\n",
      "Epoch 00111: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1565 - acc: 0.9499 - val_loss: 0.1533 - val_acc: 0.9583\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9525\n",
      "Epoch 00112: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1491 - acc: 0.9525 - val_loss: 0.1592 - val_acc: 0.9571\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9515\n",
      "Epoch 00113: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1514 - acc: 0.9516 - val_loss: 0.1469 - val_acc: 0.9583\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9517\n",
      "Epoch 00114: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1487 - acc: 0.9517 - val_loss: 0.1537 - val_acc: 0.9576\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9513\n",
      "Epoch 00115: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1490 - acc: 0.9513 - val_loss: 0.1498 - val_acc: 0.9578\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9530\n",
      "Epoch 00116: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1478 - acc: 0.9530 - val_loss: 0.1503 - val_acc: 0.9595\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9533\n",
      "Epoch 00117: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1471 - acc: 0.9533 - val_loss: 0.1734 - val_acc: 0.9525\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9515\n",
      "Epoch 00118: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1446 - acc: 0.9516 - val_loss: 0.1463 - val_acc: 0.9611\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9547\n",
      "Epoch 00119: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1430 - acc: 0.9547 - val_loss: 0.1521 - val_acc: 0.9578\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9545\n",
      "Epoch 00120: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1415 - acc: 0.9544 - val_loss: 0.1493 - val_acc: 0.9604\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9536\n",
      "Epoch 00121: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 835us/sample - loss: 0.1425 - acc: 0.9536 - val_loss: 0.1503 - val_acc: 0.9555\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9535\n",
      "Epoch 00122: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1422 - acc: 0.9535 - val_loss: 0.1531 - val_acc: 0.9597\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9558\n",
      "Epoch 00123: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1364 - acc: 0.9558 - val_loss: 0.1578 - val_acc: 0.9576\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9550\n",
      "Epoch 00124: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1396 - acc: 0.9550 - val_loss: 0.1478 - val_acc: 0.9606\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9556\n",
      "Epoch 00125: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1363 - acc: 0.9556 - val_loss: 0.1538 - val_acc: 0.9604\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9563\n",
      "Epoch 00126: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1341 - acc: 0.9563 - val_loss: 0.1463 - val_acc: 0.9613\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9548\n",
      "Epoch 00127: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1384 - acc: 0.9548 - val_loss: 0.1406 - val_acc: 0.9611\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9566\n",
      "Epoch 00128: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1324 - acc: 0.9566 - val_loss: 0.1424 - val_acc: 0.9632\n",
      "Epoch 129/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9566\n",
      "Epoch 00129: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1322 - acc: 0.9566 - val_loss: 0.1446 - val_acc: 0.9602\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9566\n",
      "Epoch 00130: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1328 - acc: 0.9566 - val_loss: 0.1608 - val_acc: 0.9550\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9576\n",
      "Epoch 00131: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1294 - acc: 0.9576 - val_loss: 0.1565 - val_acc: 0.9602\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9575\n",
      "Epoch 00132: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1301 - acc: 0.9575 - val_loss: 0.1473 - val_acc: 0.9602\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9579\n",
      "Epoch 00133: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1296 - acc: 0.9579 - val_loss: 0.1465 - val_acc: 0.9604\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9585\n",
      "Epoch 00134: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1289 - acc: 0.9585 - val_loss: 0.1457 - val_acc: 0.9646\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9586\n",
      "Epoch 00135: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1301 - acc: 0.9586 - val_loss: 0.1510 - val_acc: 0.9599\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9583\n",
      "Epoch 00136: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1274 - acc: 0.9583 - val_loss: 0.1579 - val_acc: 0.9574\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9578\n",
      "Epoch 00137: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1294 - acc: 0.9578 - val_loss: 0.1505 - val_acc: 0.9599\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9587\n",
      "Epoch 00138: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1261 - acc: 0.9587 - val_loss: 0.1439 - val_acc: 0.9625\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9598\n",
      "Epoch 00139: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.1237 - acc: 0.9598 - val_loss: 0.1457 - val_acc: 0.9609\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9622\n",
      "Epoch 00140: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1186 - acc: 0.9622 - val_loss: 0.1487 - val_acc: 0.9616\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9609\n",
      "Epoch 00141: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1218 - acc: 0.9609 - val_loss: 0.1496 - val_acc: 0.9625\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9604\n",
      "Epoch 00142: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 836us/sample - loss: 0.1202 - acc: 0.9604 - val_loss: 0.1493 - val_acc: 0.9627\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9606\n",
      "Epoch 00143: val_loss did not improve from 0.14040\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1197 - acc: 0.9606 - val_loss: 0.1504 - val_acc: 0.9618\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9604\n",
      "Epoch 00144: val_loss improved from 0.14040 to 0.13750, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/144-0.1375.hdf5\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1192 - acc: 0.9604 - val_loss: 0.1375 - val_acc: 0.9630\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9610\n",
      "Epoch 00145: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1182 - acc: 0.9610 - val_loss: 0.1524 - val_acc: 0.9595\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9618\n",
      "Epoch 00146: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1139 - acc: 0.9618 - val_loss: 0.1504 - val_acc: 0.9604\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9627\n",
      "Epoch 00147: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1154 - acc: 0.9627 - val_loss: 0.1441 - val_acc: 0.9625\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9619\n",
      "Epoch 00148: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1146 - acc: 0.9619 - val_loss: 0.1597 - val_acc: 0.9595\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9615\n",
      "Epoch 00149: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1156 - acc: 0.9616 - val_loss: 0.1548 - val_acc: 0.9578\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9628\n",
      "Epoch 00150: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1136 - acc: 0.9628 - val_loss: 0.1511 - val_acc: 0.9623\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9629\n",
      "Epoch 00151: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1148 - acc: 0.9629 - val_loss: 0.1468 - val_acc: 0.9620\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9644\n",
      "Epoch 00152: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1089 - acc: 0.9644 - val_loss: 0.1487 - val_acc: 0.9592\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9638\n",
      "Epoch 00153: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1107 - acc: 0.9638 - val_loss: 0.1536 - val_acc: 0.9588\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9625\n",
      "Epoch 00154: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1140 - acc: 0.9625 - val_loss: 0.1529 - val_acc: 0.9632\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9639\n",
      "Epoch 00155: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1086 - acc: 0.9639 - val_loss: 0.1542 - val_acc: 0.9618\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9645\n",
      "Epoch 00156: val_loss did not improve from 0.13750\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1090 - acc: 0.9645 - val_loss: 0.1439 - val_acc: 0.9637\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9637\n",
      "Epoch 00157: val_loss improved from 0.13750 to 0.13625, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_6_conv_checkpoint/157-0.1363.hdf5\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1100 - acc: 0.9637 - val_loss: 0.1363 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9643\n",
      "Epoch 00158: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 832us/sample - loss: 0.1061 - acc: 0.9644 - val_loss: 0.1562 - val_acc: 0.9599\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9652\n",
      "Epoch 00159: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.1052 - acc: 0.9652 - val_loss: 0.1495 - val_acc: 0.9632\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9656\n",
      "Epoch 00160: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.1075 - acc: 0.9656 - val_loss: 0.1534 - val_acc: 0.9632\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9651\n",
      "Epoch 00161: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1068 - acc: 0.9651 - val_loss: 0.1449 - val_acc: 0.9627\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9645\n",
      "Epoch 00162: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.1050 - acc: 0.9645 - val_loss: 0.1590 - val_acc: 0.9604\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9649\n",
      "Epoch 00163: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 847us/sample - loss: 0.1069 - acc: 0.9649 - val_loss: 0.1554 - val_acc: 0.9613\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9656\n",
      "Epoch 00164: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 849us/sample - loss: 0.1044 - acc: 0.9656 - val_loss: 0.1532 - val_acc: 0.9604\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9660\n",
      "Epoch 00165: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.1043 - acc: 0.9660 - val_loss: 0.1511 - val_acc: 0.9630\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9674\n",
      "Epoch 00166: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0988 - acc: 0.9675 - val_loss: 0.1573 - val_acc: 0.9611\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9645\n",
      "Epoch 00167: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.1043 - acc: 0.9645 - val_loss: 0.1532 - val_acc: 0.9602\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9677\n",
      "Epoch 00168: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.0958 - acc: 0.9677 - val_loss: 0.1547 - val_acc: 0.9609\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9652\n",
      "Epoch 00169: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.1057 - acc: 0.9652 - val_loss: 0.1460 - val_acc: 0.9630\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9679\n",
      "Epoch 00170: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0962 - acc: 0.9679 - val_loss: 0.1476 - val_acc: 0.9627\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9671\n",
      "Epoch 00171: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0982 - acc: 0.9671 - val_loss: 0.1704 - val_acc: 0.9630\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9679\n",
      "Epoch 00172: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0960 - acc: 0.9679 - val_loss: 0.1541 - val_acc: 0.9641\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9679\n",
      "Epoch 00173: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0965 - acc: 0.9679 - val_loss: 0.1635 - val_acc: 0.9627\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9673\n",
      "Epoch 00174: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0969 - acc: 0.9673 - val_loss: 0.1527 - val_acc: 0.9625\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9687\n",
      "Epoch 00175: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 850us/sample - loss: 0.0972 - acc: 0.9687 - val_loss: 0.1584 - val_acc: 0.9590\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9690\n",
      "Epoch 00176: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 848us/sample - loss: 0.0946 - acc: 0.9690 - val_loss: 0.1488 - val_acc: 0.9618\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9689\n",
      "Epoch 00177: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 840us/sample - loss: 0.0951 - acc: 0.9689 - val_loss: 0.1547 - val_acc: 0.9609\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9687\n",
      "Epoch 00178: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0940 - acc: 0.9686 - val_loss: 0.1460 - val_acc: 0.9637\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9683\n",
      "Epoch 00179: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0950 - acc: 0.9683 - val_loss: 0.1628 - val_acc: 0.9611\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9693\n",
      "Epoch 00180: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0935 - acc: 0.9693 - val_loss: 0.1525 - val_acc: 0.9627\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9700\n",
      "Epoch 00181: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0890 - acc: 0.9700 - val_loss: 0.1495 - val_acc: 0.9623\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9691\n",
      "Epoch 00182: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0943 - acc: 0.9691 - val_loss: 0.1551 - val_acc: 0.9611\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9697\n",
      "Epoch 00183: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0904 - acc: 0.9697 - val_loss: 0.1557 - val_acc: 0.9609\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9692\n",
      "Epoch 00184: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0902 - acc: 0.9692 - val_loss: 0.1619 - val_acc: 0.9583\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9692\n",
      "Epoch 00185: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 846us/sample - loss: 0.0921 - acc: 0.9692 - val_loss: 0.1563 - val_acc: 0.9606\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9718\n",
      "Epoch 00186: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0876 - acc: 0.9718 - val_loss: 0.1506 - val_acc: 0.9634\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9689\n",
      "Epoch 00187: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0930 - acc: 0.9689 - val_loss: 0.1520 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9701\n",
      "Epoch 00188: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0885 - acc: 0.9701 - val_loss: 0.1545 - val_acc: 0.9648\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9704\n",
      "Epoch 00189: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0887 - acc: 0.9704 - val_loss: 0.1534 - val_acc: 0.9620\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9709\n",
      "Epoch 00190: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0871 - acc: 0.9709 - val_loss: 0.1587 - val_acc: 0.9627\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9720\n",
      "Epoch 00191: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0861 - acc: 0.9720 - val_loss: 0.1587 - val_acc: 0.9618\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9723\n",
      "Epoch 00192: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0858 - acc: 0.9723 - val_loss: 0.1764 - val_acc: 0.9637\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9697\n",
      "Epoch 00193: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0903 - acc: 0.9697 - val_loss: 0.1520 - val_acc: 0.9658\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9715\n",
      "Epoch 00194: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0844 - acc: 0.9715 - val_loss: 0.1596 - val_acc: 0.9630\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9719\n",
      "Epoch 00195: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0873 - acc: 0.9719 - val_loss: 0.1550 - val_acc: 0.9623\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9732\n",
      "Epoch 00196: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0821 - acc: 0.9732 - val_loss: 0.1631 - val_acc: 0.9632\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9730\n",
      "Epoch 00197: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0824 - acc: 0.9729 - val_loss: 0.1550 - val_acc: 0.9632\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9723\n",
      "Epoch 00198: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 835us/sample - loss: 0.0821 - acc: 0.9723 - val_loss: 0.1582 - val_acc: 0.9630\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9728\n",
      "Epoch 00199: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0813 - acc: 0.9728 - val_loss: 0.1557 - val_acc: 0.9623\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9728\n",
      "Epoch 00200: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 841us/sample - loss: 0.0809 - acc: 0.9728 - val_loss: 0.1593 - val_acc: 0.9641\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9726\n",
      "Epoch 00201: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 842us/sample - loss: 0.0837 - acc: 0.9726 - val_loss: 0.1576 - val_acc: 0.9623\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9727\n",
      "Epoch 00202: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0838 - acc: 0.9727 - val_loss: 0.1839 - val_acc: 0.9581\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9733\n",
      "Epoch 00203: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 845us/sample - loss: 0.0820 - acc: 0.9733 - val_loss: 0.1536 - val_acc: 0.9632\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9735\n",
      "Epoch 00204: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 843us/sample - loss: 0.0790 - acc: 0.9735 - val_loss: 0.1608 - val_acc: 0.9641\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9735\n",
      "Epoch 00205: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0805 - acc: 0.9735 - val_loss: 0.1587 - val_acc: 0.9623\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9737\n",
      "Epoch 00206: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0798 - acc: 0.9737 - val_loss: 0.1654 - val_acc: 0.9597\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9735\n",
      "Epoch 00207: val_loss did not improve from 0.13625\n",
      "36805/36805 [==============================] - 31s 844us/sample - loss: 0.0800 - acc: 0.9735 - val_loss: 0.1625 - val_acc: 0.9623\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 421us/sample - loss: 0.1785 - acc: 0.9508\n",
      "Loss: 0.17850961259190043 Accuracy: 0.95077884\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3062 - acc: 0.2465\n",
      "Epoch 00001: val_loss improved from inf to 1.54815, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/001-1.5482.hdf5\n",
      "36805/36805 [==============================] - 35s 960us/sample - loss: 2.3062 - acc: 0.2465 - val_loss: 1.5482 - val_acc: 0.5653\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4910 - acc: 0.5240\n",
      "Epoch 00002: val_loss improved from 1.54815 to 1.06334, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/002-1.0633.hdf5\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 1.4910 - acc: 0.5240 - val_loss: 1.0633 - val_acc: 0.6981\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1670 - acc: 0.6313\n",
      "Epoch 00003: val_loss improved from 1.06334 to 0.83804, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/003-0.8380.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 1.1672 - acc: 0.6312 - val_loss: 0.8380 - val_acc: 0.7498\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9808 - acc: 0.6916\n",
      "Epoch 00004: val_loss improved from 0.83804 to 0.66840, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/004-0.6684.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.9808 - acc: 0.6916 - val_loss: 0.6684 - val_acc: 0.8118\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8435 - acc: 0.7377\n",
      "Epoch 00005: val_loss improved from 0.66840 to 0.64388, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/005-0.6439.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.8435 - acc: 0.7377 - val_loss: 0.6439 - val_acc: 0.8069\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7473 - acc: 0.7712\n",
      "Epoch 00006: val_loss improved from 0.64388 to 0.52524, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/006-0.5252.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.7473 - acc: 0.7712 - val_loss: 0.5252 - val_acc: 0.8556\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6745 - acc: 0.7924\n",
      "Epoch 00007: val_loss improved from 0.52524 to 0.44083, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/007-0.4408.hdf5\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.6745 - acc: 0.7924 - val_loss: 0.4408 - val_acc: 0.8784\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6059 - acc: 0.8147\n",
      "Epoch 00008: val_loss improved from 0.44083 to 0.40397, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/008-0.4040.hdf5\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.6060 - acc: 0.8147 - val_loss: 0.4040 - val_acc: 0.8854\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5584 - acc: 0.8276\n",
      "Epoch 00009: val_loss improved from 0.40397 to 0.36554, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/009-0.3655.hdf5\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.5584 - acc: 0.8276 - val_loss: 0.3655 - val_acc: 0.8954\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8426\n",
      "Epoch 00010: val_loss improved from 0.36554 to 0.32569, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/010-0.3257.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.5146 - acc: 0.8426 - val_loss: 0.3257 - val_acc: 0.9106\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4830 - acc: 0.8527\n",
      "Epoch 00011: val_loss did not improve from 0.32569\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.4829 - acc: 0.8527 - val_loss: 0.3400 - val_acc: 0.9024\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4529 - acc: 0.8608\n",
      "Epoch 00012: val_loss improved from 0.32569 to 0.28559, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/012-0.2856.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.4528 - acc: 0.8608 - val_loss: 0.2856 - val_acc: 0.9185\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4290 - acc: 0.8673\n",
      "Epoch 00013: val_loss did not improve from 0.28559\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.4290 - acc: 0.8673 - val_loss: 0.3061 - val_acc: 0.9103\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8755\n",
      "Epoch 00014: val_loss improved from 0.28559 to 0.24989, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/014-0.2499.hdf5\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.4053 - acc: 0.8755 - val_loss: 0.2499 - val_acc: 0.9278\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3842 - acc: 0.8827\n",
      "Epoch 00015: val_loss improved from 0.24989 to 0.24330, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/015-0.2433.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.3842 - acc: 0.8827 - val_loss: 0.2433 - val_acc: 0.9278\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.8874\n",
      "Epoch 00016: val_loss improved from 0.24330 to 0.23580, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/016-0.2358.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.3648 - acc: 0.8874 - val_loss: 0.2358 - val_acc: 0.9320\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3498 - acc: 0.8940\n",
      "Epoch 00017: val_loss improved from 0.23580 to 0.23055, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/017-0.2305.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.3498 - acc: 0.8940 - val_loss: 0.2305 - val_acc: 0.9287\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3385 - acc: 0.8970\n",
      "Epoch 00018: val_loss improved from 0.23055 to 0.22121, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/018-0.2212.hdf5\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.3385 - acc: 0.8970 - val_loss: 0.2212 - val_acc: 0.9331\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.9007\n",
      "Epoch 00019: val_loss improved from 0.22121 to 0.20770, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/019-0.2077.hdf5\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.3236 - acc: 0.9006 - val_loss: 0.2077 - val_acc: 0.9364\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3071 - acc: 0.9048\n",
      "Epoch 00020: val_loss improved from 0.20770 to 0.20399, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/020-0.2040.hdf5\n",
      "36805/36805 [==============================] - 32s 862us/sample - loss: 0.3071 - acc: 0.9048 - val_loss: 0.2040 - val_acc: 0.9373\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2976 - acc: 0.9086\n",
      "Epoch 00021: val_loss did not improve from 0.20399\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.2976 - acc: 0.9086 - val_loss: 0.2097 - val_acc: 0.9387\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9103\n",
      "Epoch 00022: val_loss improved from 0.20399 to 0.19316, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/022-0.1932.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.2908 - acc: 0.9103 - val_loss: 0.1932 - val_acc: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2834 - acc: 0.9124\n",
      "Epoch 00023: val_loss improved from 0.19316 to 0.18623, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/023-0.1862.hdf5\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.2834 - acc: 0.9124 - val_loss: 0.1862 - val_acc: 0.9425\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2722 - acc: 0.9149\n",
      "Epoch 00024: val_loss improved from 0.18623 to 0.18054, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/024-0.1805.hdf5\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.2723 - acc: 0.9149 - val_loss: 0.1805 - val_acc: 0.9432\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2644 - acc: 0.9170\n",
      "Epoch 00025: val_loss improved from 0.18054 to 0.17366, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/025-0.1737.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.2644 - acc: 0.9170 - val_loss: 0.1737 - val_acc: 0.9467\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9207\n",
      "Epoch 00026: val_loss did not improve from 0.17366\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.2555 - acc: 0.9207 - val_loss: 0.1834 - val_acc: 0.9415\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9231\n",
      "Epoch 00027: val_loss did not improve from 0.17366\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.2438 - acc: 0.9231 - val_loss: 0.1740 - val_acc: 0.9485\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9235\n",
      "Epoch 00028: val_loss improved from 0.17366 to 0.16388, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/028-0.1639.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.2408 - acc: 0.9235 - val_loss: 0.1639 - val_acc: 0.9504\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9277\n",
      "Epoch 00029: val_loss did not improve from 0.16388\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.2355 - acc: 0.9277 - val_loss: 0.1724 - val_acc: 0.9474\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9295\n",
      "Epoch 00030: val_loss did not improve from 0.16388\n",
      "36805/36805 [==============================] - 32s 864us/sample - loss: 0.2238 - acc: 0.9295 - val_loss: 0.1714 - val_acc: 0.9474\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9310\n",
      "Epoch 00031: val_loss did not improve from 0.16388\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.2208 - acc: 0.9310 - val_loss: 0.1689 - val_acc: 0.9460\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9309\n",
      "Epoch 00032: val_loss did not improve from 0.16388\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.2174 - acc: 0.9309 - val_loss: 0.1735 - val_acc: 0.9485\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9344\n",
      "Epoch 00033: val_loss improved from 0.16388 to 0.16122, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/033-0.1612.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.2109 - acc: 0.9344 - val_loss: 0.1612 - val_acc: 0.9497\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2087 - acc: 0.9338\n",
      "Epoch 00034: val_loss improved from 0.16122 to 0.15681, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/034-0.1568.hdf5\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.2088 - acc: 0.9338 - val_loss: 0.1568 - val_acc: 0.9518\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9365\n",
      "Epoch 00035: val_loss did not improve from 0.15681\n",
      "36805/36805 [==============================] - 32s 864us/sample - loss: 0.1992 - acc: 0.9365 - val_loss: 0.1609 - val_acc: 0.9502\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9383\n",
      "Epoch 00036: val_loss improved from 0.15681 to 0.15448, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/036-0.1545.hdf5\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.1957 - acc: 0.9384 - val_loss: 0.1545 - val_acc: 0.9525\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9369\n",
      "Epoch 00037: val_loss improved from 0.15448 to 0.14687, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/037-0.1469.hdf5\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.1966 - acc: 0.9369 - val_loss: 0.1469 - val_acc: 0.9560\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9406\n",
      "Epoch 00038: val_loss did not improve from 0.14687\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.1875 - acc: 0.9406 - val_loss: 0.1476 - val_acc: 0.9539\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1803 - acc: 0.9430\n",
      "Epoch 00039: val_loss did not improve from 0.14687\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.1803 - acc: 0.9430 - val_loss: 0.1550 - val_acc: 0.9534\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9428\n",
      "Epoch 00040: val_loss improved from 0.14687 to 0.14027, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/040-0.1403.hdf5\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.1811 - acc: 0.9428 - val_loss: 0.1403 - val_acc: 0.9571\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9443\n",
      "Epoch 00041: val_loss did not improve from 0.14027\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.1778 - acc: 0.9443 - val_loss: 0.1422 - val_acc: 0.9581\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9444\n",
      "Epoch 00042: val_loss did not improve from 0.14027\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.1744 - acc: 0.9444 - val_loss: 0.1435 - val_acc: 0.9571\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9461\n",
      "Epoch 00043: val_loss improved from 0.14027 to 0.13601, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/043-0.1360.hdf5\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.1678 - acc: 0.9461 - val_loss: 0.1360 - val_acc: 0.9606\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1657 - acc: 0.9474\n",
      "Epoch 00044: val_loss improved from 0.13601 to 0.13220, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/044-0.1322.hdf5\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.1657 - acc: 0.9474 - val_loss: 0.1322 - val_acc: 0.9585\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9474\n",
      "Epoch 00045: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 864us/sample - loss: 0.1654 - acc: 0.9474 - val_loss: 0.1341 - val_acc: 0.9590\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9493\n",
      "Epoch 00046: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.1563 - acc: 0.9492 - val_loss: 0.1371 - val_acc: 0.9560\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9499\n",
      "Epoch 00047: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.1556 - acc: 0.9499 - val_loss: 0.1408 - val_acc: 0.9574\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9505\n",
      "Epoch 00048: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.1551 - acc: 0.9506 - val_loss: 0.1404 - val_acc: 0.9550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9504\n",
      "Epoch 00049: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.1500 - acc: 0.9504 - val_loss: 0.1624 - val_acc: 0.9520\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9519\n",
      "Epoch 00050: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.1492 - acc: 0.9519 - val_loss: 0.1399 - val_acc: 0.9597\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9517\n",
      "Epoch 00051: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 863us/sample - loss: 0.1457 - acc: 0.9517 - val_loss: 0.1361 - val_acc: 0.9592\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9545\n",
      "Epoch 00052: val_loss did not improve from 0.13220\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.1402 - acc: 0.9545 - val_loss: 0.1330 - val_acc: 0.9623\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9552\n",
      "Epoch 00053: val_loss improved from 0.13220 to 0.13026, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/053-0.1303.hdf5\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.1384 - acc: 0.9552 - val_loss: 0.1303 - val_acc: 0.9592\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9554\n",
      "Epoch 00054: val_loss improved from 0.13026 to 0.12923, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/054-0.1292.hdf5\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.1376 - acc: 0.9554 - val_loss: 0.1292 - val_acc: 0.9611\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9549\n",
      "Epoch 00055: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.1360 - acc: 0.9549 - val_loss: 0.1332 - val_acc: 0.9583\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9582\n",
      "Epoch 00056: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 875us/sample - loss: 0.1279 - acc: 0.9582 - val_loss: 0.1384 - val_acc: 0.9630\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9584\n",
      "Epoch 00057: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 878us/sample - loss: 0.1307 - acc: 0.9584 - val_loss: 0.1391 - val_acc: 0.9611\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9590\n",
      "Epoch 00058: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.1281 - acc: 0.9590 - val_loss: 0.1552 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9596\n",
      "Epoch 00059: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 877us/sample - loss: 0.1224 - acc: 0.9596 - val_loss: 0.1396 - val_acc: 0.9623\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9602\n",
      "Epoch 00060: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.1201 - acc: 0.9602 - val_loss: 0.1383 - val_acc: 0.9590\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9607\n",
      "Epoch 00061: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.1204 - acc: 0.9607 - val_loss: 0.1360 - val_acc: 0.9592\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9611\n",
      "Epoch 00062: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 876us/sample - loss: 0.1193 - acc: 0.9610 - val_loss: 0.1348 - val_acc: 0.9578\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9614\n",
      "Epoch 00063: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 864us/sample - loss: 0.1201 - acc: 0.9614 - val_loss: 0.1311 - val_acc: 0.9627\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9623\n",
      "Epoch 00064: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.1136 - acc: 0.9623 - val_loss: 0.1352 - val_acc: 0.9604\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9621\n",
      "Epoch 00065: val_loss did not improve from 0.12923\n",
      "36805/36805 [==============================] - 32s 876us/sample - loss: 0.1145 - acc: 0.9621 - val_loss: 0.1310 - val_acc: 0.9592\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9632\n",
      "Epoch 00066: val_loss improved from 0.12923 to 0.12841, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/066-0.1284.hdf5\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.1095 - acc: 0.9632 - val_loss: 0.1284 - val_acc: 0.9634\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9646\n",
      "Epoch 00067: val_loss did not improve from 0.12841\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.1063 - acc: 0.9646 - val_loss: 0.1290 - val_acc: 0.9606\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9653\n",
      "Epoch 00068: val_loss did not improve from 0.12841\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.1061 - acc: 0.9653 - val_loss: 0.1342 - val_acc: 0.9588\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9668\n",
      "Epoch 00069: val_loss did not improve from 0.12841\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.1004 - acc: 0.9668 - val_loss: 0.1373 - val_acc: 0.9583\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9655\n",
      "Epoch 00070: val_loss improved from 0.12841 to 0.12339, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/070-0.1234.hdf5\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.1049 - acc: 0.9655 - val_loss: 0.1234 - val_acc: 0.9653\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9674\n",
      "Epoch 00071: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 865us/sample - loss: 0.1000 - acc: 0.9674 - val_loss: 0.1340 - val_acc: 0.9637\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9673\n",
      "Epoch 00072: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.0980 - acc: 0.9673 - val_loss: 0.1257 - val_acc: 0.9634\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9667\n",
      "Epoch 00073: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.0990 - acc: 0.9667 - val_loss: 0.1354 - val_acc: 0.9625\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9678\n",
      "Epoch 00074: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0959 - acc: 0.9678 - val_loss: 0.1262 - val_acc: 0.9646\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9688\n",
      "Epoch 00075: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0925 - acc: 0.9688 - val_loss: 0.1325 - val_acc: 0.9627\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9684\n",
      "Epoch 00076: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0962 - acc: 0.9684 - val_loss: 0.1351 - val_acc: 0.9611\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9682\n",
      "Epoch 00077: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 873us/sample - loss: 0.0933 - acc: 0.9682 - val_loss: 0.1299 - val_acc: 0.9644\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9701\n",
      "Epoch 00078: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 873us/sample - loss: 0.0915 - acc: 0.9701 - val_loss: 0.1301 - val_acc: 0.9655\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9714\n",
      "Epoch 00079: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0878 - acc: 0.9714 - val_loss: 0.1316 - val_acc: 0.9625\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9701\n",
      "Epoch 00080: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.0879 - acc: 0.9701 - val_loss: 0.1379 - val_acc: 0.9604\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9704\n",
      "Epoch 00081: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.0877 - acc: 0.9704 - val_loss: 0.1465 - val_acc: 0.9602\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9707\n",
      "Epoch 00082: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 881us/sample - loss: 0.0876 - acc: 0.9707 - val_loss: 0.1298 - val_acc: 0.9611\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9714\n",
      "Epoch 00083: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.0847 - acc: 0.9714 - val_loss: 0.1436 - val_acc: 0.9606\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9713\n",
      "Epoch 00084: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 876us/sample - loss: 0.0849 - acc: 0.9713 - val_loss: 0.1466 - val_acc: 0.9574\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9737\n",
      "Epoch 00085: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 875us/sample - loss: 0.0794 - acc: 0.9737 - val_loss: 0.1294 - val_acc: 0.9648\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9733\n",
      "Epoch 00086: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 875us/sample - loss: 0.0800 - acc: 0.9733 - val_loss: 0.1235 - val_acc: 0.9651\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9709\n",
      "Epoch 00087: val_loss did not improve from 0.12339\n",
      "36805/36805 [==============================] - 32s 880us/sample - loss: 0.0817 - acc: 0.9709 - val_loss: 0.1298 - val_acc: 0.9639\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9742\n",
      "Epoch 00088: val_loss improved from 0.12339 to 0.12285, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/088-0.1229.hdf5\n",
      "36805/36805 [==============================] - 32s 875us/sample - loss: 0.0772 - acc: 0.9742 - val_loss: 0.1229 - val_acc: 0.9662\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9736\n",
      "Epoch 00089: val_loss improved from 0.12285 to 0.12080, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/089-0.1208.hdf5\n",
      "36805/36805 [==============================] - 32s 874us/sample - loss: 0.0783 - acc: 0.9736 - val_loss: 0.1208 - val_acc: 0.9644\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9750\n",
      "Epoch 00090: val_loss improved from 0.12080 to 0.11804, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_7_conv_checkpoint/090-0.1180.hdf5\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0739 - acc: 0.9750 - val_loss: 0.1180 - val_acc: 0.9655\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9742\n",
      "Epoch 00091: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0747 - acc: 0.9742 - val_loss: 0.1466 - val_acc: 0.9592\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9749\n",
      "Epoch 00092: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0733 - acc: 0.9749 - val_loss: 0.1410 - val_acc: 0.9639\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9753\n",
      "Epoch 00093: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0741 - acc: 0.9753 - val_loss: 0.1523 - val_acc: 0.9576\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9750\n",
      "Epoch 00094: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0723 - acc: 0.9750 - val_loss: 0.1364 - val_acc: 0.9634\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9764\n",
      "Epoch 00095: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0710 - acc: 0.9764 - val_loss: 0.1448 - val_acc: 0.9630\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9756\n",
      "Epoch 00096: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0698 - acc: 0.9756 - val_loss: 0.1322 - val_acc: 0.9637\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9767\n",
      "Epoch 00097: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.0698 - acc: 0.9767 - val_loss: 0.1287 - val_acc: 0.9632\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9773\n",
      "Epoch 00098: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0682 - acc: 0.9773 - val_loss: 0.1453 - val_acc: 0.9611\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9776\n",
      "Epoch 00099: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0669 - acc: 0.9776 - val_loss: 0.1448 - val_acc: 0.9660\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9771\n",
      "Epoch 00100: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0643 - acc: 0.9771 - val_loss: 0.1311 - val_acc: 0.9623\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9777\n",
      "Epoch 00101: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0643 - acc: 0.9777 - val_loss: 0.1350 - val_acc: 0.9651\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9782\n",
      "Epoch 00102: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0646 - acc: 0.9782 - val_loss: 0.1373 - val_acc: 0.9639\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9777\n",
      "Epoch 00103: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0639 - acc: 0.9777 - val_loss: 0.1339 - val_acc: 0.9658\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9789\n",
      "Epoch 00104: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0604 - acc: 0.9789 - val_loss: 0.1306 - val_acc: 0.9660\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9791\n",
      "Epoch 00105: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 872us/sample - loss: 0.0636 - acc: 0.9791 - val_loss: 0.1266 - val_acc: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9794\n",
      "Epoch 00106: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0626 - acc: 0.9794 - val_loss: 0.1501 - val_acc: 0.9641\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9799\n",
      "Epoch 00107: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.0608 - acc: 0.9799 - val_loss: 0.1331 - val_acc: 0.9634\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9813\n",
      "Epoch 00108: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0558 - acc: 0.9813 - val_loss: 0.1324 - val_acc: 0.9660\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9798\n",
      "Epoch 00109: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0601 - acc: 0.9798 - val_loss: 0.1407 - val_acc: 0.9644\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9809\n",
      "Epoch 00110: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0571 - acc: 0.9809 - val_loss: 0.1397 - val_acc: 0.9653\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9804\n",
      "Epoch 00111: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0577 - acc: 0.9804 - val_loss: 0.1361 - val_acc: 0.9616\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9803\n",
      "Epoch 00112: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0580 - acc: 0.9803 - val_loss: 0.1241 - val_acc: 0.9681\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9818\n",
      "Epoch 00113: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0543 - acc: 0.9818 - val_loss: 0.1481 - val_acc: 0.9641\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9799\n",
      "Epoch 00114: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0568 - acc: 0.9799 - val_loss: 0.1287 - val_acc: 0.9651\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9814\n",
      "Epoch 00115: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0544 - acc: 0.9814 - val_loss: 0.1399 - val_acc: 0.9644\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9813\n",
      "Epoch 00116: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0535 - acc: 0.9813 - val_loss: 0.1253 - val_acc: 0.9686\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9814\n",
      "Epoch 00117: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0537 - acc: 0.9814 - val_loss: 0.1467 - val_acc: 0.9672\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9836\n",
      "Epoch 00118: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 866us/sample - loss: 0.0480 - acc: 0.9836 - val_loss: 0.1406 - val_acc: 0.9639\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9808\n",
      "Epoch 00119: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0562 - acc: 0.9808 - val_loss: 0.1409 - val_acc: 0.9658\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9826\n",
      "Epoch 00120: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0505 - acc: 0.9826 - val_loss: 0.1549 - val_acc: 0.9618\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9828\n",
      "Epoch 00121: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0496 - acc: 0.9828 - val_loss: 0.1392 - val_acc: 0.9658\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9813\n",
      "Epoch 00122: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0540 - acc: 0.9813 - val_loss: 0.1416 - val_acc: 0.9618\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9837\n",
      "Epoch 00123: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 871us/sample - loss: 0.0475 - acc: 0.9837 - val_loss: 0.1387 - val_acc: 0.9655\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9832\n",
      "Epoch 00124: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0521 - acc: 0.9832 - val_loss: 0.1482 - val_acc: 0.9667\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9841\n",
      "Epoch 00125: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0474 - acc: 0.9841 - val_loss: 0.1455 - val_acc: 0.9655\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9839\n",
      "Epoch 00126: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0470 - acc: 0.9839 - val_loss: 0.1649 - val_acc: 0.9616\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9833\n",
      "Epoch 00127: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0476 - acc: 0.9833 - val_loss: 0.1621 - val_acc: 0.9681\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9849\n",
      "Epoch 00128: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0456 - acc: 0.9849 - val_loss: 0.1405 - val_acc: 0.9669\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9837\n",
      "Epoch 00129: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0482 - acc: 0.9837 - val_loss: 0.1449 - val_acc: 0.9658\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9843\n",
      "Epoch 00130: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0446 - acc: 0.9843 - val_loss: 0.1641 - val_acc: 0.9641\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9844\n",
      "Epoch 00131: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0453 - acc: 0.9844 - val_loss: 0.1527 - val_acc: 0.9644\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9849\n",
      "Epoch 00132: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0449 - acc: 0.9849 - val_loss: 0.1489 - val_acc: 0.9660\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9843\n",
      "Epoch 00133: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0467 - acc: 0.9843 - val_loss: 0.1513 - val_acc: 0.9648\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9860\n",
      "Epoch 00134: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 870us/sample - loss: 0.0414 - acc: 0.9860 - val_loss: 0.1577 - val_acc: 0.9646\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9849\n",
      "Epoch 00135: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0435 - acc: 0.9849 - val_loss: 0.1523 - val_acc: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9856\n",
      "Epoch 00136: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0428 - acc: 0.9856 - val_loss: 0.1686 - val_acc: 0.9641\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9854\n",
      "Epoch 00137: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0432 - acc: 0.9854 - val_loss: 0.1627 - val_acc: 0.9658\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9867\n",
      "Epoch 00138: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 867us/sample - loss: 0.0392 - acc: 0.9867 - val_loss: 0.1718 - val_acc: 0.9625\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9853\n",
      "Epoch 00139: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 868us/sample - loss: 0.0437 - acc: 0.9853 - val_loss: 0.1619 - val_acc: 0.9644\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9851\n",
      "Epoch 00140: val_loss did not improve from 0.11804\n",
      "36805/36805 [==============================] - 32s 869us/sample - loss: 0.0442 - acc: 0.9851 - val_loss: 0.1525 - val_acc: 0.9644\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 444us/sample - loss: 0.1744 - acc: 0.9510\n",
      "Loss: 0.17435325513422675 Accuracy: 0.9509865\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0573 - acc: 0.3314\n",
      "Epoch 00001: val_loss improved from inf to 1.15250, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/001-1.1525.hdf5\n",
      "36805/36805 [==============================] - 37s 1ms/sample - loss: 2.0572 - acc: 0.3314 - val_loss: 1.1525 - val_acc: 0.6560\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1355 - acc: 0.6381\n",
      "Epoch 00002: val_loss improved from 1.15250 to 0.72865, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/002-0.7286.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 1.1355 - acc: 0.6381 - val_loss: 0.7286 - val_acc: 0.7813\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8418 - acc: 0.7304\n",
      "Epoch 00003: val_loss improved from 0.72865 to 0.58975, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/003-0.5898.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.8417 - acc: 0.7304 - val_loss: 0.5898 - val_acc: 0.8164\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6845 - acc: 0.7837\n",
      "Epoch 00004: val_loss improved from 0.58975 to 0.47138, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/004-0.4714.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.6845 - acc: 0.7838 - val_loss: 0.4714 - val_acc: 0.8512\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5881 - acc: 0.8128\n",
      "Epoch 00005: val_loss improved from 0.47138 to 0.38087, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/005-0.3809.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.5880 - acc: 0.8128 - val_loss: 0.3809 - val_acc: 0.8863\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5101 - acc: 0.8417\n",
      "Epoch 00006: val_loss improved from 0.38087 to 0.32131, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/006-0.3213.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.5100 - acc: 0.8417 - val_loss: 0.3213 - val_acc: 0.9087\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4604 - acc: 0.8537\n",
      "Epoch 00007: val_loss improved from 0.32131 to 0.29870, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/007-0.2987.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.4603 - acc: 0.8537 - val_loss: 0.2987 - val_acc: 0.9085\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4169 - acc: 0.8681\n",
      "Epoch 00008: val_loss improved from 0.29870 to 0.26547, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/008-0.2655.hdf5\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.4169 - acc: 0.8681 - val_loss: 0.2655 - val_acc: 0.9189\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3811 - acc: 0.8793\n",
      "Epoch 00009: val_loss improved from 0.26547 to 0.26356, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/009-0.2636.hdf5\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.3811 - acc: 0.8794 - val_loss: 0.2636 - val_acc: 0.9185\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3475 - acc: 0.8900\n",
      "Epoch 00010: val_loss improved from 0.26356 to 0.23964, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/010-0.2396.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.3475 - acc: 0.8900 - val_loss: 0.2396 - val_acc: 0.9290\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3251 - acc: 0.8967\n",
      "Epoch 00011: val_loss did not improve from 0.23964\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.3251 - acc: 0.8967 - val_loss: 0.2669 - val_acc: 0.9147\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.9005\n",
      "Epoch 00012: val_loss improved from 0.23964 to 0.21291, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/012-0.2129.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.3121 - acc: 0.9004 - val_loss: 0.2129 - val_acc: 0.9371\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9089\n",
      "Epoch 00013: val_loss improved from 0.21291 to 0.19729, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/013-0.1973.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.2878 - acc: 0.9089 - val_loss: 0.1973 - val_acc: 0.9443\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.9126\n",
      "Epoch 00014: val_loss improved from 0.19729 to 0.18624, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/014-0.1862.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.2739 - acc: 0.9126 - val_loss: 0.1862 - val_acc: 0.9427\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9189\n",
      "Epoch 00015: val_loss did not improve from 0.18624\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.2561 - acc: 0.9190 - val_loss: 0.1889 - val_acc: 0.9429\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9215\n",
      "Epoch 00016: val_loss did not improve from 0.18624\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.2485 - acc: 0.9216 - val_loss: 0.1981 - val_acc: 0.9369\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2359 - acc: 0.9247\n",
      "Epoch 00017: val_loss improved from 0.18624 to 0.16718, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/017-0.1672.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.2359 - acc: 0.9247 - val_loss: 0.1672 - val_acc: 0.9483\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9299\n",
      "Epoch 00018: val_loss improved from 0.16718 to 0.16500, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/018-0.1650.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.2199 - acc: 0.9299 - val_loss: 0.1650 - val_acc: 0.9492\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9342\n",
      "Epoch 00019: val_loss improved from 0.16500 to 0.16199, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/019-0.1620.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.2114 - acc: 0.9342 - val_loss: 0.1620 - val_acc: 0.9518\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9351\n",
      "Epoch 00020: val_loss improved from 0.16199 to 0.15841, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/020-0.1584.hdf5\n",
      "36805/36805 [==============================] - 33s 890us/sample - loss: 0.2048 - acc: 0.9351 - val_loss: 0.1584 - val_acc: 0.9509\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9351\n",
      "Epoch 00021: val_loss improved from 0.15841 to 0.14823, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/021-0.1482.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1986 - acc: 0.9351 - val_loss: 0.1482 - val_acc: 0.9555\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9410\n",
      "Epoch 00022: val_loss improved from 0.14823 to 0.14522, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/022-0.1452.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1847 - acc: 0.9410 - val_loss: 0.1452 - val_acc: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9436\n",
      "Epoch 00023: val_loss did not improve from 0.14522\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1767 - acc: 0.9436 - val_loss: 0.1454 - val_acc: 0.9555\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9432\n",
      "Epoch 00024: val_loss improved from 0.14522 to 0.13577, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/024-0.1358.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1732 - acc: 0.9432 - val_loss: 0.1358 - val_acc: 0.9599\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9450\n",
      "Epoch 00025: val_loss did not improve from 0.13577\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1680 - acc: 0.9450 - val_loss: 0.1492 - val_acc: 0.9539\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9489\n",
      "Epoch 00026: val_loss did not improve from 0.13577\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.1579 - acc: 0.9489 - val_loss: 0.1437 - val_acc: 0.9578\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9493\n",
      "Epoch 00027: val_loss improved from 0.13577 to 0.13489, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/027-0.1349.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.1522 - acc: 0.9494 - val_loss: 0.1349 - val_acc: 0.9583\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9517\n",
      "Epoch 00028: val_loss improved from 0.13489 to 0.13283, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/028-0.1328.hdf5\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1461 - acc: 0.9517 - val_loss: 0.1328 - val_acc: 0.9597\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9543\n",
      "Epoch 00029: val_loss did not improve from 0.13283\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1408 - acc: 0.9544 - val_loss: 0.1370 - val_acc: 0.9588\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9552\n",
      "Epoch 00030: val_loss did not improve from 0.13283\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1333 - acc: 0.9552 - val_loss: 0.1424 - val_acc: 0.9583\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9548\n",
      "Epoch 00031: val_loss did not improve from 0.13283\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1352 - acc: 0.9548 - val_loss: 0.1555 - val_acc: 0.9555\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9555\n",
      "Epoch 00032: val_loss improved from 0.13283 to 0.13194, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/032-0.1319.hdf5\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.1332 - acc: 0.9555 - val_loss: 0.1319 - val_acc: 0.9613\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9598\n",
      "Epoch 00033: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.1218 - acc: 0.9598 - val_loss: 0.1430 - val_acc: 0.9564\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9578\n",
      "Epoch 00034: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 32s 882us/sample - loss: 0.1240 - acc: 0.9578 - val_loss: 0.1320 - val_acc: 0.9599\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9632\n",
      "Epoch 00035: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1134 - acc: 0.9632 - val_loss: 0.1507 - val_acc: 0.9578\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9632\n",
      "Epoch 00036: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.1104 - acc: 0.9632 - val_loss: 0.1323 - val_acc: 0.9623\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9648\n",
      "Epoch 00037: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1074 - acc: 0.9648 - val_loss: 0.1386 - val_acc: 0.9592\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9653\n",
      "Epoch 00038: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 32s 882us/sample - loss: 0.1044 - acc: 0.9653 - val_loss: 0.1490 - val_acc: 0.9550\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9650\n",
      "Epoch 00039: val_loss did not improve from 0.13194\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1048 - acc: 0.9650 - val_loss: 0.1327 - val_acc: 0.9597\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9678\n",
      "Epoch 00040: val_loss improved from 0.13194 to 0.12775, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/040-0.1278.hdf5\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0977 - acc: 0.9678 - val_loss: 0.1278 - val_acc: 0.9630\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9671\n",
      "Epoch 00041: val_loss did not improve from 0.12775\n",
      "36805/36805 [==============================] - 32s 882us/sample - loss: 0.0973 - acc: 0.9671 - val_loss: 0.1426 - val_acc: 0.9578\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9689\n",
      "Epoch 00042: val_loss did not improve from 0.12775\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0948 - acc: 0.9689 - val_loss: 0.1575 - val_acc: 0.9553\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9678\n",
      "Epoch 00043: val_loss did not improve from 0.12775\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0960 - acc: 0.9678 - val_loss: 0.1300 - val_acc: 0.9639\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9717\n",
      "Epoch 00044: val_loss improved from 0.12775 to 0.12574, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_DO_8_conv_checkpoint/044-0.1257.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0829 - acc: 0.9717 - val_loss: 0.1257 - val_acc: 0.9634\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9717\n",
      "Epoch 00045: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0831 - acc: 0.9717 - val_loss: 0.1363 - val_acc: 0.9632\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9721\n",
      "Epoch 00046: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0813 - acc: 0.9721 - val_loss: 0.1355 - val_acc: 0.9630\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9731\n",
      "Epoch 00047: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0788 - acc: 0.9731 - val_loss: 0.1327 - val_acc: 0.9602\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9740\n",
      "Epoch 00048: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0777 - acc: 0.9740 - val_loss: 0.1419 - val_acc: 0.9576\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9736\n",
      "Epoch 00049: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0790 - acc: 0.9736 - val_loss: 0.1299 - val_acc: 0.9618\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9761\n",
      "Epoch 00050: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0705 - acc: 0.9761 - val_loss: 0.1390 - val_acc: 0.9627\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9767\n",
      "Epoch 00051: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 32s 880us/sample - loss: 0.0681 - acc: 0.9767 - val_loss: 0.1487 - val_acc: 0.9597\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9756\n",
      "Epoch 00052: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0710 - acc: 0.9756 - val_loss: 0.1273 - val_acc: 0.9644\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9786\n",
      "Epoch 00053: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0637 - acc: 0.9786 - val_loss: 0.1389 - val_acc: 0.9597\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9753\n",
      "Epoch 00054: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0740 - acc: 0.9753 - val_loss: 0.1422 - val_acc: 0.9599\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9777\n",
      "Epoch 00055: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0666 - acc: 0.9777 - val_loss: 0.1394 - val_acc: 0.9646\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9784\n",
      "Epoch 00056: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 32s 883us/sample - loss: 0.0626 - acc: 0.9784 - val_loss: 0.1417 - val_acc: 0.9634\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9785\n",
      "Epoch 00057: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0604 - acc: 0.9785 - val_loss: 0.1369 - val_acc: 0.9655\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9797\n",
      "Epoch 00058: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0583 - acc: 0.9797 - val_loss: 0.1634 - val_acc: 0.9613\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9786\n",
      "Epoch 00059: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0631 - acc: 0.9786 - val_loss: 0.1400 - val_acc: 0.9646\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9818\n",
      "Epoch 00060: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0533 - acc: 0.9819 - val_loss: 0.1514 - val_acc: 0.9623\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9798\n",
      "Epoch 00061: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0580 - acc: 0.9798 - val_loss: 0.1712 - val_acc: 0.9567\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9827\n",
      "Epoch 00062: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0511 - acc: 0.9826 - val_loss: 0.1316 - val_acc: 0.9679\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9812\n",
      "Epoch 00063: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0527 - acc: 0.9813 - val_loss: 0.1484 - val_acc: 0.9644\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9835\n",
      "Epoch 00064: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 32s 883us/sample - loss: 0.0507 - acc: 0.9835 - val_loss: 0.1604 - val_acc: 0.9581\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9820\n",
      "Epoch 00065: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0523 - acc: 0.9820 - val_loss: 0.1426 - val_acc: 0.9634\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9836\n",
      "Epoch 00066: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0491 - acc: 0.9836 - val_loss: 0.1377 - val_acc: 0.9667\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9827\n",
      "Epoch 00067: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 32s 882us/sample - loss: 0.0509 - acc: 0.9827 - val_loss: 0.1517 - val_acc: 0.9655\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9831\n",
      "Epoch 00068: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0497 - acc: 0.9831 - val_loss: 0.1407 - val_acc: 0.9651\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9850\n",
      "Epoch 00069: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0440 - acc: 0.9850 - val_loss: 0.1651 - val_acc: 0.9634\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9837\n",
      "Epoch 00070: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0465 - acc: 0.9837 - val_loss: 0.1517 - val_acc: 0.9669\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9855\n",
      "Epoch 00071: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0432 - acc: 0.9855 - val_loss: 0.1540 - val_acc: 0.9660\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9853\n",
      "Epoch 00072: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0417 - acc: 0.9853 - val_loss: 0.1623 - val_acc: 0.9625\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9858\n",
      "Epoch 00073: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0414 - acc: 0.9858 - val_loss: 0.1538 - val_acc: 0.9620\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9857\n",
      "Epoch 00074: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0423 - acc: 0.9857 - val_loss: 0.1531 - val_acc: 0.9637\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9867\n",
      "Epoch 00075: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0386 - acc: 0.9867 - val_loss: 0.1488 - val_acc: 0.9667\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9866\n",
      "Epoch 00076: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.0409 - acc: 0.9866 - val_loss: 0.1582 - val_acc: 0.9637\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9859\n",
      "Epoch 00077: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 32s 883us/sample - loss: 0.0393 - acc: 0.9859 - val_loss: 0.1703 - val_acc: 0.9646\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9868\n",
      "Epoch 00078: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0383 - acc: 0.9868 - val_loss: 0.1489 - val_acc: 0.9669\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9872\n",
      "Epoch 00079: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0386 - acc: 0.9872 - val_loss: 0.1585 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9871\n",
      "Epoch 00080: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0376 - acc: 0.9871 - val_loss: 0.1776 - val_acc: 0.9641\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9865\n",
      "Epoch 00081: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0395 - acc: 0.9865 - val_loss: 0.1742 - val_acc: 0.9590\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9879\n",
      "Epoch 00082: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0367 - acc: 0.9879 - val_loss: 0.1590 - val_acc: 0.9625\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9874\n",
      "Epoch 00083: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0369 - acc: 0.9874 - val_loss: 0.1723 - val_acc: 0.9641\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9898\n",
      "Epoch 00084: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0313 - acc: 0.9898 - val_loss: 0.1763 - val_acc: 0.9644\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9890\n",
      "Epoch 00085: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0318 - acc: 0.9890 - val_loss: 0.1604 - val_acc: 0.9688\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9877\n",
      "Epoch 00086: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0362 - acc: 0.9877 - val_loss: 0.1753 - val_acc: 0.9632\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9885\n",
      "Epoch 00087: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0328 - acc: 0.9885 - val_loss: 0.1593 - val_acc: 0.9676\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9897\n",
      "Epoch 00088: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 32s 883us/sample - loss: 0.0300 - acc: 0.9897 - val_loss: 0.1746 - val_acc: 0.9646\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9896\n",
      "Epoch 00089: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0316 - acc: 0.9896 - val_loss: 0.1641 - val_acc: 0.9665\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9892\n",
      "Epoch 00090: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0328 - acc: 0.9892 - val_loss: 0.1544 - val_acc: 0.9646\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9898\n",
      "Epoch 00091: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0319 - acc: 0.9898 - val_loss: 0.1580 - val_acc: 0.9660\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9904\n",
      "Epoch 00092: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.0293 - acc: 0.9904 - val_loss: 0.1666 - val_acc: 0.9632\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9887\n",
      "Epoch 00093: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 883us/sample - loss: 0.0346 - acc: 0.9888 - val_loss: 0.1558 - val_acc: 0.9672\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9908\n",
      "Epoch 00094: val_loss did not improve from 0.12574\n",
      "36805/36805 [==============================] - 33s 887us/sample - loss: 0.0261 - acc: 0.9908 - val_loss: 0.1758 - val_acc: 0.9630\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 479us/sample - loss: 0.2174 - acc: 0.9394\n",
      "Loss: 0.21736131861442284 Accuracy: 0.9393562\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_2_GAP_DO'\n",
    "\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 64)    384         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 64)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 64)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 64)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 64)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 64)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 64)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 64)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           2064        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 43,536\n",
      "Trainable params: 43,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 445us/sample - loss: 0.7135 - acc: 0.7940\n",
      "Loss: 0.7134613753355429 Accuracy: 0.79397714\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 64)    384         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 64)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 64)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 64)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 64)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 64)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 64)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 64)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 64)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 64)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128)          0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_average_pooling1d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           2064        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,080\n",
      "Trainable params: 64,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 479us/sample - loss: 0.4633 - acc: 0.8665\n",
      "Loss: 0.4633347888849482 Accuracy: 0.866459\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 64)    384         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 64)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 64)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 64)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 64)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 64)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 64)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 64)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 128)     0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 128)      0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 64)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 128)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 192)          0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_average_pooling1d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 192)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           3088        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 106,192\n",
      "Trainable params: 106,192\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 476us/sample - loss: 0.2775 - acc: 0.9192\n",
      "Loss: 0.2775282277496433 Accuracy: 0.9192108\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 64)    384         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 64)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 64)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 64)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 64)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 64)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 64)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 64)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 128)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 128)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 128)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 128)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 128)          0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 128)          0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 256)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           4112        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 189,264\n",
      "Trainable params: 189,264\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 517us/sample - loss: 0.1785 - acc: 0.9508\n",
      "Loss: 0.17850961259190043 Accuracy: 0.95077884\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 64)    384         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 64)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 64)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 64)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 64)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 64)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 64)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 64)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 64)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 128)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 128)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 128)      0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 128)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 128)      0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 128)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 128)          0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 128)          0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 256)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_average_pooling1d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           4112        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 271,312\n",
      "Trainable params: 271,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 511us/sample - loss: 0.1744 - acc: 0.9510\n",
      "Loss: 0.17435325513422675 Accuracy: 0.9509865\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 64)    384         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 64)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 64)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 64)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 64)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 64)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 64)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 64)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 64)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 128)     0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 128)      0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 128)      0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 128)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 128)      0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 128)       0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 128)       82048       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 128)       0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 128)       0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 128)          0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 128)          0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 256)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 256)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           4112        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 353,360\n",
      "Trainable params: 353,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 531us/sample - loss: 0.2174 - acc: 0.9394\n",
      "Loss: 0.21736131861442284 Accuracy: 0.9393562\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_2_GAP_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 64)    384         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 64)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 64)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 64)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 64)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 64)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 64)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 64)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 64)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           2064        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 43,536\n",
      "Trainable params: 43,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 490us/sample - loss: 0.7107 - acc: 0.7967\n",
      "Loss: 0.7107135740148439 Accuracy: 0.79667705\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 64)    384         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 64)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 64)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 64)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 64)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 64)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 64)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 64)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 64)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 64)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 64)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128)          0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_average_pooling1d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           2064        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 64,080\n",
      "Trainable params: 64,080\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 510us/sample - loss: 0.4633 - acc: 0.8665\n",
      "Loss: 0.4633347888849482 Accuracy: 0.866459\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 64)    384         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 64)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 64)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 64)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 64)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 64)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 64)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 64)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 64)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 128)     0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 128)      0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 64)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 128)          0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 192)          0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_average_pooling1d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 192)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           3088        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 106,192\n",
      "Trainable params: 106,192\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 525us/sample - loss: 0.2985 - acc: 0.9126\n",
      "Loss: 0.29848054330544554 Accuracy: 0.9125649\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 64)    384         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 64)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 64)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 64)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 64)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 64)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 64)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 64)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 64)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 128)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 128)      0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 128)      0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 128)      0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 128)          0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 128)          0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 256)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 256)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           4112        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 189,264\n",
      "Trainable params: 189,264\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 529us/sample - loss: 0.2083 - acc: 0.9485\n",
      "Loss: 0.2083203055885227 Accuracy: 0.9484943\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 64)    384         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 64)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 64)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 64)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 64)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 64)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 64)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 64)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 64)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 128)     0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 128)      0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 128)      0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 128)      0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 128)      0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 128)       0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 128)          0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 128)          0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 256)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_average_pooling1d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 256)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           4112        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 271,312\n",
      "Trainable params: 271,312\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 549us/sample - loss: 0.2010 - acc: 0.9549\n",
      "Loss: 0.20104904692554276 Accuracy: 0.9549325\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 64)    384         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 64)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 64)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 64)     20544       max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 64)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 64)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 64)     20544       max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 64)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 64)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 64)      20544       max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 64)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 64)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 128)     41088       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 128)     0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 128)      0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 128)      82048       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 128)      0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 128)      0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 128)      82048       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 128)      0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 128)       0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 128)       82048       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 128)       0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 128)       0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 128)          0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 128)          0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 256)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 256)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           4112        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 353,360\n",
      "Trainable params: 353,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 587us/sample - loss: 0.2735 - acc: 0.9468\n",
      "Loss: 0.27350776488482925 Accuracy: 0.94683284\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
