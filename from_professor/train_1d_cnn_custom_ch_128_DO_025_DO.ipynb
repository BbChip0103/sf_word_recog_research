{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_128_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=128, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=128*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9660 - acc: 0.3801\n",
      "Epoch 00001: val_loss improved from inf to 1.55874, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_3_conv_checkpoint/001-1.5587.hdf5\n",
      "36805/36805 [==============================] - 108s 3ms/sample - loss: 1.9659 - acc: 0.3801 - val_loss: 1.5587 - val_acc: 0.5304\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3597 - acc: 0.5824\n",
      "Epoch 00002: val_loss improved from 1.55874 to 1.34426, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_3_conv_checkpoint/002-1.3443.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.3597 - acc: 0.5824 - val_loss: 1.3443 - val_acc: 0.5933\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1018 - acc: 0.6645\n",
      "Epoch 00003: val_loss improved from 1.34426 to 1.30712, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_3_conv_checkpoint/003-1.3071.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.1018 - acc: 0.6645 - val_loss: 1.3071 - val_acc: 0.5933\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8989 - acc: 0.7300\n",
      "Epoch 00004: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.8989 - acc: 0.7300 - val_loss: 1.3536 - val_acc: 0.5947\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7154 - acc: 0.7855\n",
      "Epoch 00005: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.7156 - acc: 0.7855 - val_loss: 1.4411 - val_acc: 0.5782\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5478 - acc: 0.8411\n",
      "Epoch 00006: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.5478 - acc: 0.8412 - val_loss: 1.5584 - val_acc: 0.5742\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4070 - acc: 0.8838\n",
      "Epoch 00007: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.4070 - acc: 0.8837 - val_loss: 1.6358 - val_acc: 0.5875\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2975 - acc: 0.9191\n",
      "Epoch 00008: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2975 - acc: 0.9191 - val_loss: 1.8051 - val_acc: 0.5816\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9452\n",
      "Epoch 00009: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2132 - acc: 0.9451 - val_loss: 2.0817 - val_acc: 0.5667\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9585\n",
      "Epoch 00010: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1697 - acc: 0.9585 - val_loss: 2.0833 - val_acc: 0.5807\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9718\n",
      "Epoch 00011: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1247 - acc: 0.9718 - val_loss: 2.2593 - val_acc: 0.5744\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9768\n",
      "Epoch 00012: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1052 - acc: 0.9768 - val_loss: 2.3050 - val_acc: 0.5849\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9804\n",
      "Epoch 00013: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0887 - acc: 0.9804 - val_loss: 2.4980 - val_acc: 0.5646\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9780\n",
      "Epoch 00014: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0926 - acc: 0.9780 - val_loss: 2.5419 - val_acc: 0.5723\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9845\n",
      "Epoch 00015: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0744 - acc: 0.9845 - val_loss: 2.5373 - val_acc: 0.5837\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9871\n",
      "Epoch 00016: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0639 - acc: 0.9871 - val_loss: 2.6464 - val_acc: 0.5842\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9857\n",
      "Epoch 00017: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0659 - acc: 0.9857 - val_loss: 2.8559 - val_acc: 0.5625\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9873\n",
      "Epoch 00018: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0610 - acc: 0.9873 - val_loss: 2.7791 - val_acc: 0.5795\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9854\n",
      "Epoch 00019: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0650 - acc: 0.9854 - val_loss: 2.7811 - val_acc: 0.5719\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9894\n",
      "Epoch 00020: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0515 - acc: 0.9894 - val_loss: 2.8706 - val_acc: 0.5777\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9896\n",
      "Epoch 00021: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0541 - acc: 0.9896 - val_loss: 2.8587 - val_acc: 0.5751\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9910\n",
      "Epoch 00022: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0476 - acc: 0.9910 - val_loss: 2.8764 - val_acc: 0.5861\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9865\n",
      "Epoch 00023: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0626 - acc: 0.9866 - val_loss: 3.0346 - val_acc: 0.5684\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9919\n",
      "Epoch 00024: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0421 - acc: 0.9919 - val_loss: 2.9456 - val_acc: 0.5788\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9941\n",
      "Epoch 00025: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0364 - acc: 0.9941 - val_loss: 3.0080 - val_acc: 0.5921\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9908\n",
      "Epoch 00026: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0450 - acc: 0.9908 - val_loss: 3.0160 - val_acc: 0.5712\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9917\n",
      "Epoch 00027: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0429 - acc: 0.9917 - val_loss: 3.0327 - val_acc: 0.5733\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9903\n",
      "Epoch 00028: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0457 - acc: 0.9903 - val_loss: 3.1174 - val_acc: 0.5751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9919\n",
      "Epoch 00029: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0397 - acc: 0.9919 - val_loss: 3.1319 - val_acc: 0.5707\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9921\n",
      "Epoch 00030: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0419 - acc: 0.9921 - val_loss: 3.1234 - val_acc: 0.5795\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9929\n",
      "Epoch 00031: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0377 - acc: 0.9929 - val_loss: 3.0458 - val_acc: 0.5907\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9957\n",
      "Epoch 00032: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0287 - acc: 0.9957 - val_loss: 3.0911 - val_acc: 0.5917\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9924\n",
      "Epoch 00033: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0380 - acc: 0.9924 - val_loss: 3.0876 - val_acc: 0.5896\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9923\n",
      "Epoch 00034: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0402 - acc: 0.9923 - val_loss: 3.2292 - val_acc: 0.5721\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9928\n",
      "Epoch 00035: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0388 - acc: 0.9928 - val_loss: 3.0857 - val_acc: 0.5868\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9935\n",
      "Epoch 00036: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0344 - acc: 0.9935 - val_loss: 3.2068 - val_acc: 0.5765\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9951\n",
      "Epoch 00037: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0314 - acc: 0.9951 - val_loss: 3.2317 - val_acc: 0.5872\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9941\n",
      "Epoch 00038: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0331 - acc: 0.9941 - val_loss: 3.1230 - val_acc: 0.5931\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9966\n",
      "Epoch 00039: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0247 - acc: 0.9966 - val_loss: 3.1708 - val_acc: 0.5858\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9942\n",
      "Epoch 00040: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0327 - acc: 0.9942 - val_loss: 3.1949 - val_acc: 0.5968\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9932\n",
      "Epoch 00041: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0360 - acc: 0.9932 - val_loss: 3.2015 - val_acc: 0.5884\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9952\n",
      "Epoch 00042: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0298 - acc: 0.9952 - val_loss: 3.2413 - val_acc: 0.5889\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9949\n",
      "Epoch 00043: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0301 - acc: 0.9949 - val_loss: 3.2149 - val_acc: 0.5926\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0295 - acc: 0.9956 - val_loss: 3.2849 - val_acc: 0.5896\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9939\n",
      "Epoch 00045: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0322 - acc: 0.9939 - val_loss: 3.2702 - val_acc: 0.5795\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9966\n",
      "Epoch 00046: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0255 - acc: 0.9966 - val_loss: 3.3611 - val_acc: 0.5893\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9958\n",
      "Epoch 00047: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0267 - acc: 0.9958 - val_loss: 3.3710 - val_acc: 0.5837\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9946\n",
      "Epoch 00048: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0333 - acc: 0.9945 - val_loss: 3.4352 - val_acc: 0.5686\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9949\n",
      "Epoch 00049: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0314 - acc: 0.9949 - val_loss: 3.2698 - val_acc: 0.5863\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9964\n",
      "Epoch 00050: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0238 - acc: 0.9964 - val_loss: 3.3304 - val_acc: 0.5875\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9957\n",
      "Epoch 00051: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0274 - acc: 0.9957 - val_loss: 3.3689 - val_acc: 0.5893\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9957\n",
      "Epoch 00052: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0274 - acc: 0.9957 - val_loss: 3.2618 - val_acc: 0.5912\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9972\n",
      "Epoch 00053: val_loss did not improve from 1.30712\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0217 - acc: 0.9972 - val_loss: 3.4542 - val_acc: 0.5861\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3873 - acc: 0.5572\n",
      "Loss: 1.387338678042094 Accuracy: 0.557217\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9013 - acc: 0.3915\n",
      "Epoch 00001: val_loss improved from inf to 1.48261, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_4_conv_checkpoint/001-1.4826.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.9013 - acc: 0.3915 - val_loss: 1.4826 - val_acc: 0.5313\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2744 - acc: 0.6087\n",
      "Epoch 00002: val_loss improved from 1.48261 to 1.19296, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_4_conv_checkpoint/002-1.1930.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.2745 - acc: 0.6087 - val_loss: 1.1930 - val_acc: 0.6341\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0319 - acc: 0.6885\n",
      "Epoch 00003: val_loss improved from 1.19296 to 1.06298, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_4_conv_checkpoint/003-1.0630.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.0319 - acc: 0.6884 - val_loss: 1.0630 - val_acc: 0.6704\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8404 - acc: 0.7499\n",
      "Epoch 00004: val_loss did not improve from 1.06298\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.8405 - acc: 0.7499 - val_loss: 1.0753 - val_acc: 0.6678\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6694 - acc: 0.8024\n",
      "Epoch 00005: val_loss improved from 1.06298 to 0.98438, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_4_conv_checkpoint/005-0.9844.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.6695 - acc: 0.8024 - val_loss: 0.9844 - val_acc: 0.7028\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5154 - acc: 0.8470\n",
      "Epoch 00006: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.5156 - acc: 0.8470 - val_loss: 1.0213 - val_acc: 0.7095\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3942 - acc: 0.8850\n",
      "Epoch 00007: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3942 - acc: 0.8850 - val_loss: 1.0970 - val_acc: 0.6923\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9209\n",
      "Epoch 00008: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2827 - acc: 0.9209 - val_loss: 1.2391 - val_acc: 0.6853\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9426\n",
      "Epoch 00009: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2044 - acc: 0.9425 - val_loss: 1.2972 - val_acc: 0.6990\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9558\n",
      "Epoch 00010: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1599 - acc: 0.9558 - val_loss: 1.4069 - val_acc: 0.6834\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9651\n",
      "Epoch 00011: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1270 - acc: 0.9651 - val_loss: 1.7053 - val_acc: 0.6490\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9736\n",
      "Epoch 00012: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0999 - acc: 0.9736 - val_loss: 1.6099 - val_acc: 0.6753\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9763\n",
      "Epoch 00013: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0889 - acc: 0.9763 - val_loss: 1.6768 - val_acc: 0.6811\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9784\n",
      "Epoch 00014: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0803 - acc: 0.9784 - val_loss: 1.7333 - val_acc: 0.6916\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9816\n",
      "Epoch 00015: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0705 - acc: 0.9816 - val_loss: 1.7193 - val_acc: 0.6935\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9836\n",
      "Epoch 00016: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0626 - acc: 0.9836 - val_loss: 1.7831 - val_acc: 0.6839\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9822\n",
      "Epoch 00017: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0665 - acc: 0.9822 - val_loss: 1.8617 - val_acc: 0.6897\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9854\n",
      "Epoch 00018: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0557 - acc: 0.9854 - val_loss: 1.9101 - val_acc: 0.6867\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9861\n",
      "Epoch 00019: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0526 - acc: 0.9861 - val_loss: 1.8888 - val_acc: 0.7018\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9868\n",
      "Epoch 00020: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0530 - acc: 0.9868 - val_loss: 1.9336 - val_acc: 0.6956\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9857\n",
      "Epoch 00021: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0541 - acc: 0.9857 - val_loss: 2.0056 - val_acc: 0.6792\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9880\n",
      "Epoch 00022: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0467 - acc: 0.9880 - val_loss: 1.9091 - val_acc: 0.7049\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9893\n",
      "Epoch 00023: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0433 - acc: 0.9893 - val_loss: 2.0001 - val_acc: 0.6962\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9876\n",
      "Epoch 00024: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0477 - acc: 0.9876 - val_loss: 1.9129 - val_acc: 0.7046\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9877\n",
      "Epoch 00025: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0500 - acc: 0.9877 - val_loss: 1.9644 - val_acc: 0.6939\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9903\n",
      "Epoch 00026: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0383 - acc: 0.9903 - val_loss: 2.0441 - val_acc: 0.6872\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9902\n",
      "Epoch 00027: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0406 - acc: 0.9902 - val_loss: 1.9702 - val_acc: 0.6993\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9918\n",
      "Epoch 00028: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0360 - acc: 0.9918 - val_loss: 2.0618 - val_acc: 0.6939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9912\n",
      "Epoch 00029: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0363 - acc: 0.9912 - val_loss: 2.1728 - val_acc: 0.6830\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9904\n",
      "Epoch 00030: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0397 - acc: 0.9904 - val_loss: 1.9952 - val_acc: 0.6969\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9923\n",
      "Epoch 00031: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0340 - acc: 0.9923 - val_loss: 2.1229 - val_acc: 0.6972\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9894\n",
      "Epoch 00032: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0426 - acc: 0.9894 - val_loss: 2.0214 - val_acc: 0.7030\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9925\n",
      "Epoch 00033: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0317 - acc: 0.9925 - val_loss: 2.0907 - val_acc: 0.6997\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9924\n",
      "Epoch 00034: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0316 - acc: 0.9924 - val_loss: 2.2726 - val_acc: 0.6799\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9928\n",
      "Epoch 00035: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0308 - acc: 0.9928 - val_loss: 2.1322 - val_acc: 0.6988\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9922\n",
      "Epoch 00036: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0326 - acc: 0.9922 - val_loss: 2.2172 - val_acc: 0.6965\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9904\n",
      "Epoch 00037: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0392 - acc: 0.9904 - val_loss: 2.2631 - val_acc: 0.6795\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9937\n",
      "Epoch 00038: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0280 - acc: 0.9937 - val_loss: 2.3924 - val_acc: 0.6741\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9930\n",
      "Epoch 00039: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0306 - acc: 0.9930 - val_loss: 2.0895 - val_acc: 0.7023\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9936\n",
      "Epoch 00040: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0291 - acc: 0.9936 - val_loss: 2.2543 - val_acc: 0.6890\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 00041: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0307 - acc: 0.9927 - val_loss: 2.1526 - val_acc: 0.6958\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9929\n",
      "Epoch 00042: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0320 - acc: 0.9929 - val_loss: 2.1502 - val_acc: 0.7035\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9939\n",
      "Epoch 00043: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0269 - acc: 0.9939 - val_loss: 2.3288 - val_acc: 0.6769\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9929\n",
      "Epoch 00044: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0297 - acc: 0.9929 - val_loss: 2.2152 - val_acc: 0.7095\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9934\n",
      "Epoch 00045: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0297 - acc: 0.9934 - val_loss: 2.1993 - val_acc: 0.6928\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9934\n",
      "Epoch 00046: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0281 - acc: 0.9934 - val_loss: 2.1833 - val_acc: 0.7154\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9938\n",
      "Epoch 00047: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0281 - acc: 0.9938 - val_loss: 2.0779 - val_acc: 0.7114\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9950\n",
      "Epoch 00048: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0248 - acc: 0.9950 - val_loss: 2.0754 - val_acc: 0.7091\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9934\n",
      "Epoch 00049: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0290 - acc: 0.9934 - val_loss: 2.1538 - val_acc: 0.7086\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0322 - acc: 0.9924 - val_loss: 2.0752 - val_acc: 0.7142\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9947\n",
      "Epoch 00051: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0260 - acc: 0.9947 - val_loss: 2.1324 - val_acc: 0.7174\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9942\n",
      "Epoch 00052: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0264 - acc: 0.9942 - val_loss: 2.1401 - val_acc: 0.7207\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9957\n",
      "Epoch 00053: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0224 - acc: 0.9957 - val_loss: 2.2282 - val_acc: 0.7060\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9953\n",
      "Epoch 00054: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0229 - acc: 0.9953 - val_loss: 2.3769 - val_acc: 0.6995\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9944\n",
      "Epoch 00055: val_loss did not improve from 0.98438\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0263 - acc: 0.9944 - val_loss: 2.1986 - val_acc: 0.7147\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.1082 - acc: 0.6685\n",
      "Loss: 1.108153035212405 Accuracy: 0.6685358\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8650 - acc: 0.3976\n",
      "Epoch 00001: val_loss improved from inf to 1.35969, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_5_conv_checkpoint/001-1.3597.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.8649 - acc: 0.3976 - val_loss: 1.3597 - val_acc: 0.5842\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2529 - acc: 0.6149\n",
      "Epoch 00002: val_loss improved from 1.35969 to 1.10784, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_5_conv_checkpoint/002-1.1078.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 1.2528 - acc: 0.6149 - val_loss: 1.1078 - val_acc: 0.6604\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0171 - acc: 0.6906\n",
      "Epoch 00003: val_loss improved from 1.10784 to 0.97810, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_5_conv_checkpoint/003-0.9781.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 1.0170 - acc: 0.6906 - val_loss: 0.9781 - val_acc: 0.7091\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8462 - acc: 0.7467\n",
      "Epoch 00004: val_loss improved from 0.97810 to 0.89035, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_5_conv_checkpoint/004-0.8904.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.8462 - acc: 0.7467 - val_loss: 0.8904 - val_acc: 0.7321\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7164 - acc: 0.7858\n",
      "Epoch 00005: val_loss improved from 0.89035 to 0.76875, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_5_conv_checkpoint/005-0.7687.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.7164 - acc: 0.7858 - val_loss: 0.7687 - val_acc: 0.7799\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6091 - acc: 0.8177\n",
      "Epoch 00006: val_loss improved from 0.76875 to 0.76229, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_5_conv_checkpoint/006-0.7623.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.6091 - acc: 0.8177 - val_loss: 0.7623 - val_acc: 0.7789\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5160 - acc: 0.8481\n",
      "Epoch 00007: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.5159 - acc: 0.8481 - val_loss: 0.7896 - val_acc: 0.7659\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8802\n",
      "Epoch 00008: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4072 - acc: 0.8802 - val_loss: 0.7864 - val_acc: 0.7817\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3379 - acc: 0.8998\n",
      "Epoch 00009: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3379 - acc: 0.8998 - val_loss: 0.7766 - val_acc: 0.7913\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9249\n",
      "Epoch 00010: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2560 - acc: 0.9249 - val_loss: 0.8039 - val_acc: 0.7824\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9435\n",
      "Epoch 00011: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1971 - acc: 0.9435 - val_loss: 0.8944 - val_acc: 0.7813\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9549\n",
      "Epoch 00012: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1575 - acc: 0.9549 - val_loss: 0.9542 - val_acc: 0.7878\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9647\n",
      "Epoch 00013: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1231 - acc: 0.9647 - val_loss: 1.0636 - val_acc: 0.7778\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9676\n",
      "Epoch 00014: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1110 - acc: 0.9676 - val_loss: 1.1385 - val_acc: 0.7720\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9749\n",
      "Epoch 00015: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0911 - acc: 0.9749 - val_loss: 1.1722 - val_acc: 0.7787\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9804- ETA: 0s - loss: 0.0752 - acc: 0\n",
      "Epoch 00016: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0750 - acc: 0.9804 - val_loss: 1.0975 - val_acc: 0.7827\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9779\n",
      "Epoch 00017: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0794 - acc: 0.9779 - val_loss: 1.1506 - val_acc: 0.7808\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9807\n",
      "Epoch 00018: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0703 - acc: 0.9807 - val_loss: 1.1878 - val_acc: 0.7836\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9846\n",
      "Epoch 00019: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0597 - acc: 0.9846 - val_loss: 1.1616 - val_acc: 0.7789\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9829\n",
      "Epoch 00020: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0641 - acc: 0.9829 - val_loss: 1.1999 - val_acc: 0.7845\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9837\n",
      "Epoch 00021: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0607 - acc: 0.9837 - val_loss: 1.1709 - val_acc: 0.7822\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9849\n",
      "Epoch 00022: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0549 - acc: 0.9849 - val_loss: 1.1780 - val_acc: 0.7848\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9886\n",
      "Epoch 00023: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0461 - acc: 0.9886 - val_loss: 1.2760 - val_acc: 0.7754\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9874\n",
      "Epoch 00024: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0495 - acc: 0.9874 - val_loss: 1.3171 - val_acc: 0.7741\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9874\n",
      "Epoch 00025: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0487 - acc: 0.9874 - val_loss: 1.2784 - val_acc: 0.7834\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9873\n",
      "Epoch 00026: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0484 - acc: 0.9873 - val_loss: 1.3709 - val_acc: 0.7671\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9905\n",
      "Epoch 00027: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0408 - acc: 0.9905 - val_loss: 1.3512 - val_acc: 0.7782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9910\n",
      "Epoch 00028: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0387 - acc: 0.9910 - val_loss: 1.2330 - val_acc: 0.7873\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9905\n",
      "Epoch 00029: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0395 - acc: 0.9905 - val_loss: 1.3318 - val_acc: 0.7792\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9884\n",
      "Epoch 00030: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0441 - acc: 0.9884 - val_loss: 1.2662 - val_acc: 0.7824\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9902\n",
      "Epoch 00031: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0406 - acc: 0.9902 - val_loss: 1.3102 - val_acc: 0.7913\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9912\n",
      "Epoch 00032: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0376 - acc: 0.9912 - val_loss: 1.2743 - val_acc: 0.7845\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9906\n",
      "Epoch 00033: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0387 - acc: 0.9906 - val_loss: 1.3289 - val_acc: 0.7899\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9899\n",
      "Epoch 00034: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0390 - acc: 0.9899 - val_loss: 1.2901 - val_acc: 0.7887\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9929\n",
      "Epoch 00035: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0325 - acc: 0.9929 - val_loss: 1.3417 - val_acc: 0.7890\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9922\n",
      "Epoch 00036: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0328 - acc: 0.9922 - val_loss: 1.3517 - val_acc: 0.7922\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9909\n",
      "Epoch 00037: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0356 - acc: 0.9909 - val_loss: 1.3188 - val_acc: 0.7866\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 00038: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0345 - acc: 0.9917 - val_loss: 1.3208 - val_acc: 0.7864\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9900\n",
      "Epoch 00039: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0394 - acc: 0.9900 - val_loss: 1.2752 - val_acc: 0.7901\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9921\n",
      "Epoch 00040: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0343 - acc: 0.9921 - val_loss: 1.3923 - val_acc: 0.7911\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9947\n",
      "Epoch 00041: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0250 - acc: 0.9947 - val_loss: 1.3307 - val_acc: 0.7971\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9920\n",
      "Epoch 00042: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0332 - acc: 0.9920 - val_loss: 1.3458 - val_acc: 0.8006\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9946\n",
      "Epoch 00043: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0263 - acc: 0.9946 - val_loss: 1.4011 - val_acc: 0.7852\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9924\n",
      "Epoch 00044: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0329 - acc: 0.9924 - val_loss: 1.3178 - val_acc: 0.7971\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9933\n",
      "Epoch 00045: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0302 - acc: 0.9933 - val_loss: 1.3664 - val_acc: 0.7980\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9931\n",
      "Epoch 00046: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0297 - acc: 0.9931 - val_loss: 1.4298 - val_acc: 0.7959\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9929\n",
      "Epoch 00047: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0310 - acc: 0.9929 - val_loss: 1.4386 - val_acc: 0.7848\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9932\n",
      "Epoch 00048: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0302 - acc: 0.9932 - val_loss: 1.5922 - val_acc: 0.7701\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9934\n",
      "Epoch 00049: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0308 - acc: 0.9934 - val_loss: 1.3993 - val_acc: 0.7939\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9937\n",
      "Epoch 00050: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0292 - acc: 0.9938 - val_loss: 1.3174 - val_acc: 0.8004\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9944\n",
      "Epoch 00051: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0265 - acc: 0.9944 - val_loss: 1.2675 - val_acc: 0.8060\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9943- ETA: 5\n",
      "Epoch 00052: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0248 - acc: 0.9943 - val_loss: 1.3352 - val_acc: 0.8025\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9951\n",
      "Epoch 00053: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0235 - acc: 0.9951 - val_loss: 1.4735 - val_acc: 0.7915\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9939\n",
      "Epoch 00054: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0280 - acc: 0.9939 - val_loss: 1.4244 - val_acc: 0.7887\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9935\n",
      "Epoch 00055: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0286 - acc: 0.9935 - val_loss: 1.4155 - val_acc: 0.7990\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9939\n",
      "Epoch 00056: val_loss did not improve from 0.76229\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0261 - acc: 0.9939 - val_loss: 1.3105 - val_acc: 0.7997\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8661 - acc: 0.7551\n",
      "Loss: 0.8660826236040545 Accuracy: 0.7551402\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9413 - acc: 0.3705\n",
      "Epoch 00001: val_loss improved from inf to 1.36281, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/001-1.3628.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 1.9412 - acc: 0.3705 - val_loss: 1.3628 - val_acc: 0.5556\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2832 - acc: 0.5974\n",
      "Epoch 00002: val_loss improved from 1.36281 to 1.03428, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/002-1.0343.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.2831 - acc: 0.5974 - val_loss: 1.0343 - val_acc: 0.6839\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9928 - acc: 0.6999\n",
      "Epoch 00003: val_loss improved from 1.03428 to 0.83037, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/003-0.8304.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.9927 - acc: 0.7000 - val_loss: 0.8304 - val_acc: 0.7563\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7976 - acc: 0.7596\n",
      "Epoch 00004: val_loss improved from 0.83037 to 0.79164, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/004-0.7916.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.7976 - acc: 0.7597 - val_loss: 0.7916 - val_acc: 0.7563\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6627 - acc: 0.8011\n",
      "Epoch 00005: val_loss improved from 0.79164 to 0.60149, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/005-0.6015.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.6629 - acc: 0.8011 - val_loss: 0.6015 - val_acc: 0.8260\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5672 - acc: 0.8323\n",
      "Epoch 00006: val_loss improved from 0.60149 to 0.56549, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/006-0.5655.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.5672 - acc: 0.8323 - val_loss: 0.5655 - val_acc: 0.8400\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.8523\n",
      "Epoch 00007: val_loss improved from 0.56549 to 0.50344, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/007-0.5034.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.4927 - acc: 0.8522 - val_loss: 0.5034 - val_acc: 0.8551\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4329 - acc: 0.8691\n",
      "Epoch 00008: val_loss did not improve from 0.50344\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.4328 - acc: 0.8691 - val_loss: 0.5393 - val_acc: 0.8414\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3767 - acc: 0.8864\n",
      "Epoch 00009: val_loss improved from 0.50344 to 0.49030, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/009-0.4903.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3767 - acc: 0.8865 - val_loss: 0.4903 - val_acc: 0.8656\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.8988\n",
      "Epoch 00010: val_loss improved from 0.49030 to 0.43538, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/010-0.4354.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3347 - acc: 0.8988 - val_loss: 0.4354 - val_acc: 0.8761\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3090 - acc: 0.9061\n",
      "Epoch 00011: val_loss improved from 0.43538 to 0.42372, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/011-0.4237.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3090 - acc: 0.9061 - val_loss: 0.4237 - val_acc: 0.8777\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2698 - acc: 0.9170\n",
      "Epoch 00012: val_loss did not improve from 0.42372\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2698 - acc: 0.9170 - val_loss: 0.4389 - val_acc: 0.8791\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9216\n",
      "Epoch 00013: val_loss improved from 0.42372 to 0.41564, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/013-0.4156.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2457 - acc: 0.9216 - val_loss: 0.4156 - val_acc: 0.8982\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9339\n",
      "Epoch 00014: val_loss did not improve from 0.41564\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2124 - acc: 0.9338 - val_loss: 0.4188 - val_acc: 0.8903\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9370\n",
      "Epoch 00015: val_loss did not improve from 0.41564\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2011 - acc: 0.9370 - val_loss: 0.4278 - val_acc: 0.8924\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9458\n",
      "Epoch 00016: val_loss improved from 0.41564 to 0.40141, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_6_conv_checkpoint/016-0.4014.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1744 - acc: 0.9458 - val_loss: 0.4014 - val_acc: 0.9012\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9515\n",
      "Epoch 00017: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1563 - acc: 0.9515 - val_loss: 0.4512 - val_acc: 0.8921\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9557\n",
      "Epoch 00018: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1387 - acc: 0.9557 - val_loss: 0.4494 - val_acc: 0.8975\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9585\n",
      "Epoch 00019: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1267 - acc: 0.9585 - val_loss: 0.4493 - val_acc: 0.8991\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9635\n",
      "Epoch 00020: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1142 - acc: 0.9635 - val_loss: 0.4831 - val_acc: 0.8952\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9668\n",
      "Epoch 00021: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1050 - acc: 0.9669 - val_loss: 0.4627 - val_acc: 0.9057\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9683\n",
      "Epoch 00022: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0977 - acc: 0.9683 - val_loss: 0.4484 - val_acc: 0.8966\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9733\n",
      "Epoch 00023: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0854 - acc: 0.9733 - val_loss: 0.4944 - val_acc: 0.8956\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9744\n",
      "Epoch 00024: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0816 - acc: 0.9744 - val_loss: 0.4918 - val_acc: 0.9024\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9771\n",
      "Epoch 00025: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0731 - acc: 0.9771 - val_loss: 0.5185 - val_acc: 0.8938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9793\n",
      "Epoch 00026: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0658 - acc: 0.9793 - val_loss: 0.5147 - val_acc: 0.9015\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9795\n",
      "Epoch 00027: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0637 - acc: 0.9794 - val_loss: 0.5139 - val_acc: 0.8963\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9805\n",
      "Epoch 00028: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0612 - acc: 0.9805 - val_loss: 0.5352 - val_acc: 0.8998\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9827\n",
      "Epoch 00029: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0535 - acc: 0.9827 - val_loss: 0.5336 - val_acc: 0.9001\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9834\n",
      "Epoch 00030: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0542 - acc: 0.9834 - val_loss: 0.6077 - val_acc: 0.8896\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9817\n",
      "Epoch 00031: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0563 - acc: 0.9817 - val_loss: 0.5597 - val_acc: 0.8994\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9846\n",
      "Epoch 00032: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0510 - acc: 0.9846 - val_loss: 0.5487 - val_acc: 0.8998\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9852\n",
      "Epoch 00033: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0489 - acc: 0.9852 - val_loss: 0.5572 - val_acc: 0.8987\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9869\n",
      "Epoch 00034: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0436 - acc: 0.9869 - val_loss: 0.5528 - val_acc: 0.9054\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9864\n",
      "Epoch 00035: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0464 - acc: 0.9864 - val_loss: 0.5520 - val_acc: 0.9026\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9882\n",
      "Epoch 00036: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0382 - acc: 0.9882 - val_loss: 0.5594 - val_acc: 0.9052\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9864\n",
      "Epoch 00037: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0437 - acc: 0.9864 - val_loss: 0.5788 - val_acc: 0.9038\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9891\n",
      "Epoch 00038: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0375 - acc: 0.9891 - val_loss: 0.5684 - val_acc: 0.8942\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9893\n",
      "Epoch 00039: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0354 - acc: 0.9893 - val_loss: 0.6040 - val_acc: 0.9029\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9885\n",
      "Epoch 00040: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0401 - acc: 0.9885 - val_loss: 0.5923 - val_acc: 0.8952\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9899\n",
      "Epoch 00041: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0333 - acc: 0.9899 - val_loss: 0.5420 - val_acc: 0.9031\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9899- ETA: 2s - loss: 0.0351 - \n",
      "Epoch 00042: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0351 - acc: 0.9899 - val_loss: 0.5916 - val_acc: 0.9052\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9902\n",
      "Epoch 00043: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0323 - acc: 0.9902 - val_loss: 0.5946 - val_acc: 0.9043\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9910\n",
      "Epoch 00044: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0320 - acc: 0.9910 - val_loss: 0.6247 - val_acc: 0.9033\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9919\n",
      "Epoch 00045: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0289 - acc: 0.9919 - val_loss: 0.5739 - val_acc: 0.9061\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9904\n",
      "Epoch 00046: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0316 - acc: 0.9904 - val_loss: 0.6281 - val_acc: 0.9019\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9905\n",
      "Epoch 00047: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0313 - acc: 0.9905 - val_loss: 0.6414 - val_acc: 0.9012\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9913\n",
      "Epoch 00048: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0287 - acc: 0.9913 - val_loss: 0.5938 - val_acc: 0.8991\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9909\n",
      "Epoch 00049: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0296 - acc: 0.9909 - val_loss: 0.6055 - val_acc: 0.9003\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9923\n",
      "Epoch 00050: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0274 - acc: 0.9923 - val_loss: 0.6009 - val_acc: 0.9066\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9930\n",
      "Epoch 00051: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0243 - acc: 0.9930 - val_loss: 0.6129 - val_acc: 0.9085\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9911\n",
      "Epoch 00052: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0292 - acc: 0.9911 - val_loss: 0.6480 - val_acc: 0.8903\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9917\n",
      "Epoch 00053: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0297 - acc: 0.9917 - val_loss: 0.5836 - val_acc: 0.9094\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9936\n",
      "Epoch 00054: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0246 - acc: 0.9936 - val_loss: 0.5841 - val_acc: 0.9101\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9951\n",
      "Epoch 00055: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0181 - acc: 0.9951 - val_loss: 0.6976 - val_acc: 0.8938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9920\n",
      "Epoch 00056: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0269 - acc: 0.9920 - val_loss: 0.6366 - val_acc: 0.9043\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9897\n",
      "Epoch 00057: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0381 - acc: 0.9897 - val_loss: 0.6120 - val_acc: 0.9022\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9936\n",
      "Epoch 00058: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0230 - acc: 0.9936 - val_loss: 0.5792 - val_acc: 0.9071\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9952\n",
      "Epoch 00059: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0182 - acc: 0.9952 - val_loss: 0.6055 - val_acc: 0.9154\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9931\n",
      "Epoch 00060: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0248 - acc: 0.9931 - val_loss: 0.6431 - val_acc: 0.8933\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9941\n",
      "Epoch 00061: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0204 - acc: 0.9941 - val_loss: 0.6447 - val_acc: 0.9019\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9922\n",
      "Epoch 00062: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0276 - acc: 0.9922 - val_loss: 0.5686 - val_acc: 0.9103\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9954\n",
      "Epoch 00063: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0178 - acc: 0.9954 - val_loss: 0.5857 - val_acc: 0.9122\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0229 - acc: 0.9933 - val_loss: 0.6170 - val_acc: 0.9068\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9945\n",
      "Epoch 00065: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0209 - acc: 0.9945 - val_loss: 0.6586 - val_acc: 0.9001\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9945\n",
      "Epoch 00066: val_loss did not improve from 0.40141\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0189 - acc: 0.9945 - val_loss: 0.6287 - val_acc: 0.9094\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4726 - acc: 0.8744\n",
      "Loss: 0.4726447113825401 Accuracy: 0.87435097\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9718 - acc: 0.3533\n",
      "Epoch 00001: val_loss improved from inf to 1.25795, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/001-1.2580.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 1.9717 - acc: 0.3534 - val_loss: 1.2580 - val_acc: 0.6033\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1818 - acc: 0.6251\n",
      "Epoch 00002: val_loss improved from 1.25795 to 0.94052, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/002-0.9405.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 1.1817 - acc: 0.6251 - val_loss: 0.9405 - val_acc: 0.7058\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8604 - acc: 0.7320\n",
      "Epoch 00003: val_loss improved from 0.94052 to 0.64162, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/003-0.6416.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.8604 - acc: 0.7319 - val_loss: 0.6416 - val_acc: 0.8078\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6600 - acc: 0.7957\n",
      "Epoch 00004: val_loss improved from 0.64162 to 0.49444, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/004-0.4944.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.6600 - acc: 0.7957 - val_loss: 0.4944 - val_acc: 0.8516\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5209 - acc: 0.8393\n",
      "Epoch 00005: val_loss improved from 0.49444 to 0.40502, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/005-0.4050.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.5208 - acc: 0.8393 - val_loss: 0.4050 - val_acc: 0.8866\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.8690\n",
      "Epoch 00006: val_loss improved from 0.40502 to 0.34559, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/006-0.3456.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.4188 - acc: 0.8690 - val_loss: 0.3456 - val_acc: 0.8933\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8876\n",
      "Epoch 00007: val_loss improved from 0.34559 to 0.31441, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/007-0.3144.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3644 - acc: 0.8875 - val_loss: 0.3144 - val_acc: 0.9103\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3247 - acc: 0.8979\n",
      "Epoch 00008: val_loss improved from 0.31441 to 0.31275, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/008-0.3128.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3247 - acc: 0.8979 - val_loss: 0.3128 - val_acc: 0.9082\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9096\n",
      "Epoch 00009: val_loss improved from 0.31275 to 0.28356, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/009-0.2836.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2861 - acc: 0.9096 - val_loss: 0.2836 - val_acc: 0.9215\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2570 - acc: 0.9181\n",
      "Epoch 00010: val_loss improved from 0.28356 to 0.25705, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/010-0.2571.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2569 - acc: 0.9181 - val_loss: 0.2571 - val_acc: 0.9294\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2286 - acc: 0.9277\n",
      "Epoch 00011: val_loss improved from 0.25705 to 0.23740, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/011-0.2374.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2286 - acc: 0.9277 - val_loss: 0.2374 - val_acc: 0.9315\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9313\n",
      "Epoch 00012: val_loss did not improve from 0.23740\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2126 - acc: 0.9313 - val_loss: 0.2482 - val_acc: 0.9280\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9401- ETA: 2s - loss: 0.1870\n",
      "Epoch 00013: val_loss improved from 0.23740 to 0.20730, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/013-0.2073.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1872 - acc: 0.9401 - val_loss: 0.2073 - val_acc: 0.9427\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9438\n",
      "Epoch 00014: val_loss improved from 0.20730 to 0.20339, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/014-0.2034.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1733 - acc: 0.9438 - val_loss: 0.2034 - val_acc: 0.9436\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9493\n",
      "Epoch 00015: val_loss did not improve from 0.20339\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1606 - acc: 0.9493 - val_loss: 0.2376 - val_acc: 0.9299\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9523\n",
      "Epoch 00016: val_loss improved from 0.20339 to 0.19075, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_7_conv_checkpoint/016-0.1907.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1464 - acc: 0.9522 - val_loss: 0.1907 - val_acc: 0.9453\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9562\n",
      "Epoch 00017: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1372 - acc: 0.9562 - val_loss: 0.2260 - val_acc: 0.9394\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9595- ETA: 3s - loss: 0.\n",
      "Epoch 00018: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1239 - acc: 0.9595 - val_loss: 0.2284 - val_acc: 0.9322\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9621\n",
      "Epoch 00019: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1139 - acc: 0.9621 - val_loss: 0.2014 - val_acc: 0.9436\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9643\n",
      "Epoch 00020: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1058 - acc: 0.9643 - val_loss: 0.2197 - val_acc: 0.9378\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9666\n",
      "Epoch 00021: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0996 - acc: 0.9666 - val_loss: 0.2119 - val_acc: 0.9450\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9696\n",
      "Epoch 00022: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0931 - acc: 0.9697 - val_loss: 0.2116 - val_acc: 0.9481\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9726- ETA: 2s - loss: 0.0832 -\n",
      "Epoch 00023: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0831 - acc: 0.9726 - val_loss: 0.2162 - val_acc: 0.9462\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9723\n",
      "Epoch 00024: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0804 - acc: 0.9723 - val_loss: 0.2125 - val_acc: 0.9429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9741\n",
      "Epoch 00025: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0766 - acc: 0.9741 - val_loss: 0.2294 - val_acc: 0.9406\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9760\n",
      "Epoch 00026: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0743 - acc: 0.9760 - val_loss: 0.2417 - val_acc: 0.9448\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9777\n",
      "Epoch 00027: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0668 - acc: 0.9777 - val_loss: 0.2205 - val_acc: 0.9439\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9795\n",
      "Epoch 00028: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0596 - acc: 0.9795 - val_loss: 0.2291 - val_acc: 0.9441\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9804\n",
      "Epoch 00029: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0580 - acc: 0.9803 - val_loss: 0.2300 - val_acc: 0.9478\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9806\n",
      "Epoch 00030: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0587 - acc: 0.9806 - val_loss: 0.2109 - val_acc: 0.9502\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9831\n",
      "Epoch 00031: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0491 - acc: 0.9831 - val_loss: 0.2193 - val_acc: 0.9504\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9827\n",
      "Epoch 00032: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0499 - acc: 0.9827 - val_loss: 0.2104 - val_acc: 0.9529\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9848\n",
      "Epoch 00033: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0447 - acc: 0.9848 - val_loss: 0.2310 - val_acc: 0.9504\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9839\n",
      "Epoch 00034: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0474 - acc: 0.9839 - val_loss: 0.2349 - val_acc: 0.9474\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9861\n",
      "Epoch 00035: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0410 - acc: 0.9861 - val_loss: 0.2302 - val_acc: 0.9518\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9876\n",
      "Epoch 00036: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0374 - acc: 0.9876 - val_loss: 0.2474 - val_acc: 0.9485\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9859\n",
      "Epoch 00037: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0425 - acc: 0.9859 - val_loss: 0.2366 - val_acc: 0.9467\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9875\n",
      "Epoch 00038: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0384 - acc: 0.9875 - val_loss: 0.2647 - val_acc: 0.9504\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9872\n",
      "Epoch 00039: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0402 - acc: 0.9872 - val_loss: 0.2237 - val_acc: 0.9481\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9893\n",
      "Epoch 00040: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0304 - acc: 0.9893 - val_loss: 0.2471 - val_acc: 0.9450\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9897\n",
      "Epoch 00041: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0314 - acc: 0.9897 - val_loss: 0.2587 - val_acc: 0.9436\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9895\n",
      "Epoch 00042: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0316 - acc: 0.9895 - val_loss: 0.2841 - val_acc: 0.9422\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9904\n",
      "Epoch 00043: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0307 - acc: 0.9904 - val_loss: 0.2866 - val_acc: 0.9420\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 00044: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0298 - acc: 0.9903 - val_loss: 0.2413 - val_acc: 0.9515\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9909\n",
      "Epoch 00045: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0249 - acc: 0.9909 - val_loss: 0.2711 - val_acc: 0.9474\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9904\n",
      "Epoch 00046: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0281 - acc: 0.9904 - val_loss: 0.2810 - val_acc: 0.9441\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9918\n",
      "Epoch 00047: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0258 - acc: 0.9918 - val_loss: 0.2509 - val_acc: 0.9515\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9908\n",
      "Epoch 00048: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0261 - acc: 0.9908 - val_loss: 0.2621 - val_acc: 0.9490\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 00049: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0218 - acc: 0.9929 - val_loss: 0.2685 - val_acc: 0.9495\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9912- ETA: 0s - loss: 0.0270 - acc: 0.\n",
      "Epoch 00050: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0268 - acc: 0.9912 - val_loss: 0.2661 - val_acc: 0.9481\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9927\n",
      "Epoch 00051: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0231 - acc: 0.9927 - val_loss: 0.2541 - val_acc: 0.9527\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9928\n",
      "Epoch 00052: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0223 - acc: 0.9928 - val_loss: 0.2461 - val_acc: 0.9522\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9921\n",
      "Epoch 00053: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0248 - acc: 0.9921 - val_loss: 0.2609 - val_acc: 0.9529\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9929\n",
      "Epoch 00054: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0221 - acc: 0.9929 - val_loss: 0.2661 - val_acc: 0.9495\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9936\n",
      "Epoch 00055: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0197 - acc: 0.9936 - val_loss: 0.2805 - val_acc: 0.9453\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9931\n",
      "Epoch 00056: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0203 - acc: 0.9931 - val_loss: 0.2669 - val_acc: 0.9536\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9944\n",
      "Epoch 00057: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0175 - acc: 0.9944 - val_loss: 0.2920 - val_acc: 0.9529\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9940\n",
      "Epoch 00058: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0183 - acc: 0.9940 - val_loss: 0.2798 - val_acc: 0.9534\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9933\n",
      "Epoch 00059: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0203 - acc: 0.9933 - val_loss: 0.2706 - val_acc: 0.9502\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9936\n",
      "Epoch 00060: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0205 - acc: 0.9936 - val_loss: 0.2989 - val_acc: 0.9481\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9947\n",
      "Epoch 00061: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0168 - acc: 0.9947 - val_loss: 0.3203 - val_acc: 0.9488\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9936\n",
      "Epoch 00062: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0186 - acc: 0.9936 - val_loss: 0.2756 - val_acc: 0.9485\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9953\n",
      "Epoch 00063: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0148 - acc: 0.9953 - val_loss: 0.2730 - val_acc: 0.9522\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9939\n",
      "Epoch 00064: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0186 - acc: 0.9939 - val_loss: 0.2790 - val_acc: 0.9497\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9941\n",
      "Epoch 00065: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0179 - acc: 0.9941 - val_loss: 0.2807 - val_acc: 0.9495\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9952\n",
      "Epoch 00066: val_loss did not improve from 0.19075\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0149 - acc: 0.9952 - val_loss: 0.2879 - val_acc: 0.9481\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2595 - acc: 0.9308\n",
      "Loss: 0.2594976645949474 Accuracy: 0.93084115\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8009 - acc: 0.4111\n",
      "Epoch 00001: val_loss improved from inf to 0.94695, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/001-0.9469.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 1.8007 - acc: 0.4111 - val_loss: 0.9469 - val_acc: 0.6897\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9140 - acc: 0.7065\n",
      "Epoch 00002: val_loss improved from 0.94695 to 0.69014, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/002-0.6901.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.9141 - acc: 0.7065 - val_loss: 0.6901 - val_acc: 0.7731\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6522 - acc: 0.7910\n",
      "Epoch 00003: val_loss improved from 0.69014 to 0.47817, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/003-0.4782.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.6522 - acc: 0.7910 - val_loss: 0.4782 - val_acc: 0.8486\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8413\n",
      "Epoch 00004: val_loss improved from 0.47817 to 0.33191, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/004-0.3319.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.4944 - acc: 0.8413 - val_loss: 0.3319 - val_acc: 0.9031\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8714\n",
      "Epoch 00005: val_loss improved from 0.33191 to 0.27993, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/005-0.2799.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.4012 - acc: 0.8714 - val_loss: 0.2799 - val_acc: 0.9196\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8908\n",
      "Epoch 00006: val_loss improved from 0.27993 to 0.25319, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/006-0.2532.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3380 - acc: 0.8908 - val_loss: 0.2532 - val_acc: 0.9222\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2913 - acc: 0.9059- ETA: 5s - l\n",
      "Epoch 00007: val_loss improved from 0.25319 to 0.21028, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/007-0.2103.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2913 - acc: 0.9059 - val_loss: 0.2103 - val_acc: 0.9366\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9180\n",
      "Epoch 00008: val_loss improved from 0.21028 to 0.19088, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/008-0.1909.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2526 - acc: 0.9180 - val_loss: 0.1909 - val_acc: 0.9406\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9265\n",
      "Epoch 00009: val_loss did not improve from 0.19088\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2272 - acc: 0.9265 - val_loss: 0.1962 - val_acc: 0.9383\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9345\n",
      "Epoch 00010: val_loss improved from 0.19088 to 0.17049, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/010-0.1705.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2078 - acc: 0.9345 - val_loss: 0.1705 - val_acc: 0.9492\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9417\n",
      "Epoch 00011: val_loss did not improve from 0.17049\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1809 - acc: 0.9417 - val_loss: 0.1771 - val_acc: 0.9464\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9472\n",
      "Epoch 00012: val_loss improved from 0.17049 to 0.16037, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/012-0.1604.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1622 - acc: 0.9472 - val_loss: 0.1604 - val_acc: 0.9485\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9493\n",
      "Epoch 00013: val_loss did not improve from 0.16037\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1539 - acc: 0.9493 - val_loss: 0.1648 - val_acc: 0.9476\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9555\n",
      "Epoch 00014: val_loss did not improve from 0.16037\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1366 - acc: 0.9555 - val_loss: 0.1707 - val_acc: 0.9495\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9573\n",
      "Epoch 00015: val_loss did not improve from 0.16037\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1283 - acc: 0.9573 - val_loss: 0.1897 - val_acc: 0.9464\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9609\n",
      "Epoch 00016: val_loss improved from 0.16037 to 0.14840, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/016-0.1484.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1159 - acc: 0.9609 - val_loss: 0.1484 - val_acc: 0.9604\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9654\n",
      "Epoch 00017: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1058 - acc: 0.9654 - val_loss: 0.1584 - val_acc: 0.9536\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9663\n",
      "Epoch 00018: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1002 - acc: 0.9663 - val_loss: 0.1577 - val_acc: 0.9581\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9715\n",
      "Epoch 00019: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0867 - acc: 0.9716 - val_loss: 0.1533 - val_acc: 0.9560\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9714\n",
      "Epoch 00020: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0842 - acc: 0.9714 - val_loss: 0.1525 - val_acc: 0.9553\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9741\n",
      "Epoch 00021: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0769 - acc: 0.9741 - val_loss: 0.1587 - val_acc: 0.9576\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9754\n",
      "Epoch 00022: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0733 - acc: 0.9754 - val_loss: 0.1563 - val_acc: 0.9562\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9780\n",
      "Epoch 00023: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0678 - acc: 0.9780 - val_loss: 0.1576 - val_acc: 0.9543\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9796\n",
      "Epoch 00024: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0607 - acc: 0.9796 - val_loss: 0.1499 - val_acc: 0.9611\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9795\n",
      "Epoch 00025: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0601 - acc: 0.9795 - val_loss: 0.1616 - val_acc: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9815\n",
      "Epoch 00026: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0545 - acc: 0.9815 - val_loss: 0.1575 - val_acc: 0.9602\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9822\n",
      "Epoch 00027: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0526 - acc: 0.9822 - val_loss: 0.2006 - val_acc: 0.9534\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9828\n",
      "Epoch 00028: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0524 - acc: 0.9828 - val_loss: 0.1829 - val_acc: 0.9553\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9832\n",
      "Epoch 00029: val_loss did not improve from 0.14840\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0502 - acc: 0.9832 - val_loss: 0.1744 - val_acc: 0.9578\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9853\n",
      "Epoch 00030: val_loss improved from 0.14840 to 0.14622, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_8_conv_checkpoint/030-0.1462.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0439 - acc: 0.9853 - val_loss: 0.1462 - val_acc: 0.9620\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9857\n",
      "Epoch 00031: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0414 - acc: 0.9857 - val_loss: 0.1828 - val_acc: 0.9595\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9869\n",
      "Epoch 00032: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0383 - acc: 0.9869 - val_loss: 0.1697 - val_acc: 0.9616\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9876\n",
      "Epoch 00033: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0366 - acc: 0.9876 - val_loss: 0.1774 - val_acc: 0.9634\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9874\n",
      "Epoch 00034: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0353 - acc: 0.9874 - val_loss: 0.1856 - val_acc: 0.9604\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9875- ETA: 3s - loss: \n",
      "Epoch 00035: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0363 - acc: 0.9875 - val_loss: 0.1808 - val_acc: 0.9574\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9887\n",
      "Epoch 00036: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0335 - acc: 0.9888 - val_loss: 0.1985 - val_acc: 0.9560\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9893\n",
      "Epoch 00037: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0316 - acc: 0.9893 - val_loss: 0.2168 - val_acc: 0.9562\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9891\n",
      "Epoch 00038: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0317 - acc: 0.9891 - val_loss: 0.2018 - val_acc: 0.9581\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9904\n",
      "Epoch 00039: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0293 - acc: 0.9904 - val_loss: 0.1860 - val_acc: 0.9599\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9908\n",
      "Epoch 00040: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0291 - acc: 0.9908 - val_loss: 0.2094 - val_acc: 0.9560\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9909\n",
      "Epoch 00041: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0265 - acc: 0.9909 - val_loss: 0.1929 - val_acc: 0.9574\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9912\n",
      "Epoch 00042: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0258 - acc: 0.9912 - val_loss: 0.1966 - val_acc: 0.9595\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9914\n",
      "Epoch 00043: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0246 - acc: 0.9914 - val_loss: 0.1863 - val_acc: 0.9625\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9916\n",
      "Epoch 00044: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0247 - acc: 0.9916 - val_loss: 0.1978 - val_acc: 0.9585\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9911\n",
      "Epoch 00045: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0269 - acc: 0.9911 - val_loss: 0.1941 - val_acc: 0.9613\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9932\n",
      "Epoch 00046: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0215 - acc: 0.9932 - val_loss: 0.1854 - val_acc: 0.9632\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9928\n",
      "Epoch 00047: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0216 - acc: 0.9928 - val_loss: 0.1787 - val_acc: 0.9637\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9941\n",
      "Epoch 00048: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0182 - acc: 0.9941 - val_loss: 0.1909 - val_acc: 0.9611\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9924\n",
      "Epoch 00049: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0235 - acc: 0.9924 - val_loss: 0.1916 - val_acc: 0.9639\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9933\n",
      "Epoch 00050: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0192 - acc: 0.9933 - val_loss: 0.1980 - val_acc: 0.9609\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0197 - acc: 0.9937 - val_loss: 0.2097 - val_acc: 0.9602\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9925\n",
      "Epoch 00052: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0214 - acc: 0.9925 - val_loss: 0.1888 - val_acc: 0.9618\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9949\n",
      "Epoch 00053: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0154 - acc: 0.9949 - val_loss: 0.2097 - val_acc: 0.9618\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9932\n",
      "Epoch 00054: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0208 - acc: 0.9932 - val_loss: 0.2145 - val_acc: 0.9597\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9943\n",
      "Epoch 00055: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0185 - acc: 0.9943 - val_loss: 0.2137 - val_acc: 0.9611\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9942\n",
      "Epoch 00056: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0188 - acc: 0.9942 - val_loss: 0.1955 - val_acc: 0.9625\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9946\n",
      "Epoch 00057: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0172 - acc: 0.9946 - val_loss: 0.2029 - val_acc: 0.9641\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 00058: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0159 - acc: 0.9951 - val_loss: 0.2018 - val_acc: 0.9602\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9942\n",
      "Epoch 00059: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0171 - acc: 0.9942 - val_loss: 0.2295 - val_acc: 0.9562\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 00060: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.2191 - val_acc: 0.9564\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9951\n",
      "Epoch 00061: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0149 - acc: 0.9951 - val_loss: 0.2191 - val_acc: 0.9567\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9945\n",
      "Epoch 00062: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0175 - acc: 0.9945 - val_loss: 0.2292 - val_acc: 0.9574\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9952\n",
      "Epoch 00063: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0154 - acc: 0.9952 - val_loss: 0.2001 - val_acc: 0.9616\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 00064: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0125 - acc: 0.9961 - val_loss: 0.1888 - val_acc: 0.9623\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9949\n",
      "Epoch 00065: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0154 - acc: 0.9949 - val_loss: 0.1858 - val_acc: 0.9690\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9957\n",
      "Epoch 00066: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0131 - acc: 0.9957 - val_loss: 0.2122 - val_acc: 0.9613\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9964\n",
      "Epoch 00067: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0112 - acc: 0.9964 - val_loss: 0.2217 - val_acc: 0.9581\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 00068: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0146 - acc: 0.9954 - val_loss: 0.1965 - val_acc: 0.9583\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9953\n",
      "Epoch 00069: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0153 - acc: 0.9953 - val_loss: 0.1760 - val_acc: 0.9655\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9957\n",
      "Epoch 00070: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0128 - acc: 0.9957 - val_loss: 0.2079 - val_acc: 0.9646\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9975\n",
      "Epoch 00071: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0078 - acc: 0.9975 - val_loss: 0.2158 - val_acc: 0.9648\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9959\n",
      "Epoch 00072: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0119 - acc: 0.9959 - val_loss: 0.1989 - val_acc: 0.9648\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9957\n",
      "Epoch 00073: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0134 - acc: 0.9957 - val_loss: 0.2091 - val_acc: 0.9606\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9968\n",
      "Epoch 00074: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0104 - acc: 0.9968 - val_loss: 0.1892 - val_acc: 0.9632\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9966\n",
      "Epoch 00075: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0110 - acc: 0.9966 - val_loss: 0.2247 - val_acc: 0.9637\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 00076: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0120 - acc: 0.9962 - val_loss: 0.1897 - val_acc: 0.9630\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9963\n",
      "Epoch 00077: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0127 - acc: 0.9963 - val_loss: 0.1791 - val_acc: 0.9658\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9968\n",
      "Epoch 00078: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0099 - acc: 0.9968 - val_loss: 0.2097 - val_acc: 0.9639\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9950\n",
      "Epoch 00079: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0154 - acc: 0.9950 - val_loss: 0.1902 - val_acc: 0.9648\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00080: val_loss did not improve from 0.14622\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1953 - val_acc: 0.9646\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2192 - acc: 0.9472\n",
      "Loss: 0.219204667974834 Accuracy: 0.94724816\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5412 - acc: 0.4945\n",
      "Epoch 00001: val_loss improved from inf to 0.69217, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/001-0.6922.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 1.5412 - acc: 0.4945 - val_loss: 0.6922 - val_acc: 0.7687\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6894 - acc: 0.7733\n",
      "Epoch 00002: val_loss improved from 0.69217 to 0.52031, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/002-0.5203.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.6894 - acc: 0.7733 - val_loss: 0.5203 - val_acc: 0.8269\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4962 - acc: 0.8378\n",
      "Epoch 00003: val_loss improved from 0.52031 to 0.32181, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/003-0.3218.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.4962 - acc: 0.8378 - val_loss: 0.3218 - val_acc: 0.8984\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3707 - acc: 0.8784\n",
      "Epoch 00004: val_loss improved from 0.32181 to 0.30204, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/004-0.3020.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3707 - acc: 0.8784 - val_loss: 0.3020 - val_acc: 0.9040\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.9085\n",
      "Epoch 00005: val_loss improved from 0.30204 to 0.23785, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/005-0.2378.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2848 - acc: 0.9085 - val_loss: 0.2378 - val_acc: 0.9229\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9216\n",
      "Epoch 00006: val_loss improved from 0.23785 to 0.18825, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/006-0.1883.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2365 - acc: 0.9216 - val_loss: 0.1883 - val_acc: 0.9404\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9352\n",
      "Epoch 00007: val_loss did not improve from 0.18825\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1969 - acc: 0.9353 - val_loss: 0.2010 - val_acc: 0.9348\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9448\n",
      "Epoch 00008: val_loss improved from 0.18825 to 0.16371, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/008-0.1637.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1668 - acc: 0.9448 - val_loss: 0.1637 - val_acc: 0.9474\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9531\n",
      "Epoch 00009: val_loss did not improve from 0.16371\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1416 - acc: 0.9531 - val_loss: 0.1666 - val_acc: 0.9464\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9573\n",
      "Epoch 00010: val_loss improved from 0.16371 to 0.16252, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/010-0.1625.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1298 - acc: 0.9573 - val_loss: 0.1625 - val_acc: 0.9511\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9628\n",
      "Epoch 00011: val_loss did not improve from 0.16252\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1118 - acc: 0.9627 - val_loss: 0.1734 - val_acc: 0.9499\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9670\n",
      "Epoch 00012: val_loss did not improve from 0.16252\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0953 - acc: 0.9670 - val_loss: 0.2298 - val_acc: 0.9373\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9720\n",
      "Epoch 00013: val_loss did not improve from 0.16252\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0841 - acc: 0.9720 - val_loss: 0.1763 - val_acc: 0.9460\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9730\n",
      "Epoch 00014: val_loss did not improve from 0.16252\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0785 - acc: 0.9730 - val_loss: 0.1761 - val_acc: 0.9536\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9760\n",
      "Epoch 00015: val_loss did not improve from 0.16252\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0691 - acc: 0.9760 - val_loss: 0.1651 - val_acc: 0.9588\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9796\n",
      "Epoch 00016: val_loss did not improve from 0.16252\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0606 - acc: 0.9796 - val_loss: 0.1691 - val_acc: 0.9574\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9805\n",
      "Epoch 00017: val_loss improved from 0.16252 to 0.15337, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_9_conv_checkpoint/017-0.1534.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0568 - acc: 0.9805 - val_loss: 0.1534 - val_acc: 0.9569\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9837\n",
      "Epoch 00018: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0504 - acc: 0.9837 - val_loss: 0.1638 - val_acc: 0.9567\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9824\n",
      "Epoch 00019: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0509 - acc: 0.9824 - val_loss: 0.1930 - val_acc: 0.9504\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9848\n",
      "Epoch 00020: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0473 - acc: 0.9848 - val_loss: 0.1560 - val_acc: 0.9581\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9859\n",
      "Epoch 00021: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0412 - acc: 0.9859 - val_loss: 0.1787 - val_acc: 0.9578\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9877\n",
      "Epoch 00022: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0362 - acc: 0.9877 - val_loss: 0.2089 - val_acc: 0.9564\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9880\n",
      "Epoch 00023: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0385 - acc: 0.9880 - val_loss: 0.1647 - val_acc: 0.9578\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9874\n",
      "Epoch 00024: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0353 - acc: 0.9874 - val_loss: 0.1707 - val_acc: 0.9623\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9902\n",
      "Epoch 00025: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0301 - acc: 0.9902 - val_loss: 0.1797 - val_acc: 0.9590\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9906\n",
      "Epoch 00026: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0302 - acc: 0.9906 - val_loss: 0.1957 - val_acc: 0.9529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9902\n",
      "Epoch 00027: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.2037 - val_acc: 0.9576\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9910\n",
      "Epoch 00028: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0272 - acc: 0.9910 - val_loss: 0.1696 - val_acc: 0.9627\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9912\n",
      "Epoch 00029: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0279 - acc: 0.9913 - val_loss: 0.1539 - val_acc: 0.9658\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9926\n",
      "Epoch 00030: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0230 - acc: 0.9926 - val_loss: 0.2284 - val_acc: 0.9529\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9923\n",
      "Epoch 00031: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0236 - acc: 0.9923 - val_loss: 0.1919 - val_acc: 0.9599\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9920\n",
      "Epoch 00032: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0250 - acc: 0.9920 - val_loss: 0.2047 - val_acc: 0.9590\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9925\n",
      "Epoch 00033: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0224 - acc: 0.9925 - val_loss: 0.2065 - val_acc: 0.9560\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9929\n",
      "Epoch 00034: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0225 - acc: 0.9929 - val_loss: 0.1939 - val_acc: 0.9618\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9946\n",
      "Epoch 00035: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0181 - acc: 0.9946 - val_loss: 0.1778 - val_acc: 0.9639\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9937\n",
      "Epoch 00036: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0206 - acc: 0.9937 - val_loss: 0.2530 - val_acc: 0.9569\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9939\n",
      "Epoch 00037: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0186 - acc: 0.9939 - val_loss: 0.2137 - val_acc: 0.9604\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9936\n",
      "Epoch 00038: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0201 - acc: 0.9936 - val_loss: 0.2103 - val_acc: 0.9613\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9944\n",
      "Epoch 00039: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0181 - acc: 0.9944 - val_loss: 0.2152 - val_acc: 0.9604\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 00040: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.2121 - val_acc: 0.9609\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9942\n",
      "Epoch 00041: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0183 - acc: 0.9942 - val_loss: 0.1862 - val_acc: 0.9648\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9951\n",
      "Epoch 00042: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0164 - acc: 0.9951 - val_loss: 0.2092 - val_acc: 0.9623\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9951\n",
      "Epoch 00043: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0160 - acc: 0.9951 - val_loss: 0.2023 - val_acc: 0.9623\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9950\n",
      "Epoch 00044: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0161 - acc: 0.9950 - val_loss: 0.1956 - val_acc: 0.9637\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9966\n",
      "Epoch 00045: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0116 - acc: 0.9966 - val_loss: 0.1916 - val_acc: 0.9618\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9937\n",
      "Epoch 00046: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0207 - acc: 0.9937 - val_loss: 0.1635 - val_acc: 0.9639\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 00047: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0123 - acc: 0.9961 - val_loss: 0.1936 - val_acc: 0.9639\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9962\n",
      "Epoch 00048: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0123 - acc: 0.9962 - val_loss: 0.2397 - val_acc: 0.9574\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9961\n",
      "Epoch 00049: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0135 - acc: 0.9961 - val_loss: 0.2058 - val_acc: 0.9611\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9945\n",
      "Epoch 00050: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0177 - acc: 0.9945 - val_loss: 0.2006 - val_acc: 0.9641\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9963\n",
      "Epoch 00051: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0124 - acc: 0.9963 - val_loss: 0.1997 - val_acc: 0.9627\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9967\n",
      "Epoch 00052: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0095 - acc: 0.9967 - val_loss: 0.2293 - val_acc: 0.9644\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9958\n",
      "Epoch 00053: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0140 - acc: 0.9958 - val_loss: 0.2105 - val_acc: 0.9581\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9961\n",
      "Epoch 00054: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0115 - acc: 0.9961 - val_loss: 0.1988 - val_acc: 0.9648\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9956\n",
      "Epoch 00055: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0159 - acc: 0.9956 - val_loss: 0.1938 - val_acc: 0.9627\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9968\n",
      "Epoch 00056: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0109 - acc: 0.9968 - val_loss: 0.1850 - val_acc: 0.9679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 00057: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0137 - acc: 0.9957 - val_loss: 0.1902 - val_acc: 0.9646\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9984\n",
      "Epoch 00058: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0059 - acc: 0.9984 - val_loss: 0.2310 - val_acc: 0.9599\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9963\n",
      "Epoch 00059: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.1963 - val_acc: 0.9630\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 00060: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0108 - acc: 0.9969 - val_loss: 0.2542 - val_acc: 0.9592\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 00061: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 0.2351 - val_acc: 0.9602\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 00062: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0152 - acc: 0.9953 - val_loss: 0.2430 - val_acc: 0.9592\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 00063: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0103 - acc: 0.9970 - val_loss: 0.2159 - val_acc: 0.9637\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00064: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.2112 - val_acc: 0.9616\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9975\n",
      "Epoch 00065: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0081 - acc: 0.9975 - val_loss: 0.1775 - val_acc: 0.9674\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9970\n",
      "Epoch 00066: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0095 - acc: 0.9970 - val_loss: 0.2137 - val_acc: 0.9606\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 00067: val_loss did not improve from 0.15337\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0084 - acc: 0.9974 - val_loss: 0.1895 - val_acc: 0.9667\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2185 - acc: 0.9418\n",
      "Loss: 0.2185425144365891 Accuracy: 0.9418484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_ch_128_DO_025_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3873 - acc: 0.5572\n",
      "Loss: 1.387338678042094 Accuracy: 0.557217\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.1082 - acc: 0.6685\n",
      "Loss: 1.108153035212405 Accuracy: 0.6685358\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8661 - acc: 0.7551\n",
      "Loss: 0.8660826236040545 Accuracy: 0.7551402\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4726 - acc: 0.8744\n",
      "Loss: 0.4726447113825401 Accuracy: 0.87435097\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2595 - acc: 0.9308\n",
      "Loss: 0.2594976645949474 Accuracy: 0.93084115\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2192 - acc: 0.9472\n",
      "Loss: 0.219204667974834 Accuracy: 0.94724816\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2185 - acc: 0.9418\n",
      "Loss: 0.2185425144365891 Accuracy: 0.9418484\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO_025_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.7601 - acc: 0.5522\n",
      "Loss: 3.7600884397948393 Accuracy: 0.5522326\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.5307 - acc: 0.6768\n",
      "Loss: 2.530740685824417 Accuracy: 0.6768432\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.6731 - acc: 0.7601\n",
      "Loss: 1.6731315388733972 Accuracy: 0.7601246\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.7264 - acc: 0.8906\n",
      "Loss: 0.7263879891991739 Accuracy: 0.8905504\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3644 - acc: 0.9369\n",
      "Loss: 0.3644240273311657 Accuracy: 0.93686396\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2630 - acc: 0.9570\n",
      "Loss: 0.26296515500866025 Accuracy: 0.9570094\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2615 - acc: 0.9535\n",
      "Loss: 0.2615429059900725 Accuracy: 0.9534787\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
