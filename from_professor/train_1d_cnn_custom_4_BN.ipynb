{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN(conv_num=1):\n",
    "    init_channel = 256\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel/(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 4096000)           16384000  \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                65536016  \n",
      "=================================================================\n",
      "Total params: 81,922,576\n",
      "Trainable params: 73,730,064\n",
      "Non-trainable params: 8,192,512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1365248)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 1365248)           5460992   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                21843984  \n",
      "=================================================================\n",
      "Total params: 27,636,496\n",
      "Trainable params: 24,904,976\n",
      "Non-trainable params: 2,731,520\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 454912)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 454912)            1819648   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                7278608   \n",
      "=================================================================\n",
      "Total params: 9,758,736\n",
      "Trainable params: 8,847,376\n",
      "Non-trainable params: 911,360\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 75776)             303104    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,340,496\n",
      "Trainable params: 2,187,152\n",
      "Non-trainable params: 153,344\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,411,856\n",
      "Trainable params: 1,359,376\n",
      "Non-trainable params: 52,480\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,156,496\n",
      "Trainable params: 1,137,552\n",
      "Non-trainable params: 18,944\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 1344)              5376      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,058,256\n",
      "Trainable params: 1,053,136\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 448)               1792      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,061,136\n",
      "Trainable params: 1,057,680\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 64)             256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,075,536\n",
      "Trainable params: 1,072,592\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8993 - acc: 0.4995\n",
      "Epoch 00001: val_loss improved from inf to 1.60971, saving model to model/checkpoint/1D_CNN_custom_4_BN_4_conv_checkpoint/001-1.6097.hdf5\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 1.8993 - acc: 0.4995 - val_loss: 1.6097 - val_acc: 0.5148\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1407 - acc: 0.6917\n",
      "Epoch 00002: val_loss did not improve from 1.60971\n",
      "36805/36805 [==============================] - 409s 11ms/sample - loss: 1.1409 - acc: 0.6916 - val_loss: 1.6249 - val_acc: 0.5952\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7018 - acc: 0.7998\n",
      "Epoch 00003: val_loss improved from 1.60971 to 1.59144, saving model to model/checkpoint/1D_CNN_custom_4_BN_4_conv_checkpoint/003-1.5914.hdf5\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.7018 - acc: 0.7998 - val_loss: 1.5914 - val_acc: 0.6236\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8752\n",
      "Epoch 00004: val_loss improved from 1.59144 to 1.45315, saving model to model/checkpoint/1D_CNN_custom_4_BN_4_conv_checkpoint/004-1.4532.hdf5\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.4318 - acc: 0.8752 - val_loss: 1.4532 - val_acc: 0.6569\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.9216\n",
      "Epoch 00005: val_loss improved from 1.45315 to 1.30169, saving model to model/checkpoint/1D_CNN_custom_4_BN_4_conv_checkpoint/005-1.3017.hdf5\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.2873 - acc: 0.9216 - val_loss: 1.3017 - val_acc: 0.6846\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9417\n",
      "Epoch 00006: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.2203 - acc: 0.9416 - val_loss: 1.3236 - val_acc: 0.6935\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9440\n",
      "Epoch 00007: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.2133 - acc: 0.9439 - val_loss: 1.6508 - val_acc: 0.6567\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9658\n",
      "Epoch 00008: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.1391 - acc: 0.9658 - val_loss: 1.5615 - val_acc: 0.6625\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9693\n",
      "Epoch 00009: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.1271 - acc: 0.9693 - val_loss: 1.7216 - val_acc: 0.6527\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9715\n",
      "Epoch 00010: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.1175 - acc: 0.9714 - val_loss: 1.7139 - val_acc: 0.6615\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9602\n",
      "Epoch 00011: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.1568 - acc: 0.9601 - val_loss: 1.8264 - val_acc: 0.6515\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9670\n",
      "Epoch 00012: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 410s 11ms/sample - loss: 0.1343 - acc: 0.9669 - val_loss: 1.7731 - val_acc: 0.6723\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9730\n",
      "Epoch 00013: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.1084 - acc: 0.9730 - val_loss: 1.8786 - val_acc: 0.6501\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9820\n",
      "Epoch 00014: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0787 - acc: 0.9819 - val_loss: 1.8821 - val_acc: 0.6730\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9836\n",
      "Epoch 00015: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0720 - acc: 0.9835 - val_loss: 1.8414 - val_acc: 0.6744\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9826\n",
      "Epoch 00016: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0784 - acc: 0.9825 - val_loss: 1.9947 - val_acc: 0.6553\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9724\n",
      "Epoch 00017: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.1081 - acc: 0.9724 - val_loss: 1.9460 - val_acc: 0.6739\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9822\n",
      "Epoch 00018: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0748 - acc: 0.9821 - val_loss: 1.8001 - val_acc: 0.6865\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9831\n",
      "Epoch 00019: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0718 - acc: 0.9831 - val_loss: 1.8339 - val_acc: 0.6935\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9864\n",
      "Epoch 00020: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0611 - acc: 0.9864 - val_loss: 2.1214 - val_acc: 0.6669\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9840\n",
      "Epoch 00021: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0702 - acc: 0.9841 - val_loss: 2.0877 - val_acc: 0.6573\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9895\n",
      "Epoch 00022: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0528 - acc: 0.9894 - val_loss: 2.2457 - val_acc: 0.6576\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9806\n",
      "Epoch 00023: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0809 - acc: 0.9806 - val_loss: 2.1389 - val_acc: 0.6744\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9849\n",
      "Epoch 00024: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 411s 11ms/sample - loss: 0.0635 - acc: 0.9849 - val_loss: 2.1219 - val_acc: 0.6818\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9886\n",
      "Epoch 00025: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0534 - acc: 0.9885 - val_loss: 2.1668 - val_acc: 0.6676\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9847\n",
      "Epoch 00026: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0653 - acc: 0.9847 - val_loss: 2.2349 - val_acc: 0.6632\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9867\n",
      "Epoch 00027: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0617 - acc: 0.9867 - val_loss: 2.1799 - val_acc: 0.6855\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9886\n",
      "Epoch 00028: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0548 - acc: 0.9885 - val_loss: 2.1970 - val_acc: 0.6758\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9829\n",
      "Epoch 00029: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0749 - acc: 0.9829 - val_loss: 2.2778 - val_acc: 0.6746\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9875\n",
      "Epoch 00030: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0587 - acc: 0.9874 - val_loss: 2.3158 - val_acc: 0.6632\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9905\n",
      "Epoch 00031: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0450 - acc: 0.9905 - val_loss: 2.4509 - val_acc: 0.6578\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9881\n",
      "Epoch 00032: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0534 - acc: 0.9880 - val_loss: 2.2102 - val_acc: 0.6883\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9846\n",
      "Epoch 00033: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0667 - acc: 0.9846 - val_loss: 2.2875 - val_acc: 0.6727\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0537 - acc: 0.9892 - val_loss: 2.3078 - val_acc: 0.6648\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9907\n",
      "Epoch 00035: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0469 - acc: 0.9907 - val_loss: 2.4462 - val_acc: 0.6664\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9935\n",
      "Epoch 00036: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0371 - acc: 0.9935 - val_loss: 2.4325 - val_acc: 0.6692\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9915\n",
      "Epoch 00037: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0417 - acc: 0.9915 - val_loss: 2.3615 - val_acc: 0.6795\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9874\n",
      "Epoch 00038: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0565 - acc: 0.9873 - val_loss: 2.7021 - val_acc: 0.6539\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9866\n",
      "Epoch 00039: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0621 - acc: 0.9866 - val_loss: 2.4627 - val_acc: 0.6771\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9897\n",
      "Epoch 00040: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0494 - acc: 0.9897 - val_loss: 2.3010 - val_acc: 0.6904\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9943\n",
      "Epoch 00041: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0338 - acc: 0.9943 - val_loss: 3.1331 - val_acc: 0.6115\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9907\n",
      "Epoch 00042: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0462 - acc: 0.9907 - val_loss: 2.7117 - val_acc: 0.6513\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9856\n",
      "Epoch 00043: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0627 - acc: 0.9856 - val_loss: 2.8300 - val_acc: 0.6401\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9954\n",
      "Epoch 00044: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0281 - acc: 0.9954 - val_loss: 2.6336 - val_acc: 0.6643\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9918\n",
      "Epoch 00045: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0410 - acc: 0.9917 - val_loss: 2.4367 - val_acc: 0.6851\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9887\n",
      "Epoch 00046: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0513 - acc: 0.9887 - val_loss: 2.4138 - val_acc: 0.6804\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9936\n",
      "Epoch 00047: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0335 - acc: 0.9935 - val_loss: 2.7273 - val_acc: 0.6473\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9905\n",
      "Epoch 00048: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0495 - acc: 0.9905 - val_loss: 2.3777 - val_acc: 0.6886\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9938\n",
      "Epoch 00049: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0336 - acc: 0.9938 - val_loss: 2.4978 - val_acc: 0.6795\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9911\n",
      "Epoch 00050: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0412 - acc: 0.9911 - val_loss: 2.6201 - val_acc: 0.6636\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9898\n",
      "Epoch 00051: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0477 - acc: 0.9898 - val_loss: 2.7176 - val_acc: 0.6567\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9929\n",
      "Epoch 00052: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0368 - acc: 0.9929 - val_loss: 2.5145 - val_acc: 0.6809\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9957\n",
      "Epoch 00053: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0276 - acc: 0.9957 - val_loss: 2.5146 - val_acc: 0.6839\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9932\n",
      "Epoch 00054: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0391 - acc: 0.9931 - val_loss: 3.2609 - val_acc: 0.6226\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9890\n",
      "Epoch 00055: val_loss did not improve from 1.30169\n",
      "36805/36805 [==============================] - 412s 11ms/sample - loss: 0.0507 - acc: 0.9890 - val_loss: 2.5834 - val_acc: 0.6792\n",
      "\n",
      "1D_CNN_custom_4_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 1.4464 - acc: 0.6505\n",
      "Loss: 1.446361458140618 Accuracy: 0.6504673\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5798 - acc: 0.5279\n",
      "Epoch 00001: val_loss improved from inf to 1.46440, saving model to model/checkpoint/1D_CNN_custom_4_BN_5_conv_checkpoint/001-1.4644.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 1.5797 - acc: 0.5279 - val_loss: 1.4644 - val_acc: 0.5399\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0395 - acc: 0.6967\n",
      "Epoch 00002: val_loss improved from 1.46440 to 1.08663, saving model to model/checkpoint/1D_CNN_custom_4_BN_5_conv_checkpoint/002-1.0866.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 1.0395 - acc: 0.6967 - val_loss: 1.0866 - val_acc: 0.6783\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8213 - acc: 0.7586\n",
      "Epoch 00003: val_loss improved from 1.08663 to 1.00989, saving model to model/checkpoint/1D_CNN_custom_4_BN_5_conv_checkpoint/003-1.0099.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.8214 - acc: 0.7585 - val_loss: 1.0099 - val_acc: 0.7140\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6601 - acc: 0.8052\n",
      "Epoch 00004: val_loss improved from 1.00989 to 0.87272, saving model to model/checkpoint/1D_CNN_custom_4_BN_5_conv_checkpoint/004-0.8727.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.6604 - acc: 0.8052 - val_loss: 0.8727 - val_acc: 0.7536\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5429 - acc: 0.8371\n",
      "Epoch 00005: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.5430 - acc: 0.8371 - val_loss: 0.9256 - val_acc: 0.7363\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4376 - acc: 0.8702\n",
      "Epoch 00006: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.4377 - acc: 0.8701 - val_loss: 0.8937 - val_acc: 0.7508\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8967\n",
      "Epoch 00007: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.3494 - acc: 0.8967 - val_loss: 0.8913 - val_acc: 0.7682\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9209\n",
      "Epoch 00008: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2758 - acc: 0.9208 - val_loss: 0.9181 - val_acc: 0.7612\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2301 - acc: 0.9347\n",
      "Epoch 00009: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2303 - acc: 0.9347 - val_loss: 0.9060 - val_acc: 0.7678\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9496\n",
      "Epoch 00010: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1858 - acc: 0.9495 - val_loss: 0.8748 - val_acc: 0.7768\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9636\n",
      "Epoch 00011: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1527 - acc: 0.9636 - val_loss: 0.8767 - val_acc: 0.7664\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9729\n",
      "Epoch 00012: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1210 - acc: 0.9729 - val_loss: 0.9212 - val_acc: 0.7671\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9739\n",
      "Epoch 00013: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1143 - acc: 0.9739 - val_loss: 0.9733 - val_acc: 0.7643\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9828\n",
      "Epoch 00014: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0874 - acc: 0.9828 - val_loss: 0.9544 - val_acc: 0.7731\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9778\n",
      "Epoch 00015: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0966 - acc: 0.9777 - val_loss: 1.0300 - val_acc: 0.7598\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9783\n",
      "Epoch 00016: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0934 - acc: 0.9783 - val_loss: 1.0006 - val_acc: 0.7640\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9862\n",
      "Epoch 00017: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0703 - acc: 0.9862 - val_loss: 0.9677 - val_acc: 0.7759\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9863\n",
      "Epoch 00018: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0684 - acc: 0.9863 - val_loss: 1.1534 - val_acc: 0.7368\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9881\n",
      "Epoch 00019: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0595 - acc: 0.9880 - val_loss: 1.0364 - val_acc: 0.7710\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9842\n",
      "Epoch 00020: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0683 - acc: 0.9841 - val_loss: 1.3168 - val_acc: 0.7165\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9817\n",
      "Epoch 00021: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0787 - acc: 0.9816 - val_loss: 1.0672 - val_acc: 0.7661\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9872\n",
      "Epoch 00022: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0566 - acc: 0.9872 - val_loss: 1.0689 - val_acc: 0.7596\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9912\n",
      "Epoch 00023: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0435 - acc: 0.9912 - val_loss: 1.2762 - val_acc: 0.7326\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9943\n",
      "Epoch 00024: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0367 - acc: 0.9942 - val_loss: 1.6084 - val_acc: 0.6681\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9857\n",
      "Epoch 00025: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0615 - acc: 0.9856 - val_loss: 0.9864 - val_acc: 0.7883\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9899\n",
      "Epoch 00026: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0468 - acc: 0.9899 - val_loss: 1.1252 - val_acc: 0.7706\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9937\n",
      "Epoch 00027: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0340 - acc: 0.9937 - val_loss: 1.0606 - val_acc: 0.7810\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9910\n",
      "Epoch 00028: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0447 - acc: 0.9910 - val_loss: 1.1740 - val_acc: 0.7605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9883\n",
      "Epoch 00029: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0501 - acc: 0.9882 - val_loss: 1.2456 - val_acc: 0.7608\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9872\n",
      "Epoch 00030: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0524 - acc: 0.9871 - val_loss: 1.0883 - val_acc: 0.7845\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9933\n",
      "Epoch 00031: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0341 - acc: 0.9933 - val_loss: 0.9961 - val_acc: 0.7983\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9911\n",
      "Epoch 00032: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0409 - acc: 0.9911 - val_loss: 1.0819 - val_acc: 0.7780\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9937\n",
      "Epoch 00033: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0316 - acc: 0.9937 - val_loss: 1.1385 - val_acc: 0.7736\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9906\n",
      "Epoch 00034: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0423 - acc: 0.9906 - val_loss: 1.1286 - val_acc: 0.7720\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9961\n",
      "Epoch 00035: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0239 - acc: 0.9961 - val_loss: 1.2958 - val_acc: 0.7636\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9924\n",
      "Epoch 00036: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0362 - acc: 0.9924 - val_loss: 1.2812 - val_acc: 0.7382\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9895\n",
      "Epoch 00037: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0433 - acc: 0.9895 - val_loss: 1.1610 - val_acc: 0.7771\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9911\n",
      "Epoch 00038: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0400 - acc: 0.9911 - val_loss: 1.0630 - val_acc: 0.7850\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9976\n",
      "Epoch 00039: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0196 - acc: 0.9976 - val_loss: 1.2755 - val_acc: 0.7643\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9896\n",
      "Epoch 00040: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0425 - acc: 0.9896 - val_loss: 1.1548 - val_acc: 0.7841\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9927\n",
      "Epoch 00041: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0355 - acc: 0.9927 - val_loss: 1.3558 - val_acc: 0.7491\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9960\n",
      "Epoch 00042: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0229 - acc: 0.9959 - val_loss: 1.4252 - val_acc: 0.7559\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9932\n",
      "Epoch 00043: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0330 - acc: 0.9932 - val_loss: 1.1195 - val_acc: 0.7862\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9935\n",
      "Epoch 00044: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0291 - acc: 0.9935 - val_loss: 1.1438 - val_acc: 0.7766\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9980\n",
      "Epoch 00045: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0161 - acc: 0.9980 - val_loss: 1.1750 - val_acc: 0.7752\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9915\n",
      "Epoch 00046: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0367 - acc: 0.9915 - val_loss: 1.2015 - val_acc: 0.7780\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9934\n",
      "Epoch 00047: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0299 - acc: 0.9933 - val_loss: 1.4042 - val_acc: 0.7456\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9887\n",
      "Epoch 00048: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0450 - acc: 0.9887 - val_loss: 1.4043 - val_acc: 0.7449\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9933\n",
      "Epoch 00049: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0304 - acc: 0.9933 - val_loss: 1.4243 - val_acc: 0.7433\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9978\n",
      "Epoch 00050: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0163 - acc: 0.9978 - val_loss: 1.2381 - val_acc: 0.7757\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9979\n",
      "Epoch 00051: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0160 - acc: 0.9979 - val_loss: 1.4972 - val_acc: 0.7498\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9910\n",
      "Epoch 00052: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0393 - acc: 0.9910 - val_loss: 1.2120 - val_acc: 0.7822\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9919\n",
      "Epoch 00053: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0351 - acc: 0.9919 - val_loss: 1.3055 - val_acc: 0.7713\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9942\n",
      "Epoch 00054: val_loss did not improve from 0.87272\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.0281 - acc: 0.9942 - val_loss: 1.3342 - val_acc: 0.7687\n",
      "\n",
      "1D_CNN_custom_4_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 1.0379 - acc: 0.7065\n",
      "Loss: 1.037937605096296 Accuracy: 0.7065421\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5739 - acc: 0.5215\n",
      "Epoch 00001: val_loss improved from inf to 1.40725, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/001-1.4072.hdf5\n",
      "36805/36805 [==============================] - 425s 12ms/sample - loss: 1.5738 - acc: 0.5216 - val_loss: 1.4072 - val_acc: 0.5551\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9621 - acc: 0.7137\n",
      "Epoch 00002: val_loss improved from 1.40725 to 0.89239, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/002-0.8924.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.9621 - acc: 0.7137 - val_loss: 0.8924 - val_acc: 0.7342\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7763 - acc: 0.7733\n",
      "Epoch 00003: val_loss improved from 0.89239 to 0.73025, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/003-0.7302.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.7763 - acc: 0.7733 - val_loss: 0.7302 - val_acc: 0.7866\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6491 - acc: 0.8129\n",
      "Epoch 00004: val_loss did not improve from 0.73025\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.6492 - acc: 0.8128 - val_loss: 0.7650 - val_acc: 0.7834\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5575 - acc: 0.8395\n",
      "Epoch 00005: val_loss improved from 0.73025 to 0.69419, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/005-0.6942.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.5575 - acc: 0.8395 - val_loss: 0.6942 - val_acc: 0.8046\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4878 - acc: 0.8601\n",
      "Epoch 00006: val_loss improved from 0.69419 to 0.66358, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/006-0.6636.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.4878 - acc: 0.8601 - val_loss: 0.6636 - val_acc: 0.8095\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8772\n",
      "Epoch 00007: val_loss did not improve from 0.66358\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.4319 - acc: 0.8772 - val_loss: 0.6698 - val_acc: 0.8083\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.8886\n",
      "Epoch 00008: val_loss improved from 0.66358 to 0.60085, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/008-0.6008.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.3834 - acc: 0.8885 - val_loss: 0.6008 - val_acc: 0.8316\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3400 - acc: 0.9037\n",
      "Epoch 00009: val_loss improved from 0.60085 to 0.58061, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/009-0.5806.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.3400 - acc: 0.9037 - val_loss: 0.5806 - val_acc: 0.8248\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.9154\n",
      "Epoch 00010: val_loss improved from 0.58061 to 0.53169, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/010-0.5317.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.2992 - acc: 0.9153 - val_loss: 0.5317 - val_acc: 0.8563\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2703 - acc: 0.9226\n",
      "Epoch 00011: val_loss did not improve from 0.53169\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.2707 - acc: 0.9225 - val_loss: 0.5388 - val_acc: 0.8470\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2644 - acc: 0.9276\n",
      "Epoch 00012: val_loss improved from 0.53169 to 0.49789, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/012-0.4979.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.2645 - acc: 0.9276 - val_loss: 0.4979 - val_acc: 0.8572\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9431\n",
      "Epoch 00013: val_loss did not improve from 0.49789\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.2090 - acc: 0.9431 - val_loss: 0.5126 - val_acc: 0.8675\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9493\n",
      "Epoch 00014: val_loss did not improve from 0.49789\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.1885 - acc: 0.9493 - val_loss: 0.5044 - val_acc: 0.8689\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9547\n",
      "Epoch 00015: val_loss did not improve from 0.49789\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.1668 - acc: 0.9546 - val_loss: 0.6820 - val_acc: 0.8325\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9567\n",
      "Epoch 00016: val_loss did not improve from 0.49789\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.1567 - acc: 0.9566 - val_loss: 0.6393 - val_acc: 0.8367\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9648\n",
      "Epoch 00017: val_loss did not improve from 0.49789\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1367 - acc: 0.9647 - val_loss: 0.5532 - val_acc: 0.8579\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9610\n",
      "Epoch 00018: val_loss improved from 0.49789 to 0.48415, saving model to model/checkpoint/1D_CNN_custom_4_BN_6_conv_checkpoint/018-0.4841.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1414 - acc: 0.9610 - val_loss: 0.4841 - val_acc: 0.8770\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9753\n",
      "Epoch 00019: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1027 - acc: 0.9753 - val_loss: 0.5274 - val_acc: 0.8612\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9768\n",
      "Epoch 00020: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0974 - acc: 0.9768 - val_loss: 0.4940 - val_acc: 0.8782\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9818\n",
      "Epoch 00021: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0829 - acc: 0.9818 - val_loss: 0.5640 - val_acc: 0.8661\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9831\n",
      "Epoch 00022: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0762 - acc: 0.9831 - val_loss: 0.5718 - val_acc: 0.8612\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9818\n",
      "Epoch 00023: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0764 - acc: 0.9818 - val_loss: 0.5214 - val_acc: 0.8765\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9826\n",
      "Epoch 00024: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0749 - acc: 0.9826 - val_loss: 0.6030 - val_acc: 0.8647\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9873\n",
      "Epoch 00025: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0578 - acc: 0.9872 - val_loss: 0.5021 - val_acc: 0.8756\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9783\n",
      "Epoch 00026: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0875 - acc: 0.9783 - val_loss: 0.4946 - val_acc: 0.8814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9871\n",
      "Epoch 00027: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0587 - acc: 0.9871 - val_loss: 0.5244 - val_acc: 0.8728\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9887\n",
      "Epoch 00028: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0544 - acc: 0.9887 - val_loss: 0.4918 - val_acc: 0.8807\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9833\n",
      "Epoch 00029: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0695 - acc: 0.9833 - val_loss: 0.5214 - val_acc: 0.8737\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9943\n",
      "Epoch 00030: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0333 - acc: 0.9943 - val_loss: 0.6234 - val_acc: 0.8658\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9946\n",
      "Epoch 00031: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0339 - acc: 0.9946 - val_loss: 0.6246 - val_acc: 0.8593\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9896\n",
      "Epoch 00032: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0468 - acc: 0.9896 - val_loss: 0.6105 - val_acc: 0.8605\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9911\n",
      "Epoch 00033: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0434 - acc: 0.9910 - val_loss: 0.6669 - val_acc: 0.8502\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9854\n",
      "Epoch 00034: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0576 - acc: 0.9854 - val_loss: 0.5291 - val_acc: 0.8800\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9941\n",
      "Epoch 00035: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0335 - acc: 0.9941 - val_loss: 0.5761 - val_acc: 0.8742\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9953\n",
      "Epoch 00036: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0283 - acc: 0.9953 - val_loss: 0.5749 - val_acc: 0.8670\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9946\n",
      "Epoch 00037: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0301 - acc: 0.9946 - val_loss: 0.7328 - val_acc: 0.8241\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9837\n",
      "Epoch 00038: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0595 - acc: 0.9837 - val_loss: 0.6896 - val_acc: 0.8481\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9965\n",
      "Epoch 00039: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0251 - acc: 0.9965 - val_loss: 0.5549 - val_acc: 0.8833\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9962\n",
      "Epoch 00040: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0238 - acc: 0.9962 - val_loss: 0.6788 - val_acc: 0.8532\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9954\n",
      "Epoch 00041: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0264 - acc: 0.9954 - val_loss: 0.5708 - val_acc: 0.8777\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9919\n",
      "Epoch 00042: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0364 - acc: 0.9919 - val_loss: 0.6952 - val_acc: 0.8556\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9915\n",
      "Epoch 00043: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0372 - acc: 0.9915 - val_loss: 0.4893 - val_acc: 0.8982\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9955\n",
      "Epoch 00044: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0243 - acc: 0.9955 - val_loss: 0.6024 - val_acc: 0.8724\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9973\n",
      "Epoch 00045: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0195 - acc: 0.9973 - val_loss: 0.5713 - val_acc: 0.8791\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9939\n",
      "Epoch 00046: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0303 - acc: 0.9939 - val_loss: 0.5754 - val_acc: 0.8751\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9956\n",
      "Epoch 00047: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0234 - acc: 0.9956 - val_loss: 0.5502 - val_acc: 0.8826\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9913\n",
      "Epoch 00048: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0371 - acc: 0.9913 - val_loss: 0.5980 - val_acc: 0.8672\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9933\n",
      "Epoch 00049: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0296 - acc: 0.9933 - val_loss: 0.6016 - val_acc: 0.8765\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9934\n",
      "Epoch 00050: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0308 - acc: 0.9934 - val_loss: 0.5570 - val_acc: 0.8819\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9930\n",
      "Epoch 00051: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0330 - acc: 0.9930 - val_loss: 0.6615 - val_acc: 0.8668\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9843\n",
      "Epoch 00052: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0593 - acc: 0.9843 - val_loss: 0.5248 - val_acc: 0.8889\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9982\n",
      "Epoch 00053: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0152 - acc: 0.9982 - val_loss: 0.5520 - val_acc: 0.8852\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9985\n",
      "Epoch 00054: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0134 - acc: 0.9985 - val_loss: 0.5169 - val_acc: 0.8970\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9973\n",
      "Epoch 00055: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0176 - acc: 0.9973 - val_loss: 0.5350 - val_acc: 0.8919\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9912\n",
      "Epoch 00056: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0353 - acc: 0.9912 - val_loss: 0.5549 - val_acc: 0.8882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9956\n",
      "Epoch 00057: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0227 - acc: 0.9956 - val_loss: 0.5992 - val_acc: 0.8791\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9920\n",
      "Epoch 00058: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0320 - acc: 0.9920 - val_loss: 0.5251 - val_acc: 0.8919\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9979\n",
      "Epoch 00059: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0142 - acc: 0.9979 - val_loss: 0.6724 - val_acc: 0.8698\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9973\n",
      "Epoch 00060: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0168 - acc: 0.9973 - val_loss: 0.6007 - val_acc: 0.8845\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9950\n",
      "Epoch 00061: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0241 - acc: 0.9949 - val_loss: 0.7107 - val_acc: 0.8586\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9875\n",
      "Epoch 00062: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0499 - acc: 0.9874 - val_loss: 0.5591 - val_acc: 0.8812\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9937\n",
      "Epoch 00063: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0280 - acc: 0.9937 - val_loss: 0.5559 - val_acc: 0.8821\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9957\n",
      "Epoch 00064: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0213 - acc: 0.9957 - val_loss: 0.5411 - val_acc: 0.8910\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9987\n",
      "Epoch 00065: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0111 - acc: 0.9986 - val_loss: 0.5357 - val_acc: 0.8933\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9958\n",
      "Epoch 00066: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0201 - acc: 0.9958 - val_loss: 0.5828 - val_acc: 0.8826\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9896\n",
      "Epoch 00067: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0394 - acc: 0.9896 - val_loss: 0.5539 - val_acc: 0.8835\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9961\n",
      "Epoch 00068: val_loss did not improve from 0.48415\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0205 - acc: 0.9961 - val_loss: 0.5913 - val_acc: 0.8847\n",
      "\n",
      "1D_CNN_custom_4_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.5679 - acc: 0.8467\n",
      "Loss: 0.5678957583872081 Accuracy: 0.846729\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7549 - acc: 0.4621\n",
      "Epoch 00001: val_loss improved from inf to 1.44729, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/001-1.4473.hdf5\n",
      "36805/36805 [==============================] - 429s 12ms/sample - loss: 1.7548 - acc: 0.4622 - val_loss: 1.4473 - val_acc: 0.5588\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0092 - acc: 0.7050\n",
      "Epoch 00002: val_loss improved from 1.44729 to 1.05186, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/002-1.0519.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 1.0093 - acc: 0.7049 - val_loss: 1.0519 - val_acc: 0.7065\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7689 - acc: 0.7823\n",
      "Epoch 00003: val_loss improved from 1.05186 to 0.78826, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/003-0.7883.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.7690 - acc: 0.7822 - val_loss: 0.7883 - val_acc: 0.7673\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6262 - acc: 0.8237\n",
      "Epoch 00004: val_loss improved from 0.78826 to 0.52741, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/004-0.5274.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.6262 - acc: 0.8237 - val_loss: 0.5274 - val_acc: 0.8584\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.8548\n",
      "Epoch 00005: val_loss improved from 0.52741 to 0.50324, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/005-0.5032.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.5195 - acc: 0.8548 - val_loss: 0.5032 - val_acc: 0.8644\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4494 - acc: 0.8751\n",
      "Epoch 00006: val_loss improved from 0.50324 to 0.42724, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/006-0.4272.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.4494 - acc: 0.8751 - val_loss: 0.4272 - val_acc: 0.8849\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3947 - acc: 0.8901\n",
      "Epoch 00007: val_loss did not improve from 0.42724\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.3949 - acc: 0.8900 - val_loss: 0.4875 - val_acc: 0.8637\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3491 - acc: 0.9018\n",
      "Epoch 00008: val_loss improved from 0.42724 to 0.41545, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/008-0.4154.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.3492 - acc: 0.9018 - val_loss: 0.4154 - val_acc: 0.8817\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3112 - acc: 0.9123\n",
      "Epoch 00009: val_loss improved from 0.41545 to 0.39477, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/009-0.3948.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.3112 - acc: 0.9123 - val_loss: 0.3948 - val_acc: 0.8847\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9210\n",
      "Epoch 00010: val_loss did not improve from 0.39477\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2795 - acc: 0.9210 - val_loss: 0.4217 - val_acc: 0.8796\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.9300\n",
      "Epoch 00011: val_loss improved from 0.39477 to 0.32902, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/011-0.3290.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2536 - acc: 0.9300 - val_loss: 0.3290 - val_acc: 0.9117\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2369 - acc: 0.9331\n",
      "Epoch 00012: val_loss improved from 0.32902 to 0.32259, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/012-0.3226.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2370 - acc: 0.9331 - val_loss: 0.3226 - val_acc: 0.9080\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9398\n",
      "Epoch 00013: val_loss did not improve from 0.32259\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2137 - acc: 0.9398 - val_loss: 0.3350 - val_acc: 0.9087\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9472\n",
      "Epoch 00014: val_loss did not improve from 0.32259\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1922 - acc: 0.9472 - val_loss: 0.3781 - val_acc: 0.8870\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9479\n",
      "Epoch 00015: val_loss improved from 0.32259 to 0.31141, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/015-0.3114.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1823 - acc: 0.9479 - val_loss: 0.3114 - val_acc: 0.9115\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9590\n",
      "Epoch 00016: val_loss improved from 0.31141 to 0.27678, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/016-0.2768.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1532 - acc: 0.9590 - val_loss: 0.2768 - val_acc: 0.9217\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9619\n",
      "Epoch 00017: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1418 - acc: 0.9619 - val_loss: 0.2786 - val_acc: 0.9220\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9647\n",
      "Epoch 00018: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1310 - acc: 0.9647 - val_loss: 0.3343 - val_acc: 0.9050\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9674\n",
      "Epoch 00019: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1249 - acc: 0.9674 - val_loss: 0.3325 - val_acc: 0.9033\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9718\n",
      "Epoch 00020: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1085 - acc: 0.9719 - val_loss: 0.3039 - val_acc: 0.9131\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9758\n",
      "Epoch 00021: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0955 - acc: 0.9758 - val_loss: 0.3111 - val_acc: 0.9106\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9779\n",
      "Epoch 00022: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0898 - acc: 0.9779 - val_loss: 0.2807 - val_acc: 0.9227\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9765\n",
      "Epoch 00023: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0927 - acc: 0.9765 - val_loss: 0.3037 - val_acc: 0.9206\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9832\n",
      "Epoch 00024: val_loss did not improve from 0.27678\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0720 - acc: 0.9832 - val_loss: 0.2879 - val_acc: 0.9236\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9831\n",
      "Epoch 00025: val_loss improved from 0.27678 to 0.26800, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/025-0.2680.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0707 - acc: 0.9831 - val_loss: 0.2680 - val_acc: 0.9245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9852\n",
      "Epoch 00026: val_loss did not improve from 0.26800\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0631 - acc: 0.9851 - val_loss: 0.3804 - val_acc: 0.9022\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9764\n",
      "Epoch 00027: val_loss did not improve from 0.26800\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0892 - acc: 0.9764 - val_loss: 0.3096 - val_acc: 0.9192\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9827\n",
      "Epoch 00028: val_loss improved from 0.26800 to 0.25185, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/028-0.2518.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0698 - acc: 0.9827 - val_loss: 0.2518 - val_acc: 0.9285\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9849\n",
      "Epoch 00029: val_loss improved from 0.25185 to 0.24231, saving model to model/checkpoint/1D_CNN_custom_4_BN_7_conv_checkpoint/029-0.2423.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0648 - acc: 0.9849 - val_loss: 0.2423 - val_acc: 0.9327\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9911\n",
      "Epoch 00030: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0456 - acc: 0.9911 - val_loss: 0.2952 - val_acc: 0.9231\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9899\n",
      "Epoch 00031: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0474 - acc: 0.9899 - val_loss: 0.3444 - val_acc: 0.9038\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9921\n",
      "Epoch 00032: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0382 - acc: 0.9921 - val_loss: 0.3187 - val_acc: 0.9189\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9905\n",
      "Epoch 00033: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0448 - acc: 0.9904 - val_loss: 0.3102 - val_acc: 0.9196\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9824\n",
      "Epoch 00034: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0652 - acc: 0.9824 - val_loss: 0.2826 - val_acc: 0.9257\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9933\n",
      "Epoch 00035: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0343 - acc: 0.9933 - val_loss: 0.2545 - val_acc: 0.9336\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9942\n",
      "Epoch 00036: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0305 - acc: 0.9942 - val_loss: 0.3331 - val_acc: 0.9189\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9949\n",
      "Epoch 00037: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0288 - acc: 0.9949 - val_loss: 0.3224 - val_acc: 0.9201\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9919\n",
      "Epoch 00038: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0381 - acc: 0.9919 - val_loss: 0.3385 - val_acc: 0.9117\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9930\n",
      "Epoch 00039: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0337 - acc: 0.9930 - val_loss: 0.3032 - val_acc: 0.9250\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9909\n",
      "Epoch 00040: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0400 - acc: 0.9908 - val_loss: 0.2978 - val_acc: 0.9248\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9935\n",
      "Epoch 00041: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0326 - acc: 0.9934 - val_loss: 0.2662 - val_acc: 0.9341\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9889\n",
      "Epoch 00042: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0443 - acc: 0.9888 - val_loss: 0.2794 - val_acc: 0.9238\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9856\n",
      "Epoch 00043: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0572 - acc: 0.9855 - val_loss: 0.2710 - val_acc: 0.9299\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9940\n",
      "Epoch 00044: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0302 - acc: 0.9940 - val_loss: 0.2438 - val_acc: 0.9362\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9978\n",
      "Epoch 00045: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0174 - acc: 0.9978 - val_loss: 0.3025 - val_acc: 0.9290\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9969\n",
      "Epoch 00046: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0190 - acc: 0.9969 - val_loss: 0.2801 - val_acc: 0.9278\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9974\n",
      "Epoch 00047: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0172 - acc: 0.9974 - val_loss: 0.2497 - val_acc: 0.9366\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9961\n",
      "Epoch 00048: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0198 - acc: 0.9961 - val_loss: 0.3438 - val_acc: 0.9189\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9946\n",
      "Epoch 00049: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0266 - acc: 0.9945 - val_loss: 0.2883 - val_acc: 0.9273\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9873\n",
      "Epoch 00050: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0463 - acc: 0.9873 - val_loss: 0.2591 - val_acc: 0.9341\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9919\n",
      "Epoch 00051: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0339 - acc: 0.9919 - val_loss: 0.2505 - val_acc: 0.9394\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9986\n",
      "Epoch 00052: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0116 - acc: 0.9986 - val_loss: 0.2701 - val_acc: 0.9385\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9947\n",
      "Epoch 00053: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0244 - acc: 0.9946 - val_loss: 0.2727 - val_acc: 0.9364\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9935\n",
      "Epoch 00054: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0266 - acc: 0.9935 - val_loss: 0.2946 - val_acc: 0.9222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9959\n",
      "Epoch 00055: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0195 - acc: 0.9959 - val_loss: 0.2559 - val_acc: 0.9376\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9992\n",
      "Epoch 00056: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0097 - acc: 0.9992 - val_loss: 0.2585 - val_acc: 0.9378\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9969\n",
      "Epoch 00057: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0161 - acc: 0.9969 - val_loss: 0.3283 - val_acc: 0.9271\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9952\n",
      "Epoch 00058: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0215 - acc: 0.9952 - val_loss: 0.2846 - val_acc: 0.9350\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9932\n",
      "Epoch 00059: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0273 - acc: 0.9932 - val_loss: 0.2564 - val_acc: 0.9394\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9988\n",
      "Epoch 00060: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0104 - acc: 0.9988 - val_loss: 0.3495 - val_acc: 0.9266\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9966\n",
      "Epoch 00061: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0165 - acc: 0.9966 - val_loss: 0.3179 - val_acc: 0.9273\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9975\n",
      "Epoch 00062: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0143 - acc: 0.9975 - val_loss: 0.3174 - val_acc: 0.9285\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9961\n",
      "Epoch 00063: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0181 - acc: 0.9961 - val_loss: 0.6201 - val_acc: 0.8742\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9942\n",
      "Epoch 00064: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0230 - acc: 0.9942 - val_loss: 0.2858 - val_acc: 0.9364\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9936\n",
      "Epoch 00065: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0246 - acc: 0.9936 - val_loss: 0.2614 - val_acc: 0.9355\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9943\n",
      "Epoch 00066: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0233 - acc: 0.9943 - val_loss: 0.2656 - val_acc: 0.9406\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9991\n",
      "Epoch 00067: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0077 - acc: 0.9991 - val_loss: 0.2966 - val_acc: 0.9320\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9964\n",
      "Epoch 00068: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0168 - acc: 0.9964 - val_loss: 0.2845 - val_acc: 0.9345\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9936\n",
      "Epoch 00069: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0254 - acc: 0.9936 - val_loss: 0.3209 - val_acc: 0.9278\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9992\n",
      "Epoch 00070: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0077 - acc: 0.9991 - val_loss: 0.3006 - val_acc: 0.9320\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9937\n",
      "Epoch 00071: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0252 - acc: 0.9937 - val_loss: 0.2556 - val_acc: 0.9376\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9981\n",
      "Epoch 00072: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0115 - acc: 0.9981 - val_loss: 0.2578 - val_acc: 0.9408\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9983\n",
      "Epoch 00073: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0104 - acc: 0.9983 - val_loss: 0.2803 - val_acc: 0.9320\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9936\n",
      "Epoch 00074: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0265 - acc: 0.9935 - val_loss: 0.3024 - val_acc: 0.9306\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9964\n",
      "Epoch 00075: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0176 - acc: 0.9964 - val_loss: 0.2661 - val_acc: 0.9373\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9988\n",
      "Epoch 00076: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0078 - acc: 0.9988 - val_loss: 0.3316 - val_acc: 0.9248\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9945\n",
      "Epoch 00077: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0230 - acc: 0.9944 - val_loss: 0.2987 - val_acc: 0.9290\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9966\n",
      "Epoch 00078: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0150 - acc: 0.9966 - val_loss: 0.2522 - val_acc: 0.9406\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9958\n",
      "Epoch 00079: val_loss did not improve from 0.24231\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0173 - acc: 0.9958 - val_loss: 0.2665 - val_acc: 0.9411\n",
      "\n",
      "1D_CNN_custom_4_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.3207 - acc: 0.9047\n",
      "Loss: 0.3206527758919685 Accuracy: 0.9046729\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7211 - acc: 0.4814\n",
      "Epoch 00001: val_loss improved from inf to 1.51776, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/001-1.5178.hdf5\n",
      "36805/36805 [==============================] - 434s 12ms/sample - loss: 1.7211 - acc: 0.4814 - val_loss: 1.5178 - val_acc: 0.5332\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8988 - acc: 0.7449\n",
      "Epoch 00002: val_loss improved from 1.51776 to 0.88499, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/002-0.8850.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.8988 - acc: 0.7449 - val_loss: 0.8850 - val_acc: 0.7533\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6218 - acc: 0.8282\n",
      "Epoch 00003: val_loss improved from 0.88499 to 0.51583, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/003-0.5158.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.6219 - acc: 0.8281 - val_loss: 0.5158 - val_acc: 0.8530\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4798 - acc: 0.8676\n",
      "Epoch 00004: val_loss improved from 0.51583 to 0.43093, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/004-0.4309.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.4799 - acc: 0.8675 - val_loss: 0.4309 - val_acc: 0.8777\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3884 - acc: 0.8921\n",
      "Epoch 00005: val_loss improved from 0.43093 to 0.35678, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/005-0.3568.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3885 - acc: 0.8922 - val_loss: 0.3568 - val_acc: 0.9071\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3247 - acc: 0.9116\n",
      "Epoch 00006: val_loss improved from 0.35678 to 0.33373, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/006-0.3337.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3246 - acc: 0.9116 - val_loss: 0.3337 - val_acc: 0.9082\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9249\n",
      "Epoch 00007: val_loss improved from 0.33373 to 0.27707, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/007-0.2771.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2795 - acc: 0.9249 - val_loss: 0.2771 - val_acc: 0.9243\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2487 - acc: 0.9330\n",
      "Epoch 00008: val_loss improved from 0.27707 to 0.24912, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/008-0.2491.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2487 - acc: 0.9330 - val_loss: 0.2491 - val_acc: 0.9362\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9419\n",
      "Epoch 00009: val_loss did not improve from 0.24912\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2163 - acc: 0.9419 - val_loss: 0.2787 - val_acc: 0.9259\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9462\n",
      "Epoch 00010: val_loss improved from 0.24912 to 0.24177, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/010-0.2418.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2000 - acc: 0.9462 - val_loss: 0.2418 - val_acc: 0.9331\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9492\n",
      "Epoch 00011: val_loss did not improve from 0.24177\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1832 - acc: 0.9492 - val_loss: 0.2603 - val_acc: 0.9262\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9574\n",
      "Epoch 00012: val_loss improved from 0.24177 to 0.21718, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/012-0.2172.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1572 - acc: 0.9575 - val_loss: 0.2172 - val_acc: 0.9383\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9614\n",
      "Epoch 00013: val_loss improved from 0.21718 to 0.20351, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/013-0.2035.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1430 - acc: 0.9613 - val_loss: 0.2035 - val_acc: 0.9457\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9626\n",
      "Epoch 00014: val_loss did not improve from 0.20351\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1371 - acc: 0.9626 - val_loss: 0.2442 - val_acc: 0.9306\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9662\n",
      "Epoch 00015: val_loss did not improve from 0.20351\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1256 - acc: 0.9662 - val_loss: 0.2243 - val_acc: 0.9364\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9701\n",
      "Epoch 00016: val_loss improved from 0.20351 to 0.19097, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/016-0.1910.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1108 - acc: 0.9701 - val_loss: 0.1910 - val_acc: 0.9462\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9712\n",
      "Epoch 00017: val_loss did not improve from 0.19097\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1061 - acc: 0.9712 - val_loss: 0.2192 - val_acc: 0.9385\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9755\n",
      "Epoch 00018: val_loss did not improve from 0.19097\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0940 - acc: 0.9755 - val_loss: 0.1946 - val_acc: 0.9462\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9807\n",
      "Epoch 00019: val_loss did not improve from 0.19097\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0767 - acc: 0.9806 - val_loss: 0.2335 - val_acc: 0.9341\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9779\n",
      "Epoch 00020: val_loss improved from 0.19097 to 0.17978, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/020-0.1798.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0833 - acc: 0.9779 - val_loss: 0.1798 - val_acc: 0.9495\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9846\n",
      "Epoch 00021: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0632 - acc: 0.9846 - val_loss: 0.2144 - val_acc: 0.9404\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9798\n",
      "Epoch 00022: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0756 - acc: 0.9798 - val_loss: 0.2328 - val_acc: 0.9383\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9855\n",
      "Epoch 00023: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0597 - acc: 0.9855 - val_loss: 0.2134 - val_acc: 0.9408\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9886\n",
      "Epoch 00024: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0498 - acc: 0.9886 - val_loss: 0.1833 - val_acc: 0.9509\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9916\n",
      "Epoch 00025: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0408 - acc: 0.9916 - val_loss: 0.2230 - val_acc: 0.9364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9891\n",
      "Epoch 00026: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0464 - acc: 0.9891 - val_loss: 0.2135 - val_acc: 0.9446\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9865\n",
      "Epoch 00027: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0530 - acc: 0.9865 - val_loss: 0.1923 - val_acc: 0.9478\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9870\n",
      "Epoch 00028: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0513 - acc: 0.9869 - val_loss: 0.1884 - val_acc: 0.9464\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9897\n",
      "Epoch 00029: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0435 - acc: 0.9897 - val_loss: 0.1880 - val_acc: 0.9529\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9968\n",
      "Epoch 00030: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0227 - acc: 0.9968 - val_loss: 0.1930 - val_acc: 0.9481\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9941\n",
      "Epoch 00031: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0297 - acc: 0.9941 - val_loss: 0.1999 - val_acc: 0.9504\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9963\n",
      "Epoch 00032: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0234 - acc: 0.9962 - val_loss: 0.2919 - val_acc: 0.9262\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9852\n",
      "Epoch 00033: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0540 - acc: 0.9852 - val_loss: 0.1886 - val_acc: 0.9457\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9928\n",
      "Epoch 00034: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0314 - acc: 0.9928 - val_loss: 0.1868 - val_acc: 0.9518\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9976\n",
      "Epoch 00035: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0165 - acc: 0.9976 - val_loss: 0.1842 - val_acc: 0.9518\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9979\n",
      "Epoch 00036: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0153 - acc: 0.9979 - val_loss: 0.2042 - val_acc: 0.9492\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9912\n",
      "Epoch 00037: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0342 - acc: 0.9912 - val_loss: 0.2185 - val_acc: 0.9448\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9976\n",
      "Epoch 00038: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0151 - acc: 0.9976 - val_loss: 0.2675 - val_acc: 0.9364\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9973\n",
      "Epoch 00039: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0166 - acc: 0.9973 - val_loss: 0.2451 - val_acc: 0.9432\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9882\n",
      "Epoch 00040: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0407 - acc: 0.9882 - val_loss: 0.1951 - val_acc: 0.9502\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9980\n",
      "Epoch 00041: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0127 - acc: 0.9980 - val_loss: 0.1883 - val_acc: 0.9502\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9979\n",
      "Epoch 00042: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0132 - acc: 0.9979 - val_loss: 0.2495 - val_acc: 0.9399\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9975\n",
      "Epoch 00043: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0140 - acc: 0.9974 - val_loss: 0.2026 - val_acc: 0.9457\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9902\n",
      "Epoch 00044: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0373 - acc: 0.9902 - val_loss: 0.1980 - val_acc: 0.9481\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9939\n",
      "Epoch 00045: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0251 - acc: 0.9939 - val_loss: 0.1854 - val_acc: 0.9515\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9990\n",
      "Epoch 00046: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0093 - acc: 0.9990 - val_loss: 0.1898 - val_acc: 0.9536\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9991\n",
      "Epoch 00047: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0082 - acc: 0.9991 - val_loss: 0.2000 - val_acc: 0.9518\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9932\n",
      "Epoch 00048: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0260 - acc: 0.9932 - val_loss: 0.1911 - val_acc: 0.9546\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9971\n",
      "Epoch 00049: val_loss did not improve from 0.17978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0140 - acc: 0.9971 - val_loss: 0.2002 - val_acc: 0.9504\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9989\n",
      "Epoch 00050: val_loss improved from 0.17978 to 0.17421, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/050-0.1742.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0079 - acc: 0.9989 - val_loss: 0.1742 - val_acc: 0.9546\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9973\n",
      "Epoch 00051: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0139 - acc: 0.9972 - val_loss: 0.2545 - val_acc: 0.9390\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9922\n",
      "Epoch 00052: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0274 - acc: 0.9922 - val_loss: 0.2015 - val_acc: 0.9518\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9986\n",
      "Epoch 00053: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0086 - acc: 0.9986 - val_loss: 0.2146 - val_acc: 0.9518\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9985\n",
      "Epoch 00054: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0091 - acc: 0.9984 - val_loss: 0.2051 - val_acc: 0.9515\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9938\n",
      "Epoch 00055: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0232 - acc: 0.9938 - val_loss: 0.2411 - val_acc: 0.9415\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9993\n",
      "Epoch 00056: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0057 - acc: 0.9993 - val_loss: 0.1854 - val_acc: 0.9562\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9986\n",
      "Epoch 00057: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0080 - acc: 0.9986 - val_loss: 0.2572 - val_acc: 0.9392\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9980\n",
      "Epoch 00058: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0099 - acc: 0.9980 - val_loss: 0.2614 - val_acc: 0.9425\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9932\n",
      "Epoch 00059: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0252 - acc: 0.9931 - val_loss: 0.2137 - val_acc: 0.9515\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9958\n",
      "Epoch 00060: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0183 - acc: 0.9958 - val_loss: 0.1797 - val_acc: 0.9560\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9995\n",
      "Epoch 00061: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0049 - acc: 0.9995 - val_loss: 0.1755 - val_acc: 0.9592\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9992\n",
      "Epoch 00062: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0052 - acc: 0.9992 - val_loss: 0.1883 - val_acc: 0.9548\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9984\n",
      "Epoch 00063: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0090 - acc: 0.9984 - val_loss: 0.2110 - val_acc: 0.9511\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9979\n",
      "Epoch 00064: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0094 - acc: 0.9979 - val_loss: 0.1942 - val_acc: 0.9532\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9982\n",
      "Epoch 00065: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0094 - acc: 0.9982 - val_loss: 0.1991 - val_acc: 0.9525\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9973\n",
      "Epoch 00066: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0119 - acc: 0.9973 - val_loss: 0.1975 - val_acc: 0.9527\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9995\n",
      "Epoch 00067: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0042 - acc: 0.9995 - val_loss: 0.2195 - val_acc: 0.9511\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9966\n",
      "Epoch 00068: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0137 - acc: 0.9966 - val_loss: 0.1846 - val_acc: 0.9567\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9953\n",
      "Epoch 00069: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0181 - acc: 0.9953 - val_loss: 0.2024 - val_acc: 0.9548\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00070: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0035 - acc: 0.9996 - val_loss: 0.1881 - val_acc: 0.9585\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 00071: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.1912 - val_acc: 0.9571\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9934\n",
      "Epoch 00072: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0243 - acc: 0.9933 - val_loss: 0.2035 - val_acc: 0.9539\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9959\n",
      "Epoch 00073: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0150 - acc: 0.9959 - val_loss: 0.1801 - val_acc: 0.9585\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9998\n",
      "Epoch 00074: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0033 - acc: 0.9998 - val_loss: 0.1875 - val_acc: 0.9578\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9990\n",
      "Epoch 00075: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0055 - acc: 0.9989 - val_loss: 0.2551 - val_acc: 0.9432\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9934\n",
      "Epoch 00076: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0218 - acc: 0.9934 - val_loss: 0.1815 - val_acc: 0.9560\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9994\n",
      "Epoch 00077: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0041 - acc: 0.9994 - val_loss: 0.1872 - val_acc: 0.9546\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9994\n",
      "Epoch 00078: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0045 - acc: 0.9994 - val_loss: 0.2419 - val_acc: 0.9499\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9971\n",
      "Epoch 00079: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0110 - acc: 0.9971 - val_loss: 0.1949 - val_acc: 0.9567\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9979\n",
      "Epoch 00080: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0092 - acc: 0.9979 - val_loss: 0.1824 - val_acc: 0.9599\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9997\n",
      "Epoch 00081: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0033 - acc: 0.9997 - val_loss: 0.1915 - val_acc: 0.9590\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 00082: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0030 - acc: 0.9995 - val_loss: 0.2092 - val_acc: 0.9532\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9937\n",
      "Epoch 00083: val_loss did not improve from 0.17421\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0222 - acc: 0.9937 - val_loss: 0.1830 - val_acc: 0.9555\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 00084: val_loss improved from 0.17421 to 0.17155, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/084-0.1716.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.1716 - val_acc: 0.9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0050 - acc: 0.9993 - val_loss: 0.1946 - val_acc: 0.9574\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9919\n",
      "Epoch 00086: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0264 - acc: 0.9919 - val_loss: 0.2079 - val_acc: 0.9534\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 00087: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0050 - acc: 0.9993 - val_loss: 0.1866 - val_acc: 0.9571\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9995\n",
      "Epoch 00088: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0031 - acc: 0.9995 - val_loss: 0.1833 - val_acc: 0.9616\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9984\n",
      "Epoch 00089: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0074 - acc: 0.9984 - val_loss: 0.1797 - val_acc: 0.9611\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9995\n",
      "Epoch 00090: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1909 - val_acc: 0.9585\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00091: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.2242 - val_acc: 0.9534\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9970\n",
      "Epoch 00092: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 0.2946 - val_acc: 0.9320\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9962\n",
      "Epoch 00093: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0139 - acc: 0.9963 - val_loss: 0.1861 - val_acc: 0.9604\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9995\n",
      "Epoch 00094: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0040 - acc: 0.9994 - val_loss: 0.2023 - val_acc: 0.9553\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9952\n",
      "Epoch 00095: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0175 - acc: 0.9952 - val_loss: 0.1779 - val_acc: 0.9595\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 00096: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0029 - acc: 0.9995 - val_loss: 0.1869 - val_acc: 0.9595\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 00097: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0079 - acc: 0.9979 - val_loss: 0.1819 - val_acc: 0.9588\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 00098: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.2095 - val_acc: 0.9567\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9958\n",
      "Epoch 00099: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0150 - acc: 0.9958 - val_loss: 0.1898 - val_acc: 0.9555\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9964\n",
      "Epoch 00100: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0124 - acc: 0.9964 - val_loss: 0.2011 - val_acc: 0.9562\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 00101: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0023 - acc: 0.9998 - val_loss: 0.1928 - val_acc: 0.9553\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9979\n",
      "Epoch 00102: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0088 - acc: 0.9979 - val_loss: 0.1827 - val_acc: 0.9576\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9990\n",
      "Epoch 00103: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0046 - acc: 0.9990 - val_loss: 0.1906 - val_acc: 0.9562\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9954\n",
      "Epoch 00104: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0152 - acc: 0.9954 - val_loss: 0.1941 - val_acc: 0.9595\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 00105: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0030 - acc: 0.9995 - val_loss: 0.1752 - val_acc: 0.9604\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9996\n",
      "Epoch 00106: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0030 - acc: 0.9996 - val_loss: 0.1770 - val_acc: 0.9590\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9986\n",
      "Epoch 00107: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0060 - acc: 0.9986 - val_loss: 0.1891 - val_acc: 0.9597\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 00108: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1985 - val_acc: 0.9595\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9989\n",
      "Epoch 00109: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0053 - acc: 0.9989 - val_loss: 0.4767 - val_acc: 0.9031\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 00110: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0202 - acc: 0.9936 - val_loss: 0.2245 - val_acc: 0.9520\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 00111: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0135 - acc: 0.9960 - val_loss: 0.1719 - val_acc: 0.9597\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9987\n",
      "Epoch 00112: val_loss did not improve from 0.17155\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0062 - acc: 0.9987 - val_loss: 0.1804 - val_acc: 0.9609\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 00113: val_loss improved from 0.17155 to 0.16986, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/113-0.1699.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0040 - acc: 0.9993 - val_loss: 0.1699 - val_acc: 0.9627\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00114: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1867 - val_acc: 0.9613\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 00115: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0021 - acc: 0.9998 - val_loss: 0.2015 - val_acc: 0.9569\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 00116: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0030 - acc: 0.9995 - val_loss: 0.2489 - val_acc: 0.9467\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9986\n",
      "Epoch 00117: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0055 - acc: 0.9986 - val_loss: 0.2246 - val_acc: 0.9502\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9963\n",
      "Epoch 00118: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0128 - acc: 0.9963 - val_loss: 0.2320 - val_acc: 0.9532\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9961\n",
      "Epoch 00119: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0128 - acc: 0.9961 - val_loss: 0.1777 - val_acc: 0.9581\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9995\n",
      "Epoch 00120: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0029 - acc: 0.9995 - val_loss: 0.1756 - val_acc: 0.9613\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 00121: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1852 - val_acc: 0.9611\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 00122: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1922 - val_acc: 0.9590\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9964\n",
      "Epoch 00123: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0129 - acc: 0.9964 - val_loss: 0.2148 - val_acc: 0.9548\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9978\n",
      "Epoch 00124: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0089 - acc: 0.9977 - val_loss: 0.1989 - val_acc: 0.9571\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9967\n",
      "Epoch 00125: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0125 - acc: 0.9967 - val_loss: 0.2111 - val_acc: 0.9557\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 00126: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0029 - acc: 0.9994 - val_loss: 0.1964 - val_acc: 0.9595\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00127: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1899 - val_acc: 0.9588\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00128: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.2036 - val_acc: 0.9611\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 00129: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0059 - acc: 0.9985 - val_loss: 0.2192 - val_acc: 0.9548\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 00130: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0090 - acc: 0.9975 - val_loss: 0.2143 - val_acc: 0.9541\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 00131: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0095 - acc: 0.9973 - val_loss: 0.2283 - val_acc: 0.9532\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9984\n",
      "Epoch 00132: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0065 - acc: 0.9984 - val_loss: 0.1794 - val_acc: 0.9618\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9999\n",
      "Epoch 00133: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0015 - acc: 0.9999 - val_loss: 0.2058 - val_acc: 0.9585\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 00134: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.2105 - val_acc: 0.9553\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 00135: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0120 - acc: 0.9966 - val_loss: 0.2098 - val_acc: 0.9560\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9990\n",
      "Epoch 00136: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0048 - acc: 0.9990 - val_loss: 0.1774 - val_acc: 0.9606\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 00137: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0033 - acc: 0.9993 - val_loss: 0.1716 - val_acc: 0.9618\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9994\n",
      "Epoch 00138: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0030 - acc: 0.9994 - val_loss: 0.1820 - val_acc: 0.9604\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9990\n",
      "Epoch 00139: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0046 - acc: 0.9990 - val_loss: 0.2067 - val_acc: 0.9564\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9988\n",
      "Epoch 00140: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0046 - acc: 0.9988 - val_loss: 0.1978 - val_acc: 0.9562\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00141: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0038 - acc: 0.9992 - val_loss: 0.2477 - val_acc: 0.9474\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9995\n",
      "Epoch 00142: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0029 - acc: 0.9995 - val_loss: 0.1834 - val_acc: 0.9574\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9967\n",
      "Epoch 00143: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0123 - acc: 0.9967 - val_loss: 0.2012 - val_acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00144: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0018 - acc: 0.9998 - val_loss: 0.1968 - val_acc: 0.9560\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 00145: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1958 - val_acc: 0.9548\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9966\n",
      "Epoch 00146: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0120 - acc: 0.9966 - val_loss: 0.1868 - val_acc: 0.9583\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 00147: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0074 - acc: 0.9980 - val_loss: 0.1893 - val_acc: 0.9609\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00148: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0019 - acc: 0.9997 - val_loss: 0.1806 - val_acc: 0.9613\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 00149: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0015 - acc: 0.9999 - val_loss: 0.1837 - val_acc: 0.9618\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9975\n",
      "Epoch 00150: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0094 - acc: 0.9974 - val_loss: 0.1807 - val_acc: 0.9581\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9977\n",
      "Epoch 00151: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0095 - acc: 0.9977 - val_loss: 0.2008 - val_acc: 0.9576\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 00152: val_loss did not improve from 0.16986\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0013 - acc: 0.9999 - val_loss: 0.1848 - val_acc: 0.9646\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00153: val_loss improved from 0.16986 to 0.16796, saving model to model/checkpoint/1D_CNN_custom_4_BN_8_conv_checkpoint/153-0.1680.hdf5\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1680 - val_acc: 0.9651\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00154: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.2111 - val_acc: 0.9592\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9986\n",
      "Epoch 00155: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0058 - acc: 0.9986 - val_loss: 0.2151 - val_acc: 0.9590\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 00156: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1997 - val_acc: 0.9583\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 00157: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0060 - acc: 0.9984 - val_loss: 0.1782 - val_acc: 0.9620\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 00158: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0051 - acc: 0.9987 - val_loss: 0.2070 - val_acc: 0.9590\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 00159: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0036 - acc: 0.9993 - val_loss: 0.1818 - val_acc: 0.9632\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00160: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1740 - val_acc: 0.9630\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00161: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0039 - acc: 0.9990 - val_loss: 0.2656 - val_acc: 0.9420\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9956\n",
      "Epoch 00162: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0143 - acc: 0.9956 - val_loss: 0.1978 - val_acc: 0.9604\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9979\n",
      "Epoch 00163: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0079 - acc: 0.9979 - val_loss: 0.1944 - val_acc: 0.9599\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00164: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.1900 - val_acc: 0.9609\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 00165: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1945 - val_acc: 0.9597\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00166: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.2165 - val_acc: 0.9581\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00167: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 0.2564 - val_acc: 0.9539\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9978\n",
      "Epoch 00168: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0073 - acc: 0.9978 - val_loss: 0.2991 - val_acc: 0.9462\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00169: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1988 - val_acc: 0.9546\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9956\n",
      "Epoch 00170: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0147 - acc: 0.9956 - val_loss: 0.1911 - val_acc: 0.9609\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00171: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.1808 - val_acc: 0.9613\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.7025e-04 - acc: 0.9999\n",
      "Epoch 00172: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 9.7031e-04 - acc: 0.9999 - val_loss: 0.1798 - val_acc: 0.9620\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9998\n",
      "Epoch 00173: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0016 - acc: 0.9998 - val_loss: 0.2002 - val_acc: 0.9620\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 00174: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0020 - acc: 0.9997 - val_loss: 0.2189 - val_acc: 0.9574\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9958\n",
      "Epoch 00175: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0145 - acc: 0.9958 - val_loss: 0.1874 - val_acc: 0.9609\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00176: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 0.1786 - val_acc: 0.9623\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 00177: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1816 - val_acc: 0.9634\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 00178: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0015 - acc: 0.9997 - val_loss: 0.2012 - val_acc: 0.9578\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 00179: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0091 - acc: 0.9971 - val_loss: 0.1923 - val_acc: 0.9606\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00180: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1808 - val_acc: 0.9637\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00181: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.2227 - val_acc: 0.9585\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00182: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1922 - val_acc: 0.9644\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9998\n",
      "Epoch 00183: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0015 - acc: 0.9997 - val_loss: 0.2338 - val_acc: 0.9553\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9964\n",
      "Epoch 00184: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0131 - acc: 0.9963 - val_loss: 0.1865 - val_acc: 0.9609\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9979\n",
      "Epoch 00185: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0078 - acc: 0.9979 - val_loss: 0.1974 - val_acc: 0.9609\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00186: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1850 - val_acc: 0.9630\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.5825e-04 - acc: 0.9999\n",
      "Epoch 00187: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 8.7698e-04 - acc: 0.9999 - val_loss: 0.2000 - val_acc: 0.9630\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9973\n",
      "Epoch 00188: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0096 - acc: 0.9973 - val_loss: 0.2107 - val_acc: 0.9581\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9976\n",
      "Epoch 00189: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0087 - acc: 0.9976 - val_loss: 0.1990 - val_acc: 0.9618\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 00190: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0079 - acc: 0.9977 - val_loss: 0.2172 - val_acc: 0.9604\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9985\n",
      "Epoch 00191: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0059 - acc: 0.9985 - val_loss: 0.1838 - val_acc: 0.9625\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 00192: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.2102 - val_acc: 0.9588\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9966\n",
      "Epoch 00193: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0124 - acc: 0.9966 - val_loss: 0.1886 - val_acc: 0.9627\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 00194: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0014 - acc: 0.9999 - val_loss: 0.1826 - val_acc: 0.9637\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 00195: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1960 - val_acc: 0.9653\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 00196: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0043 - acc: 0.9988 - val_loss: 0.1932 - val_acc: 0.9630\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9988\n",
      "Epoch 00197: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 0.2324 - val_acc: 0.9567\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9982\n",
      "Epoch 00198: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0073 - acc: 0.9982 - val_loss: 0.1991 - val_acc: 0.9616\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9967\n",
      "Epoch 00199: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0125 - acc: 0.9967 - val_loss: 0.1869 - val_acc: 0.9630\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00200: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1827 - val_acc: 0.9623\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9999\n",
      "Epoch 00201: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0011 - acc: 0.9999 - val_loss: 0.1856 - val_acc: 0.9637\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 00202: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0061 - acc: 0.9985 - val_loss: 0.2072 - val_acc: 0.9616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00203: val_loss did not improve from 0.16796\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1911 - val_acc: 0.9620\n",
      "\n",
      "1D_CNN_custom_4_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2162 - acc: 0.9522\n",
      "Loss: 0.21618979500949012 Accuracy: 0.9522326\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4219 - acc: 0.5647\n",
      "Epoch 00001: val_loss improved from inf to 1.25034, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/001-1.2503.hdf5\n",
      "36805/36805 [==============================] - 440s 12ms/sample - loss: 1.4218 - acc: 0.5647 - val_loss: 1.2503 - val_acc: 0.6150\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6380 - acc: 0.8170\n",
      "Epoch 00002: val_loss improved from 1.25034 to 0.50821, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/002-0.5082.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.6379 - acc: 0.8170 - val_loss: 0.5082 - val_acc: 0.8656\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4419 - acc: 0.8739\n",
      "Epoch 00003: val_loss improved from 0.50821 to 0.49754, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/003-0.4975.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.4420 - acc: 0.8739 - val_loss: 0.4975 - val_acc: 0.8588\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3514 - acc: 0.8999\n",
      "Epoch 00004: val_loss improved from 0.49754 to 0.34388, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/004-0.3439.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.3515 - acc: 0.8999 - val_loss: 0.3439 - val_acc: 0.9012\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9195\n",
      "Epoch 00005: val_loss improved from 0.34388 to 0.28055, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/005-0.2806.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2878 - acc: 0.9194 - val_loss: 0.2806 - val_acc: 0.9192\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9315\n",
      "Epoch 00006: val_loss improved from 0.28055 to 0.23537, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/006-0.2354.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2446 - acc: 0.9315 - val_loss: 0.2354 - val_acc: 0.9336\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9398\n",
      "Epoch 00007: val_loss did not improve from 0.23537\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2117 - acc: 0.9397 - val_loss: 0.2691 - val_acc: 0.9199\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9450\n",
      "Epoch 00008: val_loss improved from 0.23537 to 0.19253, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/008-0.1925.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1933 - acc: 0.9450 - val_loss: 0.1925 - val_acc: 0.9443\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9522\n",
      "Epoch 00009: val_loss did not improve from 0.19253\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1703 - acc: 0.9522 - val_loss: 0.2371 - val_acc: 0.9276\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9590\n",
      "Epoch 00010: val_loss did not improve from 0.19253\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1477 - acc: 0.9590 - val_loss: 0.1961 - val_acc: 0.9439\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9643\n",
      "Epoch 00011: val_loss improved from 0.19253 to 0.18157, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/011-0.1816.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1299 - acc: 0.9643 - val_loss: 0.1816 - val_acc: 0.9488\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9656\n",
      "Epoch 00012: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1257 - acc: 0.9656 - val_loss: 0.3337 - val_acc: 0.8952\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9651\n",
      "Epoch 00013: val_loss improved from 0.18157 to 0.17554, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/013-0.1755.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1218 - acc: 0.9651 - val_loss: 0.1755 - val_acc: 0.9488\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9746\n",
      "Epoch 00014: val_loss did not improve from 0.17554\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0941 - acc: 0.9745 - val_loss: 0.1904 - val_acc: 0.9474\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9704\n",
      "Epoch 00015: val_loss improved from 0.17554 to 0.16580, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/015-0.1658.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1040 - acc: 0.9704 - val_loss: 0.1658 - val_acc: 0.9520\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9794\n",
      "Epoch 00016: val_loss did not improve from 0.16580\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0794 - acc: 0.9794 - val_loss: 0.1954 - val_acc: 0.9432\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9773\n",
      "Epoch 00017: val_loss did not improve from 0.16580\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0845 - acc: 0.9773 - val_loss: 0.1888 - val_acc: 0.9441\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9812\n",
      "Epoch 00018: val_loss did not improve from 0.16580\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0714 - acc: 0.9812 - val_loss: 0.1732 - val_acc: 0.9488\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9859\n",
      "Epoch 00019: val_loss did not improve from 0.16580\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0584 - acc: 0.9859 - val_loss: 0.1873 - val_acc: 0.9411\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9843\n",
      "Epoch 00020: val_loss improved from 0.16580 to 0.15492, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/020-0.1549.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0609 - acc: 0.9843 - val_loss: 0.1549 - val_acc: 0.9569\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9889\n",
      "Epoch 00021: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0464 - acc: 0.9889 - val_loss: 0.1686 - val_acc: 0.9492\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9904\n",
      "Epoch 00022: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0407 - acc: 0.9904 - val_loss: 0.1844 - val_acc: 0.9474\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9845\n",
      "Epoch 00023: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0565 - acc: 0.9845 - val_loss: 0.1849 - val_acc: 0.9474\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9877\n",
      "Epoch 00024: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0487 - acc: 0.9877 - val_loss: 0.1777 - val_acc: 0.9527\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9940\n",
      "Epoch 00025: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0292 - acc: 0.9940 - val_loss: 0.1594 - val_acc: 0.9578\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9934\n",
      "Epoch 00026: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0307 - acc: 0.9934 - val_loss: 0.1588 - val_acc: 0.9578\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9948\n",
      "Epoch 00027: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0256 - acc: 0.9948 - val_loss: 0.1804 - val_acc: 0.9506\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9934\n",
      "Epoch 00028: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0296 - acc: 0.9934 - val_loss: 0.1589 - val_acc: 0.9532\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9960\n",
      "Epoch 00029: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0207 - acc: 0.9960 - val_loss: 0.2044 - val_acc: 0.9455\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9952\n",
      "Epoch 00030: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0229 - acc: 0.9952 - val_loss: 0.1866 - val_acc: 0.9490\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9961\n",
      "Epoch 00031: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0206 - acc: 0.9961 - val_loss: 0.1975 - val_acc: 0.9513\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9934\n",
      "Epoch 00032: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0263 - acc: 0.9934 - val_loss: 0.1918 - val_acc: 0.9527\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9974\n",
      "Epoch 00033: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0150 - acc: 0.9974 - val_loss: 0.1794 - val_acc: 0.9515\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9971\n",
      "Epoch 00034: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0155 - acc: 0.9971 - val_loss: 0.1992 - val_acc: 0.9513\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9968\n",
      "Epoch 00035: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0158 - acc: 0.9968 - val_loss: 0.1848 - val_acc: 0.9488\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9957\n",
      "Epoch 00036: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0187 - acc: 0.9957 - val_loss: 0.1750 - val_acc: 0.9527\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9906\n",
      "Epoch 00037: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0326 - acc: 0.9906 - val_loss: 0.1556 - val_acc: 0.9597\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9983\n",
      "Epoch 00038: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0108 - acc: 0.9983 - val_loss: 0.1696 - val_acc: 0.9602\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9982\n",
      "Epoch 00039: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0098 - acc: 0.9982 - val_loss: 0.1693 - val_acc: 0.9590\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9951\n",
      "Epoch 00040: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0198 - acc: 0.9951 - val_loss: 0.1567 - val_acc: 0.9588\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9989\n",
      "Epoch 00041: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0079 - acc: 0.9989 - val_loss: 0.1573 - val_acc: 0.9616\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9983\n",
      "Epoch 00042: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0092 - acc: 0.9983 - val_loss: 0.1861 - val_acc: 0.9529\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9965\n",
      "Epoch 00043: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0156 - acc: 0.9964 - val_loss: 0.2194 - val_acc: 0.9429\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9897\n",
      "Epoch 00044: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0348 - acc: 0.9897 - val_loss: 0.1638 - val_acc: 0.9560\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9965\n",
      "Epoch 00045: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0149 - acc: 0.9965 - val_loss: 0.1640 - val_acc: 0.9578\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9968\n",
      "Epoch 00046: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0142 - acc: 0.9967 - val_loss: 0.1685 - val_acc: 0.9576\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9933\n",
      "Epoch 00047: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0243 - acc: 0.9933 - val_loss: 0.1995 - val_acc: 0.9455\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9954\n",
      "Epoch 00048: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0177 - acc: 0.9954 - val_loss: 0.1563 - val_acc: 0.9590\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9993\n",
      "Epoch 00049: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0057 - acc: 0.9992 - val_loss: 0.1638 - val_acc: 0.9571\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9940\n",
      "Epoch 00050: val_loss did not improve from 0.15492\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0225 - acc: 0.9940 - val_loss: 0.1552 - val_acc: 0.9595\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9980\n",
      "Epoch 00051: val_loss improved from 0.15492 to 0.14978, saving model to model/checkpoint/1D_CNN_custom_4_BN_9_conv_checkpoint/051-0.1498.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0093 - acc: 0.9980 - val_loss: 0.1498 - val_acc: 0.9632\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9996\n",
      "Epoch 00052: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0042 - acc: 0.9996 - val_loss: 0.1702 - val_acc: 0.9592\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9950\n",
      "Epoch 00053: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0198 - acc: 0.9949 - val_loss: 0.1740 - val_acc: 0.9583\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9958\n",
      "Epoch 00054: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0153 - acc: 0.9958 - val_loss: 0.1579 - val_acc: 0.9590\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9993\n",
      "Epoch 00055: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0048 - acc: 0.9993 - val_loss: 0.1595 - val_acc: 0.9599\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9985\n",
      "Epoch 00056: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0075 - acc: 0.9985 - val_loss: 0.1794 - val_acc: 0.9571\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9938\n",
      "Epoch 00057: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0211 - acc: 0.9938 - val_loss: 0.1887 - val_acc: 0.9560\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 00058: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0074 - acc: 0.9986 - val_loss: 0.1505 - val_acc: 0.9618\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9994\n",
      "Epoch 00059: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0038 - acc: 0.9994 - val_loss: 0.1874 - val_acc: 0.9520\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9986\n",
      "Epoch 00060: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0070 - acc: 0.9986 - val_loss: 0.1936 - val_acc: 0.9525\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9941\n",
      "Epoch 00061: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0205 - acc: 0.9941 - val_loss: 0.1634 - val_acc: 0.9592\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9981\n",
      "Epoch 00062: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0085 - acc: 0.9981 - val_loss: 0.1573 - val_acc: 0.9578\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9989\n",
      "Epoch 00063: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0062 - acc: 0.9989 - val_loss: 0.1624 - val_acc: 0.9604\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 00064: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0080 - acc: 0.9980 - val_loss: 0.1924 - val_acc: 0.9564\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9947\n",
      "Epoch 00065: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0178 - acc: 0.9947 - val_loss: 0.1679 - val_acc: 0.9616\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9949\n",
      "Epoch 00066: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0174 - acc: 0.9949 - val_loss: 0.1594 - val_acc: 0.9616\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 00067: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0112 - acc: 0.9973 - val_loss: 0.1547 - val_acc: 0.9585\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9978\n",
      "Epoch 00068: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0094 - acc: 0.9978 - val_loss: 0.1533 - val_acc: 0.9627\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00069: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.1549 - val_acc: 0.9630\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 00070: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0056 - acc: 0.9989 - val_loss: 0.1503 - val_acc: 0.9618\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 00071: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0042 - acc: 0.9992 - val_loss: 0.2831 - val_acc: 0.9364\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9982\n",
      "Epoch 00072: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0072 - acc: 0.9982 - val_loss: 0.2216 - val_acc: 0.9474\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9948\n",
      "Epoch 00073: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0178 - acc: 0.9948 - val_loss: 0.1614 - val_acc: 0.9613\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 00074: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0031 - acc: 0.9996 - val_loss: 0.1862 - val_acc: 0.9574\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9942\n",
      "Epoch 00075: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0198 - acc: 0.9942 - val_loss: 0.1658 - val_acc: 0.9590\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9970\n",
      "Epoch 00076: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0126 - acc: 0.9970 - val_loss: 0.1639 - val_acc: 0.9616\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9977\n",
      "Epoch 00077: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0090 - acc: 0.9977 - val_loss: 0.1522 - val_acc: 0.9630\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 00078: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0024 - acc: 0.9997 - val_loss: 0.1522 - val_acc: 0.9632\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00079: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0021 - acc: 0.9997 - val_loss: 0.2001 - val_acc: 0.9543\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 00080: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0035 - acc: 0.9993 - val_loss: 0.1965 - val_acc: 0.9546\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9969\n",
      "Epoch 00081: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0105 - acc: 0.9969 - val_loss: 0.2107 - val_acc: 0.9548\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945\n",
      "Epoch 00082: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0184 - acc: 0.9945 - val_loss: 0.1917 - val_acc: 0.9560\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9995\n",
      "Epoch 00083: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0034 - acc: 0.9995 - val_loss: 0.1696 - val_acc: 0.9651\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 00084: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0021 - acc: 0.9998 - val_loss: 0.1659 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 00085: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0035 - acc: 0.9992 - val_loss: 0.2034 - val_acc: 0.9515\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9985\n",
      "Epoch 00086: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0063 - acc: 0.9985 - val_loss: 0.1873 - val_acc: 0.9606\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 00087: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0094 - acc: 0.9972 - val_loss: 0.1683 - val_acc: 0.9632\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 00088: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0034 - acc: 0.9994 - val_loss: 0.1713 - val_acc: 0.9616\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9943\n",
      "Epoch 00089: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0177 - acc: 0.9943 - val_loss: 0.1614 - val_acc: 0.9639\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 00090: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1507 - val_acc: 0.9641\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00091: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0018 - acc: 0.9998 - val_loss: 0.1766 - val_acc: 0.9588\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9933\n",
      "Epoch 00092: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0199 - acc: 0.9933 - val_loss: 0.1606 - val_acc: 0.9646\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 00093: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.1533 - val_acc: 0.9653\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9954\n",
      "Epoch 00094: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0160 - acc: 0.9954 - val_loss: 0.1743 - val_acc: 0.9611\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9986\n",
      "Epoch 00095: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0057 - acc: 0.9986 - val_loss: 0.1602 - val_acc: 0.9653\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 00096: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0019 - acc: 0.9998 - val_loss: 0.1615 - val_acc: 0.9634\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9972\n",
      "Epoch 00097: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0107 - acc: 0.9972 - val_loss: 0.1836 - val_acc: 0.9550\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 00098: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0020 - acc: 0.9998 - val_loss: 0.1631 - val_acc: 0.9627\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 00099: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0024 - acc: 0.9996 - val_loss: 0.1801 - val_acc: 0.9604\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00100: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0017 - acc: 0.9998 - val_loss: 0.1642 - val_acc: 0.9646\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00101: val_loss did not improve from 0.14978\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0024 - acc: 0.9996 - val_loss: 0.2560 - val_acc: 0.9499\n",
      "\n",
      "1D_CNN_custom_4_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2029 - acc: 0.9431\n",
      "Loss: 0.20290481865344143 Accuracy: 0.9430945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_4_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 75776)             303104    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,340,496\n",
      "Trainable params: 2,187,152\n",
      "Non-trainable params: 153,344\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 1.4464 - acc: 0.6505\n",
      "Loss: 1.446361458140618 Accuracy: 0.6504673\n",
      "\n",
      "1D_CNN_custom_4_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,411,856\n",
      "Trainable params: 1,359,376\n",
      "Non-trainable params: 52,480\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 1.0379 - acc: 0.7065\n",
      "Loss: 1.037937605096296 Accuracy: 0.7065421\n",
      "\n",
      "1D_CNN_custom_4_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,156,496\n",
      "Trainable params: 1,137,552\n",
      "Non-trainable params: 18,944\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.5679 - acc: 0.8467\n",
      "Loss: 0.5678957583872081 Accuracy: 0.846729\n",
      "\n",
      "1D_CNN_custom_4_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1344)              5376      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,058,256\n",
      "Trainable params: 1,053,136\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.3207 - acc: 0.9047\n",
      "Loss: 0.3206527758919685 Accuracy: 0.9046729\n",
      "\n",
      "1D_CNN_custom_4_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 448)               1792      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,061,136\n",
      "Trainable params: 1,057,680\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2162 - acc: 0.9522\n",
      "Loss: 0.21618979500949012 Accuracy: 0.9522326\n",
      "\n",
      "1D_CNN_custom_4_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 64)             256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,075,536\n",
      "Trainable params: 1,072,592\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.2029 - acc: 0.9431\n",
      "Loss: 0.20290481865344143 Accuracy: 0.9430945\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_4_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 75776)             303104    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,340,496\n",
      "Trainable params: 2,187,152\n",
      "Non-trainable params: 153,344\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 2.9550 - acc: 0.6449\n",
      "Loss: 2.9549851901310875 Accuracy: 0.6448598\n",
      "\n",
      "1D_CNN_custom_4_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,411,856\n",
      "Trainable params: 1,359,376\n",
      "Non-trainable params: 52,480\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 1.5515 - acc: 0.7259\n",
      "Loss: 1.551548725125203 Accuracy: 0.7258567\n",
      "\n",
      "1D_CNN_custom_4_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,156,496\n",
      "Trainable params: 1,137,552\n",
      "Non-trainable params: 18,944\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.6993 - acc: 0.8577\n",
      "Loss: 0.6992539117393216 Accuracy: 0.85773623\n",
      "\n",
      "1D_CNN_custom_4_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1344)              5376      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,058,256\n",
      "Trainable params: 1,053,136\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.3356 - acc: 0.9192\n",
      "Loss: 0.33563100462885787 Accuracy: 0.9192108\n",
      "\n",
      "1D_CNN_custom_4_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 448)               1792      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,061,136\n",
      "Trainable params: 1,057,680\n",
      "Non-trainable params: 3,456\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 20s 4ms/sample - loss: 0.2494 - acc: 0.9514\n",
      "Loss: 0.2493953763675583 Accuracy: 0.9514019\n",
      "\n",
      "1D_CNN_custom_4_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 64)             256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,075,536\n",
      "Trainable params: 1,072,592\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.3608 - acc: 0.9242\n",
      "Loss: 0.36077223317397844 Accuracy: 0.92419523\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
