{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO(conv_num=1):\n",
    "    init_channel = 256\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel/(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same', activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                65536016  \n",
      "=================================================================\n",
      "Total params: 65,537,552\n",
      "Trainable params: 65,537,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1365248)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1365248)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                21843984  \n",
      "=================================================================\n",
      "Total params: 22,173,456\n",
      "Trainable params: 22,173,456\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 454912)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 454912)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                7278608   \n",
      "=================================================================\n",
      "Total params: 7,936,016\n",
      "Trainable params: 7,936,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,033,808\n",
      "Trainable params: 2,033,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,306,896\n",
      "Trainable params: 1,306,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,118,608\n",
      "Trainable params: 1,118,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,048,016\n",
      "Trainable params: 1,048,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,054,224\n",
      "Trainable params: 1,054,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,069,648\n",
      "Trainable params: 1,069,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8214 - acc: 0.4150\n",
      "Epoch 00001: val_loss improved from inf to 1.34747, saving model to model/checkpoint/1D_CNN_custom_4_DO_4_conv_checkpoint/001-1.3475.hdf5\n",
      "36805/36805 [==============================] - 273s 7ms/sample - loss: 1.8215 - acc: 0.4150 - val_loss: 1.3475 - val_acc: 0.5761\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1908 - acc: 0.6319\n",
      "Epoch 00002: val_loss improved from 1.34747 to 1.07798, saving model to model/checkpoint/1D_CNN_custom_4_DO_4_conv_checkpoint/002-1.0780.hdf5\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 1.1909 - acc: 0.6319 - val_loss: 1.0780 - val_acc: 0.6648\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9457 - acc: 0.7145\n",
      "Epoch 00003: val_loss improved from 1.07798 to 0.96347, saving model to model/checkpoint/1D_CNN_custom_4_DO_4_conv_checkpoint/003-0.9635.hdf5\n",
      "36805/36805 [==============================] - 270s 7ms/sample - loss: 0.9456 - acc: 0.7145 - val_loss: 0.9635 - val_acc: 0.7037\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7455 - acc: 0.7770\n",
      "Epoch 00004: val_loss improved from 0.96347 to 0.89372, saving model to model/checkpoint/1D_CNN_custom_4_DO_4_conv_checkpoint/004-0.8937.hdf5\n",
      "36805/36805 [==============================] - 270s 7ms/sample - loss: 0.7455 - acc: 0.7770 - val_loss: 0.8937 - val_acc: 0.7296\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5875 - acc: 0.8217\n",
      "Epoch 00005: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 270s 7ms/sample - loss: 0.5875 - acc: 0.8217 - val_loss: 0.9205 - val_acc: 0.7298\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4537 - acc: 0.8635\n",
      "Epoch 00006: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 270s 7ms/sample - loss: 0.4537 - acc: 0.8635 - val_loss: 0.9717 - val_acc: 0.7137\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3515 - acc: 0.8921\n",
      "Epoch 00007: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.3515 - acc: 0.8921 - val_loss: 1.0059 - val_acc: 0.7270\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9151\n",
      "Epoch 00008: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 270s 7ms/sample - loss: 0.2757 - acc: 0.9151 - val_loss: 1.1433 - val_acc: 0.7112\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9284\n",
      "Epoch 00009: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.2267 - acc: 0.9284 - val_loss: 1.1593 - val_acc: 0.7328\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9401\n",
      "Epoch 00010: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1939 - acc: 0.9401 - val_loss: 1.1725 - val_acc: 0.7312\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9499\n",
      "Epoch 00011: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1620 - acc: 0.9499 - val_loss: 1.1607 - val_acc: 0.7421\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9548\n",
      "Epoch 00012: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1460 - acc: 0.9548 - val_loss: 1.2498 - val_acc: 0.7335\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9592\n",
      "Epoch 00013: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1319 - acc: 0.9592 - val_loss: 1.3114 - val_acc: 0.7310\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9611\n",
      "Epoch 00014: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1252 - acc: 0.9611 - val_loss: 1.2876 - val_acc: 0.7368\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9659\n",
      "Epoch 00015: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1107 - acc: 0.9659 - val_loss: 1.4066 - val_acc: 0.7296\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9687\n",
      "Epoch 00016: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.1046 - acc: 0.9687 - val_loss: 1.3125 - val_acc: 0.7363\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9705\n",
      "Epoch 00017: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0994 - acc: 0.9705 - val_loss: 1.2904 - val_acc: 0.7510\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9731\n",
      "Epoch 00018: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0895 - acc: 0.9731 - val_loss: 1.3032 - val_acc: 0.7526\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9746\n",
      "Epoch 00019: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0852 - acc: 0.9746 - val_loss: 1.3762 - val_acc: 0.7435\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9747\n",
      "Epoch 00020: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0883 - acc: 0.9747 - val_loss: 1.4039 - val_acc: 0.7445\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9766\n",
      "Epoch 00021: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0821 - acc: 0.9766 - val_loss: 1.4783 - val_acc: 0.7475\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9768\n",
      "Epoch 00022: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0794 - acc: 0.9768 - val_loss: 1.4248 - val_acc: 0.7470\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9784\n",
      "Epoch 00023: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0755 - acc: 0.9784 - val_loss: 1.3702 - val_acc: 0.7545\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9793\n",
      "Epoch 00024: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0709 - acc: 0.9794 - val_loss: 1.4038 - val_acc: 0.7549\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9806\n",
      "Epoch 00025: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0691 - acc: 0.9806 - val_loss: 1.5927 - val_acc: 0.7421\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9789\n",
      "Epoch 00026: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0696 - acc: 0.9789 - val_loss: 1.4188 - val_acc: 0.7545\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9823\n",
      "Epoch 00027: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0650 - acc: 0.9823 - val_loss: 1.4886 - val_acc: 0.7517\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9827\n",
      "Epoch 00028: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0611 - acc: 0.9827 - val_loss: 1.4880 - val_acc: 0.7480\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9823\n",
      "Epoch 00029: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0633 - acc: 0.9823 - val_loss: 1.4677 - val_acc: 0.7487\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9833\n",
      "Epoch 00030: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 271s 7ms/sample - loss: 0.0603 - acc: 0.9833 - val_loss: 1.4990 - val_acc: 0.7556\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9829\n",
      "Epoch 00031: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0606 - acc: 0.9829 - val_loss: 1.4772 - val_acc: 0.7556\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9840\n",
      "Epoch 00032: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0587 - acc: 0.9840 - val_loss: 1.4883 - val_acc: 0.7505\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9855\n",
      "Epoch 00033: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0545 - acc: 0.9855 - val_loss: 1.4620 - val_acc: 0.7566\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9858\n",
      "Epoch 00034: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0519 - acc: 0.9858 - val_loss: 1.5465 - val_acc: 0.7573\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9849\n",
      "Epoch 00035: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0558 - acc: 0.9849 - val_loss: 1.4620 - val_acc: 0.7461\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9843\n",
      "Epoch 00036: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0585 - acc: 0.9843 - val_loss: 1.5546 - val_acc: 0.7505\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9863\n",
      "Epoch 00037: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0522 - acc: 0.9863 - val_loss: 1.4932 - val_acc: 0.7596\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9860\n",
      "Epoch 00038: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0511 - acc: 0.9860 - val_loss: 1.5352 - val_acc: 0.7589\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9863\n",
      "Epoch 00039: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0500 - acc: 0.9863 - val_loss: 1.4690 - val_acc: 0.7612\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9868\n",
      "Epoch 00040: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0496 - acc: 0.9868 - val_loss: 1.5660 - val_acc: 0.7487\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9882\n",
      "Epoch 00041: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0438 - acc: 0.9882 - val_loss: 1.5872 - val_acc: 0.7561\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9877\n",
      "Epoch 00042: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0467 - acc: 0.9877 - val_loss: 1.5394 - val_acc: 0.7549\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9882\n",
      "Epoch 00043: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0462 - acc: 0.9882 - val_loss: 1.5374 - val_acc: 0.7731\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9864\n",
      "Epoch 00044: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0516 - acc: 0.9864 - val_loss: 1.5697 - val_acc: 0.7584\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9878\n",
      "Epoch 00045: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0465 - acc: 0.9877 - val_loss: 1.4542 - val_acc: 0.7671\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9886\n",
      "Epoch 00046: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0433 - acc: 0.9886 - val_loss: 1.5517 - val_acc: 0.7556\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9888\n",
      "Epoch 00047: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0445 - acc: 0.9888 - val_loss: 1.5303 - val_acc: 0.7685\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9890\n",
      "Epoch 00048: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0435 - acc: 0.9891 - val_loss: 1.4921 - val_acc: 0.7664\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9893\n",
      "Epoch 00049: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0421 - acc: 0.9893 - val_loss: 1.4678 - val_acc: 0.7664\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9904\n",
      "Epoch 00050: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0391 - acc: 0.9904 - val_loss: 1.5396 - val_acc: 0.7568\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9901\n",
      "Epoch 00051: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0396 - acc: 0.9901 - val_loss: 1.5646 - val_acc: 0.7661\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9889\n",
      "Epoch 00052: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 272s 7ms/sample - loss: 0.0418 - acc: 0.9889 - val_loss: 1.5931 - val_acc: 0.7624\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9899\n",
      "Epoch 00053: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 273s 7ms/sample - loss: 0.0413 - acc: 0.9899 - val_loss: 1.6291 - val_acc: 0.7552\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9888\n",
      "Epoch 00054: val_loss did not improve from 0.89372\n",
      "36805/36805 [==============================] - 273s 7ms/sample - loss: 0.0425 - acc: 0.9888 - val_loss: 1.6248 - val_acc: 0.7491\n",
      "\n",
      "1D_CNN_custom_4_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.9750 - acc: 0.6982\n",
      "Loss: 0.9750270652251081 Accuracy: 0.6982347\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9735 - acc: 0.3572\n",
      "Epoch 00001: val_loss improved from inf to 1.42455, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/001-1.4245.hdf5\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 1.9734 - acc: 0.3572 - val_loss: 1.4245 - val_acc: 0.5770\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2880 - acc: 0.5965\n",
      "Epoch 00002: val_loss improved from 1.42455 to 1.05952, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/002-1.0595.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 1.2880 - acc: 0.5965 - val_loss: 1.0595 - val_acc: 0.6788\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0365 - acc: 0.6822\n",
      "Epoch 00003: val_loss improved from 1.05952 to 0.90291, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/003-0.9029.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 1.0366 - acc: 0.6822 - val_loss: 0.9029 - val_acc: 0.7226\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7313\n",
      "Epoch 00004: val_loss improved from 0.90291 to 0.79386, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/004-0.7939.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.8719 - acc: 0.7313 - val_loss: 0.7939 - val_acc: 0.7612\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7638 - acc: 0.7653\n",
      "Epoch 00005: val_loss did not improve from 0.79386\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.7637 - acc: 0.7653 - val_loss: 0.8661 - val_acc: 0.7543\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6773 - acc: 0.7950\n",
      "Epoch 00006: val_loss improved from 0.79386 to 0.76540, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/006-0.7654.hdf5\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.6773 - acc: 0.7950 - val_loss: 0.7654 - val_acc: 0.7638\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6136 - acc: 0.8157\n",
      "Epoch 00007: val_loss improved from 0.76540 to 0.66661, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/007-0.6666.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.6136 - acc: 0.8156 - val_loss: 0.6666 - val_acc: 0.8102\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.8333\n",
      "Epoch 00008: val_loss improved from 0.66661 to 0.65121, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/008-0.6512.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.5503 - acc: 0.8333 - val_loss: 0.6512 - val_acc: 0.8195\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4905 - acc: 0.8521\n",
      "Epoch 00009: val_loss improved from 0.65121 to 0.64692, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/009-0.6469.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.4905 - acc: 0.8522 - val_loss: 0.6469 - val_acc: 0.8062\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4428 - acc: 0.8650\n",
      "Epoch 00010: val_loss improved from 0.64692 to 0.63626, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/010-0.6363.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.4427 - acc: 0.8650 - val_loss: 0.6363 - val_acc: 0.8171\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8826\n",
      "Epoch 00011: val_loss improved from 0.63626 to 0.62539, saving model to model/checkpoint/1D_CNN_custom_4_DO_5_conv_checkpoint/011-0.6254.hdf5\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.3849 - acc: 0.8826 - val_loss: 0.6254 - val_acc: 0.8211\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.8927\n",
      "Epoch 00012: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.3464 - acc: 0.8927 - val_loss: 0.6303 - val_acc: 0.8279\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3137 - acc: 0.9045\n",
      "Epoch 00013: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.3137 - acc: 0.9045 - val_loss: 0.6447 - val_acc: 0.8213\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9106\n",
      "Epoch 00014: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.2859 - acc: 0.9106 - val_loss: 0.6602 - val_acc: 0.8232\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9231\n",
      "Epoch 00015: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.2470 - acc: 0.9231 - val_loss: 0.6573 - val_acc: 0.8316\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9266\n",
      "Epoch 00016: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.2300 - acc: 0.9266 - val_loss: 0.6749 - val_acc: 0.8360\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9354\n",
      "Epoch 00017: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.2046 - acc: 0.9354 - val_loss: 0.7127 - val_acc: 0.8248\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9377\n",
      "Epoch 00018: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1950 - acc: 0.9377 - val_loss: 0.7223 - val_acc: 0.8262\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9436\n",
      "Epoch 00019: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1752 - acc: 0.9436 - val_loss: 0.8154 - val_acc: 0.8150\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9455\n",
      "Epoch 00020: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1694 - acc: 0.9456 - val_loss: 0.7471 - val_acc: 0.8321\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9504\n",
      "Epoch 00021: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1562 - acc: 0.9504 - val_loss: 0.7543 - val_acc: 0.8369\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9539\n",
      "Epoch 00022: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1456 - acc: 0.9539 - val_loss: 0.7081 - val_acc: 0.8381\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9584\n",
      "Epoch 00023: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1358 - acc: 0.9584 - val_loss: 0.7435 - val_acc: 0.8337\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9598\n",
      "Epoch 00024: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.1282 - acc: 0.9598 - val_loss: 0.7511 - val_acc: 0.8358\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9617\n",
      "Epoch 00025: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.1213 - acc: 0.9617 - val_loss: 0.7330 - val_acc: 0.8316\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9630\n",
      "Epoch 00026: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.1173 - acc: 0.9630 - val_loss: 0.8120 - val_acc: 0.8362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9644\n",
      "Epoch 00027: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1120 - acc: 0.9644 - val_loss: 0.7823 - val_acc: 0.8409\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9661\n",
      "Epoch 00028: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1088 - acc: 0.9661 - val_loss: 0.8628 - val_acc: 0.8223\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9669\n",
      "Epoch 00029: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.1056 - acc: 0.9669 - val_loss: 0.7748 - val_acc: 0.8430\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9679\n",
      "Epoch 00030: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.1050 - acc: 0.9679 - val_loss: 0.7828 - val_acc: 0.8416\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9718\n",
      "Epoch 00031: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0928 - acc: 0.9718 - val_loss: 0.8712 - val_acc: 0.8281\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9716\n",
      "Epoch 00032: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0940 - acc: 0.9716 - val_loss: 0.7839 - val_acc: 0.8472\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9695\n",
      "Epoch 00033: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0965 - acc: 0.9695 - val_loss: 0.7843 - val_acc: 0.8402\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9726\n",
      "Epoch 00034: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0891 - acc: 0.9726 - val_loss: 0.7871 - val_acc: 0.8481\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9720\n",
      "Epoch 00035: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0922 - acc: 0.9720 - val_loss: 0.8233 - val_acc: 0.8449\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9741\n",
      "Epoch 00036: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0855 - acc: 0.9741 - val_loss: 0.7663 - val_acc: 0.8470\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9743\n",
      "Epoch 00037: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0825 - acc: 0.9743 - val_loss: 0.7715 - val_acc: 0.8470\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9765\n",
      "Epoch 00038: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0781 - acc: 0.9765 - val_loss: 0.8623 - val_acc: 0.8381\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9760\n",
      "Epoch 00039: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0778 - acc: 0.9759 - val_loss: 0.7842 - val_acc: 0.8528\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9767\n",
      "Epoch 00040: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0767 - acc: 0.9767 - val_loss: 0.8042 - val_acc: 0.8484\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9784\n",
      "Epoch 00041: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0718 - acc: 0.9784 - val_loss: 0.8743 - val_acc: 0.8458\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9778\n",
      "Epoch 00042: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0715 - acc: 0.9778 - val_loss: 0.8893 - val_acc: 0.8409\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9776\n",
      "Epoch 00043: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0739 - acc: 0.9776 - val_loss: 0.7971 - val_acc: 0.8572\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9799\n",
      "Epoch 00044: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0675 - acc: 0.9799 - val_loss: 0.8330 - val_acc: 0.8458\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9808\n",
      "Epoch 00045: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0665 - acc: 0.9808 - val_loss: 0.8349 - val_acc: 0.8437\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9782\n",
      "Epoch 00046: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0731 - acc: 0.9782 - val_loss: 0.8295 - val_acc: 0.8444\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9796\n",
      "Epoch 00047: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0672 - acc: 0.9796 - val_loss: 0.7779 - val_acc: 0.8523\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9815\n",
      "Epoch 00048: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0637 - acc: 0.9816 - val_loss: 0.7830 - val_acc: 0.8458\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9808\n",
      "Epoch 00049: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0648 - acc: 0.9808 - val_loss: 0.8440 - val_acc: 0.8537\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9812\n",
      "Epoch 00050: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0668 - acc: 0.9812 - val_loss: 0.9027 - val_acc: 0.8397\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9811\n",
      "Epoch 00051: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0647 - acc: 0.9811 - val_loss: 0.7930 - val_acc: 0.8588\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9829\n",
      "Epoch 00052: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0594 - acc: 0.9829 - val_loss: 0.8219 - val_acc: 0.8544\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9819\n",
      "Epoch 00053: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0634 - acc: 0.9819 - val_loss: 0.8282 - val_acc: 0.8521\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9821\n",
      "Epoch 00054: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0612 - acc: 0.9821 - val_loss: 0.8554 - val_acc: 0.8481\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9840\n",
      "Epoch 00055: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0578 - acc: 0.9840 - val_loss: 0.8444 - val_acc: 0.8500\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9828\n",
      "Epoch 00056: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0614 - acc: 0.9828 - val_loss: 0.8308 - val_acc: 0.8523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9842\n",
      "Epoch 00057: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0544 - acc: 0.9842 - val_loss: 0.8513 - val_acc: 0.8537\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9836\n",
      "Epoch 00058: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0573 - acc: 0.9836 - val_loss: 0.8232 - val_acc: 0.8595\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9839\n",
      "Epoch 00059: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0550 - acc: 0.9839 - val_loss: 0.8468 - val_acc: 0.8526\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9856\n",
      "Epoch 00060: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0521 - acc: 0.9856 - val_loss: 0.7940 - val_acc: 0.8670\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9832\n",
      "Epoch 00061: val_loss did not improve from 0.62539\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0576 - acc: 0.9832 - val_loss: 0.8364 - val_acc: 0.8512\n",
      "\n",
      "1D_CNN_custom_4_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.7217 - acc: 0.7859\n",
      "Loss: 0.7216717330218599 Accuracy: 0.78587747\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0485 - acc: 0.3290\n",
      "Epoch 00001: val_loss improved from inf to 1.43146, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/001-1.4315.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 2.0484 - acc: 0.3291 - val_loss: 1.4315 - val_acc: 0.5539\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4131 - acc: 0.5450\n",
      "Epoch 00002: val_loss improved from 1.43146 to 1.10443, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/002-1.1044.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 1.4130 - acc: 0.5450 - val_loss: 1.1044 - val_acc: 0.6671\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1326 - acc: 0.6488\n",
      "Epoch 00003: val_loss improved from 1.10443 to 0.92710, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/003-0.9271.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 1.1325 - acc: 0.6488 - val_loss: 0.9271 - val_acc: 0.7195\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9350 - acc: 0.7136\n",
      "Epoch 00004: val_loss improved from 0.92710 to 0.80451, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/004-0.8045.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.9349 - acc: 0.7137 - val_loss: 0.8045 - val_acc: 0.7629\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7901 - acc: 0.7627\n",
      "Epoch 00005: val_loss improved from 0.80451 to 0.67712, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/005-0.6771.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.7901 - acc: 0.7627 - val_loss: 0.6771 - val_acc: 0.8076\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6821 - acc: 0.7971\n",
      "Epoch 00006: val_loss improved from 0.67712 to 0.58437, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/006-0.5844.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.6820 - acc: 0.7971 - val_loss: 0.5844 - val_acc: 0.8400\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.8187\n",
      "Epoch 00007: val_loss did not improve from 0.58437\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.6062 - acc: 0.8187 - val_loss: 0.6257 - val_acc: 0.8164\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5443 - acc: 0.8378\n",
      "Epoch 00008: val_loss improved from 0.58437 to 0.48963, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/008-0.4896.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.5443 - acc: 0.8378 - val_loss: 0.4896 - val_acc: 0.8602\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4907 - acc: 0.8541\n",
      "Epoch 00009: val_loss improved from 0.48963 to 0.45289, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/009-0.4529.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.4907 - acc: 0.8541 - val_loss: 0.4529 - val_acc: 0.8710\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8694\n",
      "Epoch 00010: val_loss improved from 0.45289 to 0.42746, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/010-0.4275.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.4446 - acc: 0.8694 - val_loss: 0.4275 - val_acc: 0.8770\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8768\n",
      "Epoch 00011: val_loss improved from 0.42746 to 0.40015, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/011-0.4001.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.4135 - acc: 0.8769 - val_loss: 0.4001 - val_acc: 0.8877\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3800 - acc: 0.8856\n",
      "Epoch 00012: val_loss improved from 0.40015 to 0.37169, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/012-0.3717.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.3800 - acc: 0.8856 - val_loss: 0.3717 - val_acc: 0.8982\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3512 - acc: 0.8934\n",
      "Epoch 00013: val_loss improved from 0.37169 to 0.36625, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/013-0.3662.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.3512 - acc: 0.8934 - val_loss: 0.3662 - val_acc: 0.8970\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8971\n",
      "Epoch 00014: val_loss improved from 0.36625 to 0.35291, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/014-0.3529.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.3341 - acc: 0.8971 - val_loss: 0.3529 - val_acc: 0.9075\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9052\n",
      "Epoch 00015: val_loss did not improve from 0.35291\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.3109 - acc: 0.9052 - val_loss: 0.3785 - val_acc: 0.8956\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2883 - acc: 0.9134\n",
      "Epoch 00016: val_loss did not improve from 0.35291\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2883 - acc: 0.9134 - val_loss: 0.3976 - val_acc: 0.8945\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2676 - acc: 0.9170\n",
      "Epoch 00017: val_loss did not improve from 0.35291\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2675 - acc: 0.9170 - val_loss: 0.3623 - val_acc: 0.9059\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.9221\n",
      "Epoch 00018: val_loss did not improve from 0.35291\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2525 - acc: 0.9220 - val_loss: 0.3728 - val_acc: 0.8998\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9241\n",
      "Epoch 00019: val_loss did not improve from 0.35291\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2457 - acc: 0.9241 - val_loss: 0.3671 - val_acc: 0.9029\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9280\n",
      "Epoch 00020: val_loss improved from 0.35291 to 0.35107, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/020-0.3511.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2278 - acc: 0.9280 - val_loss: 0.3511 - val_acc: 0.9061\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2094 - acc: 0.9340\n",
      "Epoch 00021: val_loss did not improve from 0.35107\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2093 - acc: 0.9340 - val_loss: 0.3772 - val_acc: 0.9075\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9368\n",
      "Epoch 00022: val_loss did not improve from 0.35107\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.2025 - acc: 0.9369 - val_loss: 0.3569 - val_acc: 0.9059\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9386\n",
      "Epoch 00023: val_loss improved from 0.35107 to 0.34723, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/023-0.3472.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1917 - acc: 0.9386 - val_loss: 0.3472 - val_acc: 0.9159\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9411\n",
      "Epoch 00024: val_loss did not improve from 0.34723\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1834 - acc: 0.9411 - val_loss: 0.3523 - val_acc: 0.9103\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9423\n",
      "Epoch 00025: val_loss did not improve from 0.34723\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1747 - acc: 0.9423 - val_loss: 0.3547 - val_acc: 0.9140\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9471\n",
      "Epoch 00026: val_loss did not improve from 0.34723\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1658 - acc: 0.9471 - val_loss: 0.3526 - val_acc: 0.9106\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9491\n",
      "Epoch 00027: val_loss did not improve from 0.34723\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1538 - acc: 0.9491 - val_loss: 0.3535 - val_acc: 0.9154\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9523\n",
      "Epoch 00028: val_loss did not improve from 0.34723\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1490 - acc: 0.9523 - val_loss: 0.3628 - val_acc: 0.9166\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9535\n",
      "Epoch 00029: val_loss improved from 0.34723 to 0.33983, saving model to model/checkpoint/1D_CNN_custom_4_DO_6_conv_checkpoint/029-0.3398.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1450 - acc: 0.9535 - val_loss: 0.3398 - val_acc: 0.9199\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9564\n",
      "Epoch 00030: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1326 - acc: 0.9564 - val_loss: 0.3967 - val_acc: 0.9115\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9577\n",
      "Epoch 00031: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1295 - acc: 0.9577 - val_loss: 0.3637 - val_acc: 0.9159\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9589\n",
      "Epoch 00032: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1298 - acc: 0.9589 - val_loss: 0.3862 - val_acc: 0.9108\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9616\n",
      "Epoch 00033: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1179 - acc: 0.9616 - val_loss: 0.3535 - val_acc: 0.9178\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9626\n",
      "Epoch 00034: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1157 - acc: 0.9626 - val_loss: 0.3960 - val_acc: 0.9108\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9641\n",
      "Epoch 00035: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1110 - acc: 0.9641 - val_loss: 0.3770 - val_acc: 0.9189\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9646\n",
      "Epoch 00036: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1064 - acc: 0.9645 - val_loss: 0.3682 - val_acc: 0.9113\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9644\n",
      "Epoch 00037: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.1103 - acc: 0.9644 - val_loss: 0.3836 - val_acc: 0.9168\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9691\n",
      "Epoch 00038: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0968 - acc: 0.9691 - val_loss: 0.3944 - val_acc: 0.9189\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9670\n",
      "Epoch 00039: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0998 - acc: 0.9670 - val_loss: 0.3627 - val_acc: 0.9248\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9691\n",
      "Epoch 00040: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0966 - acc: 0.9691 - val_loss: 0.4058 - val_acc: 0.9147\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9693\n",
      "Epoch 00041: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0950 - acc: 0.9693 - val_loss: 0.3752 - val_acc: 0.9208\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9730\n",
      "Epoch 00042: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0831 - acc: 0.9730 - val_loss: 0.4118 - val_acc: 0.9173\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9728\n",
      "Epoch 00043: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0825 - acc: 0.9728 - val_loss: 0.3882 - val_acc: 0.9208\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9725\n",
      "Epoch 00044: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0848 - acc: 0.9725 - val_loss: 0.3730 - val_acc: 0.9194\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9740\n",
      "Epoch 00045: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0788 - acc: 0.9741 - val_loss: 0.3878 - val_acc: 0.9259\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9735\n",
      "Epoch 00046: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0814 - acc: 0.9735 - val_loss: 0.3769 - val_acc: 0.9187\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9750\n",
      "Epoch 00047: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0768 - acc: 0.9749 - val_loss: 0.3987 - val_acc: 0.9194\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9765\n",
      "Epoch 00048: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0704 - acc: 0.9765 - val_loss: 0.4150 - val_acc: 0.9269\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9758\n",
      "Epoch 00049: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0749 - acc: 0.9758 - val_loss: 0.4096 - val_acc: 0.9164\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9775\n",
      "Epoch 00050: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0684 - acc: 0.9775 - val_loss: 0.3690 - val_acc: 0.9210\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9773\n",
      "Epoch 00051: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0689 - acc: 0.9773 - val_loss: 0.4099 - val_acc: 0.9194\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9765\n",
      "Epoch 00052: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0698 - acc: 0.9765 - val_loss: 0.3893 - val_acc: 0.9276\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9797\n",
      "Epoch 00053: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0627 - acc: 0.9797 - val_loss: 0.3953 - val_acc: 0.9264\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9771\n",
      "Epoch 00054: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0690 - acc: 0.9771 - val_loss: 0.4256 - val_acc: 0.9220\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9798\n",
      "Epoch 00055: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0630 - acc: 0.9798 - val_loss: 0.3893 - val_acc: 0.9273\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9784\n",
      "Epoch 00056: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0671 - acc: 0.9784 - val_loss: 0.3653 - val_acc: 0.9278\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9810\n",
      "Epoch 00057: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0604 - acc: 0.9810 - val_loss: 0.3776 - val_acc: 0.9287\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9806\n",
      "Epoch 00058: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0594 - acc: 0.9806 - val_loss: 0.4125 - val_acc: 0.9257\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9820\n",
      "Epoch 00059: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0571 - acc: 0.9820 - val_loss: 0.4181 - val_acc: 0.9196\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9815\n",
      "Epoch 00060: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0573 - acc: 0.9815 - val_loss: 0.3872 - val_acc: 0.9304\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9807\n",
      "Epoch 00061: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0593 - acc: 0.9807 - val_loss: 0.3885 - val_acc: 0.9297\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9822\n",
      "Epoch 00062: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0553 - acc: 0.9822 - val_loss: 0.3960 - val_acc: 0.9257\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9839\n",
      "Epoch 00063: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0505 - acc: 0.9839 - val_loss: 0.4222 - val_acc: 0.9245\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9823\n",
      "Epoch 00064: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0565 - acc: 0.9823 - val_loss: 0.4249 - val_acc: 0.9231\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9820\n",
      "Epoch 00065: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0581 - acc: 0.9820 - val_loss: 0.3989 - val_acc: 0.9236\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9849\n",
      "Epoch 00066: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0476 - acc: 0.9849 - val_loss: 0.4149 - val_acc: 0.9287\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9821\n",
      "Epoch 00067: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0544 - acc: 0.9821 - val_loss: 0.3983 - val_acc: 0.9294\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9842\n",
      "Epoch 00068: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0498 - acc: 0.9842 - val_loss: 0.4226 - val_acc: 0.9180\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9835\n",
      "Epoch 00069: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0506 - acc: 0.9835 - val_loss: 0.3928 - val_acc: 0.9273\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9854\n",
      "Epoch 00070: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0450 - acc: 0.9854 - val_loss: 0.4122 - val_acc: 0.9285\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9835\n",
      "Epoch 00071: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0510 - acc: 0.9835 - val_loss: 0.4236 - val_acc: 0.9285\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9851\n",
      "Epoch 00072: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0470 - acc: 0.9851 - val_loss: 0.3921 - val_acc: 0.9299\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9858\n",
      "Epoch 00073: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0460 - acc: 0.9858 - val_loss: 0.3900 - val_acc: 0.9236\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9862\n",
      "Epoch 00074: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0430 - acc: 0.9863 - val_loss: 0.3940 - val_acc: 0.9334\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9860\n",
      "Epoch 00075: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0461 - acc: 0.9860 - val_loss: 0.3978 - val_acc: 0.9334\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9859\n",
      "Epoch 00076: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0458 - acc: 0.9859 - val_loss: 0.4134 - val_acc: 0.9334\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9856\n",
      "Epoch 00077: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0435 - acc: 0.9856 - val_loss: 0.4152 - val_acc: 0.9292\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9860\n",
      "Epoch 00078: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0441 - acc: 0.9860 - val_loss: 0.4356 - val_acc: 0.9276\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9876\n",
      "Epoch 00079: val_loss did not improve from 0.33983\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0424 - acc: 0.9876 - val_loss: 0.4003 - val_acc: 0.9280\n",
      "\n",
      "1D_CNN_custom_4_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.3909 - acc: 0.8947\n",
      "Loss: 0.3909050719141341 Accuracy: 0.89470404\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2766 - acc: 0.2430\n",
      "Epoch 00001: val_loss improved from inf to 1.59991, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/001-1.5999.hdf5\n",
      "36805/36805 [==============================] - 281s 8ms/sample - loss: 2.2765 - acc: 0.2430 - val_loss: 1.5999 - val_acc: 0.4969\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5910 - acc: 0.4672\n",
      "Epoch 00002: val_loss improved from 1.59991 to 1.27806, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/002-1.2781.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 1.5910 - acc: 0.4672 - val_loss: 1.2781 - val_acc: 0.6103\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3277 - acc: 0.5608\n",
      "Epoch 00003: val_loss improved from 1.27806 to 1.04567, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/003-1.0457.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 1.3277 - acc: 0.5608 - val_loss: 1.0457 - val_acc: 0.6853\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0756 - acc: 0.6571\n",
      "Epoch 00004: val_loss improved from 1.04567 to 0.74740, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/004-0.7474.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 1.0755 - acc: 0.6572 - val_loss: 0.7474 - val_acc: 0.7950\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8879 - acc: 0.7232\n",
      "Epoch 00005: val_loss improved from 0.74740 to 0.61390, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/005-0.6139.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.8879 - acc: 0.7232 - val_loss: 0.6139 - val_acc: 0.8223\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7516 - acc: 0.7668\n",
      "Epoch 00006: val_loss improved from 0.61390 to 0.49517, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/006-0.4952.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.7516 - acc: 0.7668 - val_loss: 0.4952 - val_acc: 0.8616\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6550 - acc: 0.7978\n",
      "Epoch 00007: val_loss improved from 0.49517 to 0.45813, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/007-0.4581.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.6550 - acc: 0.7978 - val_loss: 0.4581 - val_acc: 0.8768\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.8219\n",
      "Epoch 00008: val_loss improved from 0.45813 to 0.40805, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/008-0.4080.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.5869 - acc: 0.8219 - val_loss: 0.4080 - val_acc: 0.8838\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5260 - acc: 0.8398\n",
      "Epoch 00009: val_loss improved from 0.40805 to 0.35504, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/009-0.3550.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.5260 - acc: 0.8398 - val_loss: 0.3550 - val_acc: 0.9071\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4781 - acc: 0.8550\n",
      "Epoch 00010: val_loss improved from 0.35504 to 0.35231, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/010-0.3523.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.4781 - acc: 0.8550 - val_loss: 0.3523 - val_acc: 0.9005\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.8662\n",
      "Epoch 00011: val_loss improved from 0.35231 to 0.31967, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/011-0.3197.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.4386 - acc: 0.8662 - val_loss: 0.3197 - val_acc: 0.9133\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4129 - acc: 0.8740\n",
      "Epoch 00012: val_loss improved from 0.31967 to 0.31642, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/012-0.3164.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.4130 - acc: 0.8739 - val_loss: 0.3164 - val_acc: 0.9147\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3778 - acc: 0.8846\n",
      "Epoch 00013: val_loss improved from 0.31642 to 0.27348, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/013-0.2735.hdf5\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.3778 - acc: 0.8846 - val_loss: 0.2735 - val_acc: 0.9196\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3484 - acc: 0.8937\n",
      "Epoch 00014: val_loss improved from 0.27348 to 0.25452, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/014-0.2545.hdf5\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.3484 - acc: 0.8937 - val_loss: 0.2545 - val_acc: 0.9285\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3324 - acc: 0.8974\n",
      "Epoch 00015: val_loss improved from 0.25452 to 0.25436, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/015-0.2544.hdf5\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.3324 - acc: 0.8974 - val_loss: 0.2544 - val_acc: 0.9299\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.9024\n",
      "Epoch 00016: val_loss did not improve from 0.25436\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.3164 - acc: 0.9024 - val_loss: 0.2630 - val_acc: 0.9304\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.9079\n",
      "Epoch 00017: val_loss improved from 0.25436 to 0.22852, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/017-0.2285.hdf5\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.3037 - acc: 0.9079 - val_loss: 0.2285 - val_acc: 0.9327\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.9114\n",
      "Epoch 00018: val_loss did not improve from 0.22852\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.2819 - acc: 0.9113 - val_loss: 0.2298 - val_acc: 0.9352\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9106\n",
      "Epoch 00019: val_loss did not improve from 0.22852\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2801 - acc: 0.9106 - val_loss: 0.2349 - val_acc: 0.9366\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2618 - acc: 0.9179\n",
      "Epoch 00020: val_loss improved from 0.22852 to 0.21126, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/020-0.2113.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2618 - acc: 0.9179 - val_loss: 0.2113 - val_acc: 0.9425\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9215\n",
      "Epoch 00021: val_loss did not improve from 0.21126\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2485 - acc: 0.9215 - val_loss: 0.2360 - val_acc: 0.9371\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9257\n",
      "Epoch 00022: val_loss improved from 0.21126 to 0.19153, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/022-0.1915.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2355 - acc: 0.9257 - val_loss: 0.1915 - val_acc: 0.9453\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9274\n",
      "Epoch 00023: val_loss did not improve from 0.19153\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2306 - acc: 0.9274 - val_loss: 0.1951 - val_acc: 0.9441\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2273 - acc: 0.9277\n",
      "Epoch 00024: val_loss did not improve from 0.19153\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2273 - acc: 0.9277 - val_loss: 0.1944 - val_acc: 0.9474\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9345\n",
      "Epoch 00025: val_loss did not improve from 0.19153\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2121 - acc: 0.9344 - val_loss: 0.1959 - val_acc: 0.9420\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9335\n",
      "Epoch 00026: val_loss did not improve from 0.19153\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2117 - acc: 0.9335 - val_loss: 0.1916 - val_acc: 0.9471\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9386\n",
      "Epoch 00027: val_loss improved from 0.19153 to 0.18218, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/027-0.1822.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1947 - acc: 0.9385 - val_loss: 0.1822 - val_acc: 0.9492\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9383\n",
      "Epoch 00028: val_loss did not improve from 0.18218\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1964 - acc: 0.9383 - val_loss: 0.2005 - val_acc: 0.9464\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9401\n",
      "Epoch 00029: val_loss did not improve from 0.18218\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1846 - acc: 0.9401 - val_loss: 0.1995 - val_acc: 0.9425\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9431\n",
      "Epoch 00030: val_loss did not improve from 0.18218\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1791 - acc: 0.9431 - val_loss: 0.1862 - val_acc: 0.9502\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9456\n",
      "Epoch 00031: val_loss improved from 0.18218 to 0.17194, saving model to model/checkpoint/1D_CNN_custom_4_DO_7_conv_checkpoint/031-0.1719.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1700 - acc: 0.9456 - val_loss: 0.1719 - val_acc: 0.9506\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9465\n",
      "Epoch 00032: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1675 - acc: 0.9465 - val_loss: 0.1900 - val_acc: 0.9515\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9484\n",
      "Epoch 00033: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1638 - acc: 0.9484 - val_loss: 0.2167 - val_acc: 0.9415\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9483\n",
      "Epoch 00034: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1570 - acc: 0.9483 - val_loss: 0.1948 - val_acc: 0.9518\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9518\n",
      "Epoch 00035: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1515 - acc: 0.9517 - val_loss: 0.1844 - val_acc: 0.9536\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9499\n",
      "Epoch 00036: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1526 - acc: 0.9498 - val_loss: 0.1901 - val_acc: 0.9469\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9529\n",
      "Epoch 00037: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1457 - acc: 0.9529 - val_loss: 0.1746 - val_acc: 0.9511\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9542\n",
      "Epoch 00038: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1427 - acc: 0.9542 - val_loss: 0.1971 - val_acc: 0.9497\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9557\n",
      "Epoch 00039: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1360 - acc: 0.9557 - val_loss: 0.1923 - val_acc: 0.9520\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9570\n",
      "Epoch 00040: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1273 - acc: 0.9570 - val_loss: 0.1848 - val_acc: 0.9483\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9580\n",
      "Epoch 00041: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1276 - acc: 0.9580 - val_loss: 0.1860 - val_acc: 0.9539\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9601\n",
      "Epoch 00042: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1227 - acc: 0.9601 - val_loss: 0.2034 - val_acc: 0.9529\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9595\n",
      "Epoch 00043: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1229 - acc: 0.9595 - val_loss: 0.1929 - val_acc: 0.9464\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9608\n",
      "Epoch 00044: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1187 - acc: 0.9608 - val_loss: 0.1809 - val_acc: 0.9557\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9614\n",
      "Epoch 00045: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1159 - acc: 0.9614 - val_loss: 0.1802 - val_acc: 0.9527\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9627\n",
      "Epoch 00046: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1124 - acc: 0.9627 - val_loss: 0.1740 - val_acc: 0.9548\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9634\n",
      "Epoch 00047: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1084 - acc: 0.9634 - val_loss: 0.1899 - val_acc: 0.9541\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9643\n",
      "Epoch 00048: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1056 - acc: 0.9643 - val_loss: 0.1948 - val_acc: 0.9492\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9651\n",
      "Epoch 00049: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1033 - acc: 0.9651 - val_loss: 0.1945 - val_acc: 0.9488\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9661\n",
      "Epoch 00050: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1009 - acc: 0.9661 - val_loss: 0.1831 - val_acc: 0.9527\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9676\n",
      "Epoch 00051: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1000 - acc: 0.9676 - val_loss: 0.2014 - val_acc: 0.9502\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9667\n",
      "Epoch 00052: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1004 - acc: 0.9667 - val_loss: 0.1965 - val_acc: 0.9522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9695\n",
      "Epoch 00053: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0925 - acc: 0.9695 - val_loss: 0.1901 - val_acc: 0.9557\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9712\n",
      "Epoch 00054: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0892 - acc: 0.9712 - val_loss: 0.1899 - val_acc: 0.9518\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9695\n",
      "Epoch 00055: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0894 - acc: 0.9695 - val_loss: 0.1752 - val_acc: 0.9546\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9705\n",
      "Epoch 00056: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0853 - acc: 0.9705 - val_loss: 0.2004 - val_acc: 0.9534\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9721\n",
      "Epoch 00057: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0832 - acc: 0.9721 - val_loss: 0.1974 - val_acc: 0.9569\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9717\n",
      "Epoch 00058: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0850 - acc: 0.9717 - val_loss: 0.2028 - val_acc: 0.9567\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9718\n",
      "Epoch 00059: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0838 - acc: 0.9719 - val_loss: 0.1879 - val_acc: 0.9562\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9744\n",
      "Epoch 00060: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0784 - acc: 0.9744 - val_loss: 0.2010 - val_acc: 0.9536\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9737\n",
      "Epoch 00061: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0805 - acc: 0.9737 - val_loss: 0.1925 - val_acc: 0.9536\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9757\n",
      "Epoch 00062: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0732 - acc: 0.9757 - val_loss: 0.2021 - val_acc: 0.9539\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9746\n",
      "Epoch 00063: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0766 - acc: 0.9747 - val_loss: 0.2105 - val_acc: 0.9548\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9752\n",
      "Epoch 00064: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0733 - acc: 0.9752 - val_loss: 0.2149 - val_acc: 0.9553\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9751\n",
      "Epoch 00065: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0741 - acc: 0.9751 - val_loss: 0.1989 - val_acc: 0.9522\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9742\n",
      "Epoch 00066: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0752 - acc: 0.9742 - val_loss: 0.2157 - val_acc: 0.9592\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9748\n",
      "Epoch 00067: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0739 - acc: 0.9748 - val_loss: 0.2084 - val_acc: 0.9569\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9769\n",
      "Epoch 00068: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0689 - acc: 0.9769 - val_loss: 0.1924 - val_acc: 0.9541\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9781\n",
      "Epoch 00069: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0659 - acc: 0.9781 - val_loss: 0.2010 - val_acc: 0.9520\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9765\n",
      "Epoch 00070: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0686 - acc: 0.9765 - val_loss: 0.2172 - val_acc: 0.9511\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9791\n",
      "Epoch 00071: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0634 - acc: 0.9791 - val_loss: 0.2043 - val_acc: 0.9553\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9794\n",
      "Epoch 00072: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0628 - acc: 0.9794 - val_loss: 0.2266 - val_acc: 0.9534\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9780\n",
      "Epoch 00073: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0662 - acc: 0.9780 - val_loss: 0.2114 - val_acc: 0.9520\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9798\n",
      "Epoch 00074: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0583 - acc: 0.9798 - val_loss: 0.2306 - val_acc: 0.9543\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9792\n",
      "Epoch 00075: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0627 - acc: 0.9792 - val_loss: 0.2364 - val_acc: 0.9534\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9803\n",
      "Epoch 00076: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0591 - acc: 0.9803 - val_loss: 0.2213 - val_acc: 0.9534\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9806\n",
      "Epoch 00077: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0591 - acc: 0.9806 - val_loss: 0.2266 - val_acc: 0.9520\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9799\n",
      "Epoch 00078: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0594 - acc: 0.9799 - val_loss: 0.2241 - val_acc: 0.9532\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9819\n",
      "Epoch 00079: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0575 - acc: 0.9819 - val_loss: 0.2237 - val_acc: 0.9553\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9815\n",
      "Epoch 00080: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0535 - acc: 0.9816 - val_loss: 0.2011 - val_acc: 0.9522\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9818\n",
      "Epoch 00081: val_loss did not improve from 0.17194\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0523 - acc: 0.9818 - val_loss: 0.2401 - val_acc: 0.9548\n",
      "\n",
      "1D_CNN_custom_4_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.2027 - acc: 0.9381\n",
      "Loss: 0.20269798948386006 Accuracy: 0.93811005\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3179 - acc: 0.2430\n",
      "Epoch 00001: val_loss improved from inf to 1.56106, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/001-1.5611.hdf5\n",
      "36805/36805 [==============================] - 281s 8ms/sample - loss: 2.3178 - acc: 0.2430 - val_loss: 1.5611 - val_acc: 0.5222\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5814 - acc: 0.4807\n",
      "Epoch 00002: val_loss improved from 1.56106 to 1.12763, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/002-1.1276.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 1.5815 - acc: 0.4807 - val_loss: 1.1276 - val_acc: 0.6546\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2313 - acc: 0.5958\n",
      "Epoch 00003: val_loss improved from 1.12763 to 0.78943, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/003-0.7894.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 1.2312 - acc: 0.5958 - val_loss: 0.7894 - val_acc: 0.7675\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9812 - acc: 0.6818\n",
      "Epoch 00004: val_loss improved from 0.78943 to 0.64527, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/004-0.6453.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.9811 - acc: 0.6819 - val_loss: 0.6453 - val_acc: 0.8113\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8082 - acc: 0.7396\n",
      "Epoch 00005: val_loss improved from 0.64527 to 0.47618, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/005-0.4762.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.8081 - acc: 0.7396 - val_loss: 0.4762 - val_acc: 0.8663\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6735 - acc: 0.7886\n",
      "Epoch 00006: val_loss improved from 0.47618 to 0.40597, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/006-0.4060.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.6737 - acc: 0.7885 - val_loss: 0.4060 - val_acc: 0.8807\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5847 - acc: 0.8170\n",
      "Epoch 00007: val_loss improved from 0.40597 to 0.33007, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/007-0.3301.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.5847 - acc: 0.8170 - val_loss: 0.3301 - val_acc: 0.9082\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5168 - acc: 0.8385\n",
      "Epoch 00008: val_loss improved from 0.33007 to 0.27977, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/008-0.2798.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.5169 - acc: 0.8385 - val_loss: 0.2798 - val_acc: 0.9178\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8562\n",
      "Epoch 00009: val_loss improved from 0.27977 to 0.25872, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/009-0.2587.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.4588 - acc: 0.8562 - val_loss: 0.2587 - val_acc: 0.9276\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4178 - acc: 0.8695\n",
      "Epoch 00010: val_loss improved from 0.25872 to 0.25372, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/010-0.2537.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.4177 - acc: 0.8695 - val_loss: 0.2537 - val_acc: 0.9241\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3870 - acc: 0.8786\n",
      "Epoch 00011: val_loss improved from 0.25372 to 0.24584, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/011-0.2458.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3870 - acc: 0.8786 - val_loss: 0.2458 - val_acc: 0.9292\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3545 - acc: 0.8885\n",
      "Epoch 00012: val_loss improved from 0.24584 to 0.20109, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/012-0.2011.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3544 - acc: 0.8885 - val_loss: 0.2011 - val_acc: 0.9439\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3300 - acc: 0.8975\n",
      "Epoch 00013: val_loss improved from 0.20109 to 0.19190, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/013-0.1919.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3300 - acc: 0.8975 - val_loss: 0.1919 - val_acc: 0.9436\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3059 - acc: 0.9031\n",
      "Epoch 00014: val_loss improved from 0.19190 to 0.18555, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/014-0.1856.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3059 - acc: 0.9031 - val_loss: 0.1856 - val_acc: 0.9474\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9076\n",
      "Epoch 00015: val_loss improved from 0.18555 to 0.17278, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/015-0.1728.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2937 - acc: 0.9076 - val_loss: 0.1728 - val_acc: 0.9522\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.9151\n",
      "Epoch 00016: val_loss improved from 0.17278 to 0.16753, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/016-0.1675.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2739 - acc: 0.9151 - val_loss: 0.1675 - val_acc: 0.9522\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9184\n",
      "Epoch 00017: val_loss improved from 0.16753 to 0.16046, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/017-0.1605.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2577 - acc: 0.9184 - val_loss: 0.1605 - val_acc: 0.9527\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.9220\n",
      "Epoch 00018: val_loss improved from 0.16046 to 0.15356, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/018-0.1536.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2502 - acc: 0.9220 - val_loss: 0.1536 - val_acc: 0.9525\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2387 - acc: 0.9251\n",
      "Epoch 00019: val_loss improved from 0.15356 to 0.14601, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/019-0.1460.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2387 - acc: 0.9251 - val_loss: 0.1460 - val_acc: 0.9562\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9295\n",
      "Epoch 00020: val_loss did not improve from 0.14601\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2240 - acc: 0.9295 - val_loss: 0.1479 - val_acc: 0.9583\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2176 - acc: 0.9326\n",
      "Epoch 00021: val_loss improved from 0.14601 to 0.14560, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/021-0.1456.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2176 - acc: 0.9326 - val_loss: 0.1456 - val_acc: 0.9590\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9329\n",
      "Epoch 00022: val_loss improved from 0.14560 to 0.14292, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/022-0.1429.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2114 - acc: 0.9328 - val_loss: 0.1429 - val_acc: 0.9560\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9355\n",
      "Epoch 00023: val_loss did not improve from 0.14292\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1986 - acc: 0.9355 - val_loss: 0.1489 - val_acc: 0.9553\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9368\n",
      "Epoch 00024: val_loss improved from 0.14292 to 0.13391, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/024-0.1339.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1981 - acc: 0.9368 - val_loss: 0.1339 - val_acc: 0.9581\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1852 - acc: 0.9406\n",
      "Epoch 00025: val_loss improved from 0.13391 to 0.13162, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/025-0.1316.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1852 - acc: 0.9406 - val_loss: 0.1316 - val_acc: 0.9599\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9429\n",
      "Epoch 00026: val_loss did not improve from 0.13162\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1805 - acc: 0.9429 - val_loss: 0.1410 - val_acc: 0.9599\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9445\n",
      "Epoch 00027: val_loss did not improve from 0.13162\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1737 - acc: 0.9445 - val_loss: 0.1337 - val_acc: 0.9602\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9473\n",
      "Epoch 00028: val_loss did not improve from 0.13162\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1662 - acc: 0.9473 - val_loss: 0.1359 - val_acc: 0.9599\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9469\n",
      "Epoch 00029: val_loss did not improve from 0.13162\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1618 - acc: 0.9469 - val_loss: 0.1432 - val_acc: 0.9611\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9509\n",
      "Epoch 00030: val_loss improved from 0.13162 to 0.12983, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/030-0.1298.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1499 - acc: 0.9509 - val_loss: 0.1298 - val_acc: 0.9639\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9519\n",
      "Epoch 00031: val_loss did not improve from 0.12983\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1498 - acc: 0.9519 - val_loss: 0.1371 - val_acc: 0.9578\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9513\n",
      "Epoch 00032: val_loss improved from 0.12983 to 0.12932, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/032-0.1293.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1499 - acc: 0.9513 - val_loss: 0.1293 - val_acc: 0.9602\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9541\n",
      "Epoch 00033: val_loss did not improve from 0.12932\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1435 - acc: 0.9541 - val_loss: 0.1325 - val_acc: 0.9606\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9528\n",
      "Epoch 00034: val_loss improved from 0.12932 to 0.12769, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/034-0.1277.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1430 - acc: 0.9528 - val_loss: 0.1277 - val_acc: 0.9648\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9554\n",
      "Epoch 00035: val_loss improved from 0.12769 to 0.12742, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/035-0.1274.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1373 - acc: 0.9554 - val_loss: 0.1274 - val_acc: 0.9641\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9568\n",
      "Epoch 00036: val_loss improved from 0.12742 to 0.11717, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/036-0.1172.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1320 - acc: 0.9569 - val_loss: 0.1172 - val_acc: 0.9639\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9591\n",
      "Epoch 00037: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1232 - acc: 0.9591 - val_loss: 0.1234 - val_acc: 0.9634\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9584\n",
      "Epoch 00038: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1247 - acc: 0.9584 - val_loss: 0.1353 - val_acc: 0.9576\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9622\n",
      "Epoch 00039: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1177 - acc: 0.9622 - val_loss: 0.1301 - val_acc: 0.9616\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9614\n",
      "Epoch 00040: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1166 - acc: 0.9614 - val_loss: 0.1248 - val_acc: 0.9646\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9616\n",
      "Epoch 00041: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1188 - acc: 0.9616 - val_loss: 0.1185 - val_acc: 0.9658\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9639\n",
      "Epoch 00042: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1097 - acc: 0.9639 - val_loss: 0.1338 - val_acc: 0.9616\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9636\n",
      "Epoch 00043: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1105 - acc: 0.9636 - val_loss: 0.1262 - val_acc: 0.9639\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9641\n",
      "Epoch 00044: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1068 - acc: 0.9641 - val_loss: 0.1361 - val_acc: 0.9630\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9655\n",
      "Epoch 00045: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1026 - acc: 0.9655 - val_loss: 0.1325 - val_acc: 0.9644\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9657\n",
      "Epoch 00046: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1025 - acc: 0.9657 - val_loss: 0.1326 - val_acc: 0.9648\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9676\n",
      "Epoch 00047: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0978 - acc: 0.9676 - val_loss: 0.1785 - val_acc: 0.9564\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9651\n",
      "Epoch 00048: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1059 - acc: 0.9650 - val_loss: 0.1261 - val_acc: 0.9644\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9708\n",
      "Epoch 00049: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0865 - acc: 0.9708 - val_loss: 0.1196 - val_acc: 0.9693\n",
      "Epoch 50/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9687\n",
      "Epoch 00050: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0921 - acc: 0.9687 - val_loss: 0.1190 - val_acc: 0.9655\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9707\n",
      "Epoch 00051: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0871 - acc: 0.9707 - val_loss: 0.1239 - val_acc: 0.9651\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9705\n",
      "Epoch 00052: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0875 - acc: 0.9705 - val_loss: 0.1269 - val_acc: 0.9667\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9721\n",
      "Epoch 00053: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0811 - acc: 0.9721 - val_loss: 0.1456 - val_acc: 0.9630\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9713\n",
      "Epoch 00054: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0834 - acc: 0.9713 - val_loss: 0.1349 - val_acc: 0.9651\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9710\n",
      "Epoch 00055: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0860 - acc: 0.9710 - val_loss: 0.1356 - val_acc: 0.9620\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9726\n",
      "Epoch 00056: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0795 - acc: 0.9726 - val_loss: 0.1254 - val_acc: 0.9651\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9736\n",
      "Epoch 00057: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0783 - acc: 0.9736 - val_loss: 0.1260 - val_acc: 0.9658\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9705\n",
      "Epoch 00058: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0849 - acc: 0.9705 - val_loss: 0.1226 - val_acc: 0.9665\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9746\n",
      "Epoch 00059: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0761 - acc: 0.9746 - val_loss: 0.1178 - val_acc: 0.9660\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9754\n",
      "Epoch 00060: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0717 - acc: 0.9754 - val_loss: 0.1251 - val_acc: 0.9672\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9756\n",
      "Epoch 00061: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0728 - acc: 0.9756 - val_loss: 0.1398 - val_acc: 0.9646\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9759\n",
      "Epoch 00062: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0699 - acc: 0.9759 - val_loss: 0.1279 - val_acc: 0.9641\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9768\n",
      "Epoch 00063: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0667 - acc: 0.9769 - val_loss: 0.1373 - val_acc: 0.9613\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9772\n",
      "Epoch 00064: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0672 - acc: 0.9772 - val_loss: 0.1303 - val_acc: 0.9660\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9772\n",
      "Epoch 00065: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0662 - acc: 0.9772 - val_loss: 0.1548 - val_acc: 0.9611\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9777\n",
      "Epoch 00066: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0645 - acc: 0.9777 - val_loss: 0.1268 - val_acc: 0.9660\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9784\n",
      "Epoch 00067: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0616 - acc: 0.9784 - val_loss: 0.1343 - val_acc: 0.9653\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9790\n",
      "Epoch 00068: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0632 - acc: 0.9790 - val_loss: 0.1408 - val_acc: 0.9602\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9794\n",
      "Epoch 00069: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0616 - acc: 0.9794 - val_loss: 0.1336 - val_acc: 0.9676\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9795\n",
      "Epoch 00070: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0606 - acc: 0.9795 - val_loss: 0.1282 - val_acc: 0.9658\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9798\n",
      "Epoch 00071: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0595 - acc: 0.9798 - val_loss: 0.1354 - val_acc: 0.9686\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9812\n",
      "Epoch 00072: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0547 - acc: 0.9812 - val_loss: 0.2011 - val_acc: 0.9602\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9806\n",
      "Epoch 00073: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0602 - acc: 0.9806 - val_loss: 0.1329 - val_acc: 0.9693\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9808\n",
      "Epoch 00074: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0554 - acc: 0.9808 - val_loss: 0.1229 - val_acc: 0.9683\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9816\n",
      "Epoch 00075: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0517 - acc: 0.9816 - val_loss: 0.1296 - val_acc: 0.9676\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9817\n",
      "Epoch 00076: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0535 - acc: 0.9816 - val_loss: 0.1235 - val_acc: 0.9674\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9829\n",
      "Epoch 00077: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0498 - acc: 0.9829 - val_loss: 0.1270 - val_acc: 0.9681\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9823\n",
      "Epoch 00078: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0528 - acc: 0.9823 - val_loss: 0.1412 - val_acc: 0.9665\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9836\n",
      "Epoch 00079: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0484 - acc: 0.9836 - val_loss: 0.1374 - val_acc: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9817\n",
      "Epoch 00080: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0517 - acc: 0.9817 - val_loss: 0.1424 - val_acc: 0.9662\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9837\n",
      "Epoch 00081: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0491 - acc: 0.9837 - val_loss: 0.1621 - val_acc: 0.9658\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9841\n",
      "Epoch 00082: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0480 - acc: 0.9841 - val_loss: 0.1612 - val_acc: 0.9648\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9833\n",
      "Epoch 00083: val_loss did not improve from 0.11717\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0489 - acc: 0.9833 - val_loss: 0.1506 - val_acc: 0.9641\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9835\n",
      "Epoch 00084: val_loss improved from 0.11717 to 0.11547, saving model to model/checkpoint/1D_CNN_custom_4_DO_8_conv_checkpoint/084-0.1155.hdf5\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0493 - acc: 0.9835 - val_loss: 0.1155 - val_acc: 0.9700\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9855\n",
      "Epoch 00085: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0439 - acc: 0.9855 - val_loss: 0.1487 - val_acc: 0.9644\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9840\n",
      "Epoch 00086: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0461 - acc: 0.9840 - val_loss: 0.1432 - val_acc: 0.9679\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9851\n",
      "Epoch 00087: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0425 - acc: 0.9851 - val_loss: 0.1348 - val_acc: 0.9669\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9840\n",
      "Epoch 00088: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0472 - acc: 0.9840 - val_loss: 0.1469 - val_acc: 0.9676\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9851\n",
      "Epoch 00089: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0435 - acc: 0.9851 - val_loss: 0.1471 - val_acc: 0.9660\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9860\n",
      "Epoch 00090: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0412 - acc: 0.9860 - val_loss: 0.1551 - val_acc: 0.9674\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9853\n",
      "Epoch 00091: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0451 - acc: 0.9853 - val_loss: 0.1495 - val_acc: 0.9653\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9867\n",
      "Epoch 00092: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0393 - acc: 0.9867 - val_loss: 0.1517 - val_acc: 0.9672\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9848\n",
      "Epoch 00093: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0427 - acc: 0.9848 - val_loss: 0.1408 - val_acc: 0.9669\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9859\n",
      "Epoch 00094: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0405 - acc: 0.9859 - val_loss: 0.1461 - val_acc: 0.9665\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9861\n",
      "Epoch 00095: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0424 - acc: 0.9861 - val_loss: 0.1484 - val_acc: 0.9679\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9858\n",
      "Epoch 00096: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0410 - acc: 0.9858 - val_loss: 0.1442 - val_acc: 0.9688\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9865\n",
      "Epoch 00097: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0402 - acc: 0.9864 - val_loss: 0.1656 - val_acc: 0.9674\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9862\n",
      "Epoch 00098: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0414 - acc: 0.9862 - val_loss: 0.1415 - val_acc: 0.9672\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9882\n",
      "Epoch 00099: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0366 - acc: 0.9882 - val_loss: 0.1588 - val_acc: 0.9672\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9872\n",
      "Epoch 00100: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0383 - acc: 0.9872 - val_loss: 0.1699 - val_acc: 0.9658\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9879\n",
      "Epoch 00101: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0349 - acc: 0.9879 - val_loss: 0.1460 - val_acc: 0.9686\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9869\n",
      "Epoch 00102: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0383 - acc: 0.9869 - val_loss: 0.1739 - val_acc: 0.9679\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9874\n",
      "Epoch 00103: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0358 - acc: 0.9874 - val_loss: 0.1466 - val_acc: 0.9704\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9884\n",
      "Epoch 00104: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0345 - acc: 0.9884 - val_loss: 0.1686 - val_acc: 0.9695\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9878\n",
      "Epoch 00105: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0364 - acc: 0.9878 - val_loss: 0.1567 - val_acc: 0.9669\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9885\n",
      "Epoch 00106: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0340 - acc: 0.9885 - val_loss: 0.1557 - val_acc: 0.9686\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9884\n",
      "Epoch 00107: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0358 - acc: 0.9884 - val_loss: 0.1563 - val_acc: 0.9688\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9890\n",
      "Epoch 00108: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0336 - acc: 0.9891 - val_loss: 0.1664 - val_acc: 0.9660\n",
      "Epoch 109/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9889\n",
      "Epoch 00109: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0341 - acc: 0.9889 - val_loss: 0.1632 - val_acc: 0.9665\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9893\n",
      "Epoch 00110: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0317 - acc: 0.9893 - val_loss: 0.1480 - val_acc: 0.9667\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9885\n",
      "Epoch 00111: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0345 - acc: 0.9885 - val_loss: 0.1579 - val_acc: 0.9667\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9894\n",
      "Epoch 00112: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0321 - acc: 0.9894 - val_loss: 0.1559 - val_acc: 0.9662\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9883\n",
      "Epoch 00113: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0356 - acc: 0.9883 - val_loss: 0.1498 - val_acc: 0.9667\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9897\n",
      "Epoch 00114: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0298 - acc: 0.9897 - val_loss: 0.1605 - val_acc: 0.9688\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9893\n",
      "Epoch 00115: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0315 - acc: 0.9893 - val_loss: 0.1839 - val_acc: 0.9646\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9904\n",
      "Epoch 00116: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0297 - acc: 0.9904 - val_loss: 0.1683 - val_acc: 0.9695\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9882\n",
      "Epoch 00117: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0343 - acc: 0.9882 - val_loss: 0.1696 - val_acc: 0.9674\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9905\n",
      "Epoch 00118: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0276 - acc: 0.9905 - val_loss: 0.1881 - val_acc: 0.9641\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9917\n",
      "Epoch 00119: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0246 - acc: 0.9917 - val_loss: 0.1759 - val_acc: 0.9665\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9898\n",
      "Epoch 00120: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0319 - acc: 0.9898 - val_loss: 0.1774 - val_acc: 0.9674\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9901\n",
      "Epoch 00121: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0313 - acc: 0.9901 - val_loss: 0.1525 - val_acc: 0.9630\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9902\n",
      "Epoch 00122: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0293 - acc: 0.9902 - val_loss: 0.1700 - val_acc: 0.9688\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9914\n",
      "Epoch 00123: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0261 - acc: 0.9914 - val_loss: 0.1642 - val_acc: 0.9697\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9898\n",
      "Epoch 00124: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0290 - acc: 0.9898 - val_loss: 0.1851 - val_acc: 0.9655\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9910\n",
      "Epoch 00125: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0272 - acc: 0.9910 - val_loss: 0.1781 - val_acc: 0.9683\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9902\n",
      "Epoch 00126: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0295 - acc: 0.9902 - val_loss: 0.1900 - val_acc: 0.9658\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9906\n",
      "Epoch 00127: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0281 - acc: 0.9906 - val_loss: 0.1869 - val_acc: 0.9669\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9910\n",
      "Epoch 00128: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0265 - acc: 0.9910 - val_loss: 0.1905 - val_acc: 0.9683\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9908\n",
      "Epoch 00129: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0279 - acc: 0.9908 - val_loss: 0.1921 - val_acc: 0.9660\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9907\n",
      "Epoch 00130: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0280 - acc: 0.9907 - val_loss: 0.1603 - val_acc: 0.9693\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9918\n",
      "Epoch 00131: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0246 - acc: 0.9917 - val_loss: 0.1826 - val_acc: 0.9697\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9902\n",
      "Epoch 00132: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0296 - acc: 0.9902 - val_loss: 0.1789 - val_acc: 0.9690\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9923\n",
      "Epoch 00133: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0235 - acc: 0.9923 - val_loss: 0.1779 - val_acc: 0.9686\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9918\n",
      "Epoch 00134: val_loss did not improve from 0.11547\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0250 - acc: 0.9918 - val_loss: 0.1785 - val_acc: 0.9681\n",
      "\n",
      "1D_CNN_custom_4_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1697 - acc: 0.9572\n",
      "Loss: 0.1696946072863146 Accuracy: 0.95721704\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2910 - acc: 0.2552\n",
      "Epoch 00001: val_loss improved from inf to 1.49640, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/001-1.4964.hdf5\n",
      "36805/36805 [==============================] - 282s 8ms/sample - loss: 2.2910 - acc: 0.2552 - val_loss: 1.4964 - val_acc: 0.5355\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5337 - acc: 0.5102\n",
      "Epoch 00002: val_loss improved from 1.49640 to 1.09807, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/002-1.0981.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 1.5336 - acc: 0.5103 - val_loss: 1.0981 - val_acc: 0.6553\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1814 - acc: 0.6220\n",
      "Epoch 00003: val_loss improved from 1.09807 to 0.71243, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/003-0.7124.hdf5\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 1.1813 - acc: 0.6220 - val_loss: 0.7124 - val_acc: 0.7871\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9024 - acc: 0.7137\n",
      "Epoch 00004: val_loss improved from 0.71243 to 0.53263, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/004-0.5326.hdf5\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.9023 - acc: 0.7137 - val_loss: 0.5326 - val_acc: 0.8477\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7199 - acc: 0.7744\n",
      "Epoch 00005: val_loss improved from 0.53263 to 0.38976, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/005-0.3898.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.7199 - acc: 0.7744 - val_loss: 0.3898 - val_acc: 0.8910\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.8154\n",
      "Epoch 00006: val_loss improved from 0.38976 to 0.32208, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/006-0.3221.hdf5\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.5998 - acc: 0.8154 - val_loss: 0.3221 - val_acc: 0.9092\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5168 - acc: 0.8403\n",
      "Epoch 00007: val_loss improved from 0.32208 to 0.28034, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/007-0.2803.hdf5\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.5167 - acc: 0.8403 - val_loss: 0.2803 - val_acc: 0.9222\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8606\n",
      "Epoch 00008: val_loss improved from 0.28034 to 0.25917, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/008-0.2592.hdf5\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.4545 - acc: 0.8606 - val_loss: 0.2592 - val_acc: 0.9290\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8737\n",
      "Epoch 00009: val_loss did not improve from 0.25917\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.4138 - acc: 0.8737 - val_loss: 0.2925 - val_acc: 0.9129\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3719 - acc: 0.8861\n",
      "Epoch 00010: val_loss improved from 0.25917 to 0.20690, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/010-0.2069.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3719 - acc: 0.8861 - val_loss: 0.2069 - val_acc: 0.9406\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.8957\n",
      "Epoch 00011: val_loss improved from 0.20690 to 0.20587, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/011-0.2059.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3420 - acc: 0.8957 - val_loss: 0.2059 - val_acc: 0.9394\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.9023\n",
      "Epoch 00012: val_loss improved from 0.20587 to 0.18242, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/012-0.1824.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.3163 - acc: 0.9023 - val_loss: 0.1824 - val_acc: 0.9450\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.9119\n",
      "Epoch 00013: val_loss improved from 0.18242 to 0.18074, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/013-0.1807.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2871 - acc: 0.9119 - val_loss: 0.1807 - val_acc: 0.9488\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2812 - acc: 0.9135\n",
      "Epoch 00014: val_loss improved from 0.18074 to 0.17648, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/014-0.1765.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2812 - acc: 0.9135 - val_loss: 0.1765 - val_acc: 0.9485\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9200\n",
      "Epoch 00015: val_loss improved from 0.17648 to 0.16807, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/015-0.1681.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2615 - acc: 0.9200 - val_loss: 0.1681 - val_acc: 0.9511\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9260\n",
      "Epoch 00016: val_loss did not improve from 0.16807\n",
      "36805/36805 [==============================] - 280s 8ms/sample - loss: 0.2423 - acc: 0.9259 - val_loss: 0.1797 - val_acc: 0.9495\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9294\n",
      "Epoch 00017: val_loss did not improve from 0.16807\n",
      "36805/36805 [==============================] - 280s 8ms/sample - loss: 0.2279 - acc: 0.9294 - val_loss: 0.1688 - val_acc: 0.9518\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2171 - acc: 0.9314\n",
      "Epoch 00018: val_loss improved from 0.16807 to 0.15854, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/018-0.1585.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2172 - acc: 0.9314 - val_loss: 0.1585 - val_acc: 0.9534\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9339\n",
      "Epoch 00019: val_loss improved from 0.15854 to 0.15723, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/019-0.1572.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.2122 - acc: 0.9339 - val_loss: 0.1572 - val_acc: 0.9548\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9384\n",
      "Epoch 00020: val_loss improved from 0.15723 to 0.14224, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/020-0.1422.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1976 - acc: 0.9384 - val_loss: 0.1422 - val_acc: 0.9602\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9416\n",
      "Epoch 00021: val_loss did not improve from 0.14224\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1866 - acc: 0.9416 - val_loss: 0.1459 - val_acc: 0.9583\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9438\n",
      "Epoch 00022: val_loss did not improve from 0.14224\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1790 - acc: 0.9438 - val_loss: 0.1580 - val_acc: 0.9534\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9456\n",
      "Epoch 00023: val_loss did not improve from 0.14224\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1716 - acc: 0.9456 - val_loss: 0.1540 - val_acc: 0.9583\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9470\n",
      "Epoch 00024: val_loss did not improve from 0.14224\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1636 - acc: 0.9470 - val_loss: 0.1473 - val_acc: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9496\n",
      "Epoch 00025: val_loss improved from 0.14224 to 0.13894, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/025-0.1389.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1556 - acc: 0.9496 - val_loss: 0.1389 - val_acc: 0.9613\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9515\n",
      "Epoch 00026: val_loss improved from 0.13894 to 0.13850, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/026-0.1385.hdf5\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1522 - acc: 0.9515 - val_loss: 0.1385 - val_acc: 0.9581\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9543\n",
      "Epoch 00027: val_loss did not improve from 0.13850\n",
      "36805/36805 [==============================] - 280s 8ms/sample - loss: 0.1433 - acc: 0.9544 - val_loss: 0.1434 - val_acc: 0.9583\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9556\n",
      "Epoch 00028: val_loss improved from 0.13850 to 0.13200, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/028-0.1320.hdf5\n",
      "36805/36805 [==============================] - 280s 8ms/sample - loss: 0.1378 - acc: 0.9556 - val_loss: 0.1320 - val_acc: 0.9646\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9564\n",
      "Epoch 00029: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.1349 - acc: 0.9564 - val_loss: 0.1473 - val_acc: 0.9590\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9580\n",
      "Epoch 00030: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1298 - acc: 0.9580 - val_loss: 0.1393 - val_acc: 0.9606\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9605\n",
      "Epoch 00031: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.1221 - acc: 0.9605 - val_loss: 0.1386 - val_acc: 0.9597\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9616\n",
      "Epoch 00032: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1193 - acc: 0.9616 - val_loss: 0.1531 - val_acc: 0.9590\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9614\n",
      "Epoch 00033: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1196 - acc: 0.9614 - val_loss: 0.1531 - val_acc: 0.9585\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9648\n",
      "Epoch 00034: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1078 - acc: 0.9648 - val_loss: 0.1430 - val_acc: 0.9599\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9636\n",
      "Epoch 00035: val_loss did not improve from 0.13200\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1116 - acc: 0.9636 - val_loss: 0.1360 - val_acc: 0.9620\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9664\n",
      "Epoch 00036: val_loss improved from 0.13200 to 0.12863, saving model to model/checkpoint/1D_CNN_custom_4_DO_9_conv_checkpoint/036-0.1286.hdf5\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.1040 - acc: 0.9664 - val_loss: 0.1286 - val_acc: 0.9646\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9684\n",
      "Epoch 00037: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 278s 8ms/sample - loss: 0.0967 - acc: 0.9684 - val_loss: 0.1440 - val_acc: 0.9611\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9687\n",
      "Epoch 00038: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.0955 - acc: 0.9687 - val_loss: 0.1428 - val_acc: 0.9632\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9695\n",
      "Epoch 00039: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.0922 - acc: 0.9695 - val_loss: 0.1344 - val_acc: 0.9625\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9680\n",
      "Epoch 00040: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0988 - acc: 0.9680 - val_loss: 0.1365 - val_acc: 0.9669\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9719\n",
      "Epoch 00041: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0861 - acc: 0.9719 - val_loss: 0.1451 - val_acc: 0.9616\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9718\n",
      "Epoch 00042: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0848 - acc: 0.9718 - val_loss: 0.1535 - val_acc: 0.9618\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9725\n",
      "Epoch 00043: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.0832 - acc: 0.9725 - val_loss: 0.1298 - val_acc: 0.9662\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9735\n",
      "Epoch 00044: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 279s 8ms/sample - loss: 0.0791 - acc: 0.9735 - val_loss: 0.1393 - val_acc: 0.9660\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9751\n",
      "Epoch 00045: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0795 - acc: 0.9750 - val_loss: 0.1510 - val_acc: 0.9611\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9754\n",
      "Epoch 00046: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0746 - acc: 0.9754 - val_loss: 0.1514 - val_acc: 0.9630\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9760\n",
      "Epoch 00047: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0775 - acc: 0.9760 - val_loss: 0.1661 - val_acc: 0.9623\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9773\n",
      "Epoch 00048: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0715 - acc: 0.9773 - val_loss: 0.1607 - val_acc: 0.9613\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9766\n",
      "Epoch 00049: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0695 - acc: 0.9766 - val_loss: 0.1652 - val_acc: 0.9609\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9781\n",
      "Epoch 00050: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0662 - acc: 0.9781 - val_loss: 0.1878 - val_acc: 0.9578\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9787\n",
      "Epoch 00051: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0637 - acc: 0.9787 - val_loss: 0.1469 - val_acc: 0.9653\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9777\n",
      "Epoch 00052: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0648 - acc: 0.9777 - val_loss: 0.1569 - val_acc: 0.9630\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9801\n",
      "Epoch 00053: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0596 - acc: 0.9801 - val_loss: 0.1613 - val_acc: 0.9655\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9802\n",
      "Epoch 00054: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0608 - acc: 0.9802 - val_loss: 0.1487 - val_acc: 0.9665\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9800\n",
      "Epoch 00055: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0614 - acc: 0.9800 - val_loss: 0.1429 - val_acc: 0.9669\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9823\n",
      "Epoch 00056: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0548 - acc: 0.9823 - val_loss: 0.1639 - val_acc: 0.9655\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9810\n",
      "Epoch 00057: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0588 - acc: 0.9810 - val_loss: 0.1509 - val_acc: 0.9658\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9829\n",
      "Epoch 00058: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0522 - acc: 0.9829 - val_loss: 0.1702 - val_acc: 0.9637\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9814\n",
      "Epoch 00059: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0550 - acc: 0.9814 - val_loss: 0.1762 - val_acc: 0.9639\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9826\n",
      "Epoch 00060: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0521 - acc: 0.9826 - val_loss: 0.1434 - val_acc: 0.9662\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9830\n",
      "Epoch 00061: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0496 - acc: 0.9830 - val_loss: 0.1808 - val_acc: 0.9641\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9834\n",
      "Epoch 00062: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0508 - acc: 0.9834 - val_loss: 0.1631 - val_acc: 0.9639\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9832\n",
      "Epoch 00063: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 7ms/sample - loss: 0.0495 - acc: 0.9832 - val_loss: 0.1530 - val_acc: 0.9679\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9823\n",
      "Epoch 00064: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0516 - acc: 0.9823 - val_loss: 0.1577 - val_acc: 0.9674\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9839\n",
      "Epoch 00065: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0490 - acc: 0.9839 - val_loss: 0.1705 - val_acc: 0.9674\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9845\n",
      "Epoch 00066: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0458 - acc: 0.9845 - val_loss: 0.1722 - val_acc: 0.9667\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9841\n",
      "Epoch 00067: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0480 - acc: 0.9841 - val_loss: 0.1714 - val_acc: 0.9613\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9835\n",
      "Epoch 00068: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0491 - acc: 0.9835 - val_loss: 0.1720 - val_acc: 0.9653\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9864\n",
      "Epoch 00069: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0419 - acc: 0.9864 - val_loss: 0.1499 - val_acc: 0.9658\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9858\n",
      "Epoch 00070: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0434 - acc: 0.9858 - val_loss: 0.1740 - val_acc: 0.9648\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9859\n",
      "Epoch 00071: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0408 - acc: 0.9859 - val_loss: 0.1698 - val_acc: 0.9630\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9854\n",
      "Epoch 00072: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0431 - acc: 0.9854 - val_loss: 0.1627 - val_acc: 0.9679\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9861\n",
      "Epoch 00073: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0422 - acc: 0.9861 - val_loss: 0.1659 - val_acc: 0.9697\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9869\n",
      "Epoch 00074: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0402 - acc: 0.9869 - val_loss: 0.1634 - val_acc: 0.9674\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9871\n",
      "Epoch 00075: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0386 - acc: 0.9871 - val_loss: 0.1706 - val_acc: 0.9679\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9875\n",
      "Epoch 00076: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 276s 8ms/sample - loss: 0.0365 - acc: 0.9875 - val_loss: 0.1993 - val_acc: 0.9602\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9888\n",
      "Epoch 00077: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 277s 8ms/sample - loss: 0.0359 - acc: 0.9888 - val_loss: 0.1864 - val_acc: 0.9665\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9882\n",
      "Epoch 00078: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0384 - acc: 0.9882 - val_loss: 0.2053 - val_acc: 0.9667\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9891\n",
      "Epoch 00079: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0333 - acc: 0.9891 - val_loss: 0.1899 - val_acc: 0.9639\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9878\n",
      "Epoch 00080: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0387 - acc: 0.9878 - val_loss: 0.1706 - val_acc: 0.9679\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9887\n",
      "Epoch 00081: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0331 - acc: 0.9887 - val_loss: 0.2132 - val_acc: 0.9592\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9888\n",
      "Epoch 00082: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0337 - acc: 0.9888 - val_loss: 0.1719 - val_acc: 0.9669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9897\n",
      "Epoch 00083: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 274s 7ms/sample - loss: 0.0310 - acc: 0.9897 - val_loss: 0.2383 - val_acc: 0.9648\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9874\n",
      "Epoch 00084: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0391 - acc: 0.9874 - val_loss: 0.2023 - val_acc: 0.9595\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9888\n",
      "Epoch 00085: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0335 - acc: 0.9888 - val_loss: 0.1892 - val_acc: 0.9665\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9901\n",
      "Epoch 00086: val_loss did not improve from 0.12863\n",
      "36805/36805 [==============================] - 275s 7ms/sample - loss: 0.0316 - acc: 0.9901 - val_loss: 0.1801 - val_acc: 0.9665\n",
      "\n",
      "1D_CNN_custom_4_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1870 - acc: 0.9472\n",
      "Loss: 0.1869683701572079 Accuracy: 0.94724816\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_4_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,033,808\n",
      "Trainable params: 2,033,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.9750 - acc: 0.6982\n",
      "Loss: 0.9750270652251081 Accuracy: 0.6982347\n",
      "\n",
      "1D_CNN_custom_4_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,306,896\n",
      "Trainable params: 1,306,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.7217 - acc: 0.7859\n",
      "Loss: 0.7216717330218599 Accuracy: 0.78587747\n",
      "\n",
      "1D_CNN_custom_4_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,118,608\n",
      "Trainable params: 1,118,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.3909 - acc: 0.8947\n",
      "Loss: 0.3909050719141341 Accuracy: 0.89470404\n",
      "\n",
      "1D_CNN_custom_4_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,048,016\n",
      "Trainable params: 1,048,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2027 - acc: 0.9381\n",
      "Loss: 0.20269798948386006 Accuracy: 0.93811005\n",
      "\n",
      "1D_CNN_custom_4_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,054,224\n",
      "Trainable params: 1,054,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1697 - acc: 0.9572\n",
      "Loss: 0.1696946072863146 Accuracy: 0.95721704\n",
      "\n",
      "1D_CNN_custom_4_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,069,648\n",
      "Trainable params: 1,069,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1870 - acc: 0.9472\n",
      "Loss: 0.1869683701572079 Accuracy: 0.94724816\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_4_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,033,808\n",
      "Trainable params: 2,033,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 1.8636 - acc: 0.7173\n",
      "Loss: 1.8635548019706274 Accuracy: 0.71734166\n",
      "\n",
      "1D_CNN_custom_4_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,306,896\n",
      "Trainable params: 1,306,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 1.0343 - acc: 0.8206\n",
      "Loss: 1.034323782700492 Accuracy: 0.82056075\n",
      "\n",
      "1D_CNN_custom_4_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,118,608\n",
      "Trainable params: 1,118,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.4813 - acc: 0.9053\n",
      "Loss: 0.48130478849044595 Accuracy: 0.90529597\n",
      "\n",
      "1D_CNN_custom_4_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,048,016\n",
      "Trainable params: 1,048,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2254 - acc: 0.9458\n",
      "Loss: 0.22541982350195927 Accuracy: 0.9457944\n",
      "\n",
      "1D_CNN_custom_4_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,054,224\n",
      "Trainable params: 1,054,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2492 - acc: 0.9568\n",
      "Loss: 0.24922271611353095 Accuracy: 0.95680165\n",
      "\n",
      "1D_CNN_custom_4_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,069,648\n",
      "Trainable params: 1,069,648\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2692 - acc: 0.9541\n",
      "Loss: 0.26923900206799234 Accuracy: 0.95410174\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
