{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, \n",
    "                      padding='same')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,493,136\n",
      "Trainable params: 18,444,880\n",
      "Non-trainable params: 2,048,256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,864,592\n",
      "Trainable params: 6,181,456\n",
      "Non-trainable params: 683,136\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,338,128\n",
      "Trainable params: 2,109,904\n",
      "Non-trainable params: 228,224\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 846,544\n",
      "Trainable params: 769,744\n",
      "Non-trainable params: 76,800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 668,112\n",
      "Trainable params: 616,144\n",
      "Non-trainable params: 51,968\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 429,776\n",
      "Trainable params: 411,088\n",
      "Non-trainable params: 18,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 416,720\n",
      "Trainable params: 408,784\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 480,464\n",
      "Trainable params: 475,600\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 770,256\n",
      "Trainable params: 765,136\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4693 - acc: 0.5404\n",
      "Epoch 00001: val_loss improved from inf to 1.04390, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/001-1.0439.hdf5\n",
      "36805/36805 [==============================] - 185s 5ms/sample - loss: 1.4693 - acc: 0.5404 - val_loss: 1.0439 - val_acc: 0.6648\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.8183\n",
      "Epoch 00002: val_loss improved from 1.04390 to 0.40446, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/002-0.4045.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.5755 - acc: 0.8183 - val_loss: 0.4045 - val_acc: 0.8786\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3826 - acc: 0.8780\n",
      "Epoch 00003: val_loss did not improve from 0.40446\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3826 - acc: 0.8780 - val_loss: 0.4935 - val_acc: 0.8430\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2844 - acc: 0.9115\n",
      "Epoch 00004: val_loss improved from 0.40446 to 0.29747, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/004-0.2975.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2844 - acc: 0.9115 - val_loss: 0.2975 - val_acc: 0.9082\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9286\n",
      "Epoch 00005: val_loss improved from 0.29747 to 0.26891, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/005-0.2689.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2288 - acc: 0.9285 - val_loss: 0.2689 - val_acc: 0.9168\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9401\n",
      "Epoch 00006: val_loss did not improve from 0.26891\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1938 - acc: 0.9401 - val_loss: 0.2810 - val_acc: 0.9143\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9464\n",
      "Epoch 00007: val_loss improved from 0.26891 to 0.21082, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/007-0.2108.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1704 - acc: 0.9464 - val_loss: 0.2108 - val_acc: 0.9373\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9569\n",
      "Epoch 00008: val_loss did not improve from 0.21082\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1373 - acc: 0.9569 - val_loss: 0.2298 - val_acc: 0.9313\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9637\n",
      "Epoch 00009: val_loss did not improve from 0.21082\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1178 - acc: 0.9637 - val_loss: 0.2132 - val_acc: 0.9359\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9649\n",
      "Epoch 00010: val_loss improved from 0.21082 to 0.17836, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/010-0.1784.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1093 - acc: 0.9649 - val_loss: 0.1784 - val_acc: 0.9427\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9732\n",
      "Epoch 00011: val_loss did not improve from 0.17836\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0873 - acc: 0.9731 - val_loss: 0.2093 - val_acc: 0.9362\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9706\n",
      "Epoch 00012: val_loss did not improve from 0.17836\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0934 - acc: 0.9706 - val_loss: 0.1924 - val_acc: 0.9427\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9782\n",
      "Epoch 00013: val_loss improved from 0.17836 to 0.17534, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/013-0.1753.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0726 - acc: 0.9782 - val_loss: 0.1753 - val_acc: 0.9471\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9764\n",
      "Epoch 00014: val_loss did not improve from 0.17534\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0756 - acc: 0.9764 - val_loss: 0.1914 - val_acc: 0.9422\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9845\n",
      "Epoch 00015: val_loss improved from 0.17534 to 0.16847, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/015-0.1685.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0539 - acc: 0.9845 - val_loss: 0.1685 - val_acc: 0.9492\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9833\n",
      "Epoch 00016: val_loss did not improve from 0.16847\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0553 - acc: 0.9833 - val_loss: 0.1760 - val_acc: 0.9439\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9811\n",
      "Epoch 00017: val_loss improved from 0.16847 to 0.16288, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/017-0.1629.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0596 - acc: 0.9811 - val_loss: 0.1629 - val_acc: 0.9527\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9874\n",
      "Epoch 00018: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0473 - acc: 0.9874 - val_loss: 0.1804 - val_acc: 0.9455\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9911\n",
      "Epoch 00019: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0325 - acc: 0.9911 - val_loss: 0.1885 - val_acc: 0.9448\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9902\n",
      "Epoch 00020: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0359 - acc: 0.9902 - val_loss: 0.1790 - val_acc: 0.9467\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9902\n",
      "Epoch 00021: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0328 - acc: 0.9902 - val_loss: 0.2108 - val_acc: 0.9406\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9927\n",
      "Epoch 00022: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0284 - acc: 0.9927 - val_loss: 0.2413 - val_acc: 0.9404\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9918\n",
      "Epoch 00023: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0295 - acc: 0.9918 - val_loss: 0.1887 - val_acc: 0.9481\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9895\n",
      "Epoch 00024: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0347 - acc: 0.9895 - val_loss: 0.1712 - val_acc: 0.9529\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9945\n",
      "Epoch 00025: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0207 - acc: 0.9945 - val_loss: 0.1738 - val_acc: 0.9499\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9940\n",
      "Epoch 00026: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0219 - acc: 0.9940 - val_loss: 0.2014 - val_acc: 0.9462\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9943\n",
      "Epoch 00027: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0209 - acc: 0.9943 - val_loss: 0.1907 - val_acc: 0.9506\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9938\n",
      "Epoch 00028: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0216 - acc: 0.9938 - val_loss: 0.2370 - val_acc: 0.9357\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9886\n",
      "Epoch 00029: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0375 - acc: 0.9886 - val_loss: 0.1641 - val_acc: 0.9543\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9971\n",
      "Epoch 00030: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0126 - acc: 0.9971 - val_loss: 0.1807 - val_acc: 0.9502\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9911\n",
      "Epoch 00031: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0300 - acc: 0.9911 - val_loss: 0.1709 - val_acc: 0.9534\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9966\n",
      "Epoch 00032: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0129 - acc: 0.9966 - val_loss: 0.1720 - val_acc: 0.9555\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9953\n",
      "Epoch 00033: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0179 - acc: 0.9952 - val_loss: 0.1809 - val_acc: 0.9536\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9929\n",
      "Epoch 00034: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0249 - acc: 0.9929 - val_loss: 0.1776 - val_acc: 0.9536\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 00035: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0093 - acc: 0.9978 - val_loss: 0.1726 - val_acc: 0.9555\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9982\n",
      "Epoch 00036: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0082 - acc: 0.9982 - val_loss: 0.1934 - val_acc: 0.9550\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9915\n",
      "Epoch 00037: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0258 - acc: 0.9915 - val_loss: 0.2012 - val_acc: 0.9513\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9970\n",
      "Epoch 00038: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0115 - acc: 0.9970 - val_loss: 0.1820 - val_acc: 0.9536\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9974\n",
      "Epoch 00039: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0101 - acc: 0.9974 - val_loss: 0.2285 - val_acc: 0.9448\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9964\n",
      "Epoch 00040: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0135 - acc: 0.9964 - val_loss: 0.1926 - val_acc: 0.9534\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9962\n",
      "Epoch 00041: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0130 - acc: 0.9962 - val_loss: 0.2179 - val_acc: 0.9520\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9955\n",
      "Epoch 00042: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0146 - acc: 0.9955 - val_loss: 0.2451 - val_acc: 0.9469\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9975\n",
      "Epoch 00043: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0099 - acc: 0.9975 - val_loss: 0.1832 - val_acc: 0.9571\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9953\n",
      "Epoch 00044: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0160 - acc: 0.9953 - val_loss: 0.1729 - val_acc: 0.9553\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9956\n",
      "Epoch 00045: val_loss did not improve from 0.16288\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0145 - acc: 0.9956 - val_loss: 0.2078 - val_acc: 0.9478\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9948\n",
      "Epoch 00046: val_loss improved from 0.16288 to 0.15663, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_BN_9_conv_checkpoint/046-0.1566.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0165 - acc: 0.9948 - val_loss: 0.1566 - val_acc: 0.9595\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 00047: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0080 - acc: 0.9981 - val_loss: 0.1791 - val_acc: 0.9520\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9943\n",
      "Epoch 00048: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0188 - acc: 0.9943 - val_loss: 0.1767 - val_acc: 0.9569\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9949\n",
      "Epoch 00049: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0167 - acc: 0.9949 - val_loss: 0.1591 - val_acc: 0.9599\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9986\n",
      "Epoch 00050: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0063 - acc: 0.9986 - val_loss: 0.1848 - val_acc: 0.9557\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9988\n",
      "Epoch 00051: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0056 - acc: 0.9988 - val_loss: 0.1733 - val_acc: 0.9592\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9969\n",
      "Epoch 00052: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0120 - acc: 0.9968 - val_loss: 0.2013 - val_acc: 0.9527\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9947\n",
      "Epoch 00053: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0170 - acc: 0.9947 - val_loss: 0.1942 - val_acc: 0.9546\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9989\n",
      "Epoch 00054: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0051 - acc: 0.9989 - val_loss: 0.1662 - val_acc: 0.9581\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 00055: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.1703 - val_acc: 0.9567\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 00056: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0082 - acc: 0.9977 - val_loss: 0.1796 - val_acc: 0.9599\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 00057: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0051 - acc: 0.9988 - val_loss: 0.1899 - val_acc: 0.9548\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9983\n",
      "Epoch 00058: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0067 - acc: 0.9983 - val_loss: 0.2028 - val_acc: 0.9527\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9957\n",
      "Epoch 00059: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0138 - acc: 0.9957 - val_loss: 0.1962 - val_acc: 0.9536\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9949\n",
      "Epoch 00060: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0171 - acc: 0.9948 - val_loss: 0.1878 - val_acc: 0.9569\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9954\n",
      "Epoch 00061: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0149 - acc: 0.9954 - val_loss: 0.1618 - val_acc: 0.9623\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 00062: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0040 - acc: 0.9994 - val_loss: 0.1628 - val_acc: 0.9611\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9980\n",
      "Epoch 00063: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0075 - acc: 0.9980 - val_loss: 0.1762 - val_acc: 0.9606\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00064: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1840 - val_acc: 0.9599\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 00065: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0048 - acc: 0.9986 - val_loss: 0.1657 - val_acc: 0.9616\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 00066: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0063 - acc: 0.9983 - val_loss: 0.2244 - val_acc: 0.9548\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9971\n",
      "Epoch 00067: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0091 - acc: 0.9971 - val_loss: 0.2220 - val_acc: 0.9513\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 00068: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.1738 - val_acc: 0.9606\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 00069: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0051 - acc: 0.9988 - val_loss: 0.1970 - val_acc: 0.9555\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 00070: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0101 - acc: 0.9968 - val_loss: 0.1900 - val_acc: 0.9597\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 00071: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0089 - acc: 0.9972 - val_loss: 0.1976 - val_acc: 0.9543\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9977\n",
      "Epoch 00072: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0069 - acc: 0.9977 - val_loss: 0.2013 - val_acc: 0.9567\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 00073: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0080 - acc: 0.9975 - val_loss: 0.1974 - val_acc: 0.9585\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 00074: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0035 - acc: 0.9990 - val_loss: 0.2333 - val_acc: 0.9495\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9975\n",
      "Epoch 00075: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0086 - acc: 0.9975 - val_loss: 0.2012 - val_acc: 0.9550\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 00076: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.1931 - val_acc: 0.9574\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 00077: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0104 - acc: 0.9965 - val_loss: 0.1750 - val_acc: 0.9588\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00078: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0037 - acc: 0.9993 - val_loss: 0.1780 - val_acc: 0.9627\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00079: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0032 - acc: 0.9991 - val_loss: 0.1977 - val_acc: 0.9597\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9946\n",
      "Epoch 00080: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0169 - acc: 0.9946 - val_loss: 0.2024 - val_acc: 0.9550\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00081: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0032 - acc: 0.9992 - val_loss: 0.1815 - val_acc: 0.9602\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00082: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1823 - val_acc: 0.9602\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00083: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1905 - val_acc: 0.9569\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00084: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.1880 - val_acc: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9961\n",
      "Epoch 00085: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0133 - acc: 0.9960 - val_loss: 0.1751 - val_acc: 0.9616\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00086: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.1749 - val_acc: 0.9620\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 00087: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0031 - acc: 0.9992 - val_loss: 0.1866 - val_acc: 0.9592\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 00088: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1642 - val_acc: 0.9644\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9958\n",
      "Epoch 00089: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0129 - acc: 0.9958 - val_loss: 0.1849 - val_acc: 0.9597\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9968\n",
      "Epoch 00090: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0118 - acc: 0.9968 - val_loss: 0.1781 - val_acc: 0.9630\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 00091: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1734 - val_acc: 0.9639\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 00092: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1893 - val_acc: 0.9616\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00093: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0028 - acc: 0.9994 - val_loss: 0.1905 - val_acc: 0.9630\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 00094: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0063 - acc: 0.9982 - val_loss: 0.1875 - val_acc: 0.9560\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9988\n",
      "Epoch 00095: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0044 - acc: 0.9988 - val_loss: 0.1946 - val_acc: 0.9562\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9969\n",
      "Epoch 00096: val_loss did not improve from 0.15663\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0104 - acc: 0.9969 - val_loss: 0.1751 - val_acc: 0.9637\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2128 - acc: 0.9493\n",
      "Loss: 0.2127867239213095 Accuracy: 0.949325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9, 10):\n",
    "    model_name = '1D_CNN_custom_conv_3_VGG_BN_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,493,136\n",
      "Trainable params: 18,444,880\n",
      "Non-trainable params: 2,048,256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 893us/sample - loss: 9.6000 - acc: 0.3674\n",
      "Loss: 9.600019411085055 Accuracy: 0.36739355\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,864,592\n",
      "Trainable params: 6,181,456\n",
      "Non-trainable params: 683,136\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.7139 - acc: 0.3668\n",
      "Loss: 3.713918998110208 Accuracy: 0.3667705\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,338,128\n",
      "Trainable params: 2,109,904\n",
      "Non-trainable params: 228,224\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 2.0577 - acc: 0.4933\n",
      "Loss: 2.0576771995112657 Accuracy: 0.49325025\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 846,544\n",
      "Trainable params: 769,744\n",
      "Non-trainable params: 76,800\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.2689 - acc: 0.6521\n",
      "Loss: 1.268929294584201 Accuracy: 0.65212876\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 668,112\n",
      "Trainable params: 616,144\n",
      "Non-trainable params: 51,968\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.9899 - acc: 0.7047\n",
      "Loss: 0.9898805419851563 Accuracy: 0.7046729\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 429,776\n",
      "Trainable params: 411,088\n",
      "Non-trainable params: 18,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.6074 - acc: 0.8349\n",
      "Loss: 0.6074317322589403 Accuracy: 0.83489096\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 416,720\n",
      "Trainable params: 408,784\n",
      "Non-trainable params: 7,936\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3032 - acc: 0.9286\n",
      "Loss: 0.3031660705959562 Accuracy: 0.9285566\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 480,464\n",
      "Trainable params: 475,600\n",
      "Non-trainable params: 4,864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2028 - acc: 0.9423\n",
      "Loss: 0.2028081684592852 Accuracy: 0.9422638\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 770,256\n",
      "Trainable params: 765,136\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2128 - acc: 0.9493\n",
      "Loss: 0.2127867239213095 Accuracy: 0.949325\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
