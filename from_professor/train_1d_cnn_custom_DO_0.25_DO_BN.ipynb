{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_025_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_025_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8895 - acc: 0.2294\n",
      "Epoch 00001: val_loss improved from inf to 2.48995, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_1_conv_checkpoint/001-2.4899.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 3.8891 - acc: 0.2295 - val_loss: 2.4899 - val_acc: 0.2057\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5710 - acc: 0.5419\n",
      "Epoch 00002: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.5710 - acc: 0.5419 - val_loss: 2.6835 - val_acc: 0.2756\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0409 - acc: 0.6911\n",
      "Epoch 00003: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0410 - acc: 0.6910 - val_loss: 3.8849 - val_acc: 0.2430\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7923 - acc: 0.7664\n",
      "Epoch 00004: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7923 - acc: 0.7664 - val_loss: 3.3511 - val_acc: 0.2651\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6127 - acc: 0.8266\n",
      "Epoch 00005: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6128 - acc: 0.8265 - val_loss: 3.3694 - val_acc: 0.2774\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4962 - acc: 0.8599\n",
      "Epoch 00006: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4962 - acc: 0.8599 - val_loss: 3.6558 - val_acc: 0.2867\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4048 - acc: 0.8898\n",
      "Epoch 00007: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4048 - acc: 0.8898 - val_loss: 4.9260 - val_acc: 0.2441\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3400 - acc: 0.9096\n",
      "Epoch 00008: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3400 - acc: 0.9096 - val_loss: 4.0995 - val_acc: 0.2923\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.9195\n",
      "Epoch 00009: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3038 - acc: 0.9195 - val_loss: 4.2431 - val_acc: 0.3003\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9343\n",
      "Epoch 00010: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2554 - acc: 0.9344 - val_loss: 4.6818 - val_acc: 0.2632\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9413\n",
      "Epoch 00011: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2353 - acc: 0.9413 - val_loss: 4.8478 - val_acc: 0.2802\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9513\n",
      "Epoch 00012: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2065 - acc: 0.9513 - val_loss: 4.9955 - val_acc: 0.2791\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9561\n",
      "Epoch 00013: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1869 - acc: 0.9561 - val_loss: 5.3684 - val_acc: 0.2784\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9684\n",
      "Epoch 00014: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1446 - acc: 0.9684 - val_loss: 5.0835 - val_acc: 0.2909\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9688\n",
      "Epoch 00015: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1388 - acc: 0.9688 - val_loss: 5.3910 - val_acc: 0.2919\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9620\n",
      "Epoch 00016: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1578 - acc: 0.9620 - val_loss: 6.1876 - val_acc: 0.2618\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9733\n",
      "Epoch 00017: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1269 - acc: 0.9733 - val_loss: 5.5434 - val_acc: 0.2735\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9758\n",
      "Epoch 00018: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1203 - acc: 0.9758 - val_loss: 5.9981 - val_acc: 0.2777\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9786\n",
      "Epoch 00019: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1112 - acc: 0.9785 - val_loss: 5.9034 - val_acc: 0.2814\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9735\n",
      "Epoch 00020: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1232 - acc: 0.9735 - val_loss: 5.6245 - val_acc: 0.3012\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9789\n",
      "Epoch 00021: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1068 - acc: 0.9789 - val_loss: 6.3521 - val_acc: 0.2865\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9813\n",
      "Epoch 00022: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0967 - acc: 0.9813 - val_loss: 6.4129 - val_acc: 0.2870\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9834\n",
      "Epoch 00023: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0878 - acc: 0.9834 - val_loss: 6.0300 - val_acc: 0.2833\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9779\n",
      "Epoch 00024: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1053 - acc: 0.9779 - val_loss: 6.0325 - val_acc: 0.2886\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9818\n",
      "Epoch 00025: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0929 - acc: 0.9818 - val_loss: 6.2879 - val_acc: 0.2770\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9809\n",
      "Epoch 00026: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0945 - acc: 0.9809 - val_loss: 6.5796 - val_acc: 0.2681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9844\n",
      "Epoch 00027: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0821 - acc: 0.9844 - val_loss: 7.0044 - val_acc: 0.2602\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9874\n",
      "Epoch 00028: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0772 - acc: 0.9874 - val_loss: 6.5126 - val_acc: 0.2835\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9894\n",
      "Epoch 00029: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0707 - acc: 0.9894 - val_loss: 7.1590 - val_acc: 0.2648\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9886\n",
      "Epoch 00030: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0695 - acc: 0.9886 - val_loss: 7.2800 - val_acc: 0.2648\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9846\n",
      "Epoch 00031: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0832 - acc: 0.9846 - val_loss: 6.9945 - val_acc: 0.2665\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9818\n",
      "Epoch 00032: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0921 - acc: 0.9819 - val_loss: 7.1289 - val_acc: 0.2800\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9859\n",
      "Epoch 00033: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0805 - acc: 0.9859 - val_loss: 6.4717 - val_acc: 0.3003\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9892\n",
      "Epoch 00034: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0671 - acc: 0.9892 - val_loss: 6.6975 - val_acc: 0.2914\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9894\n",
      "Epoch 00035: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0684 - acc: 0.9894 - val_loss: 6.5203 - val_acc: 0.3033\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9891\n",
      "Epoch 00036: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0684 - acc: 0.9891 - val_loss: 7.5313 - val_acc: 0.2786\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9885\n",
      "Epoch 00037: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0696 - acc: 0.9885 - val_loss: 7.5800 - val_acc: 0.2660\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9891\n",
      "Epoch 00038: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0696 - acc: 0.9891 - val_loss: 6.9688 - val_acc: 0.2893\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9899\n",
      "Epoch 00039: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.0647 - acc: 0.9899 - val_loss: 8.1058 - val_acc: 0.2669\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9886\n",
      "Epoch 00040: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0677 - acc: 0.9886 - val_loss: 7.4193 - val_acc: 0.2686\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9904\n",
      "Epoch 00041: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0644 - acc: 0.9904 - val_loss: 7.5027 - val_acc: 0.2784\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9907\n",
      "Epoch 00042: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0619 - acc: 0.9907 - val_loss: 6.9130 - val_acc: 0.2977\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9908\n",
      "Epoch 00043: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0614 - acc: 0.9908 - val_loss: 7.0894 - val_acc: 0.2898\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9884\n",
      "Epoch 00044: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0690 - acc: 0.9884 - val_loss: 7.4936 - val_acc: 0.2660\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9911\n",
      "Epoch 00045: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0592 - acc: 0.9911 - val_loss: 7.2556 - val_acc: 0.2826\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9911\n",
      "Epoch 00046: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0579 - acc: 0.9911 - val_loss: 7.0236 - val_acc: 0.2937\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9904\n",
      "Epoch 00047: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0610 - acc: 0.9903 - val_loss: 7.7301 - val_acc: 0.2704\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9925\n",
      "Epoch 00048: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0544 - acc: 0.9925 - val_loss: 7.4485 - val_acc: 0.2819\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9944\n",
      "Epoch 00049: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0489 - acc: 0.9944 - val_loss: 7.0618 - val_acc: 0.2923\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9915\n",
      "Epoch 00050: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0568 - acc: 0.9915 - val_loss: 6.9956 - val_acc: 0.2991\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9916\n",
      "Epoch 00051: val_loss did not improve from 2.48995\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0570 - acc: 0.9916 - val_loss: 8.0562 - val_acc: 0.2751\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 406us/sample - loss: 2.5254 - acc: 0.2069\n",
      "Loss: 2.5254280345338405 Accuracy: 0.20685358\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9660 - acc: 0.2614\n",
      "Epoch 00001: val_loss improved from inf to 4.33879, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_2_conv_checkpoint/001-4.3388.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 4.9660 - acc: 0.2614 - val_loss: 4.3388 - val_acc: 0.2863\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9934 - acc: 0.4211\n",
      "Epoch 00002: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 3.9936 - acc: 0.4210 - val_loss: 4.4165 - val_acc: 0.3007\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.6382 - acc: 0.5160\n",
      "Epoch 00003: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 3.6380 - acc: 0.5160 - val_loss: 4.4716 - val_acc: 0.3666\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3080 - acc: 0.6010\n",
      "Epoch 00004: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 3.3080 - acc: 0.6010 - val_loss: 4.6365 - val_acc: 0.3403\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1003 - acc: 0.6651\n",
      "Epoch 00005: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 3.1004 - acc: 0.6650 - val_loss: 5.0170 - val_acc: 0.3443\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.9962 - acc: 0.6976\n",
      "Epoch 00006: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.9959 - acc: 0.6976 - val_loss: 5.2386 - val_acc: 0.3380\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8543 - acc: 0.7416\n",
      "Epoch 00007: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.8540 - acc: 0.7416 - val_loss: 5.2639 - val_acc: 0.3310\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8440 - acc: 0.7443\n",
      "Epoch 00008: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.8439 - acc: 0.7443 - val_loss: 5.3933 - val_acc: 0.3471\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8048 - acc: 0.7591\n",
      "Epoch 00009: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.8058 - acc: 0.7590 - val_loss: 5.2583 - val_acc: 0.3727\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7545 - acc: 0.7765\n",
      "Epoch 00010: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.7541 - acc: 0.7765 - val_loss: 5.3525 - val_acc: 0.3625\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7402 - acc: 0.7793\n",
      "Epoch 00011: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.7403 - acc: 0.7792 - val_loss: 6.2460 - val_acc: 0.3222\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7265 - acc: 0.7846\n",
      "Epoch 00012: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.7268 - acc: 0.7846 - val_loss: 7.6512 - val_acc: 0.2714\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.0154 - acc: 0.7098\n",
      "Epoch 00013: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 4.0162 - acc: 0.7098 - val_loss: 6.1408 - val_acc: 0.3464\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6941 - acc: 0.7947\n",
      "Epoch 00014: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6946 - acc: 0.7946 - val_loss: 5.8961 - val_acc: 0.3601\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6728 - acc: 0.8004\n",
      "Epoch 00015: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6737 - acc: 0.8004 - val_loss: 6.0503 - val_acc: 0.3566\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6561 - acc: 0.8060\n",
      "Epoch 00016: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6566 - acc: 0.8060 - val_loss: 6.9767 - val_acc: 0.3084\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6524 - acc: 0.8081\n",
      "Epoch 00017: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6524 - acc: 0.8081 - val_loss: 6.1652 - val_acc: 0.3657\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6901 - acc: 0.7992\n",
      "Epoch 00018: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6902 - acc: 0.7992 - val_loss: 6.9433 - val_acc: 0.3138\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6333 - acc: 0.8133\n",
      "Epoch 00019: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6330 - acc: 0.8133 - val_loss: 6.0653 - val_acc: 0.3583\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6426 - acc: 0.8124\n",
      "Epoch 00020: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6427 - acc: 0.8124 - val_loss: 6.9861 - val_acc: 0.2940\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6429 - acc: 0.8108\n",
      "Epoch 00021: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6434 - acc: 0.8107 - val_loss: 6.6403 - val_acc: 0.3559\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6231 - acc: 0.8188\n",
      "Epoch 00022: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6236 - acc: 0.8188 - val_loss: 6.7795 - val_acc: 0.3433\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6182 - acc: 0.8205\n",
      "Epoch 00023: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6179 - acc: 0.8206 - val_loss: 6.1809 - val_acc: 0.3785\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6202 - acc: 0.8183\n",
      "Epoch 00024: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6199 - acc: 0.8183 - val_loss: 7.1304 - val_acc: 0.3245\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6209 - acc: 0.8197\n",
      "Epoch 00025: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6206 - acc: 0.8197 - val_loss: 6.4723 - val_acc: 0.3510\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6319 - acc: 0.8180\n",
      "Epoch 00026: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6325 - acc: 0.8180 - val_loss: 6.7274 - val_acc: 0.3657\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5988 - acc: 0.8251\n",
      "Epoch 00027: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.5989 - acc: 0.8251 - val_loss: 6.8643 - val_acc: 0.3559\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6191 - acc: 0.8197\n",
      "Epoch 00028: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6192 - acc: 0.8197 - val_loss: 6.8297 - val_acc: 0.3578\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6014 - acc: 0.8243\n",
      "Epoch 00029: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6015 - acc: 0.8243 - val_loss: 6.3026 - val_acc: 0.3748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6005 - acc: 0.8246\n",
      "Epoch 00030: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 2.6010 - acc: 0.8246 - val_loss: 6.8246 - val_acc: 0.3673\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5981 - acc: 0.8257\n",
      "Epoch 00031: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 2.5978 - acc: 0.8257 - val_loss: 6.4996 - val_acc: 0.3802\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6048 - acc: 0.8241\n",
      "Epoch 00032: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6045 - acc: 0.8241 - val_loss: 7.3339 - val_acc: 0.3275\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6091 - acc: 0.8228\n",
      "Epoch 00033: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.6096 - acc: 0.8228 - val_loss: 7.0832 - val_acc: 0.3506\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5986 - acc: 0.8265\n",
      "Epoch 00034: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.5987 - acc: 0.8265 - val_loss: 6.9063 - val_acc: 0.3496\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9890 - acc: 0.8277\n",
      "Epoch 00035: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.9888 - acc: 0.8277 - val_loss: 5.4151 - val_acc: 0.3939\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4960 - acc: 0.8686\n",
      "Epoch 00036: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.4958 - acc: 0.8687 - val_loss: 5.1024 - val_acc: 0.4044\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3959 - acc: 0.8928\n",
      "Epoch 00037: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3957 - acc: 0.8928 - val_loss: 5.7189 - val_acc: 0.3538\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3610 - acc: 0.9035\n",
      "Epoch 00038: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3608 - acc: 0.9035 - val_loss: 5.3423 - val_acc: 0.4107\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3512 - acc: 0.9053\n",
      "Epoch 00039: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3515 - acc: 0.9053 - val_loss: 5.7575 - val_acc: 0.4011\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3560 - acc: 0.9040\n",
      "Epoch 00040: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3559 - acc: 0.9040 - val_loss: 5.6151 - val_acc: 0.4002\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3635 - acc: 0.9026\n",
      "Epoch 00041: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3633 - acc: 0.9026 - val_loss: 5.9838 - val_acc: 0.3823\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3513 - acc: 0.9052\n",
      "Epoch 00042: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3512 - acc: 0.9052 - val_loss: 6.3323 - val_acc: 0.3655\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3670 - acc: 0.9024\n",
      "Epoch 00043: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3668 - acc: 0.9024 - val_loss: 6.2410 - val_acc: 0.3760\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3416 - acc: 0.9087\n",
      "Epoch 00044: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3414 - acc: 0.9087 - val_loss: 5.7964 - val_acc: 0.3869\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3531 - acc: 0.9048\n",
      "Epoch 00045: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3529 - acc: 0.9048 - val_loss: 5.9627 - val_acc: 0.3909\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3555 - acc: 0.9046\n",
      "Epoch 00046: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3553 - acc: 0.9046 - val_loss: 6.0549 - val_acc: 0.3941\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3343 - acc: 0.9112\n",
      "Epoch 00047: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3350 - acc: 0.9112 - val_loss: 6.3522 - val_acc: 0.3774\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3421 - acc: 0.9081\n",
      "Epoch 00048: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3428 - acc: 0.9080 - val_loss: 6.0071 - val_acc: 0.3867\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3372 - acc: 0.9105\n",
      "Epoch 00049: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3370 - acc: 0.9106 - val_loss: 6.2901 - val_acc: 0.3748\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3427 - acc: 0.9086\n",
      "Epoch 00050: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3425 - acc: 0.9086 - val_loss: 6.8712 - val_acc: 0.3450\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3473 - acc: 0.9073\n",
      "Epoch 00051: val_loss did not improve from 4.33879\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3472 - acc: 0.9073 - val_loss: 5.9350 - val_acc: 0.3850\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 698us/sample - loss: 4.4010 - acc: 0.2760\n",
      "Loss: 4.401042298488281 Accuracy: 0.27601245\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1249 - acc: 0.3720\n",
      "Epoch 00001: val_loss improved from inf to 1.74177, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_3_conv_checkpoint/001-1.7418.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 2.1248 - acc: 0.3720 - val_loss: 1.7418 - val_acc: 0.4470\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3948 - acc: 0.5676\n",
      "Epoch 00002: val_loss did not improve from 1.74177\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.3947 - acc: 0.5676 - val_loss: 1.7816 - val_acc: 0.4698\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0684 - acc: 0.6674\n",
      "Epoch 00003: val_loss improved from 1.74177 to 1.55105, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_3_conv_checkpoint/003-1.5510.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.0684 - acc: 0.6674 - val_loss: 1.5510 - val_acc: 0.5264\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8410 - acc: 0.7345\n",
      "Epoch 00004: val_loss did not improve from 1.55105\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8411 - acc: 0.7345 - val_loss: 1.7326 - val_acc: 0.5320\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6589 - acc: 0.7886\n",
      "Epoch 00005: val_loss did not improve from 1.55105\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.6590 - acc: 0.7886 - val_loss: 1.7333 - val_acc: 0.5446\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5045 - acc: 0.8399\n",
      "Epoch 00006: val_loss improved from 1.55105 to 1.51802, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_3_conv_checkpoint/006-1.5180.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.5045 - acc: 0.8399 - val_loss: 1.5180 - val_acc: 0.6031\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8772\n",
      "Epoch 00007: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3949 - acc: 0.8772 - val_loss: 1.8500 - val_acc: 0.5607\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8954\n",
      "Epoch 00008: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3317 - acc: 0.8954 - val_loss: 1.9995 - val_acc: 0.5325\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9159\n",
      "Epoch 00009: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2717 - acc: 0.9159 - val_loss: 1.8191 - val_acc: 0.5919\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9327\n",
      "Epoch 00010: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2206 - acc: 0.9327 - val_loss: 1.9587 - val_acc: 0.5635\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9307\n",
      "Epoch 00011: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2248 - acc: 0.9307 - val_loss: 1.9484 - val_acc: 0.5691\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9430\n",
      "Epoch 00012: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1846 - acc: 0.9430 - val_loss: 2.0082 - val_acc: 0.5849\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9522\n",
      "Epoch 00013: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1598 - acc: 0.9522 - val_loss: 2.1185 - val_acc: 0.5698\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9517\n",
      "Epoch 00014: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1584 - acc: 0.9517 - val_loss: 2.2149 - val_acc: 0.5628\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9613\n",
      "Epoch 00015: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1314 - acc: 0.9613 - val_loss: 2.0699 - val_acc: 0.5833\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9638\n",
      "Epoch 00016: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1262 - acc: 0.9638 - val_loss: 2.0133 - val_acc: 0.5966\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9683\n",
      "Epoch 00017: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1126 - acc: 0.9683 - val_loss: 2.1005 - val_acc: 0.5882\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9715\n",
      "Epoch 00018: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1024 - acc: 0.9715 - val_loss: 2.4193 - val_acc: 0.5637\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9633\n",
      "Epoch 00019: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1236 - acc: 0.9633 - val_loss: 2.4659 - val_acc: 0.5681\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9729\n",
      "Epoch 00020: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0991 - acc: 0.9729 - val_loss: 2.4810 - val_acc: 0.5639\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9710\n",
      "Epoch 00021: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0976 - acc: 0.9710 - val_loss: 2.3312 - val_acc: 0.5809\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9714\n",
      "Epoch 00022: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0991 - acc: 0.9714 - val_loss: 2.3533 - val_acc: 0.5805\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9687\n",
      "Epoch 00023: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1069 - acc: 0.9687 - val_loss: 2.4985 - val_acc: 0.5816\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9787\n",
      "Epoch 00024: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0759 - acc: 0.9787 - val_loss: 2.5293 - val_acc: 0.5698\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9751\n",
      "Epoch 00025: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0837 - acc: 0.9751 - val_loss: 2.3543 - val_acc: 0.5919\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9791\n",
      "Epoch 00026: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0744 - acc: 0.9791 - val_loss: 2.4202 - val_acc: 0.6012\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9752\n",
      "Epoch 00027: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0852 - acc: 0.9752 - val_loss: 2.2209 - val_acc: 0.6173\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9822\n",
      "Epoch 00028: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0604 - acc: 0.9822 - val_loss: 2.7016 - val_acc: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9811\n",
      "Epoch 00029: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0682 - acc: 0.9811 - val_loss: 2.8234 - val_acc: 0.5665\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9789\n",
      "Epoch 00030: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0745 - acc: 0.9789 - val_loss: 2.2936 - val_acc: 0.6201\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9876\n",
      "Epoch 00031: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0471 - acc: 0.9875 - val_loss: 2.7262 - val_acc: 0.5882\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9804\n",
      "Epoch 00032: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0690 - acc: 0.9804 - val_loss: 2.5701 - val_acc: 0.5952\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9848\n",
      "Epoch 00033: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0561 - acc: 0.9848 - val_loss: 2.6355 - val_acc: 0.5886\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9840\n",
      "Epoch 00034: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0584 - acc: 0.9841 - val_loss: 2.5593 - val_acc: 0.5993\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9858\n",
      "Epoch 00035: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0516 - acc: 0.9858 - val_loss: 2.6116 - val_acc: 0.5975\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9830\n",
      "Epoch 00036: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0603 - acc: 0.9830 - val_loss: 2.7327 - val_acc: 0.5830\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9845\n",
      "Epoch 00037: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0547 - acc: 0.9845 - val_loss: 2.7806 - val_acc: 0.5602\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9862\n",
      "Epoch 00038: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0497 - acc: 0.9862 - val_loss: 2.7595 - val_acc: 0.5828\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9823\n",
      "Epoch 00039: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0597 - acc: 0.9823 - val_loss: 2.6408 - val_acc: 0.5945\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9858\n",
      "Epoch 00040: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0522 - acc: 0.9858 - val_loss: 3.5659 - val_acc: 0.5162\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9878\n",
      "Epoch 00041: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0437 - acc: 0.9877 - val_loss: 2.5977 - val_acc: 0.6096\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9911\n",
      "Epoch 00042: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0362 - acc: 0.9911 - val_loss: 2.8690 - val_acc: 0.5863\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9876\n",
      "Epoch 00043: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0489 - acc: 0.9876 - val_loss: 2.6959 - val_acc: 0.5914\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9885\n",
      "Epoch 00044: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0415 - acc: 0.9885 - val_loss: 2.9585 - val_acc: 0.5749\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9867\n",
      "Epoch 00045: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0502 - acc: 0.9867 - val_loss: 2.9537 - val_acc: 0.5802\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9866\n",
      "Epoch 00046: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0498 - acc: 0.9866 - val_loss: 2.7661 - val_acc: 0.5980\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9853\n",
      "Epoch 00047: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0520 - acc: 0.9853 - val_loss: 2.6639 - val_acc: 0.6077\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9921\n",
      "Epoch 00048: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0331 - acc: 0.9921 - val_loss: 2.6052 - val_acc: 0.6098\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9885\n",
      "Epoch 00049: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0423 - acc: 0.9885 - val_loss: 3.3116 - val_acc: 0.5469\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9886\n",
      "Epoch 00050: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0404 - acc: 0.9886 - val_loss: 2.5752 - val_acc: 0.6201\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9887\n",
      "Epoch 00051: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0421 - acc: 0.9887 - val_loss: 2.9148 - val_acc: 0.5795\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9861\n",
      "Epoch 00052: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0518 - acc: 0.9861 - val_loss: 2.7183 - val_acc: 0.6077\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9921\n",
      "Epoch 00053: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0327 - acc: 0.9921 - val_loss: 2.8322 - val_acc: 0.6061\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9904\n",
      "Epoch 00054: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0365 - acc: 0.9904 - val_loss: 2.8684 - val_acc: 0.5956\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9923\n",
      "Epoch 00055: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0302 - acc: 0.9923 - val_loss: 2.9977 - val_acc: 0.5912\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9899\n",
      "Epoch 00056: val_loss did not improve from 1.51802\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0388 - acc: 0.9899 - val_loss: 2.9961 - val_acc: 0.5695\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 814us/sample - loss: 1.6474 - acc: 0.5639\n",
      "Loss: 1.647401433520847 Accuracy: 0.5638629\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9213 - acc: 0.4033\n",
      "Epoch 00001: val_loss improved from inf to 1.63404, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/001-1.6340.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.9212 - acc: 0.4033 - val_loss: 1.6340 - val_acc: 0.4498\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2639 - acc: 0.6059\n",
      "Epoch 00002: val_loss improved from 1.63404 to 1.14084, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/002-1.1408.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2639 - acc: 0.6059 - val_loss: 1.1408 - val_acc: 0.6464\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0518 - acc: 0.6762\n",
      "Epoch 00003: val_loss did not improve from 1.14084\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0517 - acc: 0.6762 - val_loss: 1.1644 - val_acc: 0.6385\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9030 - acc: 0.7215\n",
      "Epoch 00004: val_loss improved from 1.14084 to 1.08855, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/004-1.0886.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9031 - acc: 0.7215 - val_loss: 1.0886 - val_acc: 0.6681\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7972 - acc: 0.7537\n",
      "Epoch 00005: val_loss improved from 1.08855 to 1.06591, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/005-1.0659.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7973 - acc: 0.7536 - val_loss: 1.0659 - val_acc: 0.6883\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.7865\n",
      "Epoch 00006: val_loss improved from 1.06591 to 1.05667, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/006-1.0567.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6936 - acc: 0.7865 - val_loss: 1.0567 - val_acc: 0.6844\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.8076\n",
      "Epoch 00007: val_loss did not improve from 1.05667\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6133 - acc: 0.8076 - val_loss: 1.0796 - val_acc: 0.6881\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5332 - acc: 0.8334\n",
      "Epoch 00008: val_loss improved from 1.05667 to 1.05167, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/008-1.0517.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5332 - acc: 0.8334 - val_loss: 1.0517 - val_acc: 0.7014\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4759 - acc: 0.8532\n",
      "Epoch 00009: val_loss did not improve from 1.05167\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4760 - acc: 0.8532 - val_loss: 1.1847 - val_acc: 0.6587\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4229 - acc: 0.8683\n",
      "Epoch 00010: val_loss improved from 1.05167 to 1.02818, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_4_conv_checkpoint/010-1.0282.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4229 - acc: 0.8684 - val_loss: 1.0282 - val_acc: 0.7093\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3626 - acc: 0.8885\n",
      "Epoch 00011: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3626 - acc: 0.8885 - val_loss: 1.0778 - val_acc: 0.7053\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3205 - acc: 0.9007\n",
      "Epoch 00012: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3204 - acc: 0.9007 - val_loss: 1.0471 - val_acc: 0.7188\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.9126\n",
      "Epoch 00013: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2897 - acc: 0.9126 - val_loss: 1.0512 - val_acc: 0.7144\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.9190\n",
      "Epoch 00014: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2682 - acc: 0.9190 - val_loss: 1.2896 - val_acc: 0.6753\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.9275\n",
      "Epoch 00015: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2410 - acc: 0.9275 - val_loss: 1.3135 - val_acc: 0.6716\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9340\n",
      "Epoch 00016: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2194 - acc: 0.9340 - val_loss: 1.2765 - val_acc: 0.6804\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9436\n",
      "Epoch 00017: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1957 - acc: 0.9436 - val_loss: 1.1292 - val_acc: 0.7184\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9489\n",
      "Epoch 00018: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1779 - acc: 0.9488 - val_loss: 1.3392 - val_acc: 0.6923\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9480\n",
      "Epoch 00019: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1791 - acc: 0.9481 - val_loss: 1.2774 - val_acc: 0.7030\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9568\n",
      "Epoch 00020: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1505 - acc: 0.9568 - val_loss: 1.1542 - val_acc: 0.7277\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9586\n",
      "Epoch 00021: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1463 - acc: 0.9586 - val_loss: 1.2125 - val_acc: 0.7167\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9615\n",
      "Epoch 00022: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1375 - acc: 0.9615 - val_loss: 1.2636 - val_acc: 0.7088\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9621\n",
      "Epoch 00023: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1358 - acc: 0.9621 - val_loss: 1.1952 - val_acc: 0.7265\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9651\n",
      "Epoch 00024: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1214 - acc: 0.9651 - val_loss: 1.5224 - val_acc: 0.6774\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9660\n",
      "Epoch 00025: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1181 - acc: 0.9660 - val_loss: 1.5126 - val_acc: 0.6792\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9675\n",
      "Epoch 00026: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1163 - acc: 0.9675 - val_loss: 1.2739 - val_acc: 0.7209\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9673\n",
      "Epoch 00027: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1127 - acc: 0.9673 - val_loss: 1.4960 - val_acc: 0.6692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9724\n",
      "Epoch 00028: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0975 - acc: 0.9724 - val_loss: 1.2868 - val_acc: 0.7191\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9745\n",
      "Epoch 00029: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0930 - acc: 0.9745 - val_loss: 1.4682 - val_acc: 0.6860\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9736\n",
      "Epoch 00030: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0950 - acc: 0.9736 - val_loss: 1.2691 - val_acc: 0.7244\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9753\n",
      "Epoch 00031: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0886 - acc: 0.9753 - val_loss: 1.3955 - val_acc: 0.7046\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9751\n",
      "Epoch 00032: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0890 - acc: 0.9751 - val_loss: 1.4080 - val_acc: 0.7035\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9757\n",
      "Epoch 00033: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0888 - acc: 0.9757 - val_loss: 1.5058 - val_acc: 0.6942\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9756\n",
      "Epoch 00034: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0852 - acc: 0.9756 - val_loss: 1.3930 - val_acc: 0.7116\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9813\n",
      "Epoch 00035: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0697 - acc: 0.9813 - val_loss: 1.3495 - val_acc: 0.7256\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9809\n",
      "Epoch 00036: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0710 - acc: 0.9809 - val_loss: 1.3261 - val_acc: 0.7277\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9776\n",
      "Epoch 00037: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0797 - acc: 0.9776 - val_loss: 1.7166 - val_acc: 0.6690\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9819\n",
      "Epoch 00038: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0682 - acc: 0.9819 - val_loss: 1.3487 - val_acc: 0.7167\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9798\n",
      "Epoch 00039: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0730 - acc: 0.9798 - val_loss: 1.4323 - val_acc: 0.7151\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9819\n",
      "Epoch 00040: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0660 - acc: 0.9819 - val_loss: 1.4903 - val_acc: 0.7130\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9820\n",
      "Epoch 00041: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0648 - acc: 0.9820 - val_loss: 1.6125 - val_acc: 0.6900\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9831\n",
      "Epoch 00042: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0633 - acc: 0.9830 - val_loss: 1.5532 - val_acc: 0.7002\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9804\n",
      "Epoch 00043: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0716 - acc: 0.9804 - val_loss: 1.4065 - val_acc: 0.7284\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9831\n",
      "Epoch 00044: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0617 - acc: 0.9831 - val_loss: 1.3746 - val_acc: 0.7310\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9856\n",
      "Epoch 00045: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0533 - acc: 0.9855 - val_loss: 1.3744 - val_acc: 0.7363\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9818\n",
      "Epoch 00046: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0656 - acc: 0.9818 - val_loss: 1.3560 - val_acc: 0.7428\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9803\n",
      "Epoch 00047: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0684 - acc: 0.9803 - val_loss: 1.4919 - val_acc: 0.7186\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9820\n",
      "Epoch 00048: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0656 - acc: 0.9820 - val_loss: 1.3704 - val_acc: 0.7403\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9859\n",
      "Epoch 00049: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0533 - acc: 0.9859 - val_loss: 1.6302 - val_acc: 0.6865\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9866\n",
      "Epoch 00050: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0519 - acc: 0.9866 - val_loss: 1.3926 - val_acc: 0.7303\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9879\n",
      "Epoch 00051: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0459 - acc: 0.9879 - val_loss: 1.5056 - val_acc: 0.7170\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9844\n",
      "Epoch 00052: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0580 - acc: 0.9844 - val_loss: 1.4864 - val_acc: 0.7221\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9844\n",
      "Epoch 00053: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0571 - acc: 0.9844 - val_loss: 1.4724 - val_acc: 0.7277\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9890\n",
      "Epoch 00054: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0436 - acc: 0.9890 - val_loss: 1.5086 - val_acc: 0.7282\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9858\n",
      "Epoch 00055: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0529 - acc: 0.9858 - val_loss: 1.6199 - val_acc: 0.7128\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9864\n",
      "Epoch 00056: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0512 - acc: 0.9864 - val_loss: 1.3323 - val_acc: 0.7522\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9856\n",
      "Epoch 00057: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0531 - acc: 0.9856 - val_loss: 1.6546 - val_acc: 0.7063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9871\n",
      "Epoch 00058: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0498 - acc: 0.9871 - val_loss: 1.4267 - val_acc: 0.7365\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9856\n",
      "Epoch 00059: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0500 - acc: 0.9856 - val_loss: 1.6090 - val_acc: 0.7093\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9906\n",
      "Epoch 00060: val_loss did not improve from 1.02818\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0381 - acc: 0.9906 - val_loss: 1.5021 - val_acc: 0.7244\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 848us/sample - loss: 1.1698 - acc: 0.6625\n",
      "Loss: 1.1697958334955472 Accuracy: 0.66251296\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8453 - acc: 0.4267\n",
      "Epoch 00001: val_loss improved from inf to 1.63311, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/001-1.6331.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 1.8454 - acc: 0.4266 - val_loss: 1.6331 - val_acc: 0.4687\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1754 - acc: 0.6339\n",
      "Epoch 00002: val_loss improved from 1.63311 to 1.00287, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/002-1.0029.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1753 - acc: 0.6340 - val_loss: 1.0029 - val_acc: 0.6830\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.7009\n",
      "Epoch 00003: val_loss improved from 1.00287 to 0.99236, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/003-0.9924.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9651 - acc: 0.7009 - val_loss: 0.9924 - val_acc: 0.6855\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8519 - acc: 0.7389\n",
      "Epoch 00004: val_loss improved from 0.99236 to 0.97088, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/004-0.9709.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8518 - acc: 0.7388 - val_loss: 0.9709 - val_acc: 0.7079\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7487 - acc: 0.7714\n",
      "Epoch 00005: val_loss improved from 0.97088 to 0.93554, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/005-0.9355.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7487 - acc: 0.7714 - val_loss: 0.9355 - val_acc: 0.7230\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6869 - acc: 0.7912\n",
      "Epoch 00006: val_loss improved from 0.93554 to 0.83779, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/006-0.8378.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6869 - acc: 0.7912 - val_loss: 0.8378 - val_acc: 0.7531\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6142 - acc: 0.8133\n",
      "Epoch 00007: val_loss did not improve from 0.83779\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6143 - acc: 0.8133 - val_loss: 0.8466 - val_acc: 0.7566\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5632 - acc: 0.8289\n",
      "Epoch 00008: val_loss did not improve from 0.83779\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5631 - acc: 0.8290 - val_loss: 0.8552 - val_acc: 0.7552\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5049 - acc: 0.8467\n",
      "Epoch 00009: val_loss did not improve from 0.83779\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5049 - acc: 0.8467 - val_loss: 0.8500 - val_acc: 0.7556\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.8585\n",
      "Epoch 00010: val_loss did not improve from 0.83779\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4628 - acc: 0.8585 - val_loss: 1.0415 - val_acc: 0.7126\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4278 - acc: 0.8687\n",
      "Epoch 00011: val_loss did not improve from 0.83779\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4278 - acc: 0.8687 - val_loss: 0.9099 - val_acc: 0.7482\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3847 - acc: 0.8839\n",
      "Epoch 00012: val_loss improved from 0.83779 to 0.82540, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/012-0.8254.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3847 - acc: 0.8840 - val_loss: 0.8254 - val_acc: 0.7661\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3508 - acc: 0.8923\n",
      "Epoch 00013: val_loss did not improve from 0.82540\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3508 - acc: 0.8923 - val_loss: 0.8351 - val_acc: 0.7750\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3202 - acc: 0.9023\n",
      "Epoch 00014: val_loss improved from 0.82540 to 0.78493, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_5_conv_checkpoint/014-0.7849.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3202 - acc: 0.9023 - val_loss: 0.7849 - val_acc: 0.7820\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9136\n",
      "Epoch 00015: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2858 - acc: 0.9136 - val_loss: 0.8053 - val_acc: 0.7892\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9193\n",
      "Epoch 00016: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2656 - acc: 0.9193 - val_loss: 0.9025 - val_acc: 0.7659\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9243\n",
      "Epoch 00017: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2502 - acc: 0.9242 - val_loss: 0.8522 - val_acc: 0.7694\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9337\n",
      "Epoch 00018: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2223 - acc: 0.9337 - val_loss: 0.8095 - val_acc: 0.7913\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9382\n",
      "Epoch 00019: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2074 - acc: 0.9382 - val_loss: 0.9491 - val_acc: 0.7638\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9413\n",
      "Epoch 00020: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1947 - acc: 0.9412 - val_loss: 0.8931 - val_acc: 0.7838\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9499\n",
      "Epoch 00021: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1750 - acc: 0.9499 - val_loss: 0.8513 - val_acc: 0.7880\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9507\n",
      "Epoch 00022: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1682 - acc: 0.9506 - val_loss: 0.8599 - val_acc: 0.7852\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9551\n",
      "Epoch 00023: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1540 - acc: 0.9551 - val_loss: 0.8455 - val_acc: 0.7978\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9560\n",
      "Epoch 00024: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1461 - acc: 0.9560 - val_loss: 0.8577 - val_acc: 0.7885\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9591\n",
      "Epoch 00025: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1337 - acc: 0.9591 - val_loss: 0.9274 - val_acc: 0.7838\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9626\n",
      "Epoch 00026: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1285 - acc: 0.9626 - val_loss: 0.9364 - val_acc: 0.7822\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9658\n",
      "Epoch 00027: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1203 - acc: 0.9657 - val_loss: 1.0088 - val_acc: 0.7629\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9619\n",
      "Epoch 00028: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1309 - acc: 0.9619 - val_loss: 0.9481 - val_acc: 0.7773\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9695\n",
      "Epoch 00029: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1049 - acc: 0.9695 - val_loss: 1.0633 - val_acc: 0.7615\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9728\n",
      "Epoch 00030: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0976 - acc: 0.9728 - val_loss: 0.9533 - val_acc: 0.7852\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9732\n",
      "Epoch 00031: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0939 - acc: 0.9732 - val_loss: 1.0022 - val_acc: 0.7775\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9709\n",
      "Epoch 00032: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0985 - acc: 0.9709 - val_loss: 0.9533 - val_acc: 0.7843\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9738\n",
      "Epoch 00033: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0940 - acc: 0.9738 - val_loss: 0.9948 - val_acc: 0.7803\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9754\n",
      "Epoch 00034: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0872 - acc: 0.9753 - val_loss: 0.8650 - val_acc: 0.8067\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9748\n",
      "Epoch 00035: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0892 - acc: 0.9748 - val_loss: 1.0664 - val_acc: 0.7645\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9769\n",
      "Epoch 00036: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0808 - acc: 0.9769 - val_loss: 0.8739 - val_acc: 0.8015\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9762\n",
      "Epoch 00037: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0838 - acc: 0.9762 - val_loss: 1.1533 - val_acc: 0.7538\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9787\n",
      "Epoch 00038: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0758 - acc: 0.9787 - val_loss: 0.9234 - val_acc: 0.7950\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9784\n",
      "Epoch 00039: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0780 - acc: 0.9784 - val_loss: 0.9122 - val_acc: 0.7999\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9827\n",
      "Epoch 00040: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0639 - acc: 0.9827 - val_loss: 0.9472 - val_acc: 0.7985\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9804\n",
      "Epoch 00041: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0679 - acc: 0.9804 - val_loss: 1.0646 - val_acc: 0.7815\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9814\n",
      "Epoch 00042: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0663 - acc: 0.9814 - val_loss: 1.0322 - val_acc: 0.7752\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9805\n",
      "Epoch 00043: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0704 - acc: 0.9805 - val_loss: 0.8908 - val_acc: 0.8139\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9850\n",
      "Epoch 00044: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0561 - acc: 0.9849 - val_loss: 1.0414 - val_acc: 0.8018\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9821\n",
      "Epoch 00045: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0623 - acc: 0.9821 - val_loss: 0.9633 - val_acc: 0.7932\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9841\n",
      "Epoch 00046: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0572 - acc: 0.9841 - val_loss: 1.0256 - val_acc: 0.7850\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9790\n",
      "Epoch 00047: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0725 - acc: 0.9790 - val_loss: 0.9816 - val_acc: 0.8020\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9838\n",
      "Epoch 00048: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0573 - acc: 0.9837 - val_loss: 0.9622 - val_acc: 0.8001\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9810\n",
      "Epoch 00049: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0691 - acc: 0.9810 - val_loss: 1.0729 - val_acc: 0.7892\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9851\n",
      "Epoch 00050: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0531 - acc: 0.9851 - val_loss: 1.1045 - val_acc: 0.7841\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9851\n",
      "Epoch 00051: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0523 - acc: 0.9851 - val_loss: 1.0299 - val_acc: 0.7941\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9842\n",
      "Epoch 00052: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0582 - acc: 0.9842 - val_loss: 0.9551 - val_acc: 0.8027\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9883\n",
      "Epoch 00053: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0428 - acc: 0.9883 - val_loss: 0.9485 - val_acc: 0.8134\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9854\n",
      "Epoch 00054: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0532 - acc: 0.9854 - val_loss: 1.1593 - val_acc: 0.7645\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9866\n",
      "Epoch 00055: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0490 - acc: 0.9866 - val_loss: 0.9589 - val_acc: 0.8092\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9876\n",
      "Epoch 00056: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0473 - acc: 0.9875 - val_loss: 1.2402 - val_acc: 0.7617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9846\n",
      "Epoch 00057: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0539 - acc: 0.9846 - val_loss: 0.9011 - val_acc: 0.8195\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9864\n",
      "Epoch 00058: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0491 - acc: 0.9864 - val_loss: 1.1056 - val_acc: 0.7901\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9878\n",
      "Epoch 00059: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0440 - acc: 0.9878 - val_loss: 1.1220 - val_acc: 0.7827\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9827\n",
      "Epoch 00060: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0600 - acc: 0.9827 - val_loss: 0.9368 - val_acc: 0.8081\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9875\n",
      "Epoch 00061: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0447 - acc: 0.9875 - val_loss: 0.9504 - val_acc: 0.8162\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9896\n",
      "Epoch 00062: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0390 - acc: 0.9896 - val_loss: 0.9581 - val_acc: 0.8137\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9884\n",
      "Epoch 00063: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0414 - acc: 0.9884 - val_loss: 0.9932 - val_acc: 0.8090\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9890\n",
      "Epoch 00064: val_loss did not improve from 0.78493\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0404 - acc: 0.9890 - val_loss: 1.0479 - val_acc: 0.8025\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd4VMXawH+z6ZUUAoEAEpQaSiChKAI2mtIUEbyooCJe64fYUCx47YoNOxYsl6YooleKoiAgIKEktITeUklIYdOzu/P9MbupuyEh2YQyv+c5z2bPmXPmPbubec9b5h0hpUSj0Wg0mjNhaGwBNBqNRnN+oBWGRqPRaGqEVhgajUajqRFaYWg0Go2mRmiFodFoNJoaoRWGRqPRaGqEVhgajUajqRFaYWg0Go2mRmiFodFoNJoa4drYAtQnTZs2lW3btm1sMTQajea8Ydu2bRlSypCatL2gFEbbtm3ZunVrY4uh0Wg05w1CiGM1batdUhqNRqOpEVphaDQajaZGaIWh0Wg0mhpxQcUw7FFSUkJiYiKFhYWNLcp5iaenJ61atcLNza2xRdFoNI3MBa8wEhMT8fPzo23btgghGluc8wopJadOnSIxMZHw8PDGFkej0TQyF7xLqrCwkODgYK0szgIhBMHBwdo602g0wEWgMACtLOqA/uw0Go2Ni0JhVIeUkqKiZEymnMYWRaPRaM5pLnqFIYSguDjVaQojOzubjz766KzOvf7668nOzq5x+1mzZjF79uyz6kuj0WjOxEWvMACEcEVKs1OuXZ3CMJlM1Z67fPlyAgICnCGWRqPR1BqtMAAhXJymMGbMmMGhQ4eIjIzk8ccfZ+3atQwYMIBRo0bRpUsXAMaMGUNUVBQRERHMnTu39Ny2bduSkZHB0aNH6dy5M/fccw8REREMGTKEgoKCavuNjY2lX79+dO/enRtvvJGsrCwA5syZQ5cuXejevTsTJkwA4K+//iIyMpLIyEh69uyJ0Wh0ymeh0WjOby74tNryHDgwjdzc2Cr7LZZ8AAwG71pf09c3kvbt33V4/LXXXmP37t3Exqp+165dy/bt29m9e3dpquqXX35JUFAQBQUF9O7dm7FjxxIcHFxJ9gMsXLiQzz77jFtuuYUffviB2267zWG/d9xxB++//z6DBg3iueee44UXXuDdd9/ltdde48iRI3h4eJS6u2bPns2HH35I//79yc3NxdPTs9afg0ajufDRFgYAApAN1lufPn0qzGuYM2cOPXr0oF+/fpw4cYIDBw5UOSc8PJzIyEgAoqKiOHr0qMPr5+TkkJ2dzaBBgwCYNGkS69atA6B79+5MnDiR//73v7i6queF/v37M336dObMmUN2dnbpfo1GoynPRTUyOLIECgqOYjbn4Ovbo0Hk8PHxKf177dq1rF69mk2bNuHt7c1VV11ld96Dh4dH6d8uLi5ndEk54tdff2XdunX88ssvvPzyy+zatYsZM2Zwww03sHz5cvr378+qVavo1KnTWV1fo9FcuGgLA+fGMPz8/KqNCeTk5BAYGIi3tzcJCQls3ry5zn02adKEwMBA1q9fD8C3337LoEGDsFgsnDhxgquvvprXX3+dnJwccnNzOXToEN26dePJJ5+kd+/eJCQk1FkGjUZz4eE0C0MI8SUwAjgppexq5/jjwMRycnQGQqSUmUKIo4ARMAMmKWW0s+RUsrgAFqS0IET96tDg4GD69+9P165dGT58ODfccEOF48OGDeOTTz6hc+fOdOzYkX79+tVLv19//TX//ve/yc/Pp127dsybNw+z2cxtt91GTk4OUkoefvhhAgICePbZZ1mzZg0Gg4GIiAiGDx9eLzJoNJoLCyGlc3z3QoiBQC7wjT2FUantSOARKeU11vdHgWgpZUZt+oyOjpaVF1CKj4+nc+fO1Z5XXHySoqLj+Pj0wGDQRfYqU5PPUKPRnJ8IIbbV9KHcaS4pKeU6ILOGzW8FFjpLljOhLAyQsvp5ERqNRnMx0+gxDCGENzAM+KHcbgn8JoTYJoSY6nwZlGfOWXEMjUajuRA4F7KkRgJ/SynLWyNXSimThBDNgN+FEAlWi6UKVoUyFaBNmzZnKYKL9VUrDI1Go3FEo1sYwAQquaOklEnW15PAUqCPo5OllHOllNFSyuiQkJCzEqDMwtAuKY1Go3FEoyoMIUQTYBCwrNw+HyGEn+1vYAiw27ly2GIY2sLQaDQaRzgzrXYhcBXQVAiRCDwPuAFIKT+xNrsR+E1KmVfu1ObAUus6DK7AAinlSmfJqWTVQW+NRqM5E05TGFLKW2vQ5ivgq0r7DgMNM+Xaipp7YThnLAxfX19yc3NrvF+j0WgagnMhhnFO4MzZ3hqNRnMhoBWGFRX4rn+X1IwZM/jwww9L39sWOcrNzeXaa6+lV69edOvWjWXLllVzlYpIKXn88cfp2rUr3bp1Y/HixQCkpKQwcOBAIiMj6dq1K+vXr8dsNjN58uTStu+8806936NGo7k4OBfSahuOadMgtmp5cwBPa4lzalviPDIS3nVc3nz8+PFMmzaNBx54AIDvvvuOVatW4enpydKlS/H39ycjI4N+/foxatSoGq2h/eOPPxIbG0tcXBwZGRn07t2bgQMHsmDBAoYOHcrMmTMxm83k5+cTGxtLUlISu3ervIHarOCn0Wg05bm4FEa1CJCWer9qz549OXnyJMnJyaSnpxMYGEjr1q0pKSnh6aefZt26dRgMBpKSkkhLSyM0NPSM19ywYQO33norLi4uNG/enEGDBhETE0Pv3r256667KCkpYcyYMURGRtKuXTsOHz7MQw89xA033MCQIUPq/R41Gs3FwcWlMKqxBIoLjmA2G/H17V7v3Y4bN44lS5aQmprK+PHjAZg/fz7p6els27YNNzc32rZta7eseW0YOHAg69at49dff2Xy5MlMnz6dO+64g7i4OFatWsUnn3zCd999x5dfflkft6XRaC4ydAzDigp6Oyetdvz48SxatIglS5Ywbtw4QJU1b9asGW5ubqxZs4Zjx47V+HoDBgxg8eLFmM1m0tPTWbduHX369OHYsWM0b96ce+65hylTprB9+3YyMjKwWCyMHTuWl156ie3btzvlHjUazYXPxWVh2ENKMBqV5hQWpJQ1iiPUhoiICIxGI2FhYbRo0QKAiRMnMnLkSLp160Z0dHStFiy68cYb2bRpEz169EAIwRtvvEFoaChff/01b775Jm5ubvj6+vLNN9+QlJTEnXfeicWi3G2vvvpqvd6bRqO5eHBaefPG4GzLm7N9O+ZgH/KDjLrEuR10eXON5sLlnChvfl7h4gJmpTj1XAyNRqOxj1YYAK6uCLPN0tIKQ6PRaOyhFQZUUBi6npRGo9HYRysMUC4pk7IstEtKo9Fo7KMVBoCrK5hVFpG2MDQajcY+WmGAUhgmpSi0haHRaDT20QoDwMUFISVYRL0rjOzsbD766KOzOvf666/XtZ80Gs05g1YYoCwMwCBdqO+KtdUpDJOp+r6WL19OQEBAvcqj0Wg0Z4tWGKCC3oAw1/+aGDNmzODQoUNERkby+OOPs3btWgYMGMCoUaPo0qULAGPGjCEqKoqIiAjmzp1bem7btm3JyMjg6NGjdO7cmXvuuYeIiAiGDBlCQUFBlb5++eUX+vbtS8+ePbnuuutIS0sDIDc3lzvvvJNu3brRvXt3fvjhBwBWrlxJr1696NGjB9dee2293rdGo7nwuKhKgzisbm72h/yOWDwN4CIw1EKNnqG6Oa+99hq7d+8m1trx2rVr2b59O7t37yY8PByAL7/8kqCgIAoKCujduzdjx44lODi4wnUOHDjAwoUL+eyzz7jlllv44YcfuO222yq0ufLKK9m8eTNCCD7//HPeeOMN3nrrLV588UWaNGnCrl27AMjKyiI9PZ177rmHdevWER4eTmZmZs1vWqPRXJQ4c03vL4ERwEkpZVc7x68ClgFHrLt+lFL+x3psGPAe4AJ8LqV8zVlyWoVRr1ItTuRs+vTpU6osAObMmcPSpUsBOHHiBAcOHKiiMMLDw4mMjAQgKiqKo0ePVrluYmIi48ePJyUlheLi4tI+Vq9ezaJFi0rbBQYG8ssvvzBw4MDSNkFBQfV6jxqN5sLDmRbGV8AHwDfVtFkvpRxRfocQwgX4EBgMJAIxQoifpZR76yqQQ0ugyAS79lHc0odifxO+vt3q2lW1+Pj4lP69du1aVq9ezaZNm/D29uaqq66yW+bcw8Oj9G8XFxe7LqmHHnqI6dOnM2rUKNauXcusWbOcIr9Go7k4cVoMQ0q5DjgbP0cf4KCU8rCUshhYBIyuV+EqYw16C4uo93kYfn5+GI1Gh8dzcnIIDAzE29ubhIQENm/efNZ95eTkEBYWBsDXX39dun/w4MEVlonNysqiX79+rFu3jiNHlIGnXVIajeZMNHbQ+3IhRJwQYoUQIsK6Lww4Ua5NonWf8zAYQAiEGcBcr26p4OBg+vfvT9euXXn88cerHB82bBgmk4nOnTszY8YM+vXrd9Z9zZo1i3HjxhEVFUXTpk1L9z/zzDNkZWXRtWtXevTowZo1awgJCWHu3LncdNNN9OjRo3RhJ41Go3GEU8ubCyHaAv9zEMPwByxSylwhxPXAe1LK9kKIm4FhUsop1na3A32llA866GMqMBWgTZs2UZUXIqpxae7YWMz+HuSH5OHjE4nBcFHlA1SLLm+u0Vy4nBflzaWUp6WUuda/lwNuQoimQBLQulzTVtZ9jq4zV0oZLaWMDgkJOXuBXF2tFgboirUajUZTlUZTGEKIUGFd2k4I0ccqyykgBmgvhAgXQrgDE4CfnS6Qriel0Wg01eLMtNqFwFVAUyFEIvA84AYgpfwEuBm4TwhhAgqACVL5x0xCiAeBVai02i+llHucJWcpLi6I4hKUfNrC0Gg0mso4TWFIKW89w/EPUGm39o4tB5Y7Qy6HuLpCgbYwNBqNxhGNnSV17uDqqtfE0Gg0mmrQCsOGiwvCYrHO9tYKQ6PRaCqjFYYN2+Q9M9R3xdra4uvr26j9azQajT20wrBhq1hrqf+KtRqNRnMhoBWGDduaGBaXeg16z5gxo0JZjlmzZjF79mxyc3O59tpr6dWrF926dWPZsmVnvJajMuj2ypQ7Kmmu0Wg0Z8tFNZ152sppxKbaq28OmM2Qn49luwFcDRgMXjW6ZmRoJO8Oc1zffPz48UybNo0HHngAgO+++45Vq1bh6enJ0qVL8ff3JyMjg379+jFq1CiErXKuHeyVQbdYLHbLlNsraa7RaDR14aJSGNVSbqCuz3IpPXv25OTJkyQnJ5Oenk5gYCCtW7empKSEp59+mnXr1mEwGEhKSiItLY3Q0FCH17JXBj09Pd1umXJ7Jc01Go2mLlxUCqM6SwCTCWJjKQn1pijAXK8lzseNG8eSJUtITU0tLfI3f/580tPT2bZtG25ubrRt29ZuWXMbNS2DrtFoNM5CxzBslC7TWv9ptePHj2fRokUsWbKEcePGAaoUebNmzXBzc2PNmjVULppYGUdl0B2VKbdX0lyj0WjqglYYNoRQSsMCYKpXt1RERARGo5GwsDBatGgBwMSJE9m6dSvdunXjm2++oVOnTtVew1EZdEdlyu2VNNdoNJq64NTy5g1NdHS03Lp1a4V9tSrNvWsXZi8X8pvn4+vbE7X4n0aXN9doLlzOi/Lm5ySurgizUqC6npRGo9FURCuM8ri4lCtxrifvaTQaTXkuCoVRY7ebqytCr4lRgQvJZanRaOrGBa8wPD09OXXqVM0GPldXMGkLw4aUklOnTuHp6dnYomg0mnOAC34eRqtWrUhMTCQ9Pf3MjbOzISeHQsDNTeLioosAenp60qpVq8YWQ6PRnANc8ArDzc2tdBb0GXn3XXjkETb8DJdEzqZ160edK5xGo9GcR1zwLqlaYS2r4XpaUFKiJ7ppNBpNebTCKI9VYXjm+2EyaYWh0Wg05XGawhBCfCmEOCmE2O3g+EQhxE4hxC4hxEYhRI9yx45a98cKIbbaO98pWBWGR56PVhgajUZTCWdaGF8Bw6o5fgQYJKXsBrwIzK10/GopZWRNZyDWC6UKw1MrDI1Go6mE04LeUsp1Qoi21RzfWO7tZqDxU3GsCsM9113HMDQajaYS50oM425gRbn3EvhNCLFNCDG1uhOFEFOFEFuFEFtrlDpbHdY1I9xzXbWFodFoKrJ3b2NL0Og0usIQQlyNUhhPltt9pZSyFzAceEAIMdDR+VLKuVLKaClldEhISN2EcXMDX19cjQKTKbtu19JoNBcOmzZBRARs3HjmthcwjaowhBDdgc+B0VLKU7b9Usok6+tJYCnQp8GECgrC7TSYTFm6LIZGo1Fs365e9+xpXDkamUZTGEKINsCPwO1Syv3l9vsIIfxsfwNDALuZVk4hKAjX0yakLMFiyW+wbjUazTlMQoJ6PXy4ceVoZJwW9BZCLASuApoKIRKB5wE3ACnlJ8BzQDDwkVDraZusGVHNgaXWfa7AAinlSmfJWYWgIFxy1Op3JSVZuLj4NFjXGo3mHMWmMKwrW16sODNL6tYzHJ8CTLGz/zDQo+oZDURQEIYT+wCsge/GT97SaDSNjFYYwDkQ9D7nCArCkJ0HoDOlNBoNGI2QmKiWcb7IXVJaYVQmKAiRZQSpFYZGowH2KY8DvXtDRgbk5jauPI2IVhiVCQpCmMy4FEBx8cnGlkaj0TQ2NnfU8OHq9SJ2S2mFURlbeZB8H3JzdzSyMBqNxuls2gQnTjg+npCglm8ePFi9v4jdUlphVMaqMJqYu3D69JZGFkajcYDFAlOmwD//NLYk5zdmMwwdCk8+6bhNQgJceil07KjeawtDU4pVYfiVXEpeXhxmc2EjC6TR2OHoUfjiC/jmm8aW5PwmPl4FtTdtctwmIQE6dYLgYPD11RaGphxWheFT3AopTeTlxTWyQBqNHWx+9R3abVontli9CEePQmpq1eMmE+zfrxSGENCunbYwNOWwKgzvgqYA2i2lOTeJj1evcXHKraI5O2Jiyv7evLnq8SNHoKQEOndW78PDa6cwpFRlRY4dq5uc5whaYVSmdJlWC+7uLTAatcLQnIPYLIz8fDhwoHFlOZ/ZsgX691eFR+25pWyfc6dO6tWmMM5UZy4xEV57Dbp0gagoGD++fuVuJLTCqIyXF3h6IrKy8PProy0MzblJfLzyqcPF55bKz4fvv4fi4rpdp7AQdu6EgQOhZ0/7FoZNYdgC3u3aqf5POki5j4+HIUOgTRt46ilo2lQF1bduvSDmb2iFYY/AQMjMxN+/DwUF+ykp0aXONecYCQkwahS4u5dVUr0Y2LFDPbHfcgu88krdrhUbq2IUvXvD5Zcr95TJVLFNQgI0b166Vg7h4erVkVvq+eeV4nn2WTh4ENavh+nTlduwusD6eYJWGPYICoLMTPz8egNgNDbcsuIazRnJyIBTp6BbN+ja9eKwMCwWeOst6NsXTp9WVsHrr9ctAG0LePfpA/36QUGBsjjKEx9f5o6CMoXhKFNq82a4/np44QWVigtKGRkMSnmc52iFYY9ShaGWE9dxDM05hS3g3bmzcqXs2HFmn/r5THIyDBsGjz0GI0aoQX3+fDWZbvr0s79uTAy0bAlhYUphQEW3lJTKwrAFvKF6CyMlRU0A7Nu34n4/P/U9aYVxgWJVGG5ugXh5ddBxDE3DkpkJaWmOj5cPxPbqpdpXN1O5Jlgs56bSyclRLqi//4a5c+GHH1TsplUreOYZ+OknWLXq7K69ZYtyRwFccgmEhlZUGOnpkJVV0cLw9lYuKnsKwzaJ0qZ8yjNggLp2XeMujYxWGPawKgwAf/8+GI0xZzhBc8EyaxbcdVfD9nnnncqt4Yj4eJWc0aaNenKFurulJk1Sgd2Yc+y3vmCBmh+xciXcc4+aC2HjkUegfXt4+OHaD8TZ2Wp+RR/rYp5CqIG+fJyhcoaUjfBw+y6pf/5R2Va276Q8AwaoIPvW89u9rRWGPcopDD+/PhQXJ1NUlNTIQmkanNxcmD0b5s1Tg0tDYLHAX3+pQHa2g2SLhAQ1uBsM0L27GuzqojDS0mDhQjh0CK64QsUKLJazv159ISV8+qkagK+8supxDw947z313bz7bu2ubRu4+5Rb/fnyy1WgOiNDvXekMBxN3tu8GXr0AE/Pqsds8jvDLZWc3GCKXisMewQFqQBYQUFp4PuccUudOAFff93YUlwcfP895Km1UZg7t2H63LdPuWHAcVaNrVQFgI+PUh51URj//a/K4tmwAUaOLIsVOEodLU9xMcyZo8pr1DcxMWpi4tSpFS2L8gwfrrLFXnwRkmrxUGcLeEdHl+2rHMewWXKtW1c8Nzxc/R+WlJTtM5uVErLnjgJo1kx9T/WtMIqKYOxY9Tk0QNquVhj2sE7eIysLX99IhHA9dwLfb70FkyeXBT41zuPLL9U/+U03wVdfqX9OZ1Peh/7331WPFxSoMhblA7G2wPfZIKW6t3791BP2Dz/ARx/Bn3+qp+UtZ/jd//QT/N//qXTS+mbuXBUz+Ne/qm/3zjtq8H7iiZpfOyYGOnSAgICyfdHRKpBu+w7KW3LlCQ9XCqJ83GjvXjVgVw54l2fAAPWd1pf1JiXcf7+S99NPVZ0rJ+NUhSGE+FIIcVIIsdvBcSGEmCOEOCiE2CmE6FXu2CQhxAHrNsmZclbBpjAyM3Fx8cTHpwenT58jvt0NG9Tr9983rhwXOvv2qc/6rrvg3ntVGuuPPzq/382boUkTpQTsKYz9+9VAUd5N0rOnGrxsrpTasH077N6tHkJAPcnfd59SFAYDzJhR/fm//qpeP/ig+hnnixfD7bfX3BI5fVq5yW69Ffz9q2/brp1SFgsW1PwJfsuWiu4oUMqpR4+KCqO8Yi7fH1R0S9kC3mdSGNnZ6vOuDz76SD3UzJyprIyGQErptA0YCPQCdjs4fj2wAhBAP+Af6/4g4LD1NdD6d+CZ+ouKipL1wu+/SwlS/vWXlFLKffvuk+vW+UuLxVw/1z9bjEYpXVyUbBERjSvLhc6TT6rPOiVFSrNZynbtpBw0yPn9du8u5ZAhUj70kJTe3lIWF1c8vnCh+v537izbZ/u9/vZb7ft74AEpPTykzMqqemzmTPUZnDpl/1yzWcqQECmvu05KX18px4yx327vXik9PZWM/ftLefr0meX6+GPV/p9/anYfeXlStmkjZY8eUppM1bdNTFTXfu+9qsceeEDdi9EopRBSvvBC1TZHjqjz584t23f33VIGBUlpsTju9/Bhdd4HH9Tolqpl7VopXV2lHDFCfQ91ANgqazimO9XCkFKuAzKraTIa+MYq92YgQAjRAhgK/C6lzJRSZgG/A8OcKWsFbBaGtWaMn18fzObT5Oc3UODTEVu2KFP4hhtgzx61ac6O335Tk9727q16zGRScaIbblCplgaDytD566+y5Torc+JE1VnCtcVoVE+fl1+u6hvl5ysffnkSEpQ87duX7TvbTKmiIvVUfuONFV0zNsaMUb83mxVRmZgYlXp6552qDMZPP8GaNRXbFBfDxInKXfLBB+rpffjw6i0NW7A7MrIs7fVMeHsrd21cnDq3OmwB4soWBijXXG6uupfKlpyNVq2U66qyhdG3r+NYC0DbtmrOR13jGMeOwc03q4mB//1vVZeZE6lRT0KI/xNC+FtdSF8IIbYLIYbUQ/9hQPkE8kTrPkf7G4awMPUlTJ4MrVsT8vB3tPwJCrY2gEuiOv7+W/0gZ89Wr9otdXbk56tA6p49MGGCSncsz8qVKpWzfDrt5Mng6mo/+P3rr8qvPWpUxUBoZbKzYcUKx/Mdtm5V/u1+/ZTCgKpuqYQE1Vf5TJzgYJViW1uF8csvap7BnXfaPx4Vpf4XfvrJ/vFff1X/J8OGqRTXNm3KymDYePZZJdcXX8ADDyg30+bN6hxHSmPbNlW2o7pgtz3GjoWrr1bzM6pzz23Zor7LyMiqx2xB63nz1Ks9heHqquZt2BSG0ah+S9W5o0Ddy4ABSmGc7ZyX/Hyl4IuLYdky5b5sQFxr2O4uKeV7QoihKBfR7cC3wG9Ok6yGCCGmAlMB2rRpUz8Xbd5cPXmuXg3r1+Oyfj0dkoH3ZsLVq9U/wVVX1e7HXB/8/TdERKgf8aBB8N13KtjY0HKc77z8snpKmzlT/f344/D++2XHv/hCZbWUnwsRGqqeuL/6Sp1jG7A3b4Zx49SM4RUrlCUyb17V7yQtTRWl27kT1q5V319lbL7zPn2Uldu6NWzcqILKNiqXqrBRi8B3Xp4a4/w+W4B3yzDEtdfabyiEuud581Sw3csLUGOd0QgpP+wmufP9pK8OwtsbAu/8nIAXphHw7vf43D2B/N//Ju+NpeSNfZG84FGIjdC63zhazDfgOnG8UhorV4KfH1KqMFFyMvDqrzTx7EjADf/Cz6J0ktmsdEBqqvoo09PtVXUXuA3/Gre/HsXttu9xe/g+SkpU+9TUsnPN628gwP9yAp/yJCBAlYkyGJTBVVR4KUVeb1D0p5kSbqD44y6USDU+m80qnBIYCIEujxH4Tzo+30Ph9hPkyankJ40n/yU1phcWlm0FBcoAatMG2rjeQ5vkk7T+M5HCkNYkJlK6JSWpZ4rc3LItP1/pJw8P8BDFeBzah5vxTcxdIzFPCcZsVnIFBJz9/MXaIGQNNJ0QYqeUsrsQ4j1grZRyqRBih5TSzgyVKue2Bf4npexq59in1usttL7fB1xl26SU99pr54jo6Gi51RkTY6Rk7/LL8VudTOvFJlUCoH9/9SQzdGjDDNhmsxpEbr0VPvkEPv5YZUjs2qVcK5qaER+vApv/+pca/KdPV1k2y5YpCyEtTbkcpk2DN9+seO7q1TB4MJZv/kvxuIlY9iZgvm4oliaBWFb9jte3c/F46RnEk0+q0tY2jh3DdN0wspLyyTH7UjDmVgoefcaWuU1JifJwuL74PC6Jx3D59ivMZjDOeovcPccwvvQeuXkCi8mC63NP4zagH643j8HFRQ0op09DzspN5GyOx3jj7eDqhsGgfpYGg/KUpaaqn21qasUHe4Ow4OtnwM9PzTkrLi7bSkpASDNuhUbc/L1w9/XA1VUN7LZs47PBYICwoHzaZOzA4OlOkm8Hkoyo/sn6AAAgAElEQVT+FBVV/T8SQnmz8vLqnlwUFAShoRLXhD1kebckWwQ5NHLcKMZDFOMW4Iubm6rxaDBYP+uc6g0EV9fSotelW16e+vwdnWcwqGeSwEB1v35+6tXLS31/RckZFMXspMjsSkn7Lrg0a4qLi/V346rubf78s/tchBDbpJTRZ25Zc4UxD+USCgd6AC6oATyqBue2xbHCuAF4EBX87gvMkVL2EUIEAdtQAXOA7UCUlLK6eIjzFAZw6NCTJCa+y4DeJzF8NV8NCCdOKBN2wYKyGjPOYudONdB9843KNklLU0+1M2fCf/7j3L4vEKRFknvVCDLjTpD541ryPIII9ium2e1DCUzchWFXHCxaRNZjL7H7mx3syWvL7t3KGDl1CjIyJKcOZZNlaYKj8J+bwYSfJQe/QDd8WvhjzCohK7WIXOnclEdfTxNNClPxbROEwccbi6Ws2ofBoIzmFi3UFhoKfv+sJu+n3zDe9yRG92CMRqUgPDzU4OjmpjYsZoo/+IySdh0p7n81JSVqcGqZuIWWS96j5Wf/IaTfpRQUKO9W9pb9ZD87mzyf5ngVZOLz/GP4dgvHx0cNfImJcPy4+tc5HpuJ5fBRWuXGE+ZxirArwwkLLsTw3UKyZ84mO6gd2dlqkG7SRN1D8+ZK/qZNrfKV/36luoeSU6cpGXEjJa3b4fLFXEJbCJo1U/fFvn3KQvviC7jrLkwm9VQvpfUp3gPcZ7+CeGamsjDtxG8sFsiZ9Q5ZL75P3ubdeM2cjs+R3Xhv34C3d1W5bBQXQ9IJC8cjR3G81xi8HppCq1bq+SQ0VA38VZBSWb+PPqqys5YuVWts1CO1URg1dUndDUQCh6WU+dYB3YHjs4IgC1HWQlMhRCLwPOAGIKX8BFiOUhYHgXzbNaWUmUKIFwFbLut/zqQsnI2/f1+kLOZ0cSwB998PU6aowfvxx1X+9uLFcN11zhPA5su2+babN1duse++U5UxLwK3VEGB+ucuKam4GY1qQM/MVK+2LSOj4paZYaHEbB0ASr8qd2ANLpgIaZeDsNxOCo/CHeqov7/6P23aFNq0EQQHHyF48//wDvLCkHsaw/3/xqVNGEIo+U5nGzAu2YLx8EnyWvTBNzOOQM9sAieNJqBzCwIOxOD9wet4vTQTr8t74umpBjLz8STMY8dhmv4k5hGjcXEBv8R4/CaOxPfDN/C94yZcfl9JyU23YFr+O6aovphM6gnU3x9cklOUz+OJD1SsoDqkhIiH4YpA+Cj4DJ+6C6Suh9+ehU9T1SMtwE2vQasYuLudynG0MaQD7M2FhZ/Bq6/CjOoepIJABsLGAnj3J/jxETUad+8OL4ZXvG6t8Ie3JsLdd0P8AOh9R9mhSgFvV1f13Vbgcmscw57rD6WAA7u0IJAj4H0I9iyDwYPhDOEEd3cIv9RA+FUC9r8JN09x3Dg9XXkPvvxSmQ6jRqnxpoFjFlWoSSoV0B/wsf59G/A2cElNU7Eaaqu3tFo7lJQY5bp1fjI+fnLFAwcOqBRXg0HKN9+sPq2uLkycKGVoaMXrf/KJStOLi3NOn/XBihVSJifbPWQySRkfL+X8+VI++6zKZJ0+XcqHH5byvvukvOMOKQcPVh9vQIC61ZpsBoOUzZpJ2aWLlAMHSnnTTVLeM6lIzvB+T77R6j35+Vyz/PFHKVeulHLBAinffVfKp0fEySnMlZP5Ur5x82a5fLmUx4/b+TrT0qR0c1PbH3/Yv+eCApWCC1K2aiVlQkLZsfx8lbY5ZUrFc+bPV+137CjbV1IipY+PSvWUUsrZs1WbjIyqfVosUjZtqtI7z8Q//1RNC62O775T7detU+8LC9U93Huv/fanTkn51VdnTm+tzNGjUj73XGk6e50wm6Xs00fJ3aKF+j6mTJFywAD1mVYnW26ulJ06Sbl8ueM2mzera7//fu1TZV9/XZ2Tmqrel5RIuWaNlE88oX7woaFlP2Zbam8dU2erg1qk1dY4hoFyRXUHvgI+B26RUtqJ3DUeznRJAezbdy9paf/liiuScXUtp+lzc1WmyZIlKsbw+ecqylWfhIerrJUlS8r2pacrW/app+Cll+q3vzpSXAypcWkk9xnDqfBosmbOJjPPg6wsVXFi504Vo7X5woVQ7gBX17LNy0t53WwVqFu2VO4QNzd13OY28fNT+4OD1au/v51Mw4cfVmmdMTHqc6yMlCoTavlyVVOpusliCxeqoLijYDEoR/fbb6tMq0suqXhs4sSyTCyb/+Lhh9XTZHZ2Rd/Eddcpc2nHDhVQX7bMccmOIUOUKVXdgkoHDqhA9tGjKsJckydWo1E9hj/4oEpdtcZy+PlnVUrkXCUlRcWpDhxQEx7371f/Mw5cTbUiPV39Bq64QiUmbN1q/3dlj02b1HnTp6vr/PqrMo/d3dUaJ7ata1flhm7evG6ynoHauKRqamFst74+B9xdft+5tDnTwpBSypycLXLNGmRS0idVD1osUr7yinoiGDiwfi2NpCT1tPHOO1WPXXedlO3bO8+yOQNGo5pD9PrrUo4dK2VkpJrLVZ0FEBCg5m899JCU8+apOWiV56fVifx8Kf/+W03Muv12KTt3Vh3bntQdYbFImZNTj4I4YNkyJU/5J9jevaW86qqqbZ99VplMp09LeeWV6rfliCeeUJZPUZH947/8ImWTJlIGBzu2jhxx/fVq8qLFIuW0aWqyX25u7a5xLpCV5fjzqQ0Wi7JUQE1KrM0PuKhITcoENdnv9tulXLKkZhManQC1sDBqGsMwCiGeQqXTDhBCGLDGIi4m/Pyi8fHpTkrK57RseW/Fg0KoJ31fX/W0uHatygmvDyrHL8pzyy0qXz0uzn5eeR2RUj38HDumApXltz171DwzW/bKpZeqSgp9+1otg0Vv0yIngZCR/Qj69BUCX32SJo/dYz+4V1+kpqo1IlJS1PsWLdTkr9tvV99LdQhx5jIU9cHQoerJfvFiNYmtoEBZEI89VrVt//7qA/7nH5XhVV0JiJ49VVDn7bdV/av27dU9WSyqON+sWarN0qVVrZ4zMWaM+p3t3q2eiK++WhU+PN+wN0HxbBBCWf27d6vfm6NItz3c3dXE0ZISVcXWqf8Q9UxNtAoQCkwHBljftwHuqKlWaqjN2RaGlFKeOPGeXLMGaTTG2m9QUKAc6DfcUH+d/t//2S8TIaWU6emqfMNTT9W5m7Q0KRcvVt2NHCllt25S+vlVtRDc3dXD5tChyuX8669KjApkZqrSBU88ofyvo0ap9zY/uLMYP149/S5erCyzc5XJk9XTfmGhsoZAyp9+qtouO1tZrQ8+qNq8/bbjayYnS3nJJWVfVMuWKvY1bJh6f8cdyvo6G1JSlBy33y5LffcXO6NGqc9i+vTGlqROUAsLo8aDMdAcGGHdmtX0vIbcGkJhFBefkmvXesj9+x9y3OiFF9RHu2dP/XQaHW3fXWFjyBApW7eutal98qSUS5eqIHO3bmXjjLe3ej9ypDr29uvF8se3D8uYGBWnq1H87dtv1cU2bVLvs7OV66x5c+cN5P/7n+rzxRedc/36ZMUKJeuyZVK+9Zb6OyXFftvu3aUMDFRtVqyo/roWi5T79qmEiPHj1cOLm5sa4OvqtrziirIfyeHDdbvWhcD//Z/6LBYvbmxJ6kS9KwzgFuAY8DXwDXAEuLmmnTTU1hAKQ0op9+y5Va5fHyBNJgdPa+npyq9Zk4yVM5GbqyyImTMdt1m5Un2VH37osElxsUqm+vRTKSdNUmO37X/fy0uFQl55RSV/lJRUOnnqVNVw0aKay33TTSo7pbx22b1b+X0vv7x+/MjlMRqV0uzSpf6v7QyKi1Us4dZbpRw3Tsq2bR23/fe/y76sI0dq14/Foqze+uCNN5QMnTvXz/XOdz75RMWXjh9vbEnqhDMURlx5qwIIAeJq2klDbQ2lMDIz/5Br1iBTU+c7bnTffcp34+ipsab8+aesEiCtjMWigqGhoVLm5UmLRcrt29VD5V13SdmrlxLFNuaEhEg5erQKVK9bp7wiDklNVS4ed3e11cSllJ+vzJT77qt6bPFiJcSIEWfvHrHHtGnqun//XX/XdDb33KMUaGiolBMmOG5ns9a8vJyaXnlG9u1Tcjz2WOPJcC5RWFgxDfo8xRkKY1el94bK+86FraEUhsVilps2hcsdO65x3Gj/fuXzfeaZunX24ovqOvbKT5dn/Xq5l07yuWs3yA4dypRD06Yqtfvxx1Wq/4EDtfRMPPOM6n/TJik7dlSukfj46s+xZQE5Krf98cfqmldfrSyDurJli3rSs6egzmVWry77ouyV2rZhK4sdGdlwsjni558dlzvXnJc4Q2G8CawCJlu3FcDrNe2kobaGUhhSSnn06EtyzRpkfv5Bx43GjFFpc3VJPxw2TMquXe0eyspShsfMmcrNDVIaMMlrB5XIzz5TZf/r5LbOzVXy29Y5OHxY+cTbtq3ecpo8WeXOVpdq+O23ytXWr58KkJ8txcVqDYSWLVWc5HyipER9nmda98FiUWs9TJ7ccLJpLhqcFfQei5rh/TZwY03Pa8itIRVGYWGiXLPGIA8detpxow0b5JliC6WYzVIeO1ZxHoDZrDJprDNqT55UYYR771U6RAh1eRcXFY+c8/hxmUJzlbpUH3zwgepgw4ayfTExyt0UFWVfEZaUKN/8bbed+fpLlyo3V/fuZdH0hAQ1/frxx1XsZNkyxz749HTlHgEpf/zx7O6xsXn4YZWKVq1fUKpZ0PrJXuMEaqMwajTT+3zB2TO9K7Nr10iMxm3063cMg8FOHraUajGcjAxV9MxWh8dkUjn127er/Pvt21X9f1vpzIAAaNMGU3Bz1q6x8Nv177E6JaK0erW/f9kaO/37q7I4pcv5jhunZhEfPgwhIWd/c2azWvO4WTM1k7V8rar//Q9Gj1Yzi5curbg2w5o1cM01am3om246cz+//65y/L29VS1o20L2tkpwp0+rmxsxQs1BCAlROeyrVqnPTUo1F2Xx4rO/18YkP1/NHbEt+6nRNDD1Vq1WCGEE7DUQgJRSNsAsp5rT0AojI+MXdu8eRZcu39Gs2Tj7jZYsUYP4o4+qAXHbNjXJrqBAHffyUhPuevVSpQCMRo7vMfL5pgi+OHI1ySXNcHOTXHGFYPBgVSkiKqqauT7x8eo606apMg5ni01uRwP/55+rUhWDB6sFdmylUB5+GD77TCnJmk7s+vtveP11tSJZr15q69xZKYM1a5QMS5eWLYrj4qKqBA8dqpRWdHSZMtZoNLWi3subny80tMKQ0sw//7THw6MVPXuus9/IbFZVLw8eVE/KPXuqEd+2degALi6UlCjD4NNPyxZlGzZMjclDhtRyUu2dd6p6Rzt2qBnPmzerbedOuO8+ePLJM92YGpBPnapoGVXmq69URdArr1RWh6+vmkHcq5fjVdrOFpMJNmxQFsegQY1ftVOjuUCo91pS58vWkDEMG8ePvyXXrEGePl1Nel1KisosqpQSabGoLND771fZTKAyLGfOrH26fQWOHFGTtcpPz+7UScq+fdXfn31W/fnr19c89rJwYVnw2pb189VXdRBeozk/MJlNcn/G/sYWo86gYxgNR0lJNps2hdGs2QQ6dfqiRuecOqXWRPn6a1U01MtLlbufOFFZFbUpS+OQ+fNVlc5+/cqW/CwpUdVFV69W6zkPH27/3DFj1NP88eM1q7q7dCmMH6/iHGazqqYaFFQPN6E5l8grzuPNjW/i7+HP0EuH0iWkC+I8WYel0FRITFIM64+vp3vz7ozoMKLa9gUlBXi5eVXbZuovU/ls+2dM6jGJd4a+Q6BXYI3lsUgLR7KOEJcWR1xqHHFpcexJ34OLcKGJZxOaeDTB38OfQM9AWvi1IMwvjDD/MML8wmjdpDXBXsH19tlrl1QDs3//faSkzOPyyxNxd6+8GksZp06punBz5qiy3oMHKyVx442qRHeDYDTCwIFKmaxbp9xHNkwmWLQI7rhDrVv+wgs1v+7y5SrWMXCgCkprzoixyMhL615ib8Ze5o2eR1Nvx7+dI1lHCPAMqNWgBFBiLuFUwSncXdzxdPXE09UTg7C/WmB1pOWmMXLhSGKSY0r3tfRryZBLhzC43WD6hvWlXWC7Wg1iO9N2cijzED7uPni7eePj5oOPuw+XNLkED1ePWstYnhRjCjtSd7A5cTN/HfuLfxL/ochcBIBAsOjmRdwScYvdc1ccWMFN393ElJ5TmDN8jt17+jr2ayYvm8yANgPYeGIjzX2b8+mIT8+oiKSULNq9iBl/zOB4znEADMJAh+AOdG3WFYHgdNFpcopyyCnMIaswi5N5J7HIiuvTBngG0CG4Ax2CO9A+qD0dgjswPmL8WSkRrTAamLy8vcTERBAe/iqXXDKjyvHKimLcODUeN9pS3CkpyvIoKlKxjWbN1FoMb72lTJ6uXVWwucpSZNWTv283bn4BuLVsVW+iSinZk76HFQdWsPLQSrILs+ndsjd9wvrQJ6wPnZt2xsVwfgW8bYPGY78/RrIxGTeDG+2D27P69tW08GtRpf38nfO56+e7aBvQlvV3rqeZTzO7180uzOa1Da+x/9R+Ek8ncuL0CdJy05CV8lbcXdwJ8wvjtu63cWfknYQHVr+88L6MfQyfP5zU3FQW3byInqE9+e3Qb/x2+DdWH15NZoFaDLOJRxN6tuhJr9Be9GrRix6hPegY3BE3lzKTOasgi4W7F/LFji/YnmJ/3Q4PFw8ub305gy4ZxKBLBtGvVb9qn/ZP5Z9ic+JmNiduZnvqdranbCc1NxVQg3GvFr0Y2GYgAy8ZSFTLKG794Va2JG1h5cSVXB1esaL0qoOrGL1oNL7uvpwqOMUzA57hxWterNBmV9ou+n7el76t+vL77b8TlxrHncvuZNfJXdze/XbeG/aeXcUekxTDtFXT2HhiI71a9OLeqHvpGdqTiGYReLs5tuRNFhOpuakknU4iyZjEsexjHMg8wIHMA+w/tZ/jOcdp6deSpOlJDq9RHVphNAKxsddRULCfvn0PYzCoFKaDB+Hdd2HePJUUdcstSlFERDSKiBXZuxfzlVdwJMyHeA8jez2N7O0Swt7LmnDKw8zUqKk83Pfhan/INtJy03hz45t8vPVjgryCeH/4+4zpNMZu2yJTESsOruBo9lFSc1NJyU0hNTeVrIIs/Dz8CPAMIMBDPUnnFOaw6tAqTpw+AUC3Zt1o5tOMrclbySnKAcDHzYeOTTsqk72c2d7Eswnebt54uXrh7eaNv4c/HYI71NmMN1lMfL/ne7ILs+nWvBtdm3UlwLOsZLaUkrS8NPZl7ONo9lH8Pfxp7tuc5j7Nae7bnKPZR3lw+YP8dewverXoxYfXf0ihqZARC0YQ6hvKH3f8wSUBqvS4RVp4bs1zvLz+ZfqG9WVn2k46h3RmzaQ1+HtUTFBMy01j2Pxh7ErbRaemnWjl34rW/q1p5d+KEJ8QSswlFJoKS7cdqTv47dBvSCTXhF/DXZF3MbqTGijLs+H4BkYvGo2rwZX/3fo/eof1rnDcbDETlxbH9pTtpVtcWhyFpkJADf4RzSKIbB5JgamApQlLKTQVEhkayd0976Z/6/7kl+STX5JPXkkexiIjsamxrD22ltjUWCzSgruLO+EB4bRu0po2/m1o06QNQV5BxKbGsjFxIwkZCYBSDl1CutCrRa9SpRUZGomfR0XzPasgiwHzBnA85zjr7lxHZKhaFmD14dWMXDiSTk07sfr21Ty5+km+2PEFbw15i+mXTweUVRj9WTSni06z494dhPqGAlBsLualdS/x6oZXEQg6Ne1ERLMIIkIi6BLShV/2/8JXsV/RzKcZr177KpN6TKq3B538knxSc1NpF3h2qdnnjMIQQgwD3gNcgM+llK9VOv4OYFPx3qh6VQHWY2Zgl/XYcSnlqDP115gKIyPjZ3bvHk2XLkvYv38sb7+tEoVcXZXb6bHHGk9RSCk5lHWI7Snb2XNyD/EZ8SRkJLA/PYEiWVLarqVfS7qEdMEiLfx55E9CfUN5buBz3N3rbtxd3KtcNzU3lTf+foNPtn5CkbmI8RHj2ZO+h51pOxnVcRTvD3+fNk3aAOqf9JOtnzBny5zSpz83gxuhvqG08GtBoGcgucW5ZBdml26uBleubXctwy8bzrDLhtHKX1kuFmnhwKkDbEnawpakLRzKOkSSMYmk00mcKjjl8HOICIlgWr9pTOw2scoT64mcE/wY/yOJpxO5qfNN9GvVr4JykVKybN8ynv7jaeIz4iuc28q/FV1CupBVkMW+U/s4XXS62u8jyCuIV655hSm9ppQOGpsTNzN8/nD83P34444/CPMPY9JPk1iydwl397ybj274iD+P/MnIhSPp37o/KyauKL2H4znHue6b60gyJvHjLT8y9LKh1fZf/p6/iv2KebHzOJJ9BIAwvzAuC7qM9kHtCfYO5t3N73JJwCWsmLiixgOSyWIiISOBuNQ4YlNjiUtTryaLiX91+xd397ybni16nvE62YXZbDi+gQ3HN3A46zDHc45zPOc4KbkppZ/jFa2v4IpWV3BF6yuIbhmNj3vN0gkTTydyxRdXUGIpYeNdGzmSfYQRC0ZwWdBl/DnpT5p6N8VsMTPhhwks2buEL0d9yeTIyUz4YQI/7P2BPyf9ycBLBla5blxqHAt2LWBP+h72pO/haPZRQFl10/pOY+bAmVWUfWNzTigMIYQLsB8YDCQCMcCtUsq9Dto/BPSUUt5lfZ8rpfS119YRjakwpDSzcmUfXnnlfTZsuIKgIJXB+sADag2fhsRsMfPbod9Yc3QN21K2sS15W+kTuUEYCA8Ip3NIZzoFd6JT0450CYmgc0jnCk/K64+t5+k/n2bD8Q20C2zHvVH3UmwuJj0vnYyCDNLz0ll/fD0l5hImdp/IzAEz6RDcgRJzCe9ufpdZf81CIHh24LMkG5P5YscX5JXkMfTSoTzS7xF6h/Um0DOw3oOmhaZCUowpGIuNpU+uBSUFnDh9gk+3fUpsaizBXsH8O/rf3NjpRtYeXcuS+CVsTtwMgKvBFZPFRLvAdtzW7TYmdp9IWm4aT65+kk2Jm+jUtBOvXPMKvVr0YvfJ3ew+uZtdJ3cRnxFPoGcgHYM70rFpRzo17UR4QDi5xbmk5aWRlptGWl4aZouy3oK9g6vIHpsay+BvB+NqcKWFbwtiU2OZPWQ2j/R7pPRzWrhrIRN/nMjIjiP54ZYfOJh5kMHfDsZYZGT5xOVc0fqKWn9mFmnhr6N/sfHERg5kHuBg5kEOZB7gZN5JBrQZwNLxS+3KWxts40x9fN9FpiIyCzIJ9Q2t0/Xi0+Pp/2V/mng24WTeSdoFtuPPO/4kxKdswmuRqYiRC0fyx5E/mNB1Agt2LeD1617nif5P1KiP3OJc4tPjCfUNpXWT1mctqzM5VxTG5cAsKeVQ6/unAKSUrzpovxF4Xkr5u/X9eaUw1q6FCROMZGa68fzzmUyb1rLC3IkiUxEZ+Rmk56eTkZ9BRr6ahGYLRHq6euLhogJ9ZmnGbDFjkRb8Pfzp1aJXjf4xUnNT+WL7F8zdPpfjOcdxd3Gne/PuRLWIUlvLKLqEdMHT1fOM1wL1T77i4Aqe/uNp4tLiAPD38Kepd1OaejelR/MePNH/CS4LuqzKuceyj/HA8gf49cCvuBnc+Fe3fzH98ul0b969Rn07Aykl646t491/3mVZwrJS336vFr24ufPNjO0ylha+LViasJT/7vwvfxz5ozTY2NKvJS9c9QKTIyfjanDeCmnx6fFc+821GIuNLBy70G4Q9aOYj3hg+QOM7jiajSc2IoTgt9t+o0doj3qVJa84D2837/MmE+ps2HhiI9d9cx3hgeGsmbTGbnwotziXwd8OZnPiZkZ2GMlPE346q8SBc5VzRWHcDAyTUk6xvr8d6CulfNBO20uAzUArKaXZus8ExAIm4DUp5RlngjWGwjCb4T//UStgXnaZmSefvJL+/buUptjGpcZx9893sy1l21n38dSVT/HyNS87/MeNTY3l5fUv81PCT5gsJq5rdx3/jvo3IzqMqHO2Cagn0PS8dAI8A2p1PSklW5O30tKvJWH+YXWWoz45nHWYtUfXclXbqxy6WpKNySzevRgXgwtTek2pUTynPsjIz6DIVFTtZ/biXy/y3NrnaNOkDatvX0374PYNItuFyLHsYwR5BVWJdZQnsyCTz7d/ztSoqRUs8QuB81FhPIlSFg+V2xcmpUwSQrQD/gSulVIesnPuVGAqQJs2baKOHTvmlPuxR0oKTJigslPvuAM+/BBSUh4mKelDuvX4k093/82stbMI8gri/t73E+obSlPvpoR4hxDsHYxBGCg0FVJQUlAajDQIAwZhwMXggkEYWLBrAZ9t/4zp/aYze8jsKkrjm7hvmPrLVHzcfbgr8i6mRk3Vg8dFgJSSn/f9TJ+wPnYzqzSamlIbheHM1ceTgPJOu1bWffaYADxQfoeUMsn6elgIsRboCVRRGFLKucBcUBZGnaWuIXFxqh5eZqaagHfHHWp/ePjLbD++lAe/HsKenGJu7nIzH9/wcbU59tUx6JJBeLp68vbmtyk2F5fmhZssJh777THe++c9rgm/hsU3Lz7rPjTnH0IIRnca3dhiaC4ynKkwYoD2QohwlKKYAPyrciMhRCcgENhUbl8gkC+lLBJCNAX6A284UdZasWKFSpFt0kTVzYuMVE98O9N2smDXAub8k46bKObNvlfw6NDv6uQDFkLw3rD3cHdx561Nb1FiKeHFq19kwg8T+PPIn/xf3/9j9pDZTvWrazQaDThRYUgpTUKIB1ELL7kAX0op9wgh/oOqXfKztekEYJGs6BvrDHwqhLCgVvd7zVF2VUPz8cfw4IPQvbuqt2f0SGDW2kUs3rOYhIwEXIQLYzqN4Ymul5J/8g3S0uYTGnpbnfoUQvDm4Ddxd3Hn1Q2v8u3ObzFbzHw1+uCzmwsAABn8SURBVCsmRU6qpzvTaDSa6tET92qIxQKPP65mbN9wAzzy9iZe/+d5fj/8OwLBoLaDmBAxgZs630SITwhSmomNvZrc3Fiio2Px8qr7egdSSl5Z/woLdi9g3uh59AnrUw93ptFoLmbOiaB3Y+BMhfHGG6oq+LhpWzgd9TyrDq2kmU8zHr38UW7rfhst/VpWOaew8DgxMd3x8elCZOS60hngGo1Gc65wrgS9z2s2HN/Akawj5BTlcDAxhw/W5NBs+k6+919FcHIwb1z3Bvf3vr/amaWenm3o2PFT9u6dwPHjL9O27fMNeAcajUZTv2iFYYeDmQcZMG9AxZ3RHrgFNOeVPq/wYJ8Hq83ZLk+zZuPJyPiZY8deoVmzCXh7d3SCxBqNRuN8LpzpivXIphMqYeu3237jRb+T8GIh33QoJPHRYzw14KkaKwsbl132NgaDFwcOPMiF5ALUaDQXF1ph2GFr8lZ83HxoY76GV54J4YZhHtxWh0Qnd/fmtGv3MllZq0lP/67+BNVoNJoGRCsMO8Qkx6h69VNdcHdX62zXtZxOy5b/xte3FwcPPoLJVH01U41GozkX0QqjEiXmEnak7sAtvTd//aXSaMPqoQySEC506PAxxcWpHD2qg98ajeb8QyuMSuxJ30OhqZC/v49myBC48876u7a/fx9atryXxMQ55ObG1d+FNRqNpgHQCqMSW5PVPI6iw715+um6u6IqEx7+Mm5uQezffz+y0jq9Go1Gcy6jFUYlYpJi8JSBiOxLiYqq/+u7uQXRrt2bnD69keTkj+u/A41Go3ESWmFUIiY5Bp+caLp1FfjWavmmmhMaegdBQcM4eHAamZmrndOJRqPR1DNaYZSj0FTIrpO7yDsQTR8nlmkSwkCXLovw9u7Enj1jycvb47zONBqNpp7QCqMccalxmCwmCg/1pm9f5/bl6tqEbt1+xcXFm507r6eoKNW5HWo0Gk0d0QqjHDHJMeqP5N5OtTBseHq2oVu3/1FSksHu3SMxm/Od36lGo9GcJVphlCMmOQZvSyje5jAiIhqmTz+/KLp0WYDRuI34+IlYlzTXaDSacw6tMMoRkxSDe3o00VECF5eG67dp09Fcdtk7ZGT8xNGjsxquY41Go6kFWmFYMRYZSchIwLjP+fELe7Rq9X+Ehk7m2LGXycxc1fACaDQazRnQCsPK9pTtSCTm4w0Tv7BH+/Yf4uMTQXz8bRQWJjaOEBqNRuMArTCslAW8oxvFwgBwcfEmImIJFkshe/dOwGIpaRxBNBqNxg5OVRhCiGFCiH1CiINCiBl2jk8WQqQLIWKt25RyxyYJIQ5Yt0nOlBOsE/ZKLiHUP4RWrZzdm2O8vTvSocNcTp/+myNHZjaeIBqNRlMJp624J4RwAT4EBgOJQIwQ4mcp5d5KTRdLKR+sdG4Q8DwQDUhgm/XcLGfJG5MUg0hR8Yv6rh9VW5o3v5WcnPWcOPEmTZpcSdOmoxpXII1Go8G5FkYf4KCU8rCUshhYBIyu4blDgd+llJlWJfE7MMxJcnIq/xRHso+Qu6/x4heVufTSt/H17UVCwiRyc3c1tjgajUbjVIURBpwo9z7Ruq8yY4UQO4UQS4QQrWt5LkKIqUKIrUKIrenp6WclqK1CbWPGLyrj4uJJRMQSDAZvYmOv4vTprY0tkkajuchp7KD3L0BbKWV3lBXxdW0vIKWcK6WMllJGh4SEnJUQpQHvlCiio8/qEk7Byyucnj3X4+rahLi4a8jO3tDYImk0mosYZyqMJKB1ufetrPtKkVKeklIWWd9+DkTV9Nz6JCY5Bp+CjnQOb0KTJs7q5ezw8mpHZOQ63N1bsnPnEDIzf29skTQazUWKMxVGDNBeCBEuhHAHJgA/l28ghGhR7u0oIN769ypgiBAiUAgRCAyx7nMKW5O3YmrE+RdnwtOzFT17rsPLqwO7do0gI2NZY4uk0WguQpymMKSUJuBB1EAfD3wnpdwjhPiPEMKW9vOwEGKPECIOeBiYbD03E3gRpXRigP9Y99U7xeZiBrUYQdHOEedM/MIe7u7NiIxcg6/v/7d378Fx1dcBx79nn9qHtHqthC0sbIONMWBsrBgwSSChdBxKISEE7BCaoXToZEgbJpnh0aTtlGlnktKGpGmaQAMJFMIbAjEphDiUAAkPWdjY+I0BW7KlXT0sWVrt6+6vf9yLsjY2rA2ruyudz8wd7b17d3V+6yuf/d3fawkbN17Crl3/hjHG7bCUUtOITKX/dDo6Okxn55E3Dj/wAKxcCZ2dlGWVvY9SPj/K1q1XkUw+TDx+OQsW3IHXG3E7LKVUlRKRtcaYklpv3W70rgivvALBICxa5HYkH8zni7Jw4YPMnfttksmH6Oo6i/HxN90OSyk1DWjCAF5+GU4/Hfx+tyMpjYjQ3n4DixY9RSbTw9q1HQwMPOV2WEqpKW7aJ4xcDrq6qOj2i8NpbDyfpUs7qamZzYYNF5JIPOh2SEqpKaxsU4NUC68Xnn8e6urcjuTohEJzWLz4d2zYcAGbNq3CmBytrVe4HZZSagqa9jUMj8du6J43z+1Ijp7PV8uiRU9RX38Omzdfyd69P3M7JKXUFDTtE8ZU4fVGOPXU1TQ0nM/WrVexZ8/tboeklJpiNGFMIV5vmFNOeZzGxj9j27a/ZteuW3SshlLqI6MJY4rxems45ZRHiccvZefO69m06XLy+RG3w1JKTQGaMKYgjyfgjNX4Dsnko6xd+zFGRze6HZZSqsppwpii7LEa17N48Rosa4SurjPo7b3H7bCUUlVME8YUV19/DkuXdlFb28GWLVeyZctf6i0qpdRR0YQxDQSDMzjttDW0t/8dvb130dl5Gvv2Pe92WEqpKqMJY5rweHzMnfsvLFnyPOBh3bpzePPNGygUMh/4WqWUAk0Y004stpyOjvXMmPFX7N79r6xdu4yxsc0f/EKl1LSnCWMa8vminHji7Zxyyi/JZvfS1bWMROIht8NSSlU4TRjTWHPzhSxd2kUkcgqbNl3Gjh3foFDIuR2WUqpCacKY5mpqjmXx4udoa/sq3d3fZf3688hket0OSylVgTRhKDyeAPPm/YCTTrqH/fvX0tm5mO7u75PPj7odmlKqgpQ1YYjIChHZKiI7ROTGQzz/dRHZJCKvi8gaETmu6DlLRNY52xPljFPZWluv4PTTXyYcns+OHdfx0kvt7Nz5LbLZPrdDU0pVgLKt6S0iXmAbcD7QDbwKrDLGbCo651PAy8aYlIh8BTjXGHO589yoMSZ6JL/zaNf0Vu81PPwSu3ffQn//Y4gEaG29gmOO+QtisU8gohVTpaaKI1nTu5wLKC0DdhhjdjpB3Q9cDEwkDGPMs0XnvwR8qYzxqCMQi51JLPYIqdR2uru/S2/v3fT23kkg0EZLy+W0tKyitnYpIuJ2qEqpSVLOr4ptwO6i/W7n2OFcDfxv0X6NiHSKyEsi8tlyBKg+WDg8j/nzf8TZZyc46aT7qK1dSk/PD+jq+hhr1y5lZORVt0NUSk2Siri3ICJfAjqAW4oOH+dUk74IfE9Ejj/Ma69xEktnMpmchGinJ683QmvrSk499XGWL+9j/vzbyGb76Oo6k+3bryOf3+92iEqpMitnwugBZhXtH+scO4CI/AnwTeAiY8zEPBXGmB7n507g/4Alh/olxpjbjTEdxpiOeDz+0UWvDsvvb2DmzGtYtmwTM2d+hZ6e/+DVV0+mv3+126EppcqonAnjVWCeiMwRkQCwEjigt5OILAFuw04WiaLjDSISdB43A2dT1PahKoPPF2P+/P9kyZIX8Xrr2Ljxz3nttXPp6fkx2azW9pSaasqWMIwxeeCrwNPAZuBBY8wbInKziFzknHYLEAUeOqj77ElAp4isB54Fvl3cu0pVlljsLDo6upg79xay2b1s3/4Vfv/7Y1i//nz27LldBwIqNUWUrVutG7RbrfuMMYyNbSCReJBk8gHGx3cAEI0upanpMzQ2XkBd3TLsXtdKKbcdSbdaTRiqbOzk8ToDA08yMPArRkb+ABTw+ZqYMeMq2tr+hpqadrfDVGpa04ShKlIuN8jg4K/p73+EZPIxAFpaLuPYY79OXV1J16tS6iNWKQP3lDqA399Ia+tKWltXkk6/Q3f3D9i7979JJO6jtvYM6urOIBxeQDh8IuHwAgKBGTowUKkKojUM5ap8foS9e+8kkfg5qdRmLOuPEx76/XGami4iHr+Ehobz8HiCLkaq1NSkt6RUVTLGkM3uIZXaQiq1heHhFxkYWI1l7cfrraOp6UIaG1cQjZ5GOLwAjyfgdshKVT1NGGrKKBQyDA2tIZl8hP7+x8nnBwAQ8REKnUg0uoi6urNobFxBODzP5WiVqj6aMNSUVCjkGR/fyujoBsbGNjA29jqjo6+TyewCoKbmeBobV0zUQgKBGXg82kyn1PvRRm81JXk8PiKRk4lETsaeOMA2Pr6TwcGnGBx8it7en7Jnzw+dZ7wEg23U1LQTDB5HJHIy0ejiiWQiIljWGCMjL7Fv3+8YHn6eQmGc2bNvprHxfFfKqFQl0xqGmlIKhQzDw39gfHw7mcwu0uldpNPvkE6/NVETAfD7mwkE2kil3sCelMBDNHoa+fww6fROmps/x/HH/zuh0Bz3CqPUJNAahpq2PJ4gDQ3n0tBw7nuey+X2Obex1jM6up5MZjdNTRcQi32CWGw5Pl+MQiHD7t238s47/8zAwEm0t19Pe/uNeL3hyS+MUhVGaxhKHUIm08Obb15PIvFzRPyEQvOd22ELCYdPpqbmOPz+OIFAHK83MvE6yxojk+khk+khl0vi8zUSDLYRDM7E663TcSWq4mgNQ6kPKRhsY+HCe2lru5aBgV8yNvYG+/evJZl8CDjwS5bHE8LvbyafH8ayRg77nh5PmGBwFuHwPEKhEycGKQaDM7GsFJY1hmWNUiiM4fXWEo0uxu9vLHNJlSqdJgyl3kcstpxYbPnEvmWNk0ptIZPpJpdLksslyWYT5HL9+HwxAoGZTo2iDb8/Tj4/SCazh2x2D5lMD+n0LsbHtzE4+AxFy78cVjDY7jTUL8HrjZDPD5HLDZLPD5HP7yMYnEU0uohIZBHR6KIDEkyhkMey7IWt/P6Gj/7DUdOOJgyljoDXG6K2dgm1tYdcz6tkxlik07tIpbaQzfbh9UbweqPOzwi53CCjo+sYHX2N0dF1DAysBgqI+PD5GvH5GvD5ahkd7aK3946J9/X7WwHLqamkJ47X1n6M5uZLiMc/Rzh84hHGWiCXGyCb7SWX6ycSOZVAoPlDlT+fH6G//wnAoqnpovdNaLncAD5fAyIVsUDotKZtGEpVAcsaxxgLrzdyQDuIPTq+d2JMSiq1BY8ngNdb6ySgWixrlIGBX7J/v73+eji8kLq6M5wk0Ecu10c220ehkMHjCeH1hvB47M2yRslm+wCrKBov9fXnEI9fSnPz5wgGjwHsGk0m8w7j4zvIZvsIBGY6XZpn4fWGsKxxBgd/RV/ffQwOPjmR0ET8NDauoKVlJU1NFwEWQ0PPMjT0DENDv2F8fBvB4CxaW6+gtfVKIpGFk/Spl08+P4LHU1MRsxXowD2l1Huk07vp7/8F/f2PkkptcRrtW/H7WwkEWvF4QhQK4xObZY3j9UYIBI6Z2Hy+GPv2/Y5k8mHGx7cCQjS6BMsaIZ1+2+mi/F5+f9x5z1H8/lZaWi6jpWUVIn4SiftJJh8gk+nG46mhUMgBFh5PhPr6c4jFzmZ4+EUGB58GLKLR02lpWUkgcAwifkR8eDx+CoUc6fTbpNM7GR9/k3R6J+AhHr+ElpZVRCKnvqfTQSazl5GRP2CMdUA5vd7oYTso5HL7GB/fRiq1jVyuj0BgBsHgsc7Wdtg5zywrRX//4/T13cPg4NP4fHXE45+npWUV9fXnuLZGjCYMpVRZGWNIpTaRTD7Cvn3P4ve3EAqd4GzzCARayGZ7Sad3TYyHERGamz9Pff257xmBb0yB4eHf09//CF5vlIaG86mrO/OAb+DZbB+JxP309t7N6GjXYWPz+RoJheZSUzOXfH4fQ0NrAItweCEtLasIBFoYHn6R4eEXnKTyXnZNqw6vN+w8DgNe0um3yOUSh3zNu/z+OMFgOzU1swgG7e3dz8qy9hMMzqKlZSXZ7F76+3+BZY0SCBxDPH4ZtbUdTuxznIT4x9twxhSwrFEsK4XH40ckgMcTcJLm0d+u04ShlJrSMpm9WNYYxuQxJocxOcBDTc1s/P76A87NZhMkkw+TSNzH8PALgP2feiz2cWc7G48nTDbbW7T1Oe1AKadmlMKYLDU1swmF5hMOzycUmk8g0Eo220cm01207SaT2U06vZtMZpczeWYt8fgXaG29kvr6T078B29ZKQYGniSRuJ+BgScP6AghEiQYbKNQyGBZIxMdGA4lEJjB8uV7juqz1IShlFKHkMn0YFkpQqETJm1MTD4/7LRXvP/0/JaVdtqA3iKd3unMTtCDxxPG56vD663D56vD4wk5iTJLoZDFmCweTw3t7TccVXwVMw5DRFYA3we8wE+MMd8+6PkgcDewFBgALjfGvO08dxNwNXZr298aY54uZ6xKqakvGGyb9N/p88VKOs/rrXEWDzuyXmyTqWz91MRuwfkh8BlgIbBKRA7u3nA1MGSMOQG4FfiO89qF2LPLnQysAP5L3GoRUkopBZQxYQDLgB3GmJ3GmCxwP3DxQedcDNzlPH4YOE/seuLFwP3GmIwx5i1gh/N+SimlXFLOhNEG7C7a73aOHfIcY/fHGwaaSnwtACJyjYh0ikhnMpn8iEJXSil1sKofOmmMud0Y02GM6YjH426Ho5RSU1Y5E0YPMKto/1jn2CHPEREfEMNu/C7ltUoppSZRORPGq8A8EZkjIgHsRuwnDjrnCeDLzuNLgd8au5/vE8BKEQmKyBxgHvBKGWNVSin1AcrWrdYYkxeRrwJPY3ervdMY84aI3Ax0GmOeAO4A/kdEdgCDOOtuOuc9CGwC8sC1xhjrkL9IKaXUpNCBe0opNY1N25HeIpIE3jnKlzcD/R9hOJNN43dftZdB43efG2U4zhhTUo+hKZUwPgwR6Sw1y1Yijd991V4Gjd99lV6Gqu9Wq5RSanJowlBKKVUSTRh/dLvbAXxIGr/7qr0MGr/7KroM2oahlFKqJFrDUEopVZJpnzBEZIWIbBWRHSJyo9vxlEJE7hSRhIhsLDrWKCLPiMh252eDmzG+HxGZJSLPisgmEXlDRL7mHK+KMohIjYi8IiLrnfj/yTk+R0Redq6lB5wZDiqWiHhF5DURWe3sV1v8b4vIBhFZJyKdzrGquIYARKReRB4WkS0isllEzqr0+Kd1wihxzY5K9DPsdUKK3QisMcbMA9Y4+5UqD3zDGLMQOBO41vncq6UMGeDTxpjTgMXAChE5E3s9l1ud9V2GsNd7qWRfAzYX7Vdb/ACfMsYsLuqKWi3XENiLyz1ljFkAnIb9b1HZ8Rtjpu0GnAU8XbR/E3CT23GVGPtsYGPR/lZghvN4BrDV7RiPoCyPA+dXYxmAMNAFnIE94MrnHD/g2qq0DXtCzzXAp4HVgFRT/E6MbwPNBx2rimsIe6LVt3Dakasl/mldw+AI1t2oAq3GmL3O416g1c1gSiUis4ElwMtUURmc2znrgATwDPAmsM/Y67pA5V9L3wOuBwrOfhPVFT+AAX4tImtF5BrnWLVcQ3OAJPBT57bgT0QkQoXHP90TxpRk7K8nFd/9TUSiwCPAdcaYkeLnKr0MxhjLGLMY+5v6MmCByyGVTEQuBBLGmLVux/IhfdwYczr2LeVrReSTxU9W+DXkA04HfmSMWQKMcdDtp0qMf7onjKm07kafiMwAcH4mXI7nfYmIHztZ3GuMedQ5XFVlADDG7AOexb6FU++s6wKVfS2dDVwkIm9jL538aez76dUSPwDGmB7nZwJ4DDtxV8s11A10G2NedvYfxk4gFR3/dE8YpazZUS2K1xb5Mna7QEVy1m2/A9hsjPlu0VNVUQYRiYtIvfM4hN3+shk7cVzqnFax8RtjbjLGHGuMmY19zf/WGHMFVRI/gIhERKT23cfAnwIbqZJryBjTC+wWkROdQ+dhL+dQ2fG73Yji9gZcAGzDvgf9TbfjKTHm+4C9QA77m8rV2Peg1wDbgd8AjW7H+T7xfxy7qv06sM7ZLqiWMgCLgNec+DcC/+Acn4u90NcO4CEg6HasJZTlXGB1tcXvxLre2d5492+3Wq4hJ9bFQKdzHf0CaKj0+HWkt1JKqZJM91tSSimlSqQJQymlVEk0YSillCqJJgyllFIl0YShlFKqJJowlKoAInLuu7PGKlWpNGEopZQqiSYMpY6AiHzJWQtjnYjc5kxCOCoitzprY6wRkbhz7mIReUlEXheRx95d20BEThCR3zjraXSJyPHO20eL1ke41xkRr1TF0IShVIlE5CTgcuBsY088aAFXABGg0xhzMvAc8I/OS+4GbjDGLAI2FB2/F/ihsdfTWI49ah/sWXuvw16bZS72nE9KVQzfB5+ilHKcBywFXnW+/IewJ4crAA8459wDPCoiMaDeGPOcc/wu4CFn/qM2Y8xjAMaYNIDzfq8YY7qd/XXYa568UP5iKVUaTRhKlU6Au4wxNx1wUOTvDzrvaOfbyRQ9ttC/T1Vh9JaUUqVbA1wqIi0wsX70cdh/R+/O8vpF4AVjzDAwJCKfcI5fCTxnjNkPdIvIZ533CIpIeFJLodRR0m8wSpXIGLNJRL6FvcqbB3u24GuxF79Z5jyXwG7nAHt66h87CWEncJVz/ErgNhG52XmPL0xiMZQ6ajpbrVIfkoiMGmOibsehVLnpLSmllFIl0RqGUkqpkmgNQymlVEk0YSillCqJJgyllFIl0YShlFKqJJowlFJKlUQThlJKqZL8P0lXUhsIZwaNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 942us/sample - loss: 0.8147 - acc: 0.7653\n",
      "Loss: 0.8146993243558137 Accuracy: 0.7653167\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8375 - acc: 0.4249\n",
      "Epoch 00001: val_loss improved from inf to 1.38638, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/001-1.3864.hdf5\n",
      "36805/36805 [==============================] - 98s 3ms/sample - loss: 1.8375 - acc: 0.4249 - val_loss: 1.3864 - val_acc: 0.5572\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1315 - acc: 0.6462\n",
      "Epoch 00002: val_loss improved from 1.38638 to 0.89790, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/002-0.8979.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1315 - acc: 0.6462 - val_loss: 0.8979 - val_acc: 0.7368\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9199 - acc: 0.7176\n",
      "Epoch 00003: val_loss improved from 0.89790 to 0.84833, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/003-0.8483.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9199 - acc: 0.7176 - val_loss: 0.8483 - val_acc: 0.7410\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7933 - acc: 0.7601\n",
      "Epoch 00004: val_loss improved from 0.84833 to 0.70165, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/004-0.7017.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7933 - acc: 0.7601 - val_loss: 0.7017 - val_acc: 0.8011\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6992 - acc: 0.7898\n",
      "Epoch 00005: val_loss did not improve from 0.70165\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6994 - acc: 0.7898 - val_loss: 0.7556 - val_acc: 0.7734\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6300 - acc: 0.8126\n",
      "Epoch 00006: val_loss did not improve from 0.70165\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6301 - acc: 0.8125 - val_loss: 0.7620 - val_acc: 0.7862\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5692 - acc: 0.8327\n",
      "Epoch 00007: val_loss improved from 0.70165 to 0.57707, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/007-0.5771.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5692 - acc: 0.8327 - val_loss: 0.5771 - val_acc: 0.8444\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8464\n",
      "Epoch 00008: val_loss improved from 0.57707 to 0.57223, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/008-0.5722.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5247 - acc: 0.8464 - val_loss: 0.5722 - val_acc: 0.8330\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4785 - acc: 0.8592\n",
      "Epoch 00009: val_loss improved from 0.57223 to 0.54084, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/009-0.5408.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4785 - acc: 0.8592 - val_loss: 0.5408 - val_acc: 0.8507\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4433 - acc: 0.8702\n",
      "Epoch 00010: val_loss did not improve from 0.54084\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4433 - acc: 0.8701 - val_loss: 0.5447 - val_acc: 0.8507\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8794\n",
      "Epoch 00011: val_loss improved from 0.54084 to 0.51875, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/011-0.5188.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4122 - acc: 0.8794 - val_loss: 0.5188 - val_acc: 0.8521\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8857\n",
      "Epoch 00012: val_loss did not improve from 0.51875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3877 - acc: 0.8857 - val_loss: 0.5369 - val_acc: 0.8523\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3618 - acc: 0.8936\n",
      "Epoch 00013: val_loss did not improve from 0.51875\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3619 - acc: 0.8936 - val_loss: 0.5322 - val_acc: 0.8493\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.9012\n",
      "Epoch 00014: val_loss improved from 0.51875 to 0.51166, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/014-0.5117.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3388 - acc: 0.9012 - val_loss: 0.5117 - val_acc: 0.8579\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3115 - acc: 0.9079\n",
      "Epoch 00015: val_loss did not improve from 0.51166\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3115 - acc: 0.9079 - val_loss: 0.5543 - val_acc: 0.8435\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.9134\n",
      "Epoch 00016: val_loss improved from 0.51166 to 0.48883, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/016-0.4888.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2939 - acc: 0.9134 - val_loss: 0.4888 - val_acc: 0.8665\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2773 - acc: 0.9183\n",
      "Epoch 00017: val_loss improved from 0.48883 to 0.45487, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/017-0.4549.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2775 - acc: 0.9183 - val_loss: 0.4549 - val_acc: 0.8735\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2688 - acc: 0.9217\n",
      "Epoch 00018: val_loss did not improve from 0.45487\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2688 - acc: 0.9217 - val_loss: 0.4605 - val_acc: 0.8770\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9277\n",
      "Epoch 00019: val_loss improved from 0.45487 to 0.43963, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/019-0.4396.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2465 - acc: 0.9278 - val_loss: 0.4396 - val_acc: 0.8793\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9329\n",
      "Epoch 00020: val_loss did not improve from 0.43963\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2290 - acc: 0.9328 - val_loss: 0.4686 - val_acc: 0.8698\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9319\n",
      "Epoch 00021: val_loss did not improve from 0.43963\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2279 - acc: 0.9319 - val_loss: 0.5103 - val_acc: 0.8686\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9396\n",
      "Epoch 00022: val_loss improved from 0.43963 to 0.43800, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/022-0.4380.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2057 - acc: 0.9396 - val_loss: 0.4380 - val_acc: 0.8796\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9413\n",
      "Epoch 00023: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1984 - acc: 0.9413 - val_loss: 0.5087 - val_acc: 0.8663\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9474\n",
      "Epoch 00024: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1815 - acc: 0.9475 - val_loss: 0.4559 - val_acc: 0.8805\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9473\n",
      "Epoch 00025: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1766 - acc: 0.9473 - val_loss: 0.4826 - val_acc: 0.8819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9475\n",
      "Epoch 00026: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1760 - acc: 0.9475 - val_loss: 0.5198 - val_acc: 0.8717\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9549\n",
      "Epoch 00027: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1549 - acc: 0.9549 - val_loss: 0.4494 - val_acc: 0.8880\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9566\n",
      "Epoch 00028: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1490 - acc: 0.9566 - val_loss: 0.4689 - val_acc: 0.8721\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9579\n",
      "Epoch 00029: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1446 - acc: 0.9578 - val_loss: 0.5095 - val_acc: 0.8714\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9570\n",
      "Epoch 00030: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1435 - acc: 0.9569 - val_loss: 0.5439 - val_acc: 0.8637\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9619\n",
      "Epoch 00031: val_loss did not improve from 0.43800\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1262 - acc: 0.9619 - val_loss: 0.5802 - val_acc: 0.8437\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9646\n",
      "Epoch 00032: val_loss improved from 0.43800 to 0.43659, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_6_conv_checkpoint/032-0.4366.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1211 - acc: 0.9646 - val_loss: 0.4366 - val_acc: 0.8919\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9650\n",
      "Epoch 00033: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1176 - acc: 0.9650 - val_loss: 0.4896 - val_acc: 0.8826\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9661\n",
      "Epoch 00034: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1156 - acc: 0.9661 - val_loss: 0.4700 - val_acc: 0.8782\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9712\n",
      "Epoch 00035: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1034 - acc: 0.9712 - val_loss: 0.5184 - val_acc: 0.8740\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9720\n",
      "Epoch 00036: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1009 - acc: 0.9720 - val_loss: 0.7426 - val_acc: 0.8160\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9732\n",
      "Epoch 00037: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0965 - acc: 0.9732 - val_loss: 0.5528 - val_acc: 0.8649\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9727\n",
      "Epoch 00038: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0940 - acc: 0.9727 - val_loss: 0.4587 - val_acc: 0.8901\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9700\n",
      "Epoch 00039: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1030 - acc: 0.9700 - val_loss: 0.4621 - val_acc: 0.8868\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9737\n",
      "Epoch 00040: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0881 - acc: 0.9737 - val_loss: 0.4589 - val_acc: 0.8880\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9742\n",
      "Epoch 00041: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0893 - acc: 0.9742 - val_loss: 0.5220 - val_acc: 0.8796\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9744\n",
      "Epoch 00042: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0886 - acc: 0.9744 - val_loss: 0.4794 - val_acc: 0.8777\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9802\n",
      "Epoch 00043: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0732 - acc: 0.9802 - val_loss: 0.5965 - val_acc: 0.8649\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9752\n",
      "Epoch 00044: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0855 - acc: 0.9752 - val_loss: 0.4417 - val_acc: 0.8940\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9785\n",
      "Epoch 00045: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0763 - acc: 0.9785 - val_loss: 0.4438 - val_acc: 0.8968\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9805\n",
      "Epoch 00046: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0696 - acc: 0.9805 - val_loss: 0.4998 - val_acc: 0.8819\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9812\n",
      "Epoch 00047: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0684 - acc: 0.9812 - val_loss: 0.5434 - val_acc: 0.8691\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9794\n",
      "Epoch 00048: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0717 - acc: 0.9794 - val_loss: 0.5027 - val_acc: 0.8814\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9832\n",
      "Epoch 00049: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0614 - acc: 0.9832 - val_loss: 0.5015 - val_acc: 0.8942\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9809\n",
      "Epoch 00050: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0660 - acc: 0.9808 - val_loss: 0.4872 - val_acc: 0.8882\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9812\n",
      "Epoch 00051: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0656 - acc: 0.9812 - val_loss: 0.4555 - val_acc: 0.8894\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9847\n",
      "Epoch 00052: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0576 - acc: 0.9847 - val_loss: 0.5524 - val_acc: 0.8805\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9840\n",
      "Epoch 00053: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0566 - acc: 0.9840 - val_loss: 0.4436 - val_acc: 0.8926\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9835\n",
      "Epoch 00054: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0593 - acc: 0.9834 - val_loss: 0.6238 - val_acc: 0.8724\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9820\n",
      "Epoch 00055: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0640 - acc: 0.9820 - val_loss: 0.5234 - val_acc: 0.8831\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9850\n",
      "Epoch 00056: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0533 - acc: 0.9850 - val_loss: 0.5623 - val_acc: 0.8761\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9861\n",
      "Epoch 00057: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0503 - acc: 0.9861 - val_loss: 0.4462 - val_acc: 0.8991\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9853\n",
      "Epoch 00058: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0529 - acc: 0.9853 - val_loss: 0.4657 - val_acc: 0.8970\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9882\n",
      "Epoch 00059: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0464 - acc: 0.9882 - val_loss: 0.5227 - val_acc: 0.8882\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9871\n",
      "Epoch 00060: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0484 - acc: 0.9870 - val_loss: 0.5750 - val_acc: 0.8758\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9834\n",
      "Epoch 00061: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0588 - acc: 0.9834 - val_loss: 0.5217 - val_acc: 0.8835\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9873\n",
      "Epoch 00062: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0478 - acc: 0.9873 - val_loss: 0.4905 - val_acc: 0.8942\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9868\n",
      "Epoch 00063: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0473 - acc: 0.9868 - val_loss: 0.4694 - val_acc: 0.8994\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9883\n",
      "Epoch 00064: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0440 - acc: 0.9883 - val_loss: 0.5122 - val_acc: 0.8901\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9871\n",
      "Epoch 00065: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0465 - acc: 0.9871 - val_loss: 0.5226 - val_acc: 0.8859\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9852\n",
      "Epoch 00066: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0526 - acc: 0.9852 - val_loss: 0.5534 - val_acc: 0.8819\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9885\n",
      "Epoch 00067: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0419 - acc: 0.9885 - val_loss: 0.4738 - val_acc: 0.8956\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9887\n",
      "Epoch 00068: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0423 - acc: 0.9887 - val_loss: 0.5353 - val_acc: 0.8828\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9897\n",
      "Epoch 00069: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0406 - acc: 0.9897 - val_loss: 0.6128 - val_acc: 0.8661\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9877\n",
      "Epoch 00070: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0451 - acc: 0.9877 - val_loss: 0.5509 - val_acc: 0.8828\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9905\n",
      "Epoch 00071: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0367 - acc: 0.9905 - val_loss: 0.4735 - val_acc: 0.8959\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9905\n",
      "Epoch 00072: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0366 - acc: 0.9904 - val_loss: 0.5336 - val_acc: 0.8863\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9847\n",
      "Epoch 00073: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0554 - acc: 0.9847 - val_loss: 0.5481 - val_acc: 0.8845\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9914\n",
      "Epoch 00074: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0348 - acc: 0.9914 - val_loss: 0.6252 - val_acc: 0.8700\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9902\n",
      "Epoch 00075: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0376 - acc: 0.9902 - val_loss: 0.5313 - val_acc: 0.8861\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9914\n",
      "Epoch 00076: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0337 - acc: 0.9914 - val_loss: 0.5131 - val_acc: 0.8949\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9908\n",
      "Epoch 00077: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0361 - acc: 0.9908 - val_loss: 0.5144 - val_acc: 0.8968\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9891\n",
      "Epoch 00078: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0392 - acc: 0.9891 - val_loss: 0.5164 - val_acc: 0.8889\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9900\n",
      "Epoch 00079: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0353 - acc: 0.9900 - val_loss: 0.4554 - val_acc: 0.9010\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9907\n",
      "Epoch 00080: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0357 - acc: 0.9907 - val_loss: 0.5148 - val_acc: 0.8947\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9904\n",
      "Epoch 00081: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0356 - acc: 0.9904 - val_loss: 0.5019 - val_acc: 0.8945\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9881\n",
      "Epoch 00082: val_loss did not improve from 0.43659\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0429 - acc: 0.9881 - val_loss: 0.5317 - val_acc: 0.8847\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 955us/sample - loss: 0.5152 - acc: 0.8633\n",
      "Loss: 0.51524708325494 Accuracy: 0.8633437\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8948 - acc: 0.4029\n",
      "Epoch 00001: val_loss improved from inf to 1.35416, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/001-1.3542.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 1.8948 - acc: 0.4029 - val_loss: 1.3542 - val_acc: 0.5823\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0738 - acc: 0.6629\n",
      "Epoch 00002: val_loss improved from 1.35416 to 0.79796, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/002-0.7980.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.0738 - acc: 0.6629 - val_loss: 0.7980 - val_acc: 0.7626\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7942 - acc: 0.7595\n",
      "Epoch 00003: val_loss improved from 0.79796 to 0.74794, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/003-0.7479.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7942 - acc: 0.7595 - val_loss: 0.7479 - val_acc: 0.7817\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.8135\n",
      "Epoch 00004: val_loss improved from 0.74794 to 0.55118, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/004-0.5512.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6308 - acc: 0.8135 - val_loss: 0.5512 - val_acc: 0.8495\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5295 - acc: 0.8438\n",
      "Epoch 00005: val_loss improved from 0.55118 to 0.46243, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/005-0.4624.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5294 - acc: 0.8438 - val_loss: 0.4624 - val_acc: 0.8765\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8671\n",
      "Epoch 00006: val_loss improved from 0.46243 to 0.43204, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/006-0.4320.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4519 - acc: 0.8671 - val_loss: 0.4320 - val_acc: 0.8789\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3999 - acc: 0.8820\n",
      "Epoch 00007: val_loss improved from 0.43204 to 0.41983, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/007-0.4198.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3999 - acc: 0.8819 - val_loss: 0.4198 - val_acc: 0.8775\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3562 - acc: 0.8936\n",
      "Epoch 00008: val_loss improved from 0.41983 to 0.36297, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/008-0.3630.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3561 - acc: 0.8937 - val_loss: 0.3630 - val_acc: 0.8987\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3240 - acc: 0.9036\n",
      "Epoch 00009: val_loss improved from 0.36297 to 0.34641, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/009-0.3464.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3240 - acc: 0.9035 - val_loss: 0.3464 - val_acc: 0.9017\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2942 - acc: 0.9123\n",
      "Epoch 00010: val_loss did not improve from 0.34641\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2942 - acc: 0.9123 - val_loss: 0.3493 - val_acc: 0.9040\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2665 - acc: 0.9208\n",
      "Epoch 00011: val_loss improved from 0.34641 to 0.32148, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/011-0.3215.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2667 - acc: 0.9208 - val_loss: 0.3215 - val_acc: 0.9075\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2511 - acc: 0.9249\n",
      "Epoch 00012: val_loss improved from 0.32148 to 0.30926, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/012-0.3093.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2511 - acc: 0.9249 - val_loss: 0.3093 - val_acc: 0.9089\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9326\n",
      "Epoch 00013: val_loss improved from 0.30926 to 0.26586, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/013-0.2659.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2265 - acc: 0.9326 - val_loss: 0.2659 - val_acc: 0.9217\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9372\n",
      "Epoch 00014: val_loss did not improve from 0.26586\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2130 - acc: 0.9372 - val_loss: 0.3055 - val_acc: 0.9099\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9404\n",
      "Epoch 00015: val_loss did not improve from 0.26586\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1998 - acc: 0.9403 - val_loss: 0.3102 - val_acc: 0.9143\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9440\n",
      "Epoch 00016: val_loss improved from 0.26586 to 0.26521, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/016-0.2652.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1865 - acc: 0.9440 - val_loss: 0.2652 - val_acc: 0.9215\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9470\n",
      "Epoch 00017: val_loss did not improve from 0.26521\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1740 - acc: 0.9470 - val_loss: 0.2869 - val_acc: 0.9208\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9496\n",
      "Epoch 00018: val_loss did not improve from 0.26521\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1666 - acc: 0.9496 - val_loss: 0.2733 - val_acc: 0.9292\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9558\n",
      "Epoch 00019: val_loss improved from 0.26521 to 0.26223, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/019-0.2622.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1503 - acc: 0.9558 - val_loss: 0.2622 - val_acc: 0.9264\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9565\n",
      "Epoch 00020: val_loss improved from 0.26223 to 0.25202, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/020-0.2520.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1468 - acc: 0.9565 - val_loss: 0.2520 - val_acc: 0.9334\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9599\n",
      "Epoch 00021: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1358 - acc: 0.9598 - val_loss: 0.3458 - val_acc: 0.9059\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9579\n",
      "Epoch 00022: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1395 - acc: 0.9579 - val_loss: 0.2891 - val_acc: 0.9259\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9636\n",
      "Epoch 00023: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1193 - acc: 0.9636 - val_loss: 0.2730 - val_acc: 0.9271\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9672\n",
      "Epoch 00024: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1143 - acc: 0.9672 - val_loss: 0.2953 - val_acc: 0.9229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9679\n",
      "Epoch 00025: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1075 - acc: 0.9679 - val_loss: 0.2727 - val_acc: 0.9276\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9681\n",
      "Epoch 00026: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1078 - acc: 0.9681 - val_loss: 0.2820 - val_acc: 0.9229\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9713\n",
      "Epoch 00027: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0960 - acc: 0.9713 - val_loss: 0.3099 - val_acc: 0.9131\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9688\n",
      "Epoch 00028: val_loss did not improve from 0.25202\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1018 - acc: 0.9687 - val_loss: 0.3152 - val_acc: 0.9152\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9717\n",
      "Epoch 00029: val_loss improved from 0.25202 to 0.22711, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/029-0.2271.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0942 - acc: 0.9717 - val_loss: 0.2271 - val_acc: 0.9369\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9751\n",
      "Epoch 00030: val_loss did not improve from 0.22711\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0823 - acc: 0.9750 - val_loss: 0.2625 - val_acc: 0.9304\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9726\n",
      "Epoch 00031: val_loss improved from 0.22711 to 0.22326, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_7_conv_checkpoint/031-0.2233.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0910 - acc: 0.9726 - val_loss: 0.2233 - val_acc: 0.9422\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9787\n",
      "Epoch 00032: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0745 - acc: 0.9786 - val_loss: 0.2782 - val_acc: 0.9283\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9784\n",
      "Epoch 00033: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0750 - acc: 0.9784 - val_loss: 0.2386 - val_acc: 0.9399\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9808\n",
      "Epoch 00034: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0664 - acc: 0.9808 - val_loss: 0.2275 - val_acc: 0.9422\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9802\n",
      "Epoch 00035: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0674 - acc: 0.9801 - val_loss: 0.3122 - val_acc: 0.9217\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9769\n",
      "Epoch 00036: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0799 - acc: 0.9769 - val_loss: 0.3171 - val_acc: 0.9224\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9840\n",
      "Epoch 00037: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0569 - acc: 0.9839 - val_loss: 0.2314 - val_acc: 0.9394\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9821\n",
      "Epoch 00038: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0621 - acc: 0.9821 - val_loss: 0.2562 - val_acc: 0.9380\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9839\n",
      "Epoch 00039: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0565 - acc: 0.9839 - val_loss: 0.2765 - val_acc: 0.9306\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9836\n",
      "Epoch 00040: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0572 - acc: 0.9836 - val_loss: 0.2514 - val_acc: 0.9385\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9838\n",
      "Epoch 00041: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0573 - acc: 0.9838 - val_loss: 0.2813 - val_acc: 0.9345\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9859\n",
      "Epoch 00042: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0494 - acc: 0.9859 - val_loss: 0.3417 - val_acc: 0.9187\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9868\n",
      "Epoch 00043: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0471 - acc: 0.9868 - val_loss: 0.2562 - val_acc: 0.9392\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9841\n",
      "Epoch 00044: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0529 - acc: 0.9841 - val_loss: 0.2676 - val_acc: 0.9348\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9862\n",
      "Epoch 00045: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0478 - acc: 0.9863 - val_loss: 0.2687 - val_acc: 0.9383\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9885\n",
      "Epoch 00046: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0406 - acc: 0.9885 - val_loss: 0.2749 - val_acc: 0.9345\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9890\n",
      "Epoch 00047: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0397 - acc: 0.9890 - val_loss: 0.3106 - val_acc: 0.9278\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9865\n",
      "Epoch 00048: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0470 - acc: 0.9865 - val_loss: 0.2559 - val_acc: 0.9369\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9883\n",
      "Epoch 00049: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0407 - acc: 0.9883 - val_loss: 0.2663 - val_acc: 0.9371\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9905\n",
      "Epoch 00050: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0352 - acc: 0.9905 - val_loss: 0.2819 - val_acc: 0.9301\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9881\n",
      "Epoch 00051: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0425 - acc: 0.9881 - val_loss: 0.2639 - val_acc: 0.9366\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9895\n",
      "Epoch 00052: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0366 - acc: 0.9895 - val_loss: 0.2870 - val_acc: 0.9341\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9914\n",
      "Epoch 00053: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0323 - acc: 0.9914 - val_loss: 0.2600 - val_acc: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9884\n",
      "Epoch 00054: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0388 - acc: 0.9884 - val_loss: 0.3138 - val_acc: 0.9243\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9920\n",
      "Epoch 00055: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0301 - acc: 0.9920 - val_loss: 0.2820 - val_acc: 0.9359\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9901\n",
      "Epoch 00056: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0337 - acc: 0.9901 - val_loss: 0.3121 - val_acc: 0.9322\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9913\n",
      "Epoch 00057: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0296 - acc: 0.9913 - val_loss: 0.3092 - val_acc: 0.9299\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9914\n",
      "Epoch 00058: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0319 - acc: 0.9914 - val_loss: 0.2471 - val_acc: 0.9453\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9922\n",
      "Epoch 00059: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0278 - acc: 0.9922 - val_loss: 0.3365 - val_acc: 0.9271\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9896\n",
      "Epoch 00060: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0375 - acc: 0.9896 - val_loss: 0.3133 - val_acc: 0.9290\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9922\n",
      "Epoch 00061: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0302 - acc: 0.9922 - val_loss: 0.2445 - val_acc: 0.9462\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9917\n",
      "Epoch 00062: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0289 - acc: 0.9917 - val_loss: 0.3160 - val_acc: 0.9336\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9925\n",
      "Epoch 00063: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0273 - acc: 0.9925 - val_loss: 0.3225 - val_acc: 0.9248\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0254 - acc: 0.9933 - val_loss: 0.3375 - val_acc: 0.9238\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9924\n",
      "Epoch 00065: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0272 - acc: 0.9924 - val_loss: 0.2886 - val_acc: 0.9366\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9927\n",
      "Epoch 00066: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0256 - acc: 0.9927 - val_loss: 0.4200 - val_acc: 0.9150\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9885\n",
      "Epoch 00067: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0380 - acc: 0.9885 - val_loss: 0.2532 - val_acc: 0.9427\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9940\n",
      "Epoch 00068: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0224 - acc: 0.9940 - val_loss: 0.3219 - val_acc: 0.9213\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9905\n",
      "Epoch 00069: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0334 - acc: 0.9905 - val_loss: 0.2871 - val_acc: 0.9408\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9937\n",
      "Epoch 00070: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0243 - acc: 0.9937 - val_loss: 0.2668 - val_acc: 0.9362\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9956\n",
      "Epoch 00071: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0177 - acc: 0.9956 - val_loss: 0.3086 - val_acc: 0.9327\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9939\n",
      "Epoch 00072: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0224 - acc: 0.9939 - val_loss: 0.2974 - val_acc: 0.9397\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9929\n",
      "Epoch 00073: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0254 - acc: 0.9929 - val_loss: 0.2756 - val_acc: 0.9404\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9929\n",
      "Epoch 00074: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0247 - acc: 0.9929 - val_loss: 0.4049 - val_acc: 0.9210\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9946\n",
      "Epoch 00075: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0205 - acc: 0.9946 - val_loss: 0.3635 - val_acc: 0.9243\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9945\n",
      "Epoch 00076: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0203 - acc: 0.9945 - val_loss: 0.2922 - val_acc: 0.9390\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9949\n",
      "Epoch 00077: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0183 - acc: 0.9949 - val_loss: 0.2610 - val_acc: 0.9422\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9918\n",
      "Epoch 00078: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0293 - acc: 0.9918 - val_loss: 0.2505 - val_acc: 0.9453\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9959\n",
      "Epoch 00079: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0159 - acc: 0.9959 - val_loss: 0.2284 - val_acc: 0.9481\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9957\n",
      "Epoch 00080: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0166 - acc: 0.9956 - val_loss: 0.3924 - val_acc: 0.9189\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9889\n",
      "Epoch 00081: val_loss did not improve from 0.22326\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0411 - acc: 0.9889 - val_loss: 0.2690 - val_acc: 0.9385\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4lNX58PHvmWSyh+yEsAYUkT2sYlVEqYjYolYRF9yX1rr81Naq3UStr1qtpdatVHGpilKUqnWB2oKgghKQJQjKToCQfd9n5n7/ODPJZCVAhoRwf65rriTPcp4zk5lzn23OY0QEpZRS6mAcHZ0BpZRSxwYNGEoppdpEA4ZSSqk20YChlFKqTTRgKKWUahMNGEoppdpEA4ZSSqk20YChlFKqTTRgKKWUapPgjs5Ae0pMTJTU1NSOzoZSSh0z1qxZkyciSW05tksFjNTUVNLT0zs6G0opdcwwxuxu67HaJaWUUqpNNGAopZRqEw0YSiml2qRLjWE0p7a2lr1791JVVdXRWTkmhYWF0bt3b5xOZ0dnRSnVwbp8wNi7dy/R0dGkpqZijOno7BxTRIT8/Hz27t1L//79Ozo7SqkO1uW7pKqqqkhISNBgcRiMMSQkJGjrTCkFHAcBA9BgcQT0tVNK+RwXAeNgqqv343IVd3Q2lFKqU9OAAdTUHMDlKglI2kVFRTz33HOHde60adMoKipq8/GzZ8/mySefPKxrKaXUwWjAAIwJAjwBSbu1gOFyuVo996OPPiI2NjYQ2VJKqUOmAQMAByLugKR83333sX37dtLS0rjnnntYtmwZZ5xxBtOnT2fIkCEAXHjhhYwZM4ahQ4cyd+7cunNTU1PJy8tj165dDB48mJtuuomhQ4cyZcoUKisrW73uunXrmDBhAiNGjOCiiy6isLAQgKeffpohQ4YwYsQILrvsMgA+++wz0tLSSEtLY9SoUZSWlgbktVBKHdu6/LRaf1u33klZ2bom2z2ecsCBwxF+yGlGRaUxcOCcFvc/9thjZGRksG6dve6yZctYu3YtGRkZdVNV582bR3x8PJWVlYwbN46LL76YhISERnnfyvz58/n73//OpZdeyjvvvMOsWbNavO7VV1/NX//6V84880x+//vf8+CDDzJnzhwee+wxdu7cSWhoaF1315NPPsmzzz7LaaedRllZGWFhYYf8Oiiluj5tYQBwdGcCjR8/vsH3Gp5++mlGjhzJhAkTyMzMZOvWrU3O6d+/P2lpaQCMGTOGXbt2tZh+cXExRUVFnHnmmQBcc801LF++HIARI0Zw5ZVX8vrrrxMcbOsLp512GnfffTdPP/00RUVFdduVUsrfcVUytNQSqKj4HhE3kZGDj0o+IiMj635ftmwZn376KStXriQiIoJJkyY1+72H0NDQut+DgoIO2iXVkg8//JDly5fzwQcf8Mgjj7Bx40buu+8+zj//fD766CNOO+00Fi9ezMknn3xY6Sului5tYQDGOAjUoHd0dHSrYwLFxcXExcURERHBli1bWLVq1RFfMyYmhri4OFasWAHAP/7xD84880w8Hg+ZmZmcddZZPP744xQXF1NWVsb27dsZPnw49957L+PGjWPLli1HnAelVNdzXLUwWuZAJDABIyEhgdNOO41hw4Zx3nnncf755zfYP3XqVF544QUGDx7MoEGDmDBhQrtc99VXX+VnP/sZFRUVDBgwgJdffhm3282sWbMoLi5GRLjjjjuIjY3ld7/7HUuXLsXhcDB06FDOO++8dsmDUqprMSLS0XloN2PHjpXGN1DavHkzgwe33tVUVbUbl6uIqKiRgczeMastr6FS6thkjFkjImPbcqx2SQGBnFarlFJdhQYM6scwulJrSyml2psGDKD+ZQjMOIZSSnUFAQsYxph5xpgcY0xGC/vvMcas8z4yjDFuY0y8d98uY8xG77705s5v37wGAQRs4FsppbqCQLYwXgGmtrRTRJ4QkTQRSQPuBz4TkQK/Q87y7m/TYMyR0RaGUkodTMAChogsBwoOeqB1OTA/UHk5GDuGoS0MpZRqTYePYRhjIrAtkXf8NguwxBizxhhz80HOv9kYk26MSc/NzT3MPAR5f+scM6WioqIOabtSSh0NHR4wgB8DXzTqjjpdREYD5wG3GmMmtnSyiMwVkbEiMjYpKekws6AtDKWUOpjOEDAuo1F3lIjs8/7MARYB4wOZgUB2Sd133308++yzdX/7bnJUVlbG5MmTGT16NMOHD+e9995rc5oiwj333MOwYcMYPnw4b7/9NgBZWVlMnDiRtLQ0hg0bxooVK3C73Vx77bV1x/75z39u9+eolDo+dOjSIMaYGOBMYJbftkjAISKl3t+nAA+1ywXvvBPWNV3e3CEewj3lOBxhYJyHlmZaGsxpeXnzmTNncuedd3LrrbcCsGDBAhYvXkxYWBiLFi2iW7du5OXlMWHCBKZPn96me2i/++67rFu3jvXr15OXl8e4ceOYOHEib775Jueeey6/+c1vcLvdVFRUsG7dOvbt20dGhp2sdih38FNKKX8BCxjGmPnAJCDRGLMXeABwAojIC97DLgKWiEi536nJwCJvwRkMvCkinwQqn97MBizpUaNGkZOTw/79+8nNzSUuLo4+ffpQW1vLr3/9a5YvX47D4WDfvn1kZ2fTo0ePg6b5+eefc/nllxMUFERycjJnnnkmq1evZty4cVx//fXU1tZy4YUXkpaWxoABA9ixYwe33347559/PlOmTAnYc1VKdW0BCxgicnkbjnkFO/3Wf9sOIDCLOrXQEhCPi8rydYSG9iEkJLndLztjxgwWLlzIgQMHmDlzJgBvvPEGubm5rFmzBqfTSWpqarPLmh+KiRMnsnz5cj788EOuvfZa7r77bq6++mrWr1/P4sWLeeGFF1iwYAHz5s1rj6ellDrOdIYxjA4X6Gm1M2fO5K233mLhwoXMmDEDsMuad+/eHafTydKlS9m9e3eb0zvjjDN4++23cbvd5Obmsnz5csaPH8/u3btJTk7mpptu4sYbb2Tt2rXk5eXh8Xi4+OKL+cMf/sDatWsD8hyVUl2fLm+OL2AYAjWtdujQoZSWltKrVy9SUlIAuPLKK/nxj3/M8OHDGTt27CHdsOiiiy5i5cqVjBw5EmMMf/zjH+nRowevvvoqTzzxBE6nk6ioKF577TX27dvHddddh8djg+Gjjz4akOeolOr6dHlzr9LSb3A6EwgL6xuo7B2zdHlzpbouXd78MBgTuJsoKaVUV6ABo04QupaUUkq1TAOGl21hdI6lQZRSqjPSgOHlu4mSUkqp5mnAqKNjGEop1RoNGF52xVrtklJKqZZowKgTmBZGUVERzz333GGdO23aNF37SSnVaWjA8ArUGEZrAcPlcrV67kcffURsbGy750kppQ6HBow6QQFb3nz79u2kpaVxzz33sGzZMs444wymT5/OkCFDALjwwgsZM2YMQ4cOZe7cuXXnpqamkpeXx65duxg8eDA33XQTQ4cOZcqUKVRWVja51gcffMApp5zCqFGj+OEPf0h2djYAZWVlXHfddQwfPpwRI0bwzjv2XlWffPIJo0ePZuTIkUyePLndn7tSqms5rpYGaWF1cwA8niREYggKEuwyIW1zkNXNeeyxx8jIyGCd98LLli1j7dq1ZGRk0L9/fwDmzZtHfHw8lZWVjBs3josvvpiEhIQG6WzdupX58+fz97//nUsvvZR33nmHWbNmNTjm9NNPZ9WqVRhjePHFF/njH//In/70Jx5++GFiYmLYuHEjAIWFheTm5nLTTTexfPly+vfvT0FBW++mq5Q6Xh1XAaM1xhiO1iop48ePrwsWAE8//TSLFi0CIDMzk61btzYJGP379yctLQ2AMWPGsGvXribp7t27l5kzZ5KVlUVNTU3dNT799FPeeuutuuPi4uL44IMPmDhxYt0x8fHx7foclVJdz3EVMFprCdTUFFFdvYfIyJE4HId4E6VDFBkZWff7smXL+PTTT1m5ciURERFMmjSp2WXOQ0ND634PCgpqtkvq9ttv5+6772b69OksW7aM2bNnByT/Sqnjk45heNlptdDeU2ujo6MpLS1tcX9xcTFxcXFERESwZcsWVq1addjXKi4uplevXgC8+uqrddvPOeecBreJLSwsZMKECSxfvpydO3cCaJeUUuqgNGDUCcw9MRISEjjttNMYNmwY99xzT5P9U6dOxeVyMXjwYO677z4mTJhw2NeaPXs2M2bMYMyYMSQmJtZt/+1vf0thYSHDhg1j5MiRLF26lKSkJObOnctPfvITRo4cWXdjJ6WUaknAljc3xswDfgTkiMiwZvZPAt4Ddno3vSsiD3n3TQX+gl0R8EUReawt1zyS5c1drmIqK7cSHn4ywcFRbbnccUOXN1eq6+osy5u/Akw9yDErRCTN+/AFiyDgWeA8YAhwuTFmSADz6eXrktLlQZRSqjkBCxgishw4nI7x8cA2EdkhIjXAW8AF7Zq5ZtTfplWXB1FKqeZ09BjGqcaY9caYj40xQ73begGZfsfs9W4LMN9LoS0MpZRqTkdOq10L9BORMmPMNOBfwMBDTcQYczNwM0Dfvod/e9X6FoYGDKWUak6HtTBEpEREyry/fwQ4jTGJwD6gj9+hvb3bWkpnroiMFZGxSUlJh52fQE2rVUqprqLDAoYxpocxxnh/H+/NSz6wGhhojOlvjAkBLgPeD3yOtIWhlFKtCViXlDFmPjAJSDTG7AUeAJwAIvICcAlwizHGBVQCl4md4+syxtwGLMZOXZonIpsClU+//AKmUwSMqKgoysrKOjobSinVQMAChohcfpD9zwDPtLDvI+CjQOSrdUHooLdSSjWvo2dJdSrGONp9Wu19993XYFmO2bNn8+STT1JWVsbkyZMZPXo0w4cP57333jtoWi0tg97cMuUtLWmulFKH67hafPDOT+5k3YEW1jcH3O5yjHHgcIS3Oc20HmnMmdryqoYzZ87kzjvv5NZbbwVgwYIFLF68mLCwMBYtWkS3bt3Iy8tjwoQJTJ8+3ds11rzmlkH3eDzNLlPe3JLmSil1JI6rgHFwbb8PRluNGjWKnJwc9u/fT25uLnFxcfTp04fa2lp+/etfs3z5chwOB/v27SM7O5sePXq0mFZzy6Dn5uY2u0x5c0uaK6XUkTiuAkZrLQGAiorvACEi4uR2ve6MGTNYuHAhBw4cqFvk74033iA3N5c1a9bgdDpJTU1tdllzn7Yug66UUoGiYxgNOAIyS2rmzJm89dZbLFy4kBkzZgB2KfLu3bvjdDpZunQpu3fvbjWNlpZBb2mZ8uaWNFdKqSOhAcOPHfRu/4AxdOhQSktL6dWrFykpKQBceeWVpKenM3z4cF577TVOPrn1Vk1Ly6C3tEx5c0uaK6XUkQjY8uYd4UiWNweorNyF211CVNSIQGTvmKXLmyvVdXWW5c2POYGYVquUUl2FBgw/dgFC/eKeUko157gIGK12u4nArl1QUID9prd0iuVBOouu1GWplDoyXT5ghIWFkZ+f33LBZwwUFkJZmS5x3oiIkJ+fT1hYWEdnRSnVCXT572H07t2bvXv3kpub2/JB+flQVoa7JJTa2gJCQzdjTJd/adokLCyM3r17d3Q2lFKdQJcvFZ1OZ923oFt0xRXQuzfZL17B5s1XMH78FiIiBh2dDCql1DGiy3dJtUlcHBQVERQUCdg1pZRSSjWkAQNswCgs1IChlFKt0IABEBsLhYU4HL6AoTcvUkqpxjRggF+XVBSgLQyllGpOwAKGMWaeMSbHGJPRwv4rjTEbjDEbjTFfGmNG+u3b5d2+zhiT3tz57SouDioqCHI7AfB4NGAopVRjgWxhvAJMbWX/TuBMERkOPAzMbbT/LBFJa+saJ0ckNhaAoJJaQFsYSinVnEDe03u5MSa1lf1f+v25Cui4yf7emwsFlfoCho5hKKVUY51lDOMG4GO/vwVYYoxZY4y5OeBX97YwHMWVgNEWhlJKNaPDv7hnjDkLGzBO99t8uojsM8Z0B/5jjNkiIstbOP9m4GaAvn37Hl4mvC0MU1yCIyJCA4ZSSjWjQ1sYxpgRwIvABSKS79suIvu8P3OARcD4ltIQkbkiMlZExiYlJR1eRnz3u/Z+F0O7pJRSqqkOCxjGmL7Au8BVIvK93/ZIY0y073dgCtDsTKt24+2SsgEjSmdJKaVUMwLWJWWMmQ9MAhKNMXuBBwAngIi8APweSACeM8YAuLwzopKBRd5twcCbIvJJoPIJ1LcwvMuDaJeUUko1FchZUpcfZP+NwI3NbN8BjGx6RgCFhkJ4uF+XlAYMpZRqrLPMkup4fsuD6BiGUko1pQHDx295EG1hKKVUUxowfPxWrNVBb6WUakoDho+3S0rHMJRSqnkaMHwadEnpGIZSSjWmAcOnUQtDRDo6R0op1alowPCJi4PiYhyEAx48nuqOzpFSSnUqGjB84uJAhOCKIEBXrFVKqcY0YPh4lwdxlhlAb6KklFKNacDw8S4PElzqAfQmSkop1ZgGDJ+6myhpwFBKqeZowPDxdkkFl7oAHcNQSqnGNGD4eFsYDr2vt1JKNUsDhk9dwLDTad3uko7MjVJKdToaMHyioiAoCGep/cJedXVmB2dIKaU6Fw0YPsZAbCyOkgqczkQqK3d2dI6UUqpT0YDhz7s8SFhYf6qqNGAopZQ/DRj+vEuc24Cxo6Nzo5RSnUpAA4YxZp4xJscYk9HCfmOMedoYs80Ys8EYM9pv3zXGmK3exzWBzGcd74q14eEDqKrajYj7qFxWKaWOBW0KGMaY/zPGdPMW8C8ZY9YaY6a04dRXgKmt7D8PGOh93Aw8771ePPAAcAowHnjAGBPXlrweEb8uKZFaqqv3B/ySSil1rGhrC+N6ESkBpgBxwFXAYwc7SUSWAwWtHHIB8JpYq4BYY0wKcC7wHxEpEJFC4D+0Hnjah1+XFKDjGEop5Se4jccZ789pwD9EZJMxxrR2Qhv1Avznr+71bmtpe9OMGXMztnVC3759jyw33i6psNBUwBcwJh5Zmkq1A7cbSkqguBgqKsDlsttcLoiMhPh4+/YNDQURKC+H0tL6c3yP2lrbkI6Lsz+dTpue71FWZs8pLbVpdOsGSUn20a0b5ObC/v32UVIC0dH20a0bBAVBVZV9VFba/PmI2GvX1kJNjd0XEwMJCTbv4eFQUGAf+fk2jeDg+ofHY8+rrrY//R8ul30eISH2+Tud9ngR+zMiAvr0gb597c/SUvjuO/vYts3uT0mxj4QEKCqC7Gz7yMurfx1LS22+o6LqH+HhEBZmrxsaaidb+p6vx2Nf0/Jy+7pWVTX8n/qO8XhsuhER0L27fSQm2v/Xnj2QmWlfb4/HvsYOh73usGGQllb/OPHE+usHSlsDxhpjzBKgP3C/MSYa8AQuW20nInOBuQBjx449srsexcZCTQ1hkgQYnVp7DBOxhVtVlf2AObxt6eJiKCy0j7Iy+wF0Om2hFBlpP6zJybYQKy6Gb76BtWth/Xr7oe7WzRaQkZG2UPQVJpWV9sPq+0A7HA0LrcpKm56vAK+stIVfdbUt8HyFZ2KiTb+01B5XVFR/XluEhdk0j8b9v4w5vOs4nfbcmprm9zsctvD1BUSPt6QJCbEPp9Pu9/0dFGSP8wUUl8um73DYn6Wl9vVuLDLSFrJVVbBkScPXOCLCvg8SE+3/PDnZ/l+Cguz7pqzMput7j/n+lyL1hbbDYdOJjLTBJTq6aYHu/34pL4e9e+37LTfXvif69oUTToCJE+2xvgBTXAwbN8LixfZ1iouzgTbQ2howbgDSgB0iUuEdY7iuHa6/D+jj93dv77Z9wKRG25e1w/Va5/u2d3E5oaG9tUsqgETqH8XFkJNjH7m5tvYUF2cL7ehoW2jm5tpHTk597e/AAfsh9dWY4+JsjfDbb2HTJhsUDldwsC14fHr2tIVxaal9VFXZwspXw46IqA8Obrf96SsIjLHnxsTYGu7QofZ4X600ONi+Bnl59kOfk2MLqRNOsM8tJsb+9P0eHl4f5IKCbC3WVzsvKrJp+mr90dH2HN/D6WwYNGtrbYEWEWEfvoLNFxSLi+tf+5ISG1B79rS18aiohkHT5aqvcYeH2/z5czrrgwXYcwsL7XOurLT/74QEm0+HX2e5x2PPOdzas4i9jq+2HhEBgwZBr14N06yosHmJi7PP7VhQVWXf7wcOBL51AW0PGKcC60Sk3BgzCxgN/KUdrv8+cJsx5i3sAHexiGQZYxYD/89voHsKcH87XK913oBBUZF+F6MFNTW2QBOxBZL3C/Lk5cGWLfbx/fewb59tRmdl2X01NfVdEu4jnHxmjK35JSfbwmnbNlsgFBXZPA0dCpdeCoMH24LPVyvz5dkXXKKj62uxtbW21pidXR+UoqNhzBgYNcp2yfhzu+3z7up8tdyW+AJNcvKhpx0ebh89e7Z+nOMI53IaY4NRfLztummJ77kcS8LCYPTogx/XXtoaMJ4HRhpjRgK/AF4EXgPObO0kY8x8bEsh0RizFzvzyQkgIi8AH2HHRbYBFXhbLSJSYIx5GFjtTeohEWlt8Lx9eFespbCQsIT+FBZ+GvBLdgYeT33NPCPDPnbtqi/kXS5bg8zObr7ZGxbWsH82NNTW3lJSYMQIW7j7+padzvpmuK/W2K1bw77b6mobAAoKbA03Lq6+H913TOPaK9R3jxyNmtbxECyUaqytAcMlImKMuQB4RkReMsbccLCTROTyg+wX4NYW9s0D5rUxf+3D18IoLCS8d3+ys/fj8VTjcIQe1WwcKd+g54EDtpbvq+1nZ9d3L/i6P3zdGB6/Eam4ONu3GxZmC/iICFsLnDQJevSwtUmHo74roqzM7h88GE4+2dZIj7RWeOjPWdiUu4mokChSY1ObPaaitoKCygIKKwsprCokJCiEU3qdQvvM3+haSqtL2ZK3heHJwwkLDjuitNYfWM8/v/0nE/tN5JwB57T6eueU5/DM18+QX5HPJUMuYWK/iQQ52i86b8jeQExoDP1i+zW7P7ssm5iwmDY9ZxGhylVFraeWWnctHvGQGJHY5veTiFBQWUB2eTbZZdnklOeQU55DbkUuOeU55FXkkV+ZT15FHtWuamZPms0Vw69oNq3K2krCneFtuu6RaGvAKDXG3I+dTnuGMcaBt6XQpfhaGEVFhIUNAISqqt1ERJzUodlqzoEDdkB2xw7bGti50/bP+rpTmhvkCwmpr6knJcGAAfVN9cREW9gPH26Dgu89X1BZwDdZ35Aclcyw7sOO6nP0JyK8sfEN/rXlXwyMH8iI5BGMSB5BRW0FC79dyDub32F74XYAzu5/NjeMuoGLTr6I/Mp83t38Lu9ufpcVe1bgkYZzNSalTuKpKU8xKmVUs9ctrCzk2dXP8szXz1BUVUSEM4IIZwRRIVEM6z6MsT3HMq7nOPrF9uObrG9YtXcVq/at4kDZAXpF96J3t9707tabU3ufyvRB0xsUflWuKuasmsOcVXOIcEaQGptKv9h+JEUkkVeRR1ZZFlmlWVS7q0mJSqFndE96RvfkhLgTSOuRxvDk4UQ4I6h115K+P51lu5axcu9KKmor8IgHQXA6nAzrPoxRPUYxOmU0iRGJZORksCF7AxtyNlBaXUp8eDzx4fHEhcWxo3AHq/atIiMnA4946Bndk1/94FfcNOYmIpy2vyazOJNFWxaxKWcTPaJ61OUrOSqZ2LBY4sLiiAqJ4oPvP+CvX/+Vz/d8DsAjKx7hB31+wIOTHmRy/8kNCtbM4kye/PJJ/r7271S5qggLDuO59OdIiUph5tCZTB80nQm9J7RaKO4u2s38jPnsKd7DL3/wSwbEDajb5xEPf/zij/zmf7/B6XByzw/u4f4z7q97ThuzN3Lff+/jo60fAdAzuif9Y/uTGptKSlQKKdEppESlUO2u5pusb1h7YC3rDqyjrKbhfXNO7X0qj/3wMSb2a352ZbWrmnc3v8vf1vyNLzK/wOVxNTnGYEiISCApIonEiEROjD+RPcV7uPLdK/km6xse/eGjBDts0b2jcAe//d9v2ZK3hfSb03GYwNbUjLRhmoMxpgdwBbBaRFYYY/oCk0TktYDm7hCNHTtW0tPTDz+BvDxbkv7lLxRdPZp1685gxIhPiI8/t/0yeQhcLts6yMy0j127YM0a+PpryMwUCC+EynjCwiA11Q6oJifbh2+2T69etvYfGV9CcEQZIUFOQoJCEIR1B9bx+Z7P+SLzCzZmbyQ6NJqE8AQSIxLr9u8p3gOAwzj4w1l/4N7T723wpswpz+HZr58lqyyLSlclVa4qXB4XKVEp9OnWh74xfekW2o3dxbvZVbSLnUU7qXHXkBqTSv+4/vSP7c+olFEttgrA1gpv++g2VuxZQUpUCnkVedR6auv2BzuCmdx/MhcPvpjs8mzmfTOPnUU7iXRGUl5r72syNGkoFwy6gNTYVFuohcexJW8Ls5fNpqCygGvTruWuCXcR5Aii1l1LtbuaBZsW8Lc1f6OspoxpA6cxvPtwKmorqKitoLCqkHUH1rGjsOESMmHBYYxJGUOfmD7sL93P3pK97C3Za59zbCq3j7+d60ddz+Jti7n303vZXbybqSdOJS4sjt3Fu9ldtJvcilySIpLoEdWDlOgUwoLDyCrNYn/pfvaX7qfaXV33Pzkh7gT2l+6ve56DEwcTHx6PMQaHcVBRW8GmnE1UuprWIHpE9SAuLI6CygIKKguo9dQSGxbLKb1O4dTep3JC/Am89M1LLNu1jO6R3bli2BV8ufdLvt73NQDx4fEUVhYitFyGDIgbwK3jbuXK4VeyaMsiHlnxCHtL9jKqxyiiQ6MprS6ltKaUXUW7AJg1Yhb3nnYvfbr14d/f/5v5GfP5eNvH1LhrCAkKYXyv8ZzR9wySI5MJDQ4lJCiE0upSFm5eWBeYQoJCMBjuO/0+7j3tXqpcVVz9r6v59/f/5tKhlxLsCObNjW/SN6YvD016iKW7lvLa+teICYvhjvF3EOQIYmfRTnYW7mR38e66oO0T6YxkZI+RjOoxit7deuN0OHEGOSmvKefZ1c+yr3Qf5514Hg9OepBuod3ILs/mQNkB0ven8/K6l8mryKN/bH8uHnwxvbv1JjkqmeTIZLpHdqcudPXEAAAgAElEQVR7ZHfiw+ObtKpq3DXcvfhunl39LOcMOIe/nvdXnlv9HM+nP0+wI5i7JtzF78783WG1Bo0xa0RkbJuObUvA8CaaDIzz/vm1iOQccs4C7IgDhm9C94MPUn3vDaxc2ZuBA5+nV6+ftV8mW1FaCitXwuefw4oV8NVXTVsKfUZuI+b0N8lJfpMcz3cMihvKzOGXMGPoJQxNGkp5bTm7i3azu3g3m3I2sSZrDWuy1rCtYFuL1x2aNJTRKaOpclXVNYNdHhcjkkcwqsco0nqk8fK6l3kr4y2mDZzGaxe+RoQzgjmr5vDo549SXltO98juhAeHExYchsM4yCrLoqCy4bBTWHAYqbGphASFsKtoFyXV9fMYT4w/kSkDpjB5wGSiQqIoriqmuLqYtVlrmbtmLrFhsTz+w8e5btR1uDwutuRtYf2B9RhjmDZwGvHh8XVpecTDsl3LWLBpAf1i+vGTwT9hUOKgZp97UVURf1j+B57+6ukGQQggyARx2bDL+NVpv2JE8ohmzy+oLCB9fzp7iveQ1iONEckjCAkKaXCM2+Pmve/eY86qOazYs4IgE4Rb3IxMHslT5z7F2f3PbvF/05iIsLt4N+sOrGPdgXVszNlIz6ieTEqdxMR+E0mKTGpyjsvj4ru87/jmwDfkV+QzrPswhicPp3tk9wbplteWE+GMaFJLXbF7BQ8vf5j/7PgPY3uO5eLBF3PRyRcxKHEQte5assuz2Veyj7yKPAqrCimqKqKoqoi0Hmmcd+J5DQq/alc1876Zx+sbX8fpcBIdGk10SDR9Y/pyy9hbmu0qKq4q5vM9n/PZ7s/4bPdnrNm/BnejZXuGJA3hyuFXcvmwywkJCuGX//klb2W8Rf/Y/gjCvpJ9PHXuU9w67laMMSzfvZzbP76dDdkbCA0K5fbxt3P/Gfc3eB/5vzbF1cVklWbhMA5OjD+xxW6yytpKnvn6GR79/FEKqxpO0wsyQUwfNJ2fjvkp55xwzmG1Bl5a+xI//+jn1LhrCDJB3DDqBh6Y9AA9ow8yc6AV7R4wjDGXAk9gp7Ya4AzgHhFZeNi5DIAjDhhgp8bceCPy1J9YvjyC3r3/jxNOeLx9MthIQYGwZFk5//uyiC/WFrJ5ZxESnouJziL5xCzi+x4gLLaYoLAKcFZQ7snj2/wMDIYzU89kUr9JLN21lOW7lyMI0SHRlNaUNrhG35i+jEkZw5iUMSREJFDrrsXlceEWN0OShnBq71OJCz/4qisiwvPpz3PX4rtIjrRTYjJLMpk+aDqP//BxTk48uck55TXlZJZkUlxVTN+YvvSI6lHXDSEiFFYVsr1gO19mfsl/dvyHZbuW1dWUfRzGwc2jb+aRyY80+2FuLzsKd/Bl5pd1tUWnw8mI5BEt9nUfrjX71/Dq+lcZmTySa9Oubdf++UDzdRV1tGpXNeW15VS7qqlx12CMoU+3Pk3GDpbuXMptH99GWU0ZCy5ZwCm9T2mw3+VxsWT7EoZ1H0bfmCP80m8jhZWFvLP5HcKDw+taEH1i+hAbFnvEaX+19yv+seEf3Db+tmY/d4cqEAFjPXCOr1VhjEkCPhWRkUeU03bWLgGjb184+2x45RW++moQUVEjGTp0Qbvk79/ffcyjnz7Hztz95FflUOPMheDqZo91GAfJkbZP2NdvHhkSydmpZ3PZsMvoE1P/9ZUDZQdYtHkRGTkZ9O7Wu64vfGD8wGZrnEcifX86MxfOJD48nifOeYJJqZPaLe0adw1r9q/BIx5iwmKICY0hPjyeyJDIdruGOr54xIPb48YZ1PWGXNvLoQSMtg56Oxp1QeXTVZdG9y4PArTLdzFqa+H1j7Yxe9Vd7An7NxT1hdxhJIaPYGDPJEYMSGTESXF0j44jNiyWxIhEUqJSSIxIbHPts0dUD24Zd8sR5bOtxvYcy7bbtwVkZlFIUAin9jm13dNVxy+HceAI6ppFVUdoa8D4xPtluvnev2div0PR9XhXrAUID+9PTs7qVg/PyMlg+e7lFFUVUVhp+28dxkFNeQTfbghn/XdFVA95CRwhjMh+gl9NvINp54bUzeA9Fuk0VKWOT20KGCJyjzHmYuA076a5IrIocNnqQHFxdq4qtoXhchXgcpUQHNytwWEiwpxVc7j303vrBkvDg8MJMzGUl0ONpwJCymG4cFbCLF687DEGJKUc9aejlFLtpa0tDETkHeCdAOalc2jUJQV21dqoqPrhmoLKAq577zre/+59Lhh0AX+Z+hc8pT34xf+FsmiRnd56881www3QPdl9TA1sKqVUS1oNGMaYUmh2krXBflG7WzP7jm0NuqTsF38qK+sDxobsDfx4/o/JKs1izrlzuH38Hbz0kuGee+ySFo8/DnfdZWfnWhoslFJdQ6sBQ0Sij1ZGOo24OLvWRW1tkxspiQg3vH8DNe4avrj+CwZGjuP88+GTT+yyGXPnwsCBHZh3pZQKoDZ3SR03fKPRxcUEJyQQFNStLmAs/HYh6fvTeeWCV4irHMepP7QrpT77LNxyy9FZ9E4ppTqKBozG/FasNYmJdVNra921/OZ/v2FY92H0KZrFKZPtYZ9+Cme2umavUkp1DTpBuTG/FWvBTq2trNzJy+teZmvBVn4U/v8495wgune3azppsFBKHS80YDTmt2It2JlSReU7mL1sNuOST+P5u37E6NGwapW9I5pSSh0vNGA05ru12tq1gA0YCzMrySrLInjZY9RUG15/3d6JTCmljicaMBo76SSYNg1mz4YNGyglmfmZMNQ5kZVvn86jj+pMKKXU8SmgAcMYM9UY850xZpsx5r5m9v/ZGLPO+/jeGFPkt8/tt+/9QOazUabg5ZcpSerGA3+YzPjXrqfKDTtf/BNnnAG3337UcqKUUp1KwGZJGWOCgGeBc4C9wGpjzPsi8q3vGBG5y+/42wH/255Vikgrt2wPnGd2LWD2z6rJd5VwSckAtq15kC1Zw5i35OjfelQppTqLQBZ/44FtIrJDRGqAt4ALWjn+cuoXN+ww6w6s4/aPb2d479GkV17FFY+PYN2ns/jpT3/PCSd4Dp6AUkp1UYEMGL2ATL+/93q3NWGM6Qf0B/7ntznMGJNujFlljLkwcNlsyHf7yZemv8SYh17kxZhf0Nvs5aKz/kRFxfdHKxtKKdXpdJYOlsuAhSIN7rvYz3tTjyuAOcaYZiexGmNu9gaW9Nzc3CPOSPr+dOLC4ugf25+s/BA+KT2Nq+VVYr/zUFKy8ojTV0qpY1UgA8Y+oI/f372925pzGY26o0Rkn/fnDuytYUc1PQ1EZK6IjBWRsUlJR353uTVZaxjTcwzGGN54Azwew9W8RredYRowlFLHtUAGjNXAQGNMf2NMCDYoNJntZIw5GYgDVvptizPGhHp/T8Teh+Pbxue2t2pXNRuzNzImZQwi8MorcOqpMKh3BbF74igpWRXoLCilVKcVsIAhIi7gNmAxsBlYICKbjDEPGWOm+x16GfCWNLy5+GAg3Xsv8aXAY/6zqwJlY85Gaj21jO05ljVrYNMmuPZaYORIIre5KC/PwOUqCXQ2lFKqUwro4oMi8hGNbuUqIr9v9PfsZs77EhgeyLw1Z83+NQCMSRnDn34HYWFw6aXA7pE4P/kYR41QUvI18fE/PNpZU0qpDtdZBr07hTVZa4gLiyMlPJU334SLLvIuLTVyJMbtIWIXOo6hlDpuacDwk74/nbE9x/Lhh4bCQrjmGu+OkfZue/GZPXUcQyl13NKA4VXtqiYjJ4MxKWN45RXo2RN+6Ot5OvFECA8ndrcd+G443KKUUscHDRhevgHvgVFj+PhjuPpqCPLdjjsoCIYPJ3KbC5ergMpK/QKfUur4owHDK31/OgDhhWNwu2Hy5EYHjBxJyJYsELRbSil1XNKA4bVm/xriw+Mp25sK2F6oBkaOxBSWEJ4fRXGxDnwrpY4/GjC80rPSGZMyhu3bDU4n9OnT6ADvwHdS1ok6U0opdVzSgAFUuarqBry3b4cBA/zGL3xGjAAgbk8i5eUbqarKbJqQUkp1YRowgI3ZG3F5XIztOZZt21q4V3e3bjBgANE7nICQk/PW0c6mUkp1KA0Y1A94j04Zw7ZtzYxf+IwcSXDGdqKjTyE7+/Wjl0GllOoENGBgv+EdHx5PRE0/yspaaGGAHcfYupUe0TMoL99AWVnGUc2nUkp1JA0Y2IAxtudYtm83QOstDETonjMECCIn542jlkellOpox33AqHHXsDl3c92ANxwkYADObzOJj59CdvYbiOhtW5VSx4fjPmCEBIWQ/6t8fvmDX7JtGzgckJrawsGpqXbwe/16kpOvpLo6k+Liz49ibpVSquMc9wEDIDIkkvjweLZtg759ISSkhQONsdNr168nMfFCHI5IsrO1W0opdXzQgOFn+/ZWBrx90tJg3TqCqg2JiReSm7sAj6f6qORPKaU6kgYMP61OqfWZMQPKy+Htt0lOvhKXq4j8/I+PSv6UUqojBTRgGGOmGmO+M8ZsM8bc18z+a40xucaYdd7HjX77rjHGbPU+rml8bnsrKoL8/DYEjDPOgCFD4PnniYs7B6cziezs1wKdPaWU6nABCxjGmCDgWeA8YAhwuTFmSDOHvi0iad7Hi95z44EHgFOA8cADxpi4QOUVqJshddAuKWPgZz+D1atxfLOeHj2uJy/vPSortwcye0op1eEC2cIYD2wTkR0iUgO8BVzQxnPPBf4jIgUiUgj8B5gaoHwCtjsK2tDCALjqKoiIgBdeoHfv/8OYYDIznwxk9pRSqsMFMmD0AvxX6Nvr3dbYxcaYDcaYhcYY3xqxbT233fgCxoABbTg4NhYuvxzefJPQqgh69LiGrKyXqa4+EMgsKqVUh+roQe8PgFQRGYFtRbx6qAkYY242xqQbY9Jzc3MPOyPbt0NKCkRGtvGEn/0MKirg9dfp0+eXiNSwb9/Th319pZTq7AIZMPYB/neV6O3dVkdE8kXENyf1RWBMW8/1S2OuiIwVkbFJSUmHndk2zZDyN3YsjBkDzz9PRPhAkpIuZt++53C5Sg47D0op1ZkFMmCsBgYaY/obY0KAy4D3/Q8wxqT4/Tkd2Oz9fTEwxRgT5x3snuLdFjBt+g5GY7fcAps2wRdf0KfPvbjdxezf/7eA5E8ppTpawAKGiLiA27AF/WZggYhsMsY8ZIyZ7j3sDmPMJmPMeuAO4FrvuQXAw9igsxp4yLstIMrLYf/+Q2xhAFx2mV0q5OGH6RY6nNjYyezd+2f9Ip9SqksK6BiGiHwkIieJyAki8oh32+9F5H3v7/eLyFARGSkiZ4nIFr9z54nIid7Hy4HM544d9uchtzAiI+Hhh2HJEpg8mX4RP6WmJousrIBmVymlOkRHD3p3CgddpbY1d9wBb70Fa9YQe+6vSM4bxY4d9+ktXJVSXY4GDOqn1B5yC8Nn5kz47DNMVRUnX/89Kf+sZNuKy3Xpc6VUl6IBAxsw4uMh7ki+Sz5+PHz9NWb4SE78aw1Dz/2C6h+cBM8/DzU17ZZXpdQhyMqCrVs7OhddhgYMbJfUYXVHNdanD3zxBZKRQc7PTsKdtQN+/nO49952SFwpdchuvBGmBnSRiOOKBgxsC+Owu6OaYYYOJW7Octa9nkDOxQnI00/D6tXtdwGl1MFVVcH//mdntRw4yqswFBbCDTfAli0HP/YYctwHDLfbvq/apYXhJyQkmUEnv8R31+bjTgy3NZ3a2va9iFKqZStW2A83wFdfHd1r//OfMG8enHde+wersjJ4//2DHxcAx33ACAqy3ZwPPND+aScmTqfn4HvYcns5bNgATz3V/hdRSjVvyRJ7+0ynE1atOrrX/uQTSEiAnBz40Y/sl73aywsvwAUXwLp17ZdmGx33AcMnKCgw6Q4Y8Cie6eeTO9Egs39fPyVLKRVYixfD6afDyJFHt4VRWwv//S/85Cfw9tvwzTf2S74uV/uk/+WX9ueHH7ZPeodAA0aAGRPEkCFvsvdXJ+AOqsV909X1zWSlVGBkZcHGjTBlCkyYYMcQ3e6jc+1Vq6CkBM4917YunnkG/v1v+L//O/K0RWDlSvu7BoyuKTi4G4PO+pidPw8naNlKJLUvPPqoHRhTSrW/JUvsz3PPhVNOsf3+3357dK69eLHtspg82f59yy3wi1/Ac8/BsmVHlvaePXZMpHdvG5jy8o44u4dCA8ZREhFxIon3/5sNTzkp7l8Ov/61nYY7YwZMmwbjxkH//rZvMieno7PbukWL4OuvOzoXx66qKvDolzoDaskS6N4dRoywLQw4euMYn3wCp55q75vj8/DD9v4JDzxgWwmHy/ccfvc7m84nnxxZXg+RBoyjKC7uLPpdv5SMJ0L55uU4an80EdassQEiMdHWhJYsgVGj4IsvOjq7zSsosDePuvBCeyN0dWhyc6FfP3jooY7OSccpLYUnnrArfh6J2lpYuNB+18n/Xjgej/0cTZkCDoedM5+QcHTGMXJy7Gf63HMbbg8Pt5XE5cvtVN/DtXKlTevaayE5+eh3S4lIl3mMGTNGjgVlZd/Kl1/2k88+i5S8vI8b7vzmG5ETThAJDhZ56ikRj6djMtmSv/5VBESMEfnpTzs6N8eeG26wr19CgkhFRUfnpmP84Q/2NYiJEZk799Df45mZIg88IJKSYtMBkalTRdxuu3/NGrvttdfqz5k2TWTo0KZptffn6/XX7bVXr266r7JSpHdvkR/84PCve8opImecYX+/7jqR2FiR2trDz6+IAOnSxjK2wwv59nwcKwFDRKSqar+sXp0mS5cGSWbm0+LxfwMVFopceKH996SliTz2mMiOHR2XWX9paSKjRon84hc2f599FpjrlJeLrF8v8umnRy9oFhSIpKeLLFhgX/Mvvmjf9FeutK/ZmWfany+/3L7pB1pe3pGn4XKJ9OsnMn68yKRJ9nWYNEnk++9bPmflSpF77rFBoWfP+grLeeeJfPCByDPP2G2PP26P/3//z/6dlVWfxoMP2nOKi+u3ZWeL9O8vcu+97fcemzVLJDGxPng19vzzNm+LFx962pWVIk6nyK9+Zf9euNCmtXz54edXNGAcM2prS2TDhh/L0qXIli03idtdXb/T47G1r/Hjpa4WNX68bYE0p7RU5K23RB55ROTGG0UmTxa5//72LWzXrrX5eOYZkbIykdRUkUGD7Bu5PWRmivzkJ7YW5nvOIPLGG+2TfmsefrjhNcE+P5erfdJ3uURGj7YFXkmJre2OHn1k/5/CQpFLLjk6r89zz9nX5KGHmuY5N1fknHNEwsLs/27UKJFzz7XBvrEPP7Tp/POfNp0XX7QtjW7dRA4caHp8VpZIeLhISIitrFx9tcgTT4hs21Z/jMdjX4fgYBtcJk0SGTmyYTqLF9vr+ufpzjvr/9c//3nLhbzPBx/Y4LJ8efPvC7dbpHt3kSuuaDmN6mqRvn1tS+FQ//dffmnz+u679u/iYhtA7r330NJpRAPGMcTjccv27ffL0qXI2rUTpbo6p+lBO3eK/PGPtrDp1Utk376G+8vKRE49tf7N3727LZDAntdebr1VJDTU1sRF6j+Ev/tdy+dUVTX8cLdkyRJbM4uKErnqKluAv/22yIknipx2WvvkvyUlJSLR0TbILlpkWzavvmqf2/vvt881fDXL+fMb/v3ll4eXXn6+yJgxNo2ICJHt29snn83ZutVeIyHBXu/GG+u7QTIybC09NNQWutdcY7t/eva078OiooZpTZ8ukpwsUlNTv23zZpGgIJE77mh67TvvtPu2bm09j4WFNsD37duwFu6/H2x3mIjI7t02CN1wg8gvf2n3XX99yxWEzz6zx/s+Y4mJtkvI///XXFdYc+bOtcd9+GHrxzX2pz/Z8/bvr9929tnNd7UdAg0Yx6ADB96QZctC5csv+0px8armD1q/XiQyUmTcuPr+75oa2zR3OET+8Q/b0hCxtZcZM+z2Tz5pmI7bLbJiRcM33sFUVNj+0ssvb7h91iz7AX3vvaY1pv/+V+Skk+o/jM11abjdttZqjH3jb9nScP+TT9rzN2xoe14PlW9c5quv6rfV1NjgPGXKkaefmysSFydy1ln1r1Fpqa1Zt1YbbUlenq3Fh4TYwqdbN1urPlgN+WC+/LJpZcTtFjn9dJvXzEyR3/zGvlbnnWdbCdHRIj16iKxq9J5NT7f/07vvrt+2Z499P/76102vfeON9vns2lW/bd8+G4iuu65t+f/qK9vKaNyS8Dn5ZJEf/9j+fv31Nu09e+z/5Pe/t+ddfnnTsaUtW+z/b9AgG2gWLLD/t5gYe84119juLV9XWHMtJX81NTbIDh588GP9zZhhu/P8+YKI/+t2iDRgHKOKi1fLypWpsmyZUzIz/9JwXMPnvffsB/Gyy+yH+aqr7L9x7tymx5aViQwfbgt6Xy3/m2/soBvYD++0afYDUFXVeubeeKP5D2JOjsiAAXbf4ME2H7t22UACdt/PfmZriYmJtvZVVWWb9bNn19eSZ82y+W0sL89+sG+5pW0vor8lS+wHuTVuty0Ixo9vus/XTdU4iDVWXS3y7bfN76upEbn0UluQZWQ03HfnnTbY+ve1H0xOju1uCQ0V+dg7YeLvf7f5fO65ls/bskXktttsDb/xuFB2tn0/gS0Y/VtVf/6z3f7KK/Xb/vY3+97xjbHt2dP8NW+80T7vzZvt3w88YN+7O3c2PXbPnqbB4fbb7fmH0np65hlb8Wju/XzNNSJJSTY/DofIXXc13P/YY/Y59eljK19ud/37OympaT7Kymx3UHCw/Yz17WsDeVssWWJbbf36iWza1LZzeve2/yd/W7bYPD/7bNvSaEanCRjAVOA7YBtwXzP77wa+BTYA/wX6+e1zA+u8j/fbcr1jPWCIiNTUFNSNa2RkzJCamsKmB/ne2KNHS4NmdnO2b7eFwLBhtkvJ4bAF9zPP2Jqeb7wgNtYW2v/8p+2iaWzyZNvkb64WW11tP2CjRkldk93ptF1Vvtra+vW239a3zzdwOWaM7cdurT/36qttV1Vz+WrJRx/Za5x8cuuDtZ98Yo/7xz+a7jtwwNZ6m+sqEbF5fvdd223mq2n6d8Hk5dlWBYg8+mjT87//3u578MH6bTk5tlIwf74dFH/+ebt/xgwbkIOC7FiB/6Cpx2PHECIjGxbGtbW222PqVHudkBDbHQS2m2/JEhsI4uPtvvvvtwEAbDdNRoa91o9+1PT/88kn9pjmgrxPdrathZ97rs1Lz562ZdKSu+6y789vvxXZu9cGkBtvbPn4Q+Ubh5kwwb6fcprp/l22rP5zNXasfYSFNW1B+fv2W9s1BLYF1larV9vWWUxM8y0if5mZNv05cxpu93jsrMpp09p+3UY6RcAAgoDtwAAgBFgPDGl0zFlAhPf3W4C3/faVHeo1u0LAELHjGrt3Py5LlwbJ8uXR8v33d0h5+ff+B9hCFGwt7GCDZ0uW2A+iw2GDhm8MQsT22S5ZYgs7Xx91SIjtipkzx9ZgduxoWrA1n3GRpUttweOrVfpzuWxt+M477ViBfz5a45td9PzzDbf/9a+21tx4WmFRkQ2Eqam20DnllPquusbOP98Woi21sGbNsl0+jYPV6tV2eqOvZeULxv362UJn0yb7QQ4JseMhLZk61U4P/fOfRSZOrK+5+z+MsWldcIHIb39r+8ob27XLFoJnnSUyb54NML4uk5QU21rKzrbP89lnG04sOO20+hZSZaUdi/AF9ri4pt1Uh+Kpp6Ru3ANE/vWvlo/NybHP4ZJL7OsZHNx8a+Rw+SZtgO2Caonbbf9nvXrZ137hwoOn7fHYWXXl5YeWp927bWUuONhW4Favbr5S5psR5d9t6nPHHXa86DCn13aWgHEqsNjv7/uB+1s5fhTwhd/fx23A8Ckp+Ua+/XaWLFvmlKVLjaxff76Ulnr78qur7RhBW/utly61tfzW1Nbawb27764fewDbT22MfXN3BI/H1nxHjKgPjg8+WJ+/a65p+DrcfLMteL/6yhZQDoet5VZXN0x32zb7vForPFatkgbdPRUVtiZsjO2meP75+g/qypW2tWGM7W5ITrbbWuObNQS2+/D3v7cFz+bNtrDMymp7IeQbSAdbm7/hBtsCavy8RWzgmDevvuulsbfftl0zCxa07dotqamxrTywBfDBCjXfWEJwsP0/tqfaWjvjKj6+6WB8c8rLD94d2R6Kiuw0emPsc+/Rw3bNrV1bf8wvfmErP839LwsKmt/eRp0lYFwCvOj391XAM60c/wzwW7+/XUA6sAq4sJXzbvYel963b9/DftE6s6qqLNm5c7Z8/nmiLFvmlF27HhW3+8i+rNMmO3bYQuiCC+w8+I70t7/Zt+sXX9haNthW1gMP2N/vussGk08/tX/75/fFF+22K65oWPjedZctmFqrQXs8tltiyBCRr7+2rQnfNEz/Of0+ZWW2dnz22S337TdO/9//bttMsraktXChyLp1nesLn77ZdLNnH/zY4mJboDudgamgzJljW7edUW6uDeCXXWZbhw6H7UEoKrKtwB/8ICCXPeYCBjDLGxhC/bb18v4cAOwCTjjYNbtaC6Ox6upcyci4RJYuRdasmSDl5d91dJaOntJS29Lxfbv3xhttzdjjsU1ysIEkNdW2jhrPdPHNYAkLszNl/vY3+6FsPOurOa+8InVdQ716Hd6Xro53n3/e9u/rfPRR82NKx5PCQtvdaoxtcYSENJxx1o46S8BoU5cU8ENgM9C9lbReAS452DW7esAQEfF4PHLgwHxZsSJOli0LlU2bLpf8/MXi8bTTF8w6s9tus2/ZW25p2I3idotceWV9of75503P9Xjs2MLtt9txBl/XTVu+B1FZabvErrqq7eMuSrWH9HTbwj3Y+M8ROJSAYezx7c8YEwx8D0wG9gGrgStEZJPfMaOAhcBUEdnqtz0OqBCRamNMIrASuEBEWl2feOzYsZKent7+T6YTqq7ez+7dj5CTM9ztgEUAABGCSURBVB+Xq5CQkF706HEVyclXExk5uKOzFxglJbB0KUyfDsY03Fdba5eRHjgQ7r239XRE7B0Q9+2zKwUr1Zm53bB2LYwd2/R93w6MMWtEZGybjg1UwPBmZBowBztjap6IPGKMeQgb0d43xnwKDAeyvKfsEZHpxpgfAH8DPNgVdeeIyEsHu97xFDB8PJ5q8vI+4MCBVygo+ARwEx09luTkq+je/XJCQpI6OotKqU6s0wSMo+14DBj+amqyyc6eT3b2PygrW4sxwcTHTyU5+WoSEn5MUFBYR2dRKdXJaMBQlJdv4sCBf5Cd/To1NfsICoohKelikpOvIDZ2EsYE6CbmSqljigYMVUfETWHhUrKz/0Fe3ru43WWEhPQgKelS4uLOJjp6LCEhPTEB6BtVSnV+GjBUs9zuSvLzPyQnZz75+R8iUg1ASEgPoqNPISXlRhISpmGM3ohRqePFoQSM4EBnRnUeQUHhdO9+Cd27X4LbXUFZ2XpKS9MpLU2nsPC/5Oe/R0TEyfTufTfJyVfpmIdSqgFtYSgAPJ5acnP/SWbmnygrW4vDEUZISC9CQ1MICUkhImIwCQk/Jjp6tLZAlOpCtEtKHTYRoajoM/LzP6CmZj/V1VnU1GRRWbkN8BASkkJCwo9xOpO8+/dTW5tHYuJ0+vT5BUFBkR39FJRSh0ADhmp3NTV5FBR8TH7++xQULMbtriAkpAehoT0xJoSSki8ICelJ//6P0KPH1doKUeoYoQFDBZTH48IY02BqbnHxF2zb9gtKS78iMnIYMTETCQ8/wfs4ifDwgTgcOmSmVGejg94qoJor+GNiTmP06JXk5LzN3r1zyMl5E5eryO+cMCIjhxMVlUZYWD/vGmEeRDxERAwiIeF8goO7HcVnoZQ6VBowVLsxxpCcfBnJyZcBUFtbQGXldioqtlBWtp6ysnXk5r6Dy1XQzLkhxMefS2LihYi4qKjYTHn5Zqqr9xARcTLR0eOIjh5Ht27jCA6OOdpPTSmFBgwVQE5nPE5nPN26jcOubu9bHbkWcHjHOYSSklXk5i4kN/cd8vM/AMDhCCci4mTCwwdSXp5BXt4ib6pBxMWdTVLSDBITL8LpjKe8/FuKiz+juNiOo/TufQdhYX074ikr1aXpGIbqNESE8vIMgoKiCQvr22DgvLa2kNLSdIqK/kdOzj+pqtoOBBEcHF3X9RUS0pOammyMMXTvfhl9+txDZOQwRFyIuABDUFD4QfNRVbWH3Nx3CQ3tRVLSJfoteNWl6aC36tJEhLKy9eTm/pPa2hxiYk4nJmYiYWGpVFdnsnfvHPbvn4vHU97k3PDwk4iJOYOYmNOJjh4NCB5PNR5PDeXl68nOnk9JyRd1x8fFncNJJ71AePiAo/gMlTp6NGCo415tbSHZ2a/jchVgTDDGBOPx1FBa+jXFxV/gchU2e15ExFCSky/n/7d37zFyVfcBx7+/uTNzZ+fhXXu9xma9xibGgEPAxpaBkkYkJOWhiDYSCaZpRKOoUVVXCVWkFquvhH+aSlUpf6Rt0jRtSJCTJoXW9R8lwSCU0PCwwcZv7Nhm/V7vss+ZnTuvX/+4Z9fjxY9Z4907eH8fabRzz5yZ+c29d/Y395x7z+no+Bz9/T/j4MH1qFZYvPjrZLMrGR09wOjofoLgKL7fSUvL9aTTN5BKLQbC5rbwVkW1BiigJJML8P0F07gGjGmMJQxjLkC15jrVdyGSIBZLIuLj+53vmXyqWDzK/v3r6OvbOF4Wi7Xg+wsJgmPUaoWG39f3FzFr1u3MmnUbqdRi4vHZxONteF6GYvEQ+fweCoU9lErH8f1FtLQspaVlKen09bS0LL3otS2qSqXSTzzeaqMRm4ZZwjDmMlJVBgdfRrVCOn3d+Oi+qjWC4BiFwl6CoBvwiMUSiCTcP2whnP8LisXDDA29wtDQKwTBO+d9r3i8Hd/vJAi6zzot2fNyZLMryeVWkUotIRbzEUkSiyUYHT0wPiZYqXSSWCxNJrOcTOYjZDI3uZMHlpFKLUYkxujor139raiWyWSWk04vJ5NZTiLRfs64SqVTFIvdZDIfxvPSl3Hthgm8Ws0Tj+cu6+ueS7k8QCyWuqLGSRsaeo3Bwf+jq+vRS3q+JQxjmlipdIpS6SSVygDlcj/V6gip1CLS6RvHZ0gMjxbeZXT0APn8LoaHtzI8vJV8fju1WnHCKwrp9I3kcqvJZG6iVDrOyMgO8vkdlMs9Z2pJglgsRbU6DITXxojEqVZHxuvE4234/iJSqWtIJudTLB5mZGT7+OuIJMjlVtPa+jHS6Rsol3sIguOUSicAxfe78P0uUqkuQKhUBtxtiESinVRqEb7fhedlGBj4Bf39zzMwsJlyuZdUajHZ7CpyuVW0tCzF8zLEYmk8r4VYLIPnnbnFYulznowQ/j/TCSdMvEtv77P09PyI/v4XiMdbWbDgD+jsXDd+Nl0QHKOvbxODg78im/0IbW13kc2uiORITbVGPr+bVGrRBa9NqtUCDh9+nO7ub+L7XaxZs+uShuZpmoQhIvcCTxJO0fpdVf3mhMd94ClgFdAHPKSqh91j64EvAVXgK6r63MXezxKGudLVahWq1cHxjnrVgGSyk3g8e876pVIvo6P7KBT2USi8TbU6Qi63klxuNen0ckTiBMER8vndFAq7GR09SBB0Uyy+M940ls3eQjZ7C8lkJ8PDWxgc/AXDw6+706PB87Ikk1cDShAcOUdCO79kcgGzZ3+KdHoZIyNvMTy81Z0BdzExPC+L5+XwvDS12ijV6gjV6giqFUR8PC+N52UolU6hWiaV+hDz5n2WQmG/O01baG+/nyA4zsjIViA8wqtU+tznaqW19U6y2ZXj6yAen02xeIhi8RCjowcplU5QLp+mVOqhXO4Fau4IM0kslsL3r3YJuItkcj7guUQniCSJx1uJx2fheTny+R309m5047idIBZLMXfuZ5g///eZPfvus5LX8PCb7N37CPn8DubP/yJLlz5xydcnNUXCkPDTvQ18CjgKvA48rKq76+r8EXCzqv6hiKwFPqOqD4nIcmADsAa4GngeWKaq1Qu9pyUMY6ZHtVogCI6TTF51VlOSqlIu9xEERwAhkRjrp8mOlxeL3VQq/cyadZtLWmcfKZTL/QTBUZcECtRqBarVAtXqCLVafjwxVCrDVKtDVKsFlxxyeF6WWCxZ97w8iUQH8+Z9jmz21vH3Khbf4dixf+TUqadIpZbQ3v4Ac+c+QDp9I6XSCQYGXmJg4EUGB1+mUNhH+Lv1vTyvlWRyHolEB4nEXEQ8VMvUaiVqtVGC4DhBcATVUkPr1fOyzJlzH3Pm3MPw8Bv09GygUuknkeggHm+lViujWqJU6iGZ7GDZsn9h7txPX9I2HNMsCeMO4Ouqeo9bXg+gqn9TV+c5V+dXIhIHTgIdwGP1devrXeg9LWEYYy63arVIobCLkZHtVCpDtLRcSyq1hFRqyXmP7Oqp1twRyKmzzpyr1QKq1WEqlUEqlSFSqS7a2u4iFvPHn1urBfT2/g99fRvdkVN4kkYiMY+urq+RSMx535+vWcaS6gSO1C0fBW47Xx1VrYjIINDuyl+Z8NzOqQvVGGPOzfNS5HJh38qlEInh+/Px/fmTfm4s5o9PetYMPvBjUIvIl0Vki4hsOX36dNThGGPMFWsqE8YxoKtueaErO2cd1yTVStj53chzAVDV76jqalVd3dHRcZlCN8YYM9FUJozXgetEZImIJIG1wMYJdTYCj7j7DwIvaNipshFYKyK+iCwBrgNem8JYjTHGXMSU9WG4Pok/Bp4jPK32e6q6S0QeB7ao6kbgX4EfiMgB4F3CpIKr9x/AbqACrLvYGVLGGGOmll24Z4wxM9hkzpL6wHd6G2OMmR6WMIwxxjTEEoYxxpiGXFF9GCJyGjj/UKAXNhfovYzhXC4W1+RYXJNjcU3OlRjXNara0DUJV1TCeD9EZEujHT/TyeKaHItrciyuyZnpcVmTlDHGmIZYwjDGGNMQSxhnfCfqAM7D4poci2tyLK7JmdFxWR+GMcaYhtgRhjHGmIbM+IQhIveKyD4ROSAij0Ucy/dEpEdEdtaVzRGRn4vIfvd39jTH1CUiL4rIbhHZJSJfbZK4UiLymohsd3F9w5UvEZFX3fb8sRv4ctqJiCcib4rIpiaL67CI7BCRbSKyxZVFui1dDG0i8lMR2Ssie0TkjqjjEpHr3Xoauw2JyKNRx+Vi+xO33+8UkQ3u+zDl+9iMThhuGtlvAfcBy4GH3fSwUfl34N4JZY8Bm1X1OmCzW55OFeBrqrocuB1Y59ZR1HEFwCdU9RZgBXCviNwO/C3whKouBfoJ54WPwleBPXXLzRIXwMdVdUXdaZhRb0uAJ4H/VdUbgFsI112kcanqPreeVgCrgALwbNRxiUgn8BVgtareRDi461qmYx9T1Rl7A+4AnqtbXg+sjzimxcDOuuV9wAJ3fwGwL+L4/ptwnvamiQtIA28QzujYC8TPtX2nMZ6FhP9IPgFsAqQZ4nLvfRiYO6Es0m1JOA/OIVyfarPENSGW3wJeboa4ODNT6RzCEcc3AfdMxz42o48wOPc0ss02FexVqnrC3T8JXBVVICKyGFgJvEoTxOWafbYBPcDPgV8DA6pacVWi2p7/APwpUHPL7U0SF4QTSv9MRLaKyJddWdTbcglwGvg314z3XRHJNEFc9dYCG9z9SONS1WPA3wHdwAlgENjKNOxjMz1hfKBo+NMhktPaRCQL/CfwqKoONUNcqlrVsLlgIbAGuGG6Y5hIRD4N9Kjq1qhjOY+PquqthM2w60TkY/UPRrQt48CtwD+p6kogz4Rmnoj3/STwAPCTiY9FEZfrM/ltwkR7NZDhvU3ZU2KmJ4yGp4KN0CkRWQDg/vZMdwAikiBMFk+r6jPNEtcYVR0AXiQ8DG9z0/1CNNvzTuABETkM/IiwWerJJogLGP91iqr2ELbHryH6bXkUOKqqr7rlnxImkKjjGnMf8IaqnnLLUcf1SeCQqp5W1TLwDOF+N+X72ExPGI1MIxu1+mlsHyHsQ5g2IiKEMyPuUdW/b6K4OkSkzd1vIexX2UOYOB6MKi5VXa+qC1V1MeH+9IKqfj7quABEJCMiubH7hO3yO4l4W6rqSeCIiFzviu4mnG0z0rjqPMyZ5iiIPq5u4HYRSbvv59j6mvp9LKpOpGa5AfcDbxO2f/95xLFsIGyTLBP+6voSYfv3ZmA/8DwwZ5pj+ijhIfdbwDZ3u78J4roZeNPFtRP4K1d+LeH87wcImxD8CLfnXcCmZonLxbDd3XaN7e9Rb0sXwwpgi9ue/wXMbpK4MkAf0FpX1gxxfQPY6/b9HwD+dOxjdqW3McaYhsz0JiljjDENsoRhjDGmIZYwjDHGNMQShjHGmIZYwjDGGNMQSxjGNAERuWtsZFtjmpUlDGOMMQ2xhGHMJIjI77l5OLaJyLfdAIgjIvKEm59gs4h0uLorROQVEXlLRJ4dmzdBRJaKyPNuLo83RORD7uWzdXNCPO2u4jWmaVjCMKZBInIj8BBwp4aDHlaBzxNeDbxFVT8MvAT8tXvKU8CfqerNwI668qeBb2k4l8dvEF7dD+FIwI8Szs1yLeH4QMY0jfjFqxhjnLsJJ9J53f34byEceK4G/NjV+SHwjIi0Am2q+pIr/z7wEzeWU6eqPgugqkUA93qvqepRt7yNcG6UX079xzKmMZYwjGmcAN9X1fVnFYr85YR6lzreTlB3v4p9P02TsSYpYxq3GXhQRObB+FzY1xB+j8ZGCf1d4JeqOgj0i8hvuvIvAC+p6jBwVER+x72GLyLpaf0Uxlwi+wVjTINUdbeI/AXhjHUxwlGF1xFO+LPGPdZD2M8B4RDT/+wSwkHgi678C8C3ReRx9xqfncaPYcwls9FqjXmfRGREVbNRx2HMVLMmKWOMMQ2xIwxjjDENsSMMY4wxDbGEYYwxpiGWMIwxxjTEEoYxxpiGWMIwxhjTEEsYxhhjGvL/U691E1mY+7wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2617 - acc: 0.9269\n",
      "Loss: 0.2617387284278127 Accuracy: 0.92689514\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7937 - acc: 0.4441\n",
      "Epoch 00001: val_loss improved from inf to 1.32118, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/001-1.3212.hdf5\n",
      "36805/36805 [==============================] - 108s 3ms/sample - loss: 1.7938 - acc: 0.4440 - val_loss: 1.3212 - val_acc: 0.5924\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8840 - acc: 0.7310\n",
      "Epoch 00002: val_loss improved from 1.32118 to 0.58305, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/002-0.5830.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.8840 - acc: 0.7310 - val_loss: 0.5830 - val_acc: 0.8376\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6161 - acc: 0.8162\n",
      "Epoch 00003: val_loss improved from 0.58305 to 0.44525, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/003-0.4453.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6161 - acc: 0.8162 - val_loss: 0.4453 - val_acc: 0.8779\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8585\n",
      "Epoch 00004: val_loss improved from 0.44525 to 0.40673, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/004-0.4067.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4740 - acc: 0.8585 - val_loss: 0.4067 - val_acc: 0.8838\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8823\n",
      "Epoch 00005: val_loss improved from 0.40673 to 0.36364, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/005-0.3636.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3920 - acc: 0.8822 - val_loss: 0.3636 - val_acc: 0.8991\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3304 - acc: 0.9016\n",
      "Epoch 00006: val_loss improved from 0.36364 to 0.28055, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/006-0.2806.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3306 - acc: 0.9016 - val_loss: 0.2806 - val_acc: 0.9217\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2900 - acc: 0.9138\n",
      "Epoch 00007: val_loss improved from 0.28055 to 0.27066, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/007-0.2707.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2900 - acc: 0.9138 - val_loss: 0.2707 - val_acc: 0.9266\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9239\n",
      "Epoch 00008: val_loss improved from 0.27066 to 0.23995, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/008-0.2400.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2529 - acc: 0.9239 - val_loss: 0.2400 - val_acc: 0.9273\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9334\n",
      "Epoch 00009: val_loss improved from 0.23995 to 0.22961, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/009-0.2296.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2233 - acc: 0.9334 - val_loss: 0.2296 - val_acc: 0.9329\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9381\n",
      "Epoch 00010: val_loss improved from 0.22961 to 0.20147, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/010-0.2015.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2036 - acc: 0.9381 - val_loss: 0.2015 - val_acc: 0.9434\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9450\n",
      "Epoch 00011: val_loss did not improve from 0.20147\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1827 - acc: 0.9450 - val_loss: 0.2931 - val_acc: 0.9113\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9508\n",
      "Epoch 00012: val_loss did not improve from 0.20147\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1665 - acc: 0.9508 - val_loss: 0.2202 - val_acc: 0.9350\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9544\n",
      "Epoch 00013: val_loss improved from 0.20147 to 0.16981, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/013-0.1698.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1558 - acc: 0.9544 - val_loss: 0.1698 - val_acc: 0.9483\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9587\n",
      "Epoch 00014: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1373 - acc: 0.9587 - val_loss: 0.1715 - val_acc: 0.9467\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9611\n",
      "Epoch 00015: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1292 - acc: 0.9611 - val_loss: 0.1953 - val_acc: 0.9434\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9645\n",
      "Epoch 00016: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1180 - acc: 0.9644 - val_loss: 0.2073 - val_acc: 0.9408\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9661\n",
      "Epoch 00017: val_loss improved from 0.16981 to 0.16437, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/017-0.1644.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1120 - acc: 0.9661 - val_loss: 0.1644 - val_acc: 0.9504\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9692\n",
      "Epoch 00018: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1012 - acc: 0.9692 - val_loss: 0.1739 - val_acc: 0.9515\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9707\n",
      "Epoch 00019: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0978 - acc: 0.9706 - val_loss: 0.1958 - val_acc: 0.9460\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9728\n",
      "Epoch 00020: val_loss did not improve from 0.16437\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0899 - acc: 0.9728 - val_loss: 0.1654 - val_acc: 0.9518\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9767\n",
      "Epoch 00021: val_loss improved from 0.16437 to 0.15546, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/021-0.1555.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0795 - acc: 0.9766 - val_loss: 0.1555 - val_acc: 0.9534\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9768\n",
      "Epoch 00022: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0748 - acc: 0.9769 - val_loss: 0.1972 - val_acc: 0.9422\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9802\n",
      "Epoch 00023: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0680 - acc: 0.9802 - val_loss: 0.1599 - val_acc: 0.9555\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9817\n",
      "Epoch 00024: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0637 - acc: 0.9817 - val_loss: 0.1618 - val_acc: 0.9539\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9800\n",
      "Epoch 00025: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0642 - acc: 0.9800 - val_loss: 0.1563 - val_acc: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9848\n",
      "Epoch 00026: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0534 - acc: 0.9848 - val_loss: 0.2046 - val_acc: 0.9418\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9826\n",
      "Epoch 00027: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0588 - acc: 0.9826 - val_loss: 0.1759 - val_acc: 0.9532\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9852\n",
      "Epoch 00028: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0524 - acc: 0.9852 - val_loss: 0.2117 - val_acc: 0.9422\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9823\n",
      "Epoch 00029: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0589 - acc: 0.9823 - val_loss: 0.1586 - val_acc: 0.9562\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9882\n",
      "Epoch 00030: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0422 - acc: 0.9882 - val_loss: 0.1735 - val_acc: 0.9541\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9843\n",
      "Epoch 00031: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0530 - acc: 0.9843 - val_loss: 0.1572 - val_acc: 0.9571\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9904\n",
      "Epoch 00032: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0361 - acc: 0.9903 - val_loss: 0.2231 - val_acc: 0.9450\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9874\n",
      "Epoch 00033: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0433 - acc: 0.9874 - val_loss: 0.1557 - val_acc: 0.9546\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9905\n",
      "Epoch 00034: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0335 - acc: 0.9905 - val_loss: 0.1590 - val_acc: 0.9597\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9887\n",
      "Epoch 00035: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0385 - acc: 0.9886 - val_loss: 0.1624 - val_acc: 0.9574\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9868\n",
      "Epoch 00036: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0447 - acc: 0.9867 - val_loss: 0.1931 - val_acc: 0.9488\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9921\n",
      "Epoch 00037: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0299 - acc: 0.9920 - val_loss: 0.1884 - val_acc: 0.9527\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9908\n",
      "Epoch 00038: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0330 - acc: 0.9908 - val_loss: 0.1830 - val_acc: 0.9518\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9924\n",
      "Epoch 00039: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0267 - acc: 0.9924 - val_loss: 0.1806 - val_acc: 0.9520\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9930\n",
      "Epoch 00040: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0261 - acc: 0.9930 - val_loss: 0.1809 - val_acc: 0.9557\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9913\n",
      "Epoch 00041: val_loss did not improve from 0.15546\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0300 - acc: 0.9913 - val_loss: 0.2050 - val_acc: 0.9511\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9888\n",
      "Epoch 00042: val_loss improved from 0.15546 to 0.14940, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/042-0.1494.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0358 - acc: 0.9888 - val_loss: 0.1494 - val_acc: 0.9606\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9933\n",
      "Epoch 00043: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0242 - acc: 0.9933 - val_loss: 0.1621 - val_acc: 0.9583\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9935\n",
      "Epoch 00044: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0255 - acc: 0.9935 - val_loss: 0.1613 - val_acc: 0.9562\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9921\n",
      "Epoch 00045: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0291 - acc: 0.9921 - val_loss: 0.1714 - val_acc: 0.9548\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9957\n",
      "Epoch 00046: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0176 - acc: 0.9957 - val_loss: 0.1821 - val_acc: 0.9588\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9935\n",
      "Epoch 00047: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0222 - acc: 0.9934 - val_loss: 0.2039 - val_acc: 0.9488\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9910\n",
      "Epoch 00048: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0298 - acc: 0.9910 - val_loss: 0.1799 - val_acc: 0.9534\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9949\n",
      "Epoch 00049: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0193 - acc: 0.9949 - val_loss: 0.1739 - val_acc: 0.9555\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9919\n",
      "Epoch 00050: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0259 - acc: 0.9919 - val_loss: 0.1635 - val_acc: 0.9588\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9959\n",
      "Epoch 00051: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0162 - acc: 0.9959 - val_loss: 0.1533 - val_acc: 0.9588\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9952\n",
      "Epoch 00052: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0164 - acc: 0.9952 - val_loss: 0.1720 - val_acc: 0.9590\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9948\n",
      "Epoch 00053: val_loss did not improve from 0.14940\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0182 - acc: 0.9947 - val_loss: 0.1879 - val_acc: 0.9553\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 00054: val_loss improved from 0.14940 to 0.14848, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/054-0.1485.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0229 - acc: 0.9932 - val_loss: 0.1485 - val_acc: 0.9623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9962\n",
      "Epoch 00055: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0139 - acc: 0.9962 - val_loss: 0.1801 - val_acc: 0.9557\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9948\n",
      "Epoch 00056: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0198 - acc: 0.9948 - val_loss: 0.1658 - val_acc: 0.9618\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9956\n",
      "Epoch 00057: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0167 - acc: 0.9956 - val_loss: 0.1669 - val_acc: 0.9606\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0192 - acc: 0.9942 - val_loss: 0.1649 - val_acc: 0.9590\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9925\n",
      "Epoch 00059: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0256 - acc: 0.9925 - val_loss: 0.1497 - val_acc: 0.9611\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9967\n",
      "Epoch 00060: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0134 - acc: 0.9967 - val_loss: 0.1598 - val_acc: 0.9623\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9962\n",
      "Epoch 00061: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0140 - acc: 0.9962 - val_loss: 0.2206 - val_acc: 0.9564\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9955\n",
      "Epoch 00062: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0163 - acc: 0.9955 - val_loss: 0.2043 - val_acc: 0.9520\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9889\n",
      "Epoch 00063: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0356 - acc: 0.9889 - val_loss: 0.1628 - val_acc: 0.9632\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9954\n",
      "Epoch 00064: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0166 - acc: 0.9954 - val_loss: 0.1515 - val_acc: 0.9641\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9977\n",
      "Epoch 00065: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0096 - acc: 0.9977 - val_loss: 0.1919 - val_acc: 0.9585\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9972\n",
      "Epoch 00066: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0117 - acc: 0.9971 - val_loss: 0.1824 - val_acc: 0.9606\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9936\n",
      "Epoch 00067: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0218 - acc: 0.9936 - val_loss: 0.1668 - val_acc: 0.9625\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9966\n",
      "Epoch 00068: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0131 - acc: 0.9966 - val_loss: 0.1494 - val_acc: 0.9676\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9977\n",
      "Epoch 00069: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0091 - acc: 0.9977 - val_loss: 0.1923 - val_acc: 0.9585\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9957\n",
      "Epoch 00070: val_loss did not improve from 0.14848\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0157 - acc: 0.9957 - val_loss: 0.3409 - val_acc: 0.9290\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9960\n",
      "Epoch 00071: val_loss improved from 0.14848 to 0.13935, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_8_conv_checkpoint/071-0.1393.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0139 - acc: 0.9960 - val_loss: 0.1393 - val_acc: 0.9662\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9971\n",
      "Epoch 00072: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0104 - acc: 0.9971 - val_loss: 0.1851 - val_acc: 0.9569\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 00073: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0147 - acc: 0.9958 - val_loss: 0.1523 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9968\n",
      "Epoch 00074: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0111 - acc: 0.9968 - val_loss: 0.1728 - val_acc: 0.9585\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9973\n",
      "Epoch 00075: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0095 - acc: 0.9973 - val_loss: 0.2285 - val_acc: 0.9492\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 00076: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0159 - acc: 0.9951 - val_loss: 0.1651 - val_acc: 0.9578\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9971\n",
      "Epoch 00077: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0111 - acc: 0.9971 - val_loss: 0.1719 - val_acc: 0.9595\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9957\n",
      "Epoch 00078: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0145 - acc: 0.9957 - val_loss: 0.2339 - val_acc: 0.9485\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9970\n",
      "Epoch 00079: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 0.2497 - val_acc: 0.9541\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9964\n",
      "Epoch 00080: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0126 - acc: 0.9964 - val_loss: 0.2291 - val_acc: 0.9502\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9971\n",
      "Epoch 00081: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0112 - acc: 0.9971 - val_loss: 0.1894 - val_acc: 0.9564\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9930\n",
      "Epoch 00082: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0219 - acc: 0.9930 - val_loss: 0.1561 - val_acc: 0.9611\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9981\n",
      "Epoch 00083: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0075 - acc: 0.9981 - val_loss: 0.1577 - val_acc: 0.9630\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9985\n",
      "Epoch 00084: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0058 - acc: 0.9985 - val_loss: 0.2106 - val_acc: 0.9555\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9968\n",
      "Epoch 00085: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0111 - acc: 0.9968 - val_loss: 0.2640 - val_acc: 0.9406\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9918\n",
      "Epoch 00086: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0270 - acc: 0.9918 - val_loss: 0.1701 - val_acc: 0.9630\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 00087: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0076 - acc: 0.9980 - val_loss: 0.1582 - val_acc: 0.9639\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9982\n",
      "Epoch 00088: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0077 - acc: 0.9982 - val_loss: 0.1586 - val_acc: 0.9630\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 00089: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1568 - val_acc: 0.9648\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 00090: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.2808 - val_acc: 0.9341\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9973\n",
      "Epoch 00091: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0099 - acc: 0.9973 - val_loss: 0.2253 - val_acc: 0.9534\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 00092: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0057 - acc: 0.9985 - val_loss: 0.1668 - val_acc: 0.9644\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9957\n",
      "Epoch 00093: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0132 - acc: 0.9957 - val_loss: 0.1758 - val_acc: 0.9620\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9974\n",
      "Epoch 00094: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0088 - acc: 0.9974 - val_loss: 0.2014 - val_acc: 0.9592\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9953\n",
      "Epoch 00095: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0157 - acc: 0.9953 - val_loss: 0.1432 - val_acc: 0.9679\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 00096: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1982 - val_acc: 0.9578\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 00097: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1681 - val_acc: 0.9630\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9977\n",
      "Epoch 00098: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0081 - acc: 0.9977 - val_loss: 0.1480 - val_acc: 0.9662\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 00099: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0103 - acc: 0.9971 - val_loss: 0.1795 - val_acc: 0.9611\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9980\n",
      "Epoch 00100: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0075 - acc: 0.9980 - val_loss: 0.2016 - val_acc: 0.9546\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 00101: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 0.1901 - val_acc: 0.9634\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9948\n",
      "Epoch 00102: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0184 - acc: 0.9948 - val_loss: 0.1913 - val_acc: 0.9609\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9983\n",
      "Epoch 00103: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0065 - acc: 0.9983 - val_loss: 0.1871 - val_acc: 0.9597\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 00104: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0067 - acc: 0.9982 - val_loss: 0.1605 - val_acc: 0.9651\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 00105: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 0.1776 - val_acc: 0.9644\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9980\n",
      "Epoch 00106: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0076 - acc: 0.9980 - val_loss: 0.1830 - val_acc: 0.9583\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9968\n",
      "Epoch 00107: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.1907 - val_acc: 0.9564\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9969\n",
      "Epoch 00108: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0109 - acc: 0.9969 - val_loss: 0.1795 - val_acc: 0.9611\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9985\n",
      "Epoch 00109: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0060 - acc: 0.9985 - val_loss: 0.1553 - val_acc: 0.9672\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00110: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0075 - acc: 0.9977 - val_loss: 0.2081 - val_acc: 0.9569\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 00111: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0101 - acc: 0.9968 - val_loss: 0.1717 - val_acc: 0.9625\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9980\n",
      "Epoch 00112: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0069 - acc: 0.9980 - val_loss: 0.1847 - val_acc: 0.9609\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 00113: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0072 - acc: 0.9979 - val_loss: 0.1520 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9972\n",
      "Epoch 00114: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0100 - acc: 0.9972 - val_loss: 0.1964 - val_acc: 0.9585\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00115: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.2215 - val_acc: 0.9529\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 00116: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0070 - acc: 0.9982 - val_loss: 0.1835 - val_acc: 0.9625\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 00117: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0079 - acc: 0.9977 - val_loss: 0.1852 - val_acc: 0.9611\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981\n",
      "Epoch 00118: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0070 - acc: 0.9981 - val_loss: 0.1682 - val_acc: 0.9641\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9938\n",
      "Epoch 00119: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0206 - acc: 0.9938 - val_loss: 0.1894 - val_acc: 0.9620\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9994\n",
      "Epoch 00120: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0032 - acc: 0.9994 - val_loss: 0.1632 - val_acc: 0.9651\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00121: val_loss did not improve from 0.13935\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0051 - acc: 0.9985 - val_loss: 0.1954 - val_acc: 0.9616\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2110 - acc: 0.9512\n",
      "Loss: 0.2109833645048287 Accuracy: 0.95119417\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3765 - acc: 0.5711\n",
      "Epoch 00001: val_loss improved from inf to 0.75864, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/001-0.7586.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 1.3763 - acc: 0.5712 - val_loss: 0.7586 - val_acc: 0.7941\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.8296\n",
      "Epoch 00002: val_loss improved from 0.75864 to 0.41967, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/002-0.4197.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5542 - acc: 0.8296 - val_loss: 0.4197 - val_acc: 0.8747\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3773 - acc: 0.8850\n",
      "Epoch 00003: val_loss improved from 0.41967 to 0.26637, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/003-0.2664.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3772 - acc: 0.8850 - val_loss: 0.2664 - val_acc: 0.9182\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2947 - acc: 0.9092\n",
      "Epoch 00004: val_loss did not improve from 0.26637\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2947 - acc: 0.9093 - val_loss: 0.2905 - val_acc: 0.9154\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9255\n",
      "Epoch 00005: val_loss improved from 0.26637 to 0.24872, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/005-0.2487.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2426 - acc: 0.9255 - val_loss: 0.2487 - val_acc: 0.9259\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9368\n",
      "Epoch 00006: val_loss improved from 0.24872 to 0.21100, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/006-0.2110.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2052 - acc: 0.9369 - val_loss: 0.2110 - val_acc: 0.9317\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9442\n",
      "Epoch 00007: val_loss improved from 0.21100 to 0.18532, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/007-0.1853.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1796 - acc: 0.9442 - val_loss: 0.1853 - val_acc: 0.9471\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9499\n",
      "Epoch 00008: val_loss did not improve from 0.18532\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1592 - acc: 0.9499 - val_loss: 0.1901 - val_acc: 0.9427\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9576\n",
      "Epoch 00009: val_loss did not improve from 0.18532\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1374 - acc: 0.9576 - val_loss: 0.2234 - val_acc: 0.9408\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9622\n",
      "Epoch 00010: val_loss improved from 0.18532 to 0.18266, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/010-0.1827.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1240 - acc: 0.9622 - val_loss: 0.1827 - val_acc: 0.9453\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9652\n",
      "Epoch 00011: val_loss improved from 0.18266 to 0.16321, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/011-0.1632.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1137 - acc: 0.9651 - val_loss: 0.1632 - val_acc: 0.9518\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9699\n",
      "Epoch 00012: val_loss improved from 0.16321 to 0.15895, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/012-0.1589.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0985 - acc: 0.9699 - val_loss: 0.1589 - val_acc: 0.9541\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9742\n",
      "Epoch 00013: val_loss did not improve from 0.15895\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0848 - acc: 0.9742 - val_loss: 0.1919 - val_acc: 0.9422\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9769\n",
      "Epoch 00014: val_loss did not improve from 0.15895\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0774 - acc: 0.9769 - val_loss: 0.1685 - val_acc: 0.9499\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9785\n",
      "Epoch 00015: val_loss improved from 0.15895 to 0.14997, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/015-0.1500.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0716 - acc: 0.9785 - val_loss: 0.1500 - val_acc: 0.9606\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9810\n",
      "Epoch 00016: val_loss improved from 0.14997 to 0.14505, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/016-0.1450.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0634 - acc: 0.9810 - val_loss: 0.1450 - val_acc: 0.9571\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9823\n",
      "Epoch 00017: val_loss did not improve from 0.14505\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0604 - acc: 0.9823 - val_loss: 0.1559 - val_acc: 0.9562\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9843\n",
      "Epoch 00018: val_loss did not improve from 0.14505\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0526 - acc: 0.9843 - val_loss: 0.1559 - val_acc: 0.9595\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9864\n",
      "Epoch 00019: val_loss did not improve from 0.14505\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0472 - acc: 0.9864 - val_loss: 0.2181 - val_acc: 0.9432\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9852\n",
      "Epoch 00020: val_loss improved from 0.14505 to 0.14210, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/020-0.1421.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0525 - acc: 0.9852 - val_loss: 0.1421 - val_acc: 0.9602\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9915\n",
      "Epoch 00021: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0341 - acc: 0.9915 - val_loss: 0.1463 - val_acc: 0.9606\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9899\n",
      "Epoch 00022: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0362 - acc: 0.9899 - val_loss: 0.1618 - val_acc: 0.9562\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9892\n",
      "Epoch 00023: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0375 - acc: 0.9892 - val_loss: 0.1805 - val_acc: 0.9548\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9908\n",
      "Epoch 00024: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0309 - acc: 0.9908 - val_loss: 0.2067 - val_acc: 0.9481\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9925\n",
      "Epoch 00025: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0280 - acc: 0.9925 - val_loss: 0.1593 - val_acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9898\n",
      "Epoch 00026: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0337 - acc: 0.9898 - val_loss: 0.1641 - val_acc: 0.9546\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9896\n",
      "Epoch 00027: val_loss did not improve from 0.14210\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0359 - acc: 0.9896 - val_loss: 0.1592 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9942\n",
      "Epoch 00028: val_loss improved from 0.14210 to 0.13774, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/028-0.1377.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0222 - acc: 0.9942 - val_loss: 0.1377 - val_acc: 0.9623\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9961\n",
      "Epoch 00029: val_loss did not improve from 0.13774\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0170 - acc: 0.9960 - val_loss: 0.1665 - val_acc: 0.9585\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9926\n",
      "Epoch 00030: val_loss did not improve from 0.13774\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0267 - acc: 0.9926 - val_loss: 0.1933 - val_acc: 0.9502\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9894\n",
      "Epoch 00031: val_loss improved from 0.13774 to 0.13463, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/031-0.1346.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0361 - acc: 0.9893 - val_loss: 0.1346 - val_acc: 0.9648\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9960\n",
      "Epoch 00032: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0165 - acc: 0.9960 - val_loss: 0.1683 - val_acc: 0.9602\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9945\n",
      "Epoch 00033: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0195 - acc: 0.9945 - val_loss: 0.1822 - val_acc: 0.9557\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9953\n",
      "Epoch 00034: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0181 - acc: 0.9953 - val_loss: 0.1669 - val_acc: 0.9595\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9961\n",
      "Epoch 00035: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0150 - acc: 0.9961 - val_loss: 0.1721 - val_acc: 0.9581\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9944\n",
      "Epoch 00036: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0201 - acc: 0.9943 - val_loss: 0.2227 - val_acc: 0.9490\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9895\n",
      "Epoch 00037: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0366 - acc: 0.9895 - val_loss: 0.1512 - val_acc: 0.9634\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9974\n",
      "Epoch 00038: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0116 - acc: 0.9974 - val_loss: 0.1602 - val_acc: 0.9590\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9977\n",
      "Epoch 00039: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0105 - acc: 0.9977 - val_loss: 0.1518 - val_acc: 0.9623\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9975\n",
      "Epoch 00040: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0110 - acc: 0.9975 - val_loss: 0.1422 - val_acc: 0.9637\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9953\n",
      "Epoch 00041: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0160 - acc: 0.9953 - val_loss: 0.1852 - val_acc: 0.9525\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 00042: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0154 - acc: 0.9954 - val_loss: 0.1677 - val_acc: 0.9581\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 00043: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 0.1472 - val_acc: 0.9632\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9935\n",
      "Epoch 00044: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0222 - acc: 0.9935 - val_loss: 0.1598 - val_acc: 0.9588\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9974\n",
      "Epoch 00045: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0100 - acc: 0.9974 - val_loss: 0.1575 - val_acc: 0.9623\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9968\n",
      "Epoch 00046: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0116 - acc: 0.9968 - val_loss: 0.1846 - val_acc: 0.9553\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9956\n",
      "Epoch 00047: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0148 - acc: 0.9956 - val_loss: 0.1580 - val_acc: 0.9611\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9939\n",
      "Epoch 00048: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0213 - acc: 0.9939 - val_loss: 0.1681 - val_acc: 0.9611\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9985\n",
      "Epoch 00049: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0071 - acc: 0.9985 - val_loss: 0.2096 - val_acc: 0.9511\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9956\n",
      "Epoch 00050: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0161 - acc: 0.9956 - val_loss: 0.1352 - val_acc: 0.9672\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9967\n",
      "Epoch 00051: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0121 - acc: 0.9967 - val_loss: 0.1542 - val_acc: 0.9651\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9978\n",
      "Epoch 00052: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0087 - acc: 0.9978 - val_loss: 0.1830 - val_acc: 0.9583\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 00053: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.1615 - val_acc: 0.9632\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9982\n",
      "Epoch 00054: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0075 - acc: 0.9982 - val_loss: 0.2031 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9958\n",
      "Epoch 00055: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0135 - acc: 0.9958 - val_loss: 0.1733 - val_acc: 0.9576\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 00056: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0097 - acc: 0.9973 - val_loss: 0.1539 - val_acc: 0.9651\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9968\n",
      "Epoch 00057: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0103 - acc: 0.9968 - val_loss: 0.1512 - val_acc: 0.9672\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9949\n",
      "Epoch 00058: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0163 - acc: 0.9949 - val_loss: 0.1815 - val_acc: 0.9599\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9979\n",
      "Epoch 00059: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0078 - acc: 0.9979 - val_loss: 0.1901 - val_acc: 0.9590\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9990\n",
      "Epoch 00060: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1691 - val_acc: 0.9639\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9987\n",
      "Epoch 00061: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0063 - acc: 0.9987 - val_loss: 0.1616 - val_acc: 0.9590\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9942\n",
      "Epoch 00062: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0176 - acc: 0.9942 - val_loss: 0.1735 - val_acc: 0.9609\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9963\n",
      "Epoch 00063: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0129 - acc: 0.9963 - val_loss: 0.1418 - val_acc: 0.9693\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9978\n",
      "Epoch 00064: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.2243 - val_acc: 0.9543\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9926\n",
      "Epoch 00065: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0253 - acc: 0.9925 - val_loss: 0.1773 - val_acc: 0.9609\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9969\n",
      "Epoch 00066: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0117 - acc: 0.9969 - val_loss: 0.1410 - val_acc: 0.9658\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00067: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0038 - acc: 0.9992 - val_loss: 0.1419 - val_acc: 0.9662\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 00068: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0041 - acc: 0.9989 - val_loss: 0.1584 - val_acc: 0.9625\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 00069: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0058 - acc: 0.9983 - val_loss: 0.1832 - val_acc: 0.9590\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 00070: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0091 - acc: 0.9976 - val_loss: 0.1766 - val_acc: 0.9625\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9986\n",
      "Epoch 00071: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0058 - acc: 0.9986 - val_loss: 0.2001 - val_acc: 0.9569\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9975\n",
      "Epoch 00072: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0098 - acc: 0.9975 - val_loss: 0.1537 - val_acc: 0.9658\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9971\n",
      "Epoch 00073: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0105 - acc: 0.9971 - val_loss: 0.1585 - val_acc: 0.9660\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 00074: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0060 - acc: 0.9982 - val_loss: 0.1537 - val_acc: 0.9660\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9970\n",
      "Epoch 00075: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0105 - acc: 0.9970 - val_loss: 0.2097 - val_acc: 0.9562\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 00076: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0084 - acc: 0.9974 - val_loss: 0.2162 - val_acc: 0.9550\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 00077: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0056 - acc: 0.9987 - val_loss: 0.1519 - val_acc: 0.9646\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981\n",
      "Epoch 00078: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0062 - acc: 0.9981 - val_loss: 0.1738 - val_acc: 0.9616\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 00079: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0089 - acc: 0.9972 - val_loss: 0.1564 - val_acc: 0.9651\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00080: val_loss did not improve from 0.13463\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0051 - acc: 0.9985 - val_loss: 0.1581 - val_acc: 0.9627\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00081: val_loss improved from 0.13463 to 0.13428, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/081-0.1343.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.1343 - val_acc: 0.9706\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 00082: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0067 - acc: 0.9979 - val_loss: 0.2229 - val_acc: 0.9504\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 00083: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0108 - acc: 0.9970 - val_loss: 0.1612 - val_acc: 0.9644\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 00084: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1499 - val_acc: 0.9693\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 00085: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0062 - acc: 0.9981 - val_loss: 0.1783 - val_acc: 0.9611\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978\n",
      "Epoch 00086: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0075 - acc: 0.9978 - val_loss: 0.1896 - val_acc: 0.9611\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 00087: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0050 - acc: 0.9987 - val_loss: 0.1687 - val_acc: 0.9634\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 00088: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0142 - acc: 0.9957 - val_loss: 0.1558 - val_acc: 0.9667\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9973\n",
      "Epoch 00089: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0098 - acc: 0.9973 - val_loss: 0.1478 - val_acc: 0.9704\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9969\n",
      "Epoch 00090: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0105 - acc: 0.9968 - val_loss: 0.1734 - val_acc: 0.9630\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 00091: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0139 - acc: 0.9961 - val_loss: 0.1462 - val_acc: 0.9697\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00092: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.1573 - val_acc: 0.9667\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9989\n",
      "Epoch 00093: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 0.1751 - val_acc: 0.9625\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9950\n",
      "Epoch 00094: val_loss did not improve from 0.13428\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0171 - acc: 0.9950 - val_loss: 0.1459 - val_acc: 0.9695\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00095: val_loss improved from 0.13428 to 0.13414, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/095-0.1341.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1341 - val_acc: 0.9713\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00096: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1494 - val_acc: 0.9676\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 00097: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0048 - acc: 0.9986 - val_loss: 0.1738 - val_acc: 0.9620\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00098: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1552 - val_acc: 0.9655\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9951\n",
      "Epoch 00099: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0175 - acc: 0.9951 - val_loss: 0.1525 - val_acc: 0.9660\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 00100: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.1444 - val_acc: 0.9679\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 00101: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0025 - acc: 0.9995 - val_loss: 0.1516 - val_acc: 0.9693\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 00102: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0022 - acc: 0.9995 - val_loss: 0.1540 - val_acc: 0.9683\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9974\n",
      "Epoch 00103: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0074 - acc: 0.9974 - val_loss: 0.2097 - val_acc: 0.9585\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9989\n",
      "Epoch 00104: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0040 - acc: 0.9989 - val_loss: 0.1562 - val_acc: 0.9669\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9987\n",
      "Epoch 00105: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0044 - acc: 0.9987 - val_loss: 0.2081 - val_acc: 0.9588\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9981\n",
      "Epoch 00106: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0065 - acc: 0.9981 - val_loss: 0.1861 - val_acc: 0.9604\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 00107: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0061 - acc: 0.9984 - val_loss: 0.1956 - val_acc: 0.9588\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9964\n",
      "Epoch 00108: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0116 - acc: 0.9964 - val_loss: 0.1439 - val_acc: 0.9679\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00109: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1994 - val_acc: 0.9606\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9986\n",
      "Epoch 00110: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0051 - acc: 0.9986 - val_loss: 0.1664 - val_acc: 0.9674\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9971\n",
      "Epoch 00111: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0105 - acc: 0.9971 - val_loss: 0.1560 - val_acc: 0.9669\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00112: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1577 - val_acc: 0.9693\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00113: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0015 - acc: 0.9998 - val_loss: 0.1542 - val_acc: 0.9681\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9981\n",
      "Epoch 00114: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.2370 - val_acc: 0.9578\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9985\n",
      "Epoch 00115: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0057 - acc: 0.9984 - val_loss: 0.1810 - val_acc: 0.9648\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9963\n",
      "Epoch 00116: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0124 - acc: 0.9963 - val_loss: 0.1814 - val_acc: 0.9646\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9970\n",
      "Epoch 00117: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0101 - acc: 0.9970 - val_loss: 0.1769 - val_acc: 0.9644\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9985\n",
      "Epoch 00118: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0055 - acc: 0.9985 - val_loss: 0.1591 - val_acc: 0.9660\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990\n",
      "Epoch 00119: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0030 - acc: 0.9990 - val_loss: 0.1458 - val_acc: 0.9711\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00120: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1473 - val_acc: 0.9688\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9978\n",
      "Epoch 00121: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0081 - acc: 0.9978 - val_loss: 0.2058 - val_acc: 0.9583\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9977\n",
      "Epoch 00122: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0080 - acc: 0.9977 - val_loss: 0.1822 - val_acc: 0.9581\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 00123: val_loss did not improve from 0.13414\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0042 - acc: 0.9987 - val_loss: 0.1433 - val_acc: 0.9695\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9989\n",
      "Epoch 00124: val_loss improved from 0.13414 to 0.13345, saving model to model/checkpoint/1D_CNN_custom_DO_025_DO_BN_9_conv_checkpoint/124-0.1334.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0038 - acc: 0.9989 - val_loss: 0.1334 - val_acc: 0.9690\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 00125: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0049 - acc: 0.9987 - val_loss: 0.2290 - val_acc: 0.9569\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9962\n",
      "Epoch 00126: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0138 - acc: 0.9962 - val_loss: 0.1728 - val_acc: 0.9627\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 00127: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1641 - val_acc: 0.9686\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 00128: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0083 - acc: 0.9975 - val_loss: 0.1671 - val_acc: 0.9623\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 00129: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.1680 - val_acc: 0.9639\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 00130: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1709 - val_acc: 0.9679\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9981\n",
      "Epoch 00131: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0065 - acc: 0.9981 - val_loss: 0.1391 - val_acc: 0.9700\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00132: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.1402 - val_acc: 0.9693\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9986\n",
      "Epoch 00133: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0044 - acc: 0.9986 - val_loss: 0.2133 - val_acc: 0.9604\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 00134: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0061 - acc: 0.9982 - val_loss: 0.1736 - val_acc: 0.9646\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 00135: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0054 - acc: 0.9984 - val_loss: 0.1556 - val_acc: 0.9676\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00136: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1915 - val_acc: 0.9658\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 00137: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0104 - acc: 0.9965 - val_loss: 0.1644 - val_acc: 0.9660\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 00138: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0025 - acc: 0.9994 - val_loss: 0.1497 - val_acc: 0.9690\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00139: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1584 - val_acc: 0.9688\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 00140: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0134 - acc: 0.9961 - val_loss: 0.1755 - val_acc: 0.9648\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9995\n",
      "Epoch 00141: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0020 - acc: 0.9995 - val_loss: 0.1460 - val_acc: 0.9683\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 00142: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.1700 - val_acc: 0.9667\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 00143: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1571 - val_acc: 0.9693\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00144: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1675 - val_acc: 0.9667\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 00145: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0066 - acc: 0.9980 - val_loss: 0.1633 - val_acc: 0.9672\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9964\n",
      "Epoch 00146: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0111 - acc: 0.9964 - val_loss: 0.1675 - val_acc: 0.9686\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 00147: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1579 - val_acc: 0.9686\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 00148: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1511 - val_acc: 0.9704\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 00149: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.1712 - val_acc: 0.9660\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9988\n",
      "Epoch 00150: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0038 - acc: 0.9988 - val_loss: 0.1896 - val_acc: 0.9613\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 00151: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1773 - val_acc: 0.9658\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 00152: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1798 - val_acc: 0.9662\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9972\n",
      "Epoch 00153: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0086 - acc: 0.9972 - val_loss: 0.2959 - val_acc: 0.9464\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00154: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1516 - val_acc: 0.9704\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00155: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1680 - val_acc: 0.9660\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 00156: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0046 - acc: 0.9987 - val_loss: 0.2115 - val_acc: 0.9625\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9982\n",
      "Epoch 00157: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0051 - acc: 0.9982 - val_loss: 0.1552 - val_acc: 0.9651\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00158: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1713 - val_acc: 0.9674\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9990\n",
      "Epoch 00159: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1553 - val_acc: 0.9683\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 00160: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0052 - acc: 0.9983 - val_loss: 0.1824 - val_acc: 0.9630\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 00161: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1528 - val_acc: 0.9679\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00162: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1692 - val_acc: 0.9639\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9985\n",
      "Epoch 00163: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0047 - acc: 0.9985 - val_loss: 0.1649 - val_acc: 0.9674\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 00164: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 0.1715 - val_acc: 0.9651\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9980\n",
      "Epoch 00165: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0069 - acc: 0.9980 - val_loss: 0.1684 - val_acc: 0.9674\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9993\n",
      "Epoch 00166: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0022 - acc: 0.9993 - val_loss: 0.1620 - val_acc: 0.9686\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00167: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1680 - val_acc: 0.9674\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9987\n",
      "Epoch 00168: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0041 - acc: 0.9987 - val_loss: 0.2118 - val_acc: 0.9574\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 00169: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1861 - val_acc: 0.9655\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9984\n",
      "Epoch 00170: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0054 - acc: 0.9984 - val_loss: 0.1754 - val_acc: 0.9660\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00171: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1732 - val_acc: 0.9695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 00172: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.1467 - val_acc: 0.9716\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.9735e-04 - acc: 0.9997\n",
      "Epoch 00173: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 9.9722e-04 - acc: 0.9997 - val_loss: 0.1672 - val_acc: 0.9681\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 00174: val_loss did not improve from 0.13345\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0021 - acc: 0.9993 - val_loss: 0.1928 - val_acc: 0.9627\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2022 - acc: 0.9578\n",
      "Loss: 0.20217632674878797 Accuracy: 0.9578401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_DO_025_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_025_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 643us/sample - loss: 2.5254 - acc: 0.2069\n",
      "Loss: 2.5254280345338405 Accuracy: 0.20685358\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 919us/sample - loss: 4.4010 - acc: 0.2760\n",
      "Loss: 4.401042298488281 Accuracy: 0.27601245\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 992us/sample - loss: 1.6474 - acc: 0.5639\n",
      "Loss: 1.647401433520847 Accuracy: 0.5638629\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.1698 - acc: 0.6625\n",
      "Loss: 1.1697958334955472 Accuracy: 0.66251296\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8147 - acc: 0.7653\n",
      "Loss: 0.8146993243558137 Accuracy: 0.7653167\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5152 - acc: 0.8633\n",
      "Loss: 0.51524708325494 Accuracy: 0.8633437\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2617 - acc: 0.9269\n",
      "Loss: 0.2617387284278127 Accuracy: 0.92689514\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2110 - acc: 0.9512\n",
      "Loss: 0.2109833645048287 Accuracy: 0.95119417\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2022 - acc: 0.9578\n",
      "Loss: 0.20217632674878797 Accuracy: 0.9578401\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_DO_025_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 785us/sample - loss: 8.4259 - acc: 0.2542\n",
      "Loss: 8.425905139324945 Accuracy: 0.2542056\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 6.2809 - acc: 0.3477\n",
      "Loss: 6.280858842507082 Accuracy: 0.34766355\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.2979 - acc: 0.5313\n",
      "Loss: 3.2979496547366227 Accuracy: 0.5312565\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.6612 - acc: 0.6974\n",
      "Loss: 1.661245329679606 Accuracy: 0.69740397\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.1825 - acc: 0.7639\n",
      "Loss: 1.1825019671538166 Accuracy: 0.7638629\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.6089 - acc: 0.8710\n",
      "Loss: 0.6089173412149693 Accuracy: 0.87102807\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3175 - acc: 0.9263\n",
      "Loss: 0.3175306691984459 Accuracy: 0.9262721\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2583 - acc: 0.9470\n",
      "Loss: 0.2582831343804677 Accuracy: 0.9470405\n",
      "\n",
      "1D_CNN_custom_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2460 - acc: 0.9524\n",
      "Loss: 0.24604999006145267 Accuracy: 0.95244026\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
