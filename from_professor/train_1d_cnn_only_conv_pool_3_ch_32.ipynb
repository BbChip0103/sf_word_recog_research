{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_pool_3_ch_32_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=25, filters=32, strides=1, \n",
    "                      activation='relu', input_shape=input_shape))\n",
    "    \n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=32*(2**int((i)/2)), strides=1, \n",
    "                          activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2726928   \n",
      "=================================================================\n",
      "Total params: 2,727,760\n",
      "Trainable params: 2,727,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                905232    \n",
      "=================================================================\n",
      "Total params: 931,696\n",
      "Trainable params: 931,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 18624)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 18624)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                298000    \n",
      "=================================================================\n",
      "Total params: 350,096\n",
      "Trainable params: 350,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 558, 64)           51264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                190480    \n",
      "=================================================================\n",
      "Total params: 293,840\n",
      "Trainable params: 293,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 558, 64)           51264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 162, 64)           102464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                55312     \n",
      "=================================================================\n",
      "Total params: 261,136\n",
      "Trainable params: 261,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 558, 64)           51264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 162, 64)           102464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 30, 128)           204928    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                20496     \n",
      "=================================================================\n",
      "Total params: 431,248\n",
      "Trainable params: 431,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2734 - acc: 0.2856\n",
      "Epoch 00001: val_loss improved from inf to 1.90840, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_checkpoint/001-1.9084.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 2.2733 - acc: 0.2856 - val_loss: 1.9084 - val_acc: 0.4027\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7133 - acc: 0.4737\n",
      "Epoch 00002: val_loss improved from 1.90840 to 1.69665, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_checkpoint/002-1.6967.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 1.7133 - acc: 0.4737 - val_loss: 1.6967 - val_acc: 0.4729\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4607 - acc: 0.5562\n",
      "Epoch 00003: val_loss improved from 1.69665 to 1.60309, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_checkpoint/003-1.6031.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 1.4607 - acc: 0.5562 - val_loss: 1.6031 - val_acc: 0.4920\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3030 - acc: 0.6049\n",
      "Epoch 00004: val_loss improved from 1.60309 to 1.55930, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_checkpoint/004-1.5593.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 1.3031 - acc: 0.6048 - val_loss: 1.5593 - val_acc: 0.5069\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1874 - acc: 0.6391\n",
      "Epoch 00005: val_loss improved from 1.55930 to 1.55141, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_checkpoint/005-1.5514.hdf5\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 1.1873 - acc: 0.6392 - val_loss: 1.5514 - val_acc: 0.5101\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0931 - acc: 0.6690\n",
      "Epoch 00006: val_loss improved from 1.55141 to 1.55057, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_checkpoint/006-1.5506.hdf5\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 1.0931 - acc: 0.6690 - val_loss: 1.5506 - val_acc: 0.5113\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0143 - acc: 0.6958\n",
      "Epoch 00007: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 1.0142 - acc: 0.6958 - val_loss: 1.5555 - val_acc: 0.5085\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9491 - acc: 0.7148\n",
      "Epoch 00008: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.9491 - acc: 0.7148 - val_loss: 1.5726 - val_acc: 0.5076\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8863 - acc: 0.7352\n",
      "Epoch 00009: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.8863 - acc: 0.7351 - val_loss: 1.5835 - val_acc: 0.5048\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8364 - acc: 0.7486\n",
      "Epoch 00010: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.8364 - acc: 0.7486 - val_loss: 1.6130 - val_acc: 0.5024\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7868 - acc: 0.7660\n",
      "Epoch 00011: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.7868 - acc: 0.7660 - val_loss: 1.6191 - val_acc: 0.5013\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7433 - acc: 0.7807\n",
      "Epoch 00012: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.7434 - acc: 0.7806 - val_loss: 1.6549 - val_acc: 0.5024\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7050 - acc: 0.7941\n",
      "Epoch 00013: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.7050 - acc: 0.7941 - val_loss: 1.6612 - val_acc: 0.5094\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6707 - acc: 0.8033\n",
      "Epoch 00014: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.6708 - acc: 0.8033 - val_loss: 1.6825 - val_acc: 0.5069\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6316 - acc: 0.8162\n",
      "Epoch 00015: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.6318 - acc: 0.8162 - val_loss: 1.7047 - val_acc: 0.5048\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6018 - acc: 0.8248\n",
      "Epoch 00016: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.6017 - acc: 0.8248 - val_loss: 1.7110 - val_acc: 0.5090\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.8355\n",
      "Epoch 00017: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.5729 - acc: 0.8355 - val_loss: 1.7369 - val_acc: 0.5052\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.8421\n",
      "Epoch 00018: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.5489 - acc: 0.8421 - val_loss: 1.7560 - val_acc: 0.5071\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5245 - acc: 0.8509\n",
      "Epoch 00019: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.5246 - acc: 0.8508 - val_loss: 1.7881 - val_acc: 0.5034\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4997 - acc: 0.8569\n",
      "Epoch 00020: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.4996 - acc: 0.8569 - val_loss: 1.8001 - val_acc: 0.5104\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4761 - acc: 0.8658\n",
      "Epoch 00021: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.4762 - acc: 0.8658 - val_loss: 1.8126 - val_acc: 0.5146\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8713\n",
      "Epoch 00022: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.4561 - acc: 0.8713 - val_loss: 1.8341 - val_acc: 0.5111\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4398 - acc: 0.8765\n",
      "Epoch 00023: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.4399 - acc: 0.8765 - val_loss: 1.8613 - val_acc: 0.5162\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8822\n",
      "Epoch 00024: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.4184 - acc: 0.8822 - val_loss: 1.8890 - val_acc: 0.5125\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8866\n",
      "Epoch 00025: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.4011 - acc: 0.8866 - val_loss: 1.9030 - val_acc: 0.5153\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3903 - acc: 0.8886\n",
      "Epoch 00026: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.3903 - acc: 0.8886 - val_loss: 1.9374 - val_acc: 0.5020\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3705 - acc: 0.8988\n",
      "Epoch 00027: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.3705 - acc: 0.8988 - val_loss: 1.9771 - val_acc: 0.5043\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.9008\n",
      "Epoch 00028: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.3581 - acc: 0.9008 - val_loss: 1.9848 - val_acc: 0.5104\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3439 - acc: 0.9065\n",
      "Epoch 00029: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3439 - acc: 0.9065 - val_loss: 2.0055 - val_acc: 0.5127\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3317 - acc: 0.9092\n",
      "Epoch 00030: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3317 - acc: 0.9092 - val_loss: 2.0172 - val_acc: 0.5132\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.9113\n",
      "Epoch 00031: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.3206 - acc: 0.9113 - val_loss: 2.0185 - val_acc: 0.5208\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3101 - acc: 0.9158\n",
      "Epoch 00032: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.3100 - acc: 0.9158 - val_loss: 2.0396 - val_acc: 0.5113\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3003 - acc: 0.9187\n",
      "Epoch 00033: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3003 - acc: 0.9187 - val_loss: 2.0650 - val_acc: 0.5153\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2882 - acc: 0.9223\n",
      "Epoch 00034: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2883 - acc: 0.9223 - val_loss: 2.0943 - val_acc: 0.5190\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.9220\n",
      "Epoch 00035: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.2855 - acc: 0.9220 - val_loss: 2.1119 - val_acc: 0.5146\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9289\n",
      "Epoch 00036: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.2692 - acc: 0.9288 - val_loss: 2.1255 - val_acc: 0.5139\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.9264\n",
      "Epoch 00037: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2671 - acc: 0.9264 - val_loss: 2.1446 - val_acc: 0.5178\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2608 - acc: 0.9296\n",
      "Epoch 00038: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2608 - acc: 0.9297 - val_loss: 2.1566 - val_acc: 0.5195\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9330\n",
      "Epoch 00039: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2504 - acc: 0.9330 - val_loss: 2.1792 - val_acc: 0.5171\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9386\n",
      "Epoch 00040: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2373 - acc: 0.9385 - val_loss: 2.2285 - val_acc: 0.5115\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2330 - acc: 0.9382\n",
      "Epoch 00041: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.2330 - acc: 0.9382 - val_loss: 2.1940 - val_acc: 0.5213\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9376\n",
      "Epoch 00042: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.2308 - acc: 0.9376 - val_loss: 2.2427 - val_acc: 0.5127\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9407\n",
      "Epoch 00043: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2235 - acc: 0.9407 - val_loss: 2.2363 - val_acc: 0.5176\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2175 - acc: 0.9429\n",
      "Epoch 00044: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.2175 - acc: 0.9429 - val_loss: 2.2597 - val_acc: 0.5171\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9423\n",
      "Epoch 00045: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2148 - acc: 0.9423 - val_loss: 2.2698 - val_acc: 0.5190\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9462\n",
      "Epoch 00046: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2073 - acc: 0.9462 - val_loss: 2.2885 - val_acc: 0.5169\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9473\n",
      "Epoch 00047: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2018 - acc: 0.9473 - val_loss: 2.3002 - val_acc: 0.5243\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9477\n",
      "Epoch 00048: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1961 - acc: 0.9477 - val_loss: 2.3098 - val_acc: 0.5181\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9492\n",
      "Epoch 00049: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1893 - acc: 0.9492 - val_loss: 2.3381 - val_acc: 0.5148\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9490\n",
      "Epoch 00050: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1907 - acc: 0.9490 - val_loss: 2.3405 - val_acc: 0.5236\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9492\n",
      "Epoch 00051: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1877 - acc: 0.9492 - val_loss: 2.3713 - val_acc: 0.5141\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9525\n",
      "Epoch 00052: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1794 - acc: 0.9525 - val_loss: 2.3901 - val_acc: 0.5218\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9539\n",
      "Epoch 00053: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1782 - acc: 0.9539 - val_loss: 2.4226 - val_acc: 0.5171\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9547\n",
      "Epoch 00054: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1724 - acc: 0.9547 - val_loss: 2.4061 - val_acc: 0.5201\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9557\n",
      "Epoch 00055: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1727 - acc: 0.9557 - val_loss: 2.4347 - val_acc: 0.5115\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9557\n",
      "Epoch 00056: val_loss did not improve from 1.55057\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1674 - acc: 0.9557 - val_loss: 2.4957 - val_acc: 0.5134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_32_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 243us/sample - loss: 1.6095 - acc: 0.4910\n",
      "Loss: 1.6094556549504044 Accuracy: 0.49096572\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0723 - acc: 0.3291\n",
      "Epoch 00001: val_loss improved from inf to 1.65380, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/001-1.6538.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 2.0722 - acc: 0.3292 - val_loss: 1.6538 - val_acc: 0.4859\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5426 - acc: 0.5187\n",
      "Epoch 00002: val_loss improved from 1.65380 to 1.42042, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/002-1.4204.hdf5\n",
      "36805/36805 [==============================] - 27s 729us/sample - loss: 1.5426 - acc: 0.5187 - val_loss: 1.4204 - val_acc: 0.5716\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3494 - acc: 0.5896\n",
      "Epoch 00003: val_loss improved from 1.42042 to 1.33358, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/003-1.3336.hdf5\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 1.3494 - acc: 0.5896 - val_loss: 1.3336 - val_acc: 0.5956\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2199 - acc: 0.6336\n",
      "Epoch 00004: val_loss improved from 1.33358 to 1.24942, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/004-1.2494.hdf5\n",
      "36805/36805 [==============================] - 27s 730us/sample - loss: 1.2198 - acc: 0.6336 - val_loss: 1.2494 - val_acc: 0.6236\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1197 - acc: 0.6634\n",
      "Epoch 00005: val_loss improved from 1.24942 to 1.24223, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/005-1.2422.hdf5\n",
      "36805/36805 [==============================] - 27s 730us/sample - loss: 1.1196 - acc: 0.6634 - val_loss: 1.2422 - val_acc: 0.6168\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0346 - acc: 0.6902\n",
      "Epoch 00006: val_loss improved from 1.24223 to 1.17267, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/006-1.1727.hdf5\n",
      "36805/36805 [==============================] - 27s 730us/sample - loss: 1.0346 - acc: 0.6902 - val_loss: 1.1727 - val_acc: 0.6422\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9612 - acc: 0.7138\n",
      "Epoch 00007: val_loss improved from 1.17267 to 1.15814, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/007-1.1581.hdf5\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.9616 - acc: 0.7137 - val_loss: 1.1581 - val_acc: 0.6520\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8988 - acc: 0.7347\n",
      "Epoch 00008: val_loss improved from 1.15814 to 1.14081, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/008-1.1408.hdf5\n",
      "36805/36805 [==============================] - 27s 729us/sample - loss: 0.8988 - acc: 0.7347 - val_loss: 1.1408 - val_acc: 0.6513\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8496 - acc: 0.7457\n",
      "Epoch 00009: val_loss did not improve from 1.14081\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.8495 - acc: 0.7458 - val_loss: 1.1446 - val_acc: 0.6515\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7898 - acc: 0.7660\n",
      "Epoch 00010: val_loss improved from 1.14081 to 1.12045, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/010-1.1205.hdf5\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.7898 - acc: 0.7660 - val_loss: 1.1205 - val_acc: 0.6643\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7423 - acc: 0.7785\n",
      "Epoch 00011: val_loss improved from 1.12045 to 1.11818, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_checkpoint/011-1.1182.hdf5\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.7423 - acc: 0.7785 - val_loss: 1.1182 - val_acc: 0.6690\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7019 - acc: 0.7889\n",
      "Epoch 00012: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.7019 - acc: 0.7889 - val_loss: 1.1279 - val_acc: 0.6632\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6611 - acc: 0.8020\n",
      "Epoch 00013: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.6612 - acc: 0.8019 - val_loss: 1.1190 - val_acc: 0.6718\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6207 - acc: 0.8145\n",
      "Epoch 00014: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.6207 - acc: 0.8145 - val_loss: 1.1236 - val_acc: 0.6737\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5861 - acc: 0.8211\n",
      "Epoch 00015: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.5862 - acc: 0.8211 - val_loss: 1.1598 - val_acc: 0.6622\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5582 - acc: 0.8319\n",
      "Epoch 00016: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.5582 - acc: 0.8319 - val_loss: 1.1506 - val_acc: 0.6744\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5266 - acc: 0.8401\n",
      "Epoch 00017: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.5266 - acc: 0.8401 - val_loss: 1.1535 - val_acc: 0.6702\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4980 - acc: 0.8503\n",
      "Epoch 00018: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.4979 - acc: 0.8503 - val_loss: 1.1722 - val_acc: 0.6767\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.8554\n",
      "Epoch 00019: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.4740 - acc: 0.8553 - val_loss: 1.1748 - val_acc: 0.6755\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8633\n",
      "Epoch 00020: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.4500 - acc: 0.8633 - val_loss: 1.1778 - val_acc: 0.6795\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4295 - acc: 0.8678\n",
      "Epoch 00021: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.4295 - acc: 0.8678 - val_loss: 1.2027 - val_acc: 0.6762\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8769\n",
      "Epoch 00022: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.4077 - acc: 0.8769 - val_loss: 1.1856 - val_acc: 0.6825\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3906 - acc: 0.8825\n",
      "Epoch 00023: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.3906 - acc: 0.8825 - val_loss: 1.2077 - val_acc: 0.6776\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8884\n",
      "Epoch 00024: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.3692 - acc: 0.8884 - val_loss: 1.2444 - val_acc: 0.6820\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8933\n",
      "Epoch 00025: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 731us/sample - loss: 0.3533 - acc: 0.8933 - val_loss: 1.2362 - val_acc: 0.6853\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.8976\n",
      "Epoch 00026: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 734us/sample - loss: 0.3378 - acc: 0.8977 - val_loss: 1.2637 - val_acc: 0.6811\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.9021\n",
      "Epoch 00027: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 26s 719us/sample - loss: 0.3237 - acc: 0.9021 - val_loss: 1.2642 - val_acc: 0.6788\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3110 - acc: 0.9052\n",
      "Epoch 00028: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.3110 - acc: 0.9052 - val_loss: 1.2730 - val_acc: 0.6818\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2950 - acc: 0.9128\n",
      "Epoch 00029: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 733us/sample - loss: 0.2950 - acc: 0.9128 - val_loss: 1.2992 - val_acc: 0.6751\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2856 - acc: 0.9117\n",
      "Epoch 00030: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.2857 - acc: 0.9117 - val_loss: 1.2790 - val_acc: 0.6872\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9147\n",
      "Epoch 00031: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.2755 - acc: 0.9147 - val_loss: 1.2799 - val_acc: 0.6825\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2648 - acc: 0.9190\n",
      "Epoch 00032: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.2648 - acc: 0.9190 - val_loss: 1.2969 - val_acc: 0.6825\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.9244\n",
      "Epoch 00033: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.2516 - acc: 0.9244 - val_loss: 1.3019 - val_acc: 0.6953\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9266\n",
      "Epoch 00034: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.2442 - acc: 0.9266 - val_loss: 1.3249 - val_acc: 0.6974\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9301\n",
      "Epoch 00035: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.2332 - acc: 0.9300 - val_loss: 1.3351 - val_acc: 0.6935\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9309\n",
      "Epoch 00036: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.2265 - acc: 0.9309 - val_loss: 1.3521 - val_acc: 0.6853\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9354\n",
      "Epoch 00037: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.2184 - acc: 0.9354 - val_loss: 1.3652 - val_acc: 0.6881\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9351\n",
      "Epoch 00038: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.2130 - acc: 0.9351 - val_loss: 1.3661 - val_acc: 0.6962\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2063 - acc: 0.9384\n",
      "Epoch 00039: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.2063 - acc: 0.9384 - val_loss: 1.3687 - val_acc: 0.6956\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9381\n",
      "Epoch 00040: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.2044 - acc: 0.9381 - val_loss: 1.3848 - val_acc: 0.6902\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1922 - acc: 0.9419\n",
      "Epoch 00041: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.1922 - acc: 0.9419 - val_loss: 1.3993 - val_acc: 0.6909\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9450\n",
      "Epoch 00042: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.1855 - acc: 0.9450 - val_loss: 1.3869 - val_acc: 0.6997\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9477\n",
      "Epoch 00043: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.1806 - acc: 0.9477 - val_loss: 1.4011 - val_acc: 0.6951\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9489\n",
      "Epoch 00044: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1745 - acc: 0.9489 - val_loss: 1.4245 - val_acc: 0.6886\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9505\n",
      "Epoch 00045: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 731us/sample - loss: 0.1697 - acc: 0.9505 - val_loss: 1.4391 - val_acc: 0.6944\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9508\n",
      "Epoch 00046: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 736us/sample - loss: 0.1678 - acc: 0.9508 - val_loss: 1.4472 - val_acc: 0.6974\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9512\n",
      "Epoch 00047: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.1666 - acc: 0.9512 - val_loss: 1.4168 - val_acc: 0.7079\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9538\n",
      "Epoch 00048: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.1578 - acc: 0.9538 - val_loss: 1.4336 - val_acc: 0.7016\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9564\n",
      "Epoch 00049: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 733us/sample - loss: 0.1536 - acc: 0.9564 - val_loss: 1.4562 - val_acc: 0.7074\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9560\n",
      "Epoch 00050: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 729us/sample - loss: 0.1522 - acc: 0.9560 - val_loss: 1.4525 - val_acc: 0.7009\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9591\n",
      "Epoch 00051: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1446 - acc: 0.9591 - val_loss: 1.4610 - val_acc: 0.7014\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9580\n",
      "Epoch 00052: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1435 - acc: 0.9580 - val_loss: 1.5143 - val_acc: 0.6928\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9606\n",
      "Epoch 00053: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1394 - acc: 0.9605 - val_loss: 1.4879 - val_acc: 0.6993\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9613\n",
      "Epoch 00054: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1367 - acc: 0.9613 - val_loss: 1.5203 - val_acc: 0.6960\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9598\n",
      "Epoch 00055: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.1353 - acc: 0.9598 - val_loss: 1.5004 - val_acc: 0.6944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9630\n",
      "Epoch 00056: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1278 - acc: 0.9630 - val_loss: 1.5115 - val_acc: 0.7021\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9636\n",
      "Epoch 00057: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1244 - acc: 0.9636 - val_loss: 1.5106 - val_acc: 0.6967\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9656\n",
      "Epoch 00058: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.1223 - acc: 0.9656 - val_loss: 1.5122 - val_acc: 0.7037\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9655\n",
      "Epoch 00059: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1216 - acc: 0.9654 - val_loss: 1.5039 - val_acc: 0.7051\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9649\n",
      "Epoch 00060: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1196 - acc: 0.9649 - val_loss: 1.5393 - val_acc: 0.6995\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9672\n",
      "Epoch 00061: val_loss did not improve from 1.11818\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1149 - acc: 0.9672 - val_loss: 1.5306 - val_acc: 0.6958\n",
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_32_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 327us/sample - loss: 1.2243 - acc: 0.6276\n",
      "Loss: 1.2243124568202415 Accuracy: 0.627622\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1528 - acc: 0.2923\n",
      "Epoch 00001: val_loss improved from inf to 1.70576, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/001-1.7058.hdf5\n",
      "36805/36805 [==============================] - 31s 831us/sample - loss: 2.1528 - acc: 0.2923 - val_loss: 1.7058 - val_acc: 0.4414\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6413 - acc: 0.4732\n",
      "Epoch 00002: val_loss improved from 1.70576 to 1.43715, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/002-1.4372.hdf5\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 1.6413 - acc: 0.4732 - val_loss: 1.4372 - val_acc: 0.5460\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4477 - acc: 0.5494\n",
      "Epoch 00003: val_loss improved from 1.43715 to 1.28609, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/003-1.2861.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 1.4478 - acc: 0.5494 - val_loss: 1.2861 - val_acc: 0.6059\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3133 - acc: 0.5972- ETA: 1s - loss: 1.\n",
      "Epoch 00004: val_loss improved from 1.28609 to 1.19733, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/004-1.1973.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.3132 - acc: 0.5972 - val_loss: 1.1973 - val_acc: 0.6320\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2058 - acc: 0.6340\n",
      "Epoch 00005: val_loss improved from 1.19733 to 1.13459, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/005-1.1346.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.2057 - acc: 0.6340 - val_loss: 1.1346 - val_acc: 0.6613\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1247 - acc: 0.6618\n",
      "Epoch 00006: val_loss improved from 1.13459 to 1.05499, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/006-1.0550.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.1247 - acc: 0.6618 - val_loss: 1.0550 - val_acc: 0.6758\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0569 - acc: 0.6819\n",
      "Epoch 00007: val_loss improved from 1.05499 to 1.00355, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/007-1.0035.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 1.0569 - acc: 0.6819 - val_loss: 1.0035 - val_acc: 0.7074\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9989 - acc: 0.7021\n",
      "Epoch 00008: val_loss improved from 1.00355 to 0.96100, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/008-0.9610.hdf5\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.9988 - acc: 0.7021 - val_loss: 0.9610 - val_acc: 0.7156\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9431 - acc: 0.7191\n",
      "Epoch 00009: val_loss improved from 0.96100 to 0.91705, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/009-0.9170.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.9431 - acc: 0.7190 - val_loss: 0.9170 - val_acc: 0.7340\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8905 - acc: 0.7340\n",
      "Epoch 00010: val_loss improved from 0.91705 to 0.87976, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/010-0.8798.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.8905 - acc: 0.7341 - val_loss: 0.8798 - val_acc: 0.7370\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8473 - acc: 0.7503\n",
      "Epoch 00011: val_loss improved from 0.87976 to 0.86609, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/011-0.8661.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.8472 - acc: 0.7504 - val_loss: 0.8661 - val_acc: 0.7566\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8033 - acc: 0.7636\n",
      "Epoch 00012: val_loss improved from 0.86609 to 0.85050, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/012-0.8505.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8033 - acc: 0.7636 - val_loss: 0.8505 - val_acc: 0.7556\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7638 - acc: 0.7762\n",
      "Epoch 00013: val_loss improved from 0.85050 to 0.82955, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/013-0.8296.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.7638 - acc: 0.7762 - val_loss: 0.8296 - val_acc: 0.7654\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7310 - acc: 0.7840\n",
      "Epoch 00014: val_loss improved from 0.82955 to 0.77781, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/014-0.7778.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7310 - acc: 0.7840 - val_loss: 0.7778 - val_acc: 0.7759\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6926 - acc: 0.7970\n",
      "Epoch 00015: val_loss did not improve from 0.77781\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.6928 - acc: 0.7970 - val_loss: 0.7805 - val_acc: 0.7706\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6624 - acc: 0.8055\n",
      "Epoch 00016: val_loss improved from 0.77781 to 0.76520, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/016-0.7652.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.6623 - acc: 0.8055 - val_loss: 0.7652 - val_acc: 0.7750\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6362 - acc: 0.8144\n",
      "Epoch 00017: val_loss improved from 0.76520 to 0.74730, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/017-0.7473.hdf5\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.6361 - acc: 0.8144 - val_loss: 0.7473 - val_acc: 0.7834\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6013 - acc: 0.8239\n",
      "Epoch 00018: val_loss improved from 0.74730 to 0.73279, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/018-0.7328.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.6013 - acc: 0.8239 - val_loss: 0.7328 - val_acc: 0.7871\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5758 - acc: 0.8319\n",
      "Epoch 00019: val_loss did not improve from 0.73279\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5758 - acc: 0.8319 - val_loss: 0.7367 - val_acc: 0.7901\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.8373\n",
      "Epoch 00020: val_loss improved from 0.73279 to 0.73183, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/020-0.7318.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.5542 - acc: 0.8373 - val_loss: 0.7318 - val_acc: 0.7925\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.8452\n",
      "Epoch 00021: val_loss did not improve from 0.73183\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5302 - acc: 0.8452 - val_loss: 0.7630 - val_acc: 0.7799\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5037 - acc: 0.8525\n",
      "Epoch 00022: val_loss improved from 0.73183 to 0.72538, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/022-0.7254.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.5037 - acc: 0.8524 - val_loss: 0.7254 - val_acc: 0.7922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.8559\n",
      "Epoch 00023: val_loss improved from 0.72538 to 0.71173, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/023-0.7117.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4861 - acc: 0.8559 - val_loss: 0.7117 - val_acc: 0.7966\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8633\n",
      "Epoch 00024: val_loss improved from 0.71173 to 0.68632, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/024-0.6863.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.4674 - acc: 0.8633 - val_loss: 0.6863 - val_acc: 0.8057\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.8677\n",
      "Epoch 00025: val_loss did not improve from 0.68632\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4454 - acc: 0.8677 - val_loss: 0.7153 - val_acc: 0.7969\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8731\n",
      "Epoch 00026: val_loss did not improve from 0.68632\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.4236 - acc: 0.8730 - val_loss: 0.7272 - val_acc: 0.7976\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4056 - acc: 0.8791\n",
      "Epoch 00027: val_loss did not improve from 0.68632\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.4056 - acc: 0.8791 - val_loss: 0.7163 - val_acc: 0.7980\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3883 - acc: 0.8833\n",
      "Epoch 00028: val_loss did not improve from 0.68632\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3882 - acc: 0.8833 - val_loss: 0.7112 - val_acc: 0.8036\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3733 - acc: 0.8883\n",
      "Epoch 00029: val_loss improved from 0.68632 to 0.68535, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_checkpoint/029-0.6853.hdf5\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3733 - acc: 0.8883 - val_loss: 0.6853 - val_acc: 0.8116\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3623 - acc: 0.8923\n",
      "Epoch 00030: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3624 - acc: 0.8923 - val_loss: 0.7084 - val_acc: 0.8039\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3454 - acc: 0.8944\n",
      "Epoch 00031: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.3453 - acc: 0.8944 - val_loss: 0.7055 - val_acc: 0.8095\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3330 - acc: 0.8996\n",
      "Epoch 00032: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.3332 - acc: 0.8996 - val_loss: 0.6980 - val_acc: 0.8097\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3213 - acc: 0.9031\n",
      "Epoch 00033: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.3213 - acc: 0.9031 - val_loss: 0.7144 - val_acc: 0.8125\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3067 - acc: 0.9072\n",
      "Epoch 00034: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.3067 - acc: 0.9072 - val_loss: 0.7408 - val_acc: 0.8064\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.9081- ETA: 1s - loss: 0\n",
      "Epoch 00035: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2997 - acc: 0.9081 - val_loss: 0.7078 - val_acc: 0.8162\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.9121\n",
      "Epoch 00036: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2871 - acc: 0.9121 - val_loss: 0.7138 - val_acc: 0.8174\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.9141\n",
      "Epoch 00037: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2782 - acc: 0.9141 - val_loss: 0.7064 - val_acc: 0.8130\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9203\n",
      "Epoch 00038: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 831us/sample - loss: 0.2624 - acc: 0.9203 - val_loss: 0.7120 - val_acc: 0.8171\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2559 - acc: 0.9223\n",
      "Epoch 00039: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 832us/sample - loss: 0.2559 - acc: 0.9223 - val_loss: 0.7150 - val_acc: 0.8176\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9233\n",
      "Epoch 00040: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.2504 - acc: 0.9232 - val_loss: 0.7254 - val_acc: 0.8162\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.9265\n",
      "Epoch 00041: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2409 - acc: 0.9265 - val_loss: 0.7126 - val_acc: 0.8141\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2363 - acc: 0.9258\n",
      "Epoch 00042: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 830us/sample - loss: 0.2363 - acc: 0.9258 - val_loss: 0.7102 - val_acc: 0.8167\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9295\n",
      "Epoch 00043: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.2280 - acc: 0.9295 - val_loss: 0.7157 - val_acc: 0.8213\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9326\n",
      "Epoch 00044: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2202 - acc: 0.9326 - val_loss: 0.7261 - val_acc: 0.8171\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2252 - acc: 0.9287\n",
      "Epoch 00045: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.2252 - acc: 0.9287 - val_loss: 0.7248 - val_acc: 0.8183\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2066 - acc: 0.9358\n",
      "Epoch 00046: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 832us/sample - loss: 0.2066 - acc: 0.9359 - val_loss: 0.7308 - val_acc: 0.8209\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9371- ETA: 0s - loss: 0.2020 - ac\n",
      "Epoch 00047: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2026 - acc: 0.9371 - val_loss: 0.7395 - val_acc: 0.8176\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9372\n",
      "Epoch 00048: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.2001 - acc: 0.9372 - val_loss: 0.7547 - val_acc: 0.8199\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9392\n",
      "Epoch 00049: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.1952 - acc: 0.9392 - val_loss: 0.7582 - val_acc: 0.8169\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9412\n",
      "Epoch 00050: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 816us/sample - loss: 0.1862 - acc: 0.9413 - val_loss: 0.7451 - val_acc: 0.8183\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9415\n",
      "Epoch 00051: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.1862 - acc: 0.9415 - val_loss: 0.7461 - val_acc: 0.8223\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1802 - acc: 0.9431\n",
      "Epoch 00052: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.1802 - acc: 0.9431 - val_loss: 0.7425 - val_acc: 0.8211\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9426\n",
      "Epoch 00053: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.1791 - acc: 0.9426 - val_loss: 0.7608 - val_acc: 0.8178\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9441\n",
      "Epoch 00054: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1742 - acc: 0.9441 - val_loss: 0.7648 - val_acc: 0.8209\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9476\n",
      "Epoch 00055: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.1672 - acc: 0.9476 - val_loss: 0.7700 - val_acc: 0.8181\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1621 - acc: 0.9496\n",
      "Epoch 00056: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 832us/sample - loss: 0.1621 - acc: 0.9496 - val_loss: 0.7668 - val_acc: 0.8174\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1624 - acc: 0.9480\n",
      "Epoch 00057: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 830us/sample - loss: 0.1624 - acc: 0.9480 - val_loss: 0.7949 - val_acc: 0.8120\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9496\n",
      "Epoch 00058: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.1574 - acc: 0.9496 - val_loss: 0.7738 - val_acc: 0.8272\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1565 - acc: 0.9504\n",
      "Epoch 00059: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1565 - acc: 0.9504 - val_loss: 0.7819 - val_acc: 0.8213\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9545\n",
      "Epoch 00060: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 829us/sample - loss: 0.1491 - acc: 0.9545 - val_loss: 0.8013 - val_acc: 0.8253\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9554\n",
      "Epoch 00061: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1430 - acc: 0.9554 - val_loss: 0.7825 - val_acc: 0.8260\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1439 - acc: 0.9542\n",
      "Epoch 00062: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.1438 - acc: 0.9542 - val_loss: 0.7900 - val_acc: 0.8244\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9546\n",
      "Epoch 00063: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.1433 - acc: 0.9546 - val_loss: 0.8278 - val_acc: 0.8216\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9550\n",
      "Epoch 00064: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1413 - acc: 0.9550 - val_loss: 0.8036 - val_acc: 0.8279\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9565\n",
      "Epoch 00065: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1366 - acc: 0.9565 - val_loss: 0.7839 - val_acc: 0.8290\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9582\n",
      "Epoch 00066: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.1334 - acc: 0.9582 - val_loss: 0.8149 - val_acc: 0.8281\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9579\n",
      "Epoch 00067: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.1342 - acc: 0.9579 - val_loss: 0.8102 - val_acc: 0.8237\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9585\n",
      "Epoch 00068: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.1335 - acc: 0.9585 - val_loss: 0.7805 - val_acc: 0.8344\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9576\n",
      "Epoch 00069: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1300 - acc: 0.9576 - val_loss: 0.8116 - val_acc: 0.8255\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9601\n",
      "Epoch 00070: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 820us/sample - loss: 0.1260 - acc: 0.9601 - val_loss: 0.8270 - val_acc: 0.8244\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9615\n",
      "Epoch 00071: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.1241 - acc: 0.9616 - val_loss: 0.8212 - val_acc: 0.8255\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9596\n",
      "Epoch 00072: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.1274 - acc: 0.9596 - val_loss: 0.8213 - val_acc: 0.8239\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9607\n",
      "Epoch 00073: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1231 - acc: 0.9607 - val_loss: 0.8066 - val_acc: 0.8227\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9613\n",
      "Epoch 00074: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.1231 - acc: 0.9613 - val_loss: 0.8041 - val_acc: 0.8286\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9624\n",
      "Epoch 00075: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.1201 - acc: 0.9624 - val_loss: 0.8209 - val_acc: 0.8246\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9629- ETA: 0s - loss: 0.1167 - acc: 0\n",
      "Epoch 00076: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.1166 - acc: 0.9629 - val_loss: 0.8353 - val_acc: 0.8272\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9620\n",
      "Epoch 00077: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 31s 830us/sample - loss: 0.1173 - acc: 0.9620 - val_loss: 0.8375 - val_acc: 0.8251\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9635\n",
      "Epoch 00078: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 824us/sample - loss: 0.1142 - acc: 0.9635 - val_loss: 0.8304 - val_acc: 0.8239\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9655\n",
      "Epoch 00079: val_loss did not improve from 0.68535\n",
      "36805/36805 [==============================] - 30s 817us/sample - loss: 0.1128 - acc: 0.9655 - val_loss: 0.8545 - val_acc: 0.8211\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_32_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 362us/sample - loss: 0.7812 - acc: 0.7772\n",
      "Loss: 0.7812266974805672 Accuracy: 0.77715474\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1416 - acc: 0.2922\n",
      "Epoch 00001: val_loss improved from inf to 1.60438, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/001-1.6044.hdf5\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 2.1415 - acc: 0.2922 - val_loss: 1.6044 - val_acc: 0.4924\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5552 - acc: 0.5040\n",
      "Epoch 00002: val_loss improved from 1.60438 to 1.29814, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/002-1.2981.hdf5\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 1.5552 - acc: 0.5040 - val_loss: 1.2981 - val_acc: 0.6073\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2900 - acc: 0.5992\n",
      "Epoch 00003: val_loss improved from 1.29814 to 1.07450, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/003-1.0745.hdf5\n",
      "36805/36805 [==============================] - 33s 902us/sample - loss: 1.2900 - acc: 0.5992 - val_loss: 1.0745 - val_acc: 0.6823\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1064 - acc: 0.6598\n",
      "Epoch 00004: val_loss improved from 1.07450 to 0.92721, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/004-0.9272.hdf5\n",
      "36805/36805 [==============================] - 33s 902us/sample - loss: 1.1064 - acc: 0.6598 - val_loss: 0.9272 - val_acc: 0.7342\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9639 - acc: 0.7086\n",
      "Epoch 00005: val_loss improved from 0.92721 to 0.80869, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/005-0.8087.hdf5\n",
      "36805/36805 [==============================] - 33s 897us/sample - loss: 0.9638 - acc: 0.7086 - val_loss: 0.8087 - val_acc: 0.7631\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8520 - acc: 0.7437\n",
      "Epoch 00006: val_loss improved from 0.80869 to 0.76430, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/006-0.7643.hdf5\n",
      "36805/36805 [==============================] - 33s 898us/sample - loss: 0.8520 - acc: 0.7438 - val_loss: 0.7643 - val_acc: 0.7794\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.7697\n",
      "Epoch 00007: val_loss improved from 0.76430 to 0.68772, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/007-0.6877.hdf5\n",
      "36805/36805 [==============================] - 33s 902us/sample - loss: 0.7698 - acc: 0.7697 - val_loss: 0.6877 - val_acc: 0.8006\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6942 - acc: 0.7939\n",
      "Epoch 00008: val_loss improved from 0.68772 to 0.61134, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/008-0.6113.hdf5\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.6943 - acc: 0.7938 - val_loss: 0.6113 - val_acc: 0.8286\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6410 - acc: 0.8110\n",
      "Epoch 00009: val_loss improved from 0.61134 to 0.56447, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/009-0.5645.hdf5\n",
      "36805/36805 [==============================] - 33s 902us/sample - loss: 0.6410 - acc: 0.8109 - val_loss: 0.5645 - val_acc: 0.8409\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5924 - acc: 0.8229\n",
      "Epoch 00010: val_loss did not improve from 0.56447\n",
      "36805/36805 [==============================] - 33s 901us/sample - loss: 0.5924 - acc: 0.8229 - val_loss: 0.5895 - val_acc: 0.8339\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5543 - acc: 0.8368\n",
      "Epoch 00011: val_loss improved from 0.56447 to 0.52320, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/011-0.5232.hdf5\n",
      "36805/36805 [==============================] - 33s 900us/sample - loss: 0.5543 - acc: 0.8368 - val_loss: 0.5232 - val_acc: 0.8505\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5137 - acc: 0.8462\n",
      "Epoch 00012: val_loss improved from 0.52320 to 0.47123, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/012-0.4712.hdf5\n",
      "36805/36805 [==============================] - 33s 900us/sample - loss: 0.5137 - acc: 0.8462 - val_loss: 0.4712 - val_acc: 0.8705\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4876 - acc: 0.8568\n",
      "Epoch 00013: val_loss improved from 0.47123 to 0.44713, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/013-0.4471.hdf5\n",
      "36805/36805 [==============================] - 33s 905us/sample - loss: 0.4878 - acc: 0.8568 - val_loss: 0.4471 - val_acc: 0.8721\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4593 - acc: 0.8625\n",
      "Epoch 00014: val_loss improved from 0.44713 to 0.43833, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/014-0.4383.hdf5\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.4592 - acc: 0.8625 - val_loss: 0.4383 - val_acc: 0.8784\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8698\n",
      "Epoch 00015: val_loss did not improve from 0.43833\n",
      "36805/36805 [==============================] - 33s 901us/sample - loss: 0.4377 - acc: 0.8698 - val_loss: 0.4455 - val_acc: 0.8726\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8755\n",
      "Epoch 00016: val_loss improved from 0.43833 to 0.40732, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/016-0.4073.hdf5\n",
      "36805/36805 [==============================] - 33s 902us/sample - loss: 0.4126 - acc: 0.8754 - val_loss: 0.4073 - val_acc: 0.8898\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8828\n",
      "Epoch 00017: val_loss improved from 0.40732 to 0.40579, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/017-0.4058.hdf5\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.3895 - acc: 0.8827 - val_loss: 0.4058 - val_acc: 0.8859\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3701 - acc: 0.8874\n",
      "Epoch 00018: val_loss improved from 0.40579 to 0.40555, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/018-0.4055.hdf5\n",
      "36805/36805 [==============================] - 33s 897us/sample - loss: 0.3702 - acc: 0.8874 - val_loss: 0.4055 - val_acc: 0.8884\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3619 - acc: 0.8904\n",
      "Epoch 00019: val_loss improved from 0.40555 to 0.38321, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/019-0.3832.hdf5\n",
      "36805/36805 [==============================] - 33s 897us/sample - loss: 0.3619 - acc: 0.8903 - val_loss: 0.3832 - val_acc: 0.8956\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3393 - acc: 0.8972\n",
      "Epoch 00020: val_loss did not improve from 0.38321\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.3393 - acc: 0.8972 - val_loss: 0.3866 - val_acc: 0.8917\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3303 - acc: 0.8985\n",
      "Epoch 00021: val_loss improved from 0.38321 to 0.37985, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/021-0.3799.hdf5\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.3303 - acc: 0.8984 - val_loss: 0.3799 - val_acc: 0.8994\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3135 - acc: 0.9036\n",
      "Epoch 00022: val_loss did not improve from 0.37985\n",
      "36805/36805 [==============================] - 33s 898us/sample - loss: 0.3136 - acc: 0.9035 - val_loss: 0.3966 - val_acc: 0.8898\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.9054\n",
      "Epoch 00023: val_loss improved from 0.37985 to 0.37261, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/023-0.3726.hdf5\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.3107 - acc: 0.9054 - val_loss: 0.3726 - val_acc: 0.8989\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9102\n",
      "Epoch 00024: val_loss did not improve from 0.37261\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.2890 - acc: 0.9103 - val_loss: 0.3922 - val_acc: 0.8919\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.9126\n",
      "Epoch 00025: val_loss improved from 0.37261 to 0.35100, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/025-0.3510.hdf5\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.2826 - acc: 0.9126 - val_loss: 0.3510 - val_acc: 0.9038\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9167\n",
      "Epoch 00026: val_loss did not improve from 0.35100\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.2678 - acc: 0.9167 - val_loss: 0.3871 - val_acc: 0.9005\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.9175\n",
      "Epoch 00027: val_loss did not improve from 0.35100\n",
      "36805/36805 [==============================] - 33s 898us/sample - loss: 0.2638 - acc: 0.9175 - val_loss: 0.3527 - val_acc: 0.9057\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9205\n",
      "Epoch 00028: val_loss did not improve from 0.35100\n",
      "36805/36805 [==============================] - 33s 897us/sample - loss: 0.2528 - acc: 0.9205 - val_loss: 0.3564 - val_acc: 0.9068\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2475 - acc: 0.9228\n",
      "Epoch 00029: val_loss improved from 0.35100 to 0.34398, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_checkpoint/029-0.3440.hdf5\n",
      "36805/36805 [==============================] - 33s 898us/sample - loss: 0.2475 - acc: 0.9228 - val_loss: 0.3440 - val_acc: 0.9126\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9264\n",
      "Epoch 00030: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.2364 - acc: 0.9264 - val_loss: 0.3744 - val_acc: 0.9024\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9273\n",
      "Epoch 00031: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 900us/sample - loss: 0.2305 - acc: 0.9273 - val_loss: 0.3654 - val_acc: 0.9068\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9309\n",
      "Epoch 00032: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.2204 - acc: 0.9309 - val_loss: 0.3627 - val_acc: 0.9066\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9300\n",
      "Epoch 00033: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 902us/sample - loss: 0.2188 - acc: 0.9300 - val_loss: 0.3623 - val_acc: 0.9078\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9330\n",
      "Epoch 00034: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.2129 - acc: 0.9330 - val_loss: 0.3646 - val_acc: 0.9059\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9348\n",
      "Epoch 00035: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 896us/sample - loss: 0.2047 - acc: 0.9348 - val_loss: 0.3971 - val_acc: 0.9054\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9375\n",
      "Epoch 00036: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.1988 - acc: 0.9375 - val_loss: 0.3729 - val_acc: 0.9040\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9375\n",
      "Epoch 00037: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.1939 - acc: 0.9375 - val_loss: 0.3608 - val_acc: 0.9096\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9400\n",
      "Epoch 00038: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.1898 - acc: 0.9400 - val_loss: 0.3486 - val_acc: 0.9119\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9424\n",
      "Epoch 00039: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.1809 - acc: 0.9425 - val_loss: 0.3657 - val_acc: 0.9168\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9420\n",
      "Epoch 00040: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.1790 - acc: 0.9420 - val_loss: 0.3718 - val_acc: 0.9082\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9430\n",
      "Epoch 00041: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.1757 - acc: 0.9431 - val_loss: 0.3748 - val_acc: 0.9108\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9451\n",
      "Epoch 00042: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.1684 - acc: 0.9451 - val_loss: 0.3559 - val_acc: 0.9115\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9456\n",
      "Epoch 00043: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 901us/sample - loss: 0.1681 - acc: 0.9456 - val_loss: 0.3670 - val_acc: 0.9136\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9476\n",
      "Epoch 00044: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1648 - acc: 0.9476 - val_loss: 0.3533 - val_acc: 0.9199\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9498\n",
      "Epoch 00045: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1554 - acc: 0.9498 - val_loss: 0.3608 - val_acc: 0.9140\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9519\n",
      "Epoch 00046: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1521 - acc: 0.9519 - val_loss: 0.3596 - val_acc: 0.9145\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9506\n",
      "Epoch 00047: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 898us/sample - loss: 0.1545 - acc: 0.9506 - val_loss: 0.3794 - val_acc: 0.9078\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9521\n",
      "Epoch 00048: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.1506 - acc: 0.9521 - val_loss: 0.3690 - val_acc: 0.9126\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9526\n",
      "Epoch 00049: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 0.1478 - acc: 0.9526 - val_loss: 0.3606 - val_acc: 0.9159\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9550\n",
      "Epoch 00050: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.1393 - acc: 0.9550 - val_loss: 0.3724 - val_acc: 0.9173\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9546\n",
      "Epoch 00051: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.1382 - acc: 0.9546 - val_loss: 0.3900 - val_acc: 0.9131\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9572\n",
      "Epoch 00052: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.1325 - acc: 0.9572 - val_loss: 0.3773 - val_acc: 0.9152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9554\n",
      "Epoch 00053: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1343 - acc: 0.9554 - val_loss: 0.3732 - val_acc: 0.9136\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9600\n",
      "Epoch 00054: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1251 - acc: 0.9600 - val_loss: 0.3577 - val_acc: 0.9189\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9599\n",
      "Epoch 00055: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1246 - acc: 0.9598 - val_loss: 0.3849 - val_acc: 0.9159\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9577\n",
      "Epoch 00056: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1295 - acc: 0.9578 - val_loss: 0.3915 - val_acc: 0.9136\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9625\n",
      "Epoch 00057: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.1171 - acc: 0.9625 - val_loss: 0.3688 - val_acc: 0.9189\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9610\n",
      "Epoch 00058: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 32s 882us/sample - loss: 0.1206 - acc: 0.9610 - val_loss: 0.3716 - val_acc: 0.9210\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9621\n",
      "Epoch 00059: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.1167 - acc: 0.9621 - val_loss: 0.3957 - val_acc: 0.9159\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9637\n",
      "Epoch 00060: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.1120 - acc: 0.9637 - val_loss: 0.3705 - val_acc: 0.9185\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9633\n",
      "Epoch 00061: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 894us/sample - loss: 0.1099 - acc: 0.9633 - val_loss: 0.3966 - val_acc: 0.9178\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9634\n",
      "Epoch 00062: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.1121 - acc: 0.9633 - val_loss: 0.3962 - val_acc: 0.9159\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9638\n",
      "Epoch 00063: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.1110 - acc: 0.9637 - val_loss: 0.3780 - val_acc: 0.9164\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9644\n",
      "Epoch 00064: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.1100 - acc: 0.9644 - val_loss: 0.3886 - val_acc: 0.9217\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9645\n",
      "Epoch 00065: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.1090 - acc: 0.9645 - val_loss: 0.3868 - val_acc: 0.9217\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9668\n",
      "Epoch 00066: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.1012 - acc: 0.9668 - val_loss: 0.3892 - val_acc: 0.9168\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9664\n",
      "Epoch 00067: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.1008 - acc: 0.9664 - val_loss: 0.4002 - val_acc: 0.9166\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9680\n",
      "Epoch 00068: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.1000 - acc: 0.9679 - val_loss: 0.3919 - val_acc: 0.9157\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9679\n",
      "Epoch 00069: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0984 - acc: 0.9679 - val_loss: 0.4081 - val_acc: 0.9171\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9685\n",
      "Epoch 00070: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 885us/sample - loss: 0.0972 - acc: 0.9685 - val_loss: 0.4188 - val_acc: 0.9150\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9693\n",
      "Epoch 00071: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 0.0927 - acc: 0.9693 - val_loss: 0.3967 - val_acc: 0.9224\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9693\n",
      "Epoch 00072: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.0940 - acc: 0.9693 - val_loss: 0.4092 - val_acc: 0.9185\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9700\n",
      "Epoch 00073: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 888us/sample - loss: 0.0935 - acc: 0.9700 - val_loss: 0.4007 - val_acc: 0.9208\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9692\n",
      "Epoch 00074: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 893us/sample - loss: 0.0930 - acc: 0.9692 - val_loss: 0.3900 - val_acc: 0.9217\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9713\n",
      "Epoch 00075: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 895us/sample - loss: 0.0897 - acc: 0.9713 - val_loss: 0.3947 - val_acc: 0.9180\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9727\n",
      "Epoch 00076: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0844 - acc: 0.9727 - val_loss: 0.4067 - val_acc: 0.9185\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9697\n",
      "Epoch 00077: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 886us/sample - loss: 0.0894 - acc: 0.9697 - val_loss: 0.4210 - val_acc: 0.9152\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9744\n",
      "Epoch 00078: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 0.0798 - acc: 0.9744 - val_loss: 0.4143 - val_acc: 0.9152\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9717\n",
      "Epoch 00079: val_loss did not improve from 0.34398\n",
      "36805/36805 [==============================] - 33s 892us/sample - loss: 0.0868 - acc: 0.9717 - val_loss: 0.4007 - val_acc: 0.9178\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_32_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 402us/sample - loss: 0.4359 - acc: 0.8731\n",
      "Loss: 0.4358552090351703 Accuracy: 0.8731049\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1571 - acc: 0.2905\n",
      "Epoch 00001: val_loss improved from inf to 1.52204, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/001-1.5220.hdf5\n",
      "36805/36805 [==============================] - 35s 954us/sample - loss: 2.1571 - acc: 0.2904 - val_loss: 1.5220 - val_acc: 0.5420\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4703 - acc: 0.5268\n",
      "Epoch 00002: val_loss improved from 1.52204 to 1.13702, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/002-1.1370.hdf5\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 1.4703 - acc: 0.5268 - val_loss: 1.1370 - val_acc: 0.6569\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1781 - acc: 0.6273\n",
      "Epoch 00003: val_loss improved from 1.13702 to 0.88205, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/003-0.8821.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 1.1781 - acc: 0.6273 - val_loss: 0.8821 - val_acc: 0.7312\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9842 - acc: 0.6958\n",
      "Epoch 00004: val_loss improved from 0.88205 to 0.73750, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/004-0.7375.hdf5\n",
      "36805/36805 [==============================] - 34s 933us/sample - loss: 0.9842 - acc: 0.6958 - val_loss: 0.7375 - val_acc: 0.7932\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8346 - acc: 0.7425\n",
      "Epoch 00005: val_loss improved from 0.73750 to 0.67184, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/005-0.6718.hdf5\n",
      "36805/36805 [==============================] - 34s 932us/sample - loss: 0.8346 - acc: 0.7425 - val_loss: 0.6718 - val_acc: 0.8057\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7206 - acc: 0.7786\n",
      "Epoch 00006: val_loss improved from 0.67184 to 0.52762, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/006-0.5276.hdf5\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.7206 - acc: 0.7786 - val_loss: 0.5276 - val_acc: 0.8630\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6306 - acc: 0.8070\n",
      "Epoch 00007: val_loss improved from 0.52762 to 0.48480, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/007-0.4848.hdf5\n",
      "36805/36805 [==============================] - 34s 933us/sample - loss: 0.6306 - acc: 0.8070 - val_loss: 0.4848 - val_acc: 0.8679\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5610 - acc: 0.8299\n",
      "Epoch 00008: val_loss improved from 0.48480 to 0.41981, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/008-0.4198.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.5610 - acc: 0.8299 - val_loss: 0.4198 - val_acc: 0.8763\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5106 - acc: 0.8420\n",
      "Epoch 00009: val_loss improved from 0.41981 to 0.38313, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/009-0.3831.hdf5\n",
      "36805/36805 [==============================] - 34s 935us/sample - loss: 0.5106 - acc: 0.8420 - val_loss: 0.3831 - val_acc: 0.8947\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4690 - acc: 0.8552\n",
      "Epoch 00010: val_loss improved from 0.38313 to 0.37649, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/010-0.3765.hdf5\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.4689 - acc: 0.8552 - val_loss: 0.3765 - val_acc: 0.8908\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4330 - acc: 0.8690\n",
      "Epoch 00011: val_loss improved from 0.37649 to 0.33929, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/011-0.3393.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.4331 - acc: 0.8690 - val_loss: 0.3393 - val_acc: 0.9054\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8730\n",
      "Epoch 00012: val_loss improved from 0.33929 to 0.31945, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/012-0.3195.hdf5\n",
      "36805/36805 [==============================] - 34s 933us/sample - loss: 0.4057 - acc: 0.8730 - val_loss: 0.3195 - val_acc: 0.9059\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3696 - acc: 0.8845\n",
      "Epoch 00013: val_loss improved from 0.31945 to 0.28881, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/013-0.2888.hdf5\n",
      "36805/36805 [==============================] - 34s 930us/sample - loss: 0.3696 - acc: 0.8844 - val_loss: 0.2888 - val_acc: 0.9192\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8924\n",
      "Epoch 00014: val_loss did not improve from 0.28881\n",
      "36805/36805 [==============================] - 34s 935us/sample - loss: 0.3495 - acc: 0.8924 - val_loss: 0.3039 - val_acc: 0.9099\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3282 - acc: 0.8976\n",
      "Epoch 00015: val_loss improved from 0.28881 to 0.26996, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/015-0.2700.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.3283 - acc: 0.8976 - val_loss: 0.2700 - val_acc: 0.9262\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.9029\n",
      "Epoch 00016: val_loss improved from 0.26996 to 0.26443, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/016-0.2644.hdf5\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.3117 - acc: 0.9029 - val_loss: 0.2644 - val_acc: 0.9238\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2959 - acc: 0.9068\n",
      "Epoch 00017: val_loss improved from 0.26443 to 0.23520, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/017-0.2352.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.2959 - acc: 0.9069 - val_loss: 0.2352 - val_acc: 0.9364\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2758 - acc: 0.9137\n",
      "Epoch 00018: val_loss improved from 0.23520 to 0.22893, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/018-0.2289.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.2758 - acc: 0.9137 - val_loss: 0.2289 - val_acc: 0.9371\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2618 - acc: 0.9165\n",
      "Epoch 00019: val_loss did not improve from 0.22893\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.2618 - acc: 0.9166 - val_loss: 0.2481 - val_acc: 0.9311\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.9201\n",
      "Epoch 00020: val_loss did not improve from 0.22893\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.2515 - acc: 0.9201 - val_loss: 0.2330 - val_acc: 0.9334\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2410 - acc: 0.9221\n",
      "Epoch 00021: val_loss improved from 0.22893 to 0.21093, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/021-0.2109.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.2410 - acc: 0.9221 - val_loss: 0.2109 - val_acc: 0.9378\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9271\n",
      "Epoch 00022: val_loss did not improve from 0.21093\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.2308 - acc: 0.9271 - val_loss: 0.2173 - val_acc: 0.9401\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9284\n",
      "Epoch 00023: val_loss did not improve from 0.21093\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.2183 - acc: 0.9284 - val_loss: 0.2119 - val_acc: 0.9399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9306\n",
      "Epoch 00024: val_loss did not improve from 0.21093\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.2125 - acc: 0.9306 - val_loss: 0.2132 - val_acc: 0.9406\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9321\n",
      "Epoch 00025: val_loss improved from 0.21093 to 0.20507, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/025-0.2051.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.2075 - acc: 0.9321 - val_loss: 0.2051 - val_acc: 0.9432\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9354\n",
      "Epoch 00026: val_loss did not improve from 0.20507\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.1977 - acc: 0.9354 - val_loss: 0.2229 - val_acc: 0.9299\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1928 - acc: 0.9364\n",
      "Epoch 00027: val_loss improved from 0.20507 to 0.19400, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/027-0.1940.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.1928 - acc: 0.9364 - val_loss: 0.1940 - val_acc: 0.9450\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9401\n",
      "Epoch 00028: val_loss did not improve from 0.19400\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.1857 - acc: 0.9401 - val_loss: 0.2192 - val_acc: 0.9376\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9419\n",
      "Epoch 00029: val_loss did not improve from 0.19400\n",
      "36805/36805 [==============================] - 34s 932us/sample - loss: 0.1764 - acc: 0.9419 - val_loss: 0.2189 - val_acc: 0.9376\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9425\n",
      "Epoch 00030: val_loss did not improve from 0.19400\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.1739 - acc: 0.9425 - val_loss: 0.2002 - val_acc: 0.9420\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9449\n",
      "Epoch 00031: val_loss did not improve from 0.19400\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.1644 - acc: 0.9450 - val_loss: 0.2015 - val_acc: 0.9413\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9454\n",
      "Epoch 00032: val_loss did not improve from 0.19400\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.1623 - acc: 0.9454 - val_loss: 0.1985 - val_acc: 0.9457\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9448\n",
      "Epoch 00033: val_loss improved from 0.19400 to 0.19041, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/033-0.1904.hdf5\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.1619 - acc: 0.9448 - val_loss: 0.1904 - val_acc: 0.9497\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9483\n",
      "Epoch 00034: val_loss improved from 0.19041 to 0.18811, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/034-0.1881.hdf5\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.1537 - acc: 0.9483 - val_loss: 0.1881 - val_acc: 0.9453\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1481 - acc: 0.9502\n",
      "Epoch 00035: val_loss improved from 0.18811 to 0.18299, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/035-0.1830.hdf5\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.1481 - acc: 0.9502 - val_loss: 0.1830 - val_acc: 0.9506\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9498\n",
      "Epoch 00036: val_loss did not improve from 0.18299\n",
      "36805/36805 [==============================] - 34s 934us/sample - loss: 0.1460 - acc: 0.9498 - val_loss: 0.1879 - val_acc: 0.9453\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9543\n",
      "Epoch 00037: val_loss did not improve from 0.18299\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.1393 - acc: 0.9544 - val_loss: 0.1936 - val_acc: 0.9469\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9533\n",
      "Epoch 00038: val_loss did not improve from 0.18299\n",
      "36805/36805 [==============================] - 34s 936us/sample - loss: 0.1401 - acc: 0.9533 - val_loss: 0.1943 - val_acc: 0.9485\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9542\n",
      "Epoch 00039: val_loss improved from 0.18299 to 0.18157, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/039-0.1816.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.1360 - acc: 0.9542 - val_loss: 0.1816 - val_acc: 0.9502\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9573\n",
      "Epoch 00040: val_loss improved from 0.18157 to 0.18157, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_checkpoint/040-0.1816.hdf5\n",
      "36805/36805 [==============================] - 34s 934us/sample - loss: 0.1281 - acc: 0.9573 - val_loss: 0.1816 - val_acc: 0.9513\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9564\n",
      "Epoch 00041: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1280 - acc: 0.9563 - val_loss: 0.1919 - val_acc: 0.9478\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9573\n",
      "Epoch 00042: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.1257 - acc: 0.9573 - val_loss: 0.1883 - val_acc: 0.9481\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9589\n",
      "Epoch 00043: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1220 - acc: 0.9589 - val_loss: 0.2037 - val_acc: 0.9422\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9600\n",
      "Epoch 00044: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 933us/sample - loss: 0.1208 - acc: 0.9600 - val_loss: 0.1924 - val_acc: 0.9478\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9605\n",
      "Epoch 00045: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 935us/sample - loss: 0.1157 - acc: 0.9605 - val_loss: 0.1947 - val_acc: 0.9488\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9625\n",
      "Epoch 00046: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 934us/sample - loss: 0.1121 - acc: 0.9625 - val_loss: 0.1995 - val_acc: 0.9497\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9623\n",
      "Epoch 00047: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 933us/sample - loss: 0.1118 - acc: 0.9623 - val_loss: 0.1939 - val_acc: 0.9490\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9618\n",
      "Epoch 00048: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.1112 - acc: 0.9618 - val_loss: 0.1895 - val_acc: 0.9513\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9649\n",
      "Epoch 00049: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1042 - acc: 0.9648 - val_loss: 0.2064 - val_acc: 0.9446\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9632\n",
      "Epoch 00050: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.1070 - acc: 0.9632 - val_loss: 0.1841 - val_acc: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9643\n",
      "Epoch 00051: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1016 - acc: 0.9643 - val_loss: 0.1963 - val_acc: 0.9513\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9671\n",
      "Epoch 00052: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0977 - acc: 0.9671 - val_loss: 0.1904 - val_acc: 0.9511\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9662\n",
      "Epoch 00053: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.0962 - acc: 0.9662 - val_loss: 0.1847 - val_acc: 0.9534\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9670\n",
      "Epoch 00054: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0982 - acc: 0.9670 - val_loss: 0.1827 - val_acc: 0.9504\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9684\n",
      "Epoch 00055: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 934us/sample - loss: 0.0937 - acc: 0.9684 - val_loss: 0.1952 - val_acc: 0.9522\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9686\n",
      "Epoch 00056: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.0913 - acc: 0.9686 - val_loss: 0.2037 - val_acc: 0.9522\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9678\n",
      "Epoch 00057: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 932us/sample - loss: 0.0924 - acc: 0.9678 - val_loss: 0.1846 - val_acc: 0.9504\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9697\n",
      "Epoch 00058: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0877 - acc: 0.9697 - val_loss: 0.1953 - val_acc: 0.9525\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9695\n",
      "Epoch 00059: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0888 - acc: 0.9695 - val_loss: 0.2046 - val_acc: 0.9485\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9715\n",
      "Epoch 00060: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.0828 - acc: 0.9715 - val_loss: 0.2266 - val_acc: 0.9450\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9710\n",
      "Epoch 00061: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.0833 - acc: 0.9710 - val_loss: 0.2133 - val_acc: 0.9522\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9716\n",
      "Epoch 00062: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0829 - acc: 0.9716 - val_loss: 0.1989 - val_acc: 0.9509\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9734\n",
      "Epoch 00063: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0773 - acc: 0.9734 - val_loss: 0.2001 - val_acc: 0.9553\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9730\n",
      "Epoch 00064: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0795 - acc: 0.9730 - val_loss: 0.2017 - val_acc: 0.9518\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9732\n",
      "Epoch 00065: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0769 - acc: 0.9732 - val_loss: 0.1909 - val_acc: 0.9548\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9724\n",
      "Epoch 00066: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0809 - acc: 0.9724 - val_loss: 0.1989 - val_acc: 0.9525\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9737\n",
      "Epoch 00067: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 35s 939us/sample - loss: 0.0768 - acc: 0.9737 - val_loss: 0.1885 - val_acc: 0.9560\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9746\n",
      "Epoch 00068: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0745 - acc: 0.9746 - val_loss: 0.1998 - val_acc: 0.9541\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9749\n",
      "Epoch 00069: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0727 - acc: 0.9749 - val_loss: 0.2180 - val_acc: 0.9511\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9744\n",
      "Epoch 00070: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 924us/sample - loss: 0.0745 - acc: 0.9744 - val_loss: 0.1942 - val_acc: 0.9550\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9739\n",
      "Epoch 00071: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0737 - acc: 0.9739 - val_loss: 0.2056 - val_acc: 0.9529\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9755\n",
      "Epoch 00072: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 924us/sample - loss: 0.0731 - acc: 0.9755 - val_loss: 0.1986 - val_acc: 0.9543\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9764\n",
      "Epoch 00073: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0709 - acc: 0.9764 - val_loss: 0.2098 - val_acc: 0.9543\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9766\n",
      "Epoch 00074: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.0696 - acc: 0.9766 - val_loss: 0.2243 - val_acc: 0.9534\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9761\n",
      "Epoch 00075: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.0679 - acc: 0.9761 - val_loss: 0.2440 - val_acc: 0.9490\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9773\n",
      "Epoch 00076: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0654 - acc: 0.9773 - val_loss: 0.2181 - val_acc: 0.9555\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9774\n",
      "Epoch 00077: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.0646 - acc: 0.9774 - val_loss: 0.2160 - val_acc: 0.9511\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9780\n",
      "Epoch 00078: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.0635 - acc: 0.9780 - val_loss: 0.2170 - val_acc: 0.9539\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9777\n",
      "Epoch 00079: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.0657 - acc: 0.9777 - val_loss: 0.2061 - val_acc: 0.9539\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9777\n",
      "Epoch 00080: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.0632 - acc: 0.9777 - val_loss: 0.2087 - val_acc: 0.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9774\n",
      "Epoch 00081: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.0659 - acc: 0.9774 - val_loss: 0.2190 - val_acc: 0.9520\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9799\n",
      "Epoch 00082: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0584 - acc: 0.9799 - val_loss: 0.2230 - val_acc: 0.9541\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9783\n",
      "Epoch 00083: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0632 - acc: 0.9783 - val_loss: 0.2319 - val_acc: 0.9509\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9793\n",
      "Epoch 00084: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0593 - acc: 0.9793 - val_loss: 0.2148 - val_acc: 0.9509\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9796\n",
      "Epoch 00085: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0600 - acc: 0.9796 - val_loss: 0.2086 - val_acc: 0.9548\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9793\n",
      "Epoch 00086: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0587 - acc: 0.9794 - val_loss: 0.2110 - val_acc: 0.9553\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9792\n",
      "Epoch 00087: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0609 - acc: 0.9792 - val_loss: 0.2174 - val_acc: 0.9550\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9817\n",
      "Epoch 00088: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0544 - acc: 0.9817 - val_loss: 0.2080 - val_acc: 0.9557\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9812\n",
      "Epoch 00089: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0563 - acc: 0.9812 - val_loss: 0.2229 - val_acc: 0.9520\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9792\n",
      "Epoch 00090: val_loss did not improve from 0.18157\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.0600 - acc: 0.9792 - val_loss: 0.2056 - val_acc: 0.9576\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_32_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 441us/sample - loss: 0.2233 - acc: 0.9358\n",
      "Loss: 0.22331035707846114 Accuracy: 0.9358255\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1852 - acc: 0.2767\n",
      "Epoch 00001: val_loss improved from inf to 1.53534, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/001-1.5353.hdf5\n",
      "36805/36805 [==============================] - 37s 1ms/sample - loss: 2.1851 - acc: 0.2768 - val_loss: 1.5353 - val_acc: 0.5113\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3668 - acc: 0.5530\n",
      "Epoch 00002: val_loss improved from 1.53534 to 0.94214, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/002-0.9421.hdf5\n",
      "36805/36805 [==============================] - 35s 963us/sample - loss: 1.3667 - acc: 0.5530 - val_loss: 0.9421 - val_acc: 0.7130\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0095 - acc: 0.6755\n",
      "Epoch 00003: val_loss improved from 0.94214 to 0.70356, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/003-0.7036.hdf5\n",
      "36805/36805 [==============================] - 36s 975us/sample - loss: 1.0094 - acc: 0.6755 - val_loss: 0.7036 - val_acc: 0.7817\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8030 - acc: 0.7435\n",
      "Epoch 00004: val_loss improved from 0.70356 to 0.63396, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/004-0.6340.hdf5\n",
      "36805/36805 [==============================] - 36s 971us/sample - loss: 0.8030 - acc: 0.7435 - val_loss: 0.6340 - val_acc: 0.7959\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6871 - acc: 0.7820\n",
      "Epoch 00005: val_loss improved from 0.63396 to 0.51275, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/005-0.5127.hdf5\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.6871 - acc: 0.7820 - val_loss: 0.5127 - val_acc: 0.8360\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5886 - acc: 0.8122\n",
      "Epoch 00006: val_loss improved from 0.51275 to 0.40363, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/006-0.4036.hdf5\n",
      "36805/36805 [==============================] - 36s 971us/sample - loss: 0.5886 - acc: 0.8122 - val_loss: 0.4036 - val_acc: 0.8761\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5144 - acc: 0.8362\n",
      "Epoch 00007: val_loss improved from 0.40363 to 0.35115, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/007-0.3512.hdf5\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.5144 - acc: 0.8362 - val_loss: 0.3512 - val_acc: 0.8947\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8532\n",
      "Epoch 00008: val_loss improved from 0.35115 to 0.35091, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/008-0.3509.hdf5\n",
      "36805/36805 [==============================] - 36s 969us/sample - loss: 0.4598 - acc: 0.8532 - val_loss: 0.3509 - val_acc: 0.8996\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4078 - acc: 0.8712\n",
      "Epoch 00009: val_loss improved from 0.35091 to 0.29048, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/009-0.2905.hdf5\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.4078 - acc: 0.8712 - val_loss: 0.2905 - val_acc: 0.9159\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3725 - acc: 0.8812\n",
      "Epoch 00010: val_loss improved from 0.29048 to 0.26202, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/010-0.2620.hdf5\n",
      "36805/36805 [==============================] - 36s 969us/sample - loss: 0.3725 - acc: 0.8812 - val_loss: 0.2620 - val_acc: 0.9229\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8939\n",
      "Epoch 00011: val_loss improved from 0.26202 to 0.24057, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/011-0.2406.hdf5\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.3321 - acc: 0.8940 - val_loss: 0.2406 - val_acc: 0.9287\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3101 - acc: 0.9016\n",
      "Epoch 00012: val_loss improved from 0.24057 to 0.23470, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/012-0.2347.hdf5\n",
      "36805/36805 [==============================] - 36s 971us/sample - loss: 0.3101 - acc: 0.9016 - val_loss: 0.2347 - val_acc: 0.9285\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2954 - acc: 0.9070\n",
      "Epoch 00013: val_loss improved from 0.23470 to 0.21866, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/013-0.2187.hdf5\n",
      "36805/36805 [==============================] - 36s 966us/sample - loss: 0.2954 - acc: 0.9070 - val_loss: 0.2187 - val_acc: 0.9329\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9111\n",
      "Epoch 00014: val_loss did not improve from 0.21866\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.2757 - acc: 0.9111 - val_loss: 0.2268 - val_acc: 0.9285\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9158\n",
      "Epoch 00015: val_loss improved from 0.21866 to 0.21129, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/015-0.2113.hdf5\n",
      "36805/36805 [==============================] - 36s 967us/sample - loss: 0.2615 - acc: 0.9158 - val_loss: 0.2113 - val_acc: 0.9364\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9209\n",
      "Epoch 00016: val_loss did not improve from 0.21129\n",
      "36805/36805 [==============================] - 35s 963us/sample - loss: 0.2469 - acc: 0.9209 - val_loss: 0.2118 - val_acc: 0.9371\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9274\n",
      "Epoch 00017: val_loss improved from 0.21129 to 0.19106, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/017-0.1911.hdf5\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.2257 - acc: 0.9274 - val_loss: 0.1911 - val_acc: 0.9413\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9269\n",
      "Epoch 00018: val_loss did not improve from 0.19106\n",
      "36805/36805 [==============================] - 35s 961us/sample - loss: 0.2231 - acc: 0.9269 - val_loss: 0.1926 - val_acc: 0.9392\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9317\n",
      "Epoch 00019: val_loss did not improve from 0.19106\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.2080 - acc: 0.9317 - val_loss: 0.2076 - val_acc: 0.9380\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9351\n",
      "Epoch 00020: val_loss improved from 0.19106 to 0.18414, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/020-0.1841.hdf5\n",
      "36805/36805 [==============================] - 34s 924us/sample - loss: 0.1998 - acc: 0.9351 - val_loss: 0.1841 - val_acc: 0.9446\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9364\n",
      "Epoch 00021: val_loss improved from 0.18414 to 0.17999, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/021-0.1800.hdf5\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1916 - acc: 0.9364 - val_loss: 0.1800 - val_acc: 0.9469\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1812 - acc: 0.9401\n",
      "Epoch 00022: val_loss did not improve from 0.17999\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.1812 - acc: 0.9401 - val_loss: 0.1808 - val_acc: 0.9464\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9422\n",
      "Epoch 00023: val_loss did not improve from 0.17999\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.1746 - acc: 0.9422 - val_loss: 0.1957 - val_acc: 0.9436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9441\n",
      "Epoch 00024: val_loss improved from 0.17999 to 0.16746, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/024-0.1675.hdf5\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.1705 - acc: 0.9441 - val_loss: 0.1675 - val_acc: 0.9504\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9481\n",
      "Epoch 00025: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.1583 - acc: 0.9481 - val_loss: 0.1763 - val_acc: 0.9457\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9499\n",
      "Epoch 00026: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1525 - acc: 0.9499 - val_loss: 0.1717 - val_acc: 0.9497\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9501\n",
      "Epoch 00027: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.1483 - acc: 0.9501 - val_loss: 0.1745 - val_acc: 0.9511\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9518\n",
      "Epoch 00028: val_loss did not improve from 0.16746\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.1454 - acc: 0.9518 - val_loss: 0.1857 - val_acc: 0.9490\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9557\n",
      "Epoch 00029: val_loss improved from 0.16746 to 0.15766, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/029-0.1577.hdf5\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.1358 - acc: 0.9556 - val_loss: 0.1577 - val_acc: 0.9550\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9532\n",
      "Epoch 00030: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.1412 - acc: 0.9532 - val_loss: 0.1666 - val_acc: 0.9522\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9571\n",
      "Epoch 00031: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.1289 - acc: 0.9572 - val_loss: 0.1581 - val_acc: 0.9520\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9577\n",
      "Epoch 00032: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.1272 - acc: 0.9578 - val_loss: 0.1651 - val_acc: 0.9539\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9594\n",
      "Epoch 00033: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.1216 - acc: 0.9594 - val_loss: 0.1581 - val_acc: 0.9525\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9595\n",
      "Epoch 00034: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.1205 - acc: 0.9595 - val_loss: 0.1953 - val_acc: 0.9467\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9617\n",
      "Epoch 00035: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.1155 - acc: 0.9617 - val_loss: 0.1626 - val_acc: 0.9515\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9633\n",
      "Epoch 00036: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.1079 - acc: 0.9633 - val_loss: 0.1617 - val_acc: 0.9536\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9643\n",
      "Epoch 00037: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.1056 - acc: 0.9642 - val_loss: 0.1648 - val_acc: 0.9560\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9649\n",
      "Epoch 00038: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.1062 - acc: 0.9649 - val_loss: 0.1588 - val_acc: 0.9576\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9668\n",
      "Epoch 00039: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.1008 - acc: 0.9667 - val_loss: 0.1609 - val_acc: 0.9553\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9666\n",
      "Epoch 00040: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.0960 - acc: 0.9666 - val_loss: 0.1768 - val_acc: 0.9532\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9685\n",
      "Epoch 00041: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0942 - acc: 0.9685 - val_loss: 0.1717 - val_acc: 0.9525\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9687\n",
      "Epoch 00042: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0921 - acc: 0.9687 - val_loss: 0.1654 - val_acc: 0.9567\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9688\n",
      "Epoch 00043: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.0910 - acc: 0.9687 - val_loss: 0.1776 - val_acc: 0.9520\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9709\n",
      "Epoch 00044: val_loss did not improve from 0.15766\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0901 - acc: 0.9709 - val_loss: 0.1690 - val_acc: 0.9560\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9699\n",
      "Epoch 00045: val_loss improved from 0.15766 to 0.15296, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_checkpoint/045-0.1530.hdf5\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0868 - acc: 0.9699 - val_loss: 0.1530 - val_acc: 0.9592\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9715\n",
      "Epoch 00046: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0828 - acc: 0.9715 - val_loss: 0.1671 - val_acc: 0.9557\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9730\n",
      "Epoch 00047: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0772 - acc: 0.9730 - val_loss: 0.1758 - val_acc: 0.9557\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9732\n",
      "Epoch 00048: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0789 - acc: 0.9732 - val_loss: 0.1632 - val_acc: 0.9557\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9733\n",
      "Epoch 00049: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0785 - acc: 0.9733 - val_loss: 0.1590 - val_acc: 0.9578\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9722\n",
      "Epoch 00050: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0820 - acc: 0.9722 - val_loss: 0.1661 - val_acc: 0.9595\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9768\n",
      "Epoch 00051: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0696 - acc: 0.9768 - val_loss: 0.1797 - val_acc: 0.9534\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9751\n",
      "Epoch 00052: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0745 - acc: 0.9751 - val_loss: 0.1640 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9752\n",
      "Epoch 00053: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0721 - acc: 0.9752 - val_loss: 0.1933 - val_acc: 0.9553\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9762\n",
      "Epoch 00054: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 918us/sample - loss: 0.0698 - acc: 0.9762 - val_loss: 0.1810 - val_acc: 0.9539\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9764\n",
      "Epoch 00055: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0723 - acc: 0.9764 - val_loss: 0.1730 - val_acc: 0.9574\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9765\n",
      "Epoch 00056: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0700 - acc: 0.9766 - val_loss: 0.1977 - val_acc: 0.9506\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9780\n",
      "Epoch 00057: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0677 - acc: 0.9780 - val_loss: 0.1929 - val_acc: 0.9546\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9783\n",
      "Epoch 00058: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0647 - acc: 0.9783 - val_loss: 0.1858 - val_acc: 0.9567\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9789\n",
      "Epoch 00059: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0646 - acc: 0.9789 - val_loss: 0.1934 - val_acc: 0.9560\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9788\n",
      "Epoch 00060: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 916us/sample - loss: 0.0626 - acc: 0.9788 - val_loss: 0.1880 - val_acc: 0.9567\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9785\n",
      "Epoch 00061: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 927us/sample - loss: 0.0646 - acc: 0.9785 - val_loss: 0.1938 - val_acc: 0.9546\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9796\n",
      "Epoch 00062: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 916us/sample - loss: 0.0605 - acc: 0.9796 - val_loss: 0.2428 - val_acc: 0.9453\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9803\n",
      "Epoch 00063: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0593 - acc: 0.9802 - val_loss: 0.1890 - val_acc: 0.9569\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9788\n",
      "Epoch 00064: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0624 - acc: 0.9788 - val_loss: 0.1948 - val_acc: 0.9562\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9812\n",
      "Epoch 00065: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0574 - acc: 0.9812 - val_loss: 0.1898 - val_acc: 0.9576\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9806\n",
      "Epoch 00066: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.0588 - acc: 0.9806 - val_loss: 0.1872 - val_acc: 0.9583\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9811\n",
      "Epoch 00067: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0568 - acc: 0.9811 - val_loss: 0.1856 - val_acc: 0.9576\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9814\n",
      "Epoch 00068: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0552 - acc: 0.9814 - val_loss: 0.1848 - val_acc: 0.9592\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9811\n",
      "Epoch 00069: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 917us/sample - loss: 0.0558 - acc: 0.9811 - val_loss: 0.1951 - val_acc: 0.9569\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9823\n",
      "Epoch 00070: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0525 - acc: 0.9823 - val_loss: 0.1889 - val_acc: 0.9576\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9830\n",
      "Epoch 00071: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0516 - acc: 0.9830 - val_loss: 0.1956 - val_acc: 0.9599\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9830\n",
      "Epoch 00072: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 916us/sample - loss: 0.0513 - acc: 0.9830 - val_loss: 0.2010 - val_acc: 0.9557\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9816\n",
      "Epoch 00073: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.0555 - acc: 0.9816 - val_loss: 0.1960 - val_acc: 0.9560\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9822\n",
      "Epoch 00074: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 915us/sample - loss: 0.0499 - acc: 0.9822 - val_loss: 0.2059 - val_acc: 0.9578\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9827\n",
      "Epoch 00075: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0511 - acc: 0.9827 - val_loss: 0.1947 - val_acc: 0.9581\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9831\n",
      "Epoch 00076: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 918us/sample - loss: 0.0503 - acc: 0.9831 - val_loss: 0.1843 - val_acc: 0.9560\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9848\n",
      "Epoch 00077: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0474 - acc: 0.9848 - val_loss: 0.1984 - val_acc: 0.9571\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9840\n",
      "Epoch 00078: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0487 - acc: 0.9840 - val_loss: 0.1973 - val_acc: 0.9597\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9847\n",
      "Epoch 00079: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 917us/sample - loss: 0.0459 - acc: 0.9847 - val_loss: 0.1997 - val_acc: 0.9588\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9846\n",
      "Epoch 00080: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 918us/sample - loss: 0.0469 - acc: 0.9846 - val_loss: 0.1989 - val_acc: 0.9555\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9835\n",
      "Epoch 00081: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0495 - acc: 0.9835 - val_loss: 0.1878 - val_acc: 0.9597\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9855\n",
      "Epoch 00082: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.0437 - acc: 0.9855 - val_loss: 0.2051 - val_acc: 0.9588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9847\n",
      "Epoch 00083: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0460 - acc: 0.9847 - val_loss: 0.1984 - val_acc: 0.9581\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9856\n",
      "Epoch 00084: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0423 - acc: 0.9856 - val_loss: 0.1928 - val_acc: 0.9588\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9864\n",
      "Epoch 00085: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 918us/sample - loss: 0.0426 - acc: 0.9864 - val_loss: 0.1947 - val_acc: 0.9618\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9849\n",
      "Epoch 00086: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0459 - acc: 0.9849 - val_loss: 0.1922 - val_acc: 0.9599\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9867\n",
      "Epoch 00087: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 918us/sample - loss: 0.0396 - acc: 0.9867 - val_loss: 0.1930 - val_acc: 0.9613\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9862\n",
      "Epoch 00088: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0414 - acc: 0.9862 - val_loss: 0.1979 - val_acc: 0.9597\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9859\n",
      "Epoch 00089: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 916us/sample - loss: 0.0419 - acc: 0.9859 - val_loss: 0.1918 - val_acc: 0.9606\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9868\n",
      "Epoch 00090: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 919us/sample - loss: 0.0402 - acc: 0.9868 - val_loss: 0.2015 - val_acc: 0.9576\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9880\n",
      "Epoch 00091: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 917us/sample - loss: 0.0373 - acc: 0.9880 - val_loss: 0.2056 - val_acc: 0.9623\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9853\n",
      "Epoch 00092: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0443 - acc: 0.9853 - val_loss: 0.2105 - val_acc: 0.9548\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9867\n",
      "Epoch 00093: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 918us/sample - loss: 0.0390 - acc: 0.9867 - val_loss: 0.1936 - val_acc: 0.9609\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9871\n",
      "Epoch 00094: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.0373 - acc: 0.9871 - val_loss: 0.1932 - val_acc: 0.9616\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9874\n",
      "Epoch 00095: val_loss did not improve from 0.15296\n",
      "36805/36805 [==============================] - 34s 915us/sample - loss: 0.0385 - acc: 0.9874 - val_loss: 0.1990 - val_acc: 0.9578\n",
      "\n",
      "1D_CNN_6_only_conv_pool_3_ch_32_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 430us/sample - loss: 0.2374 - acc: 0.9375\n",
      "Loss: 0.23735378314339606 Accuracy: 0.937487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_32_DO'.format(i)\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_32_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_32_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                2726928   \n",
      "=================================================================\n",
      "Total params: 2,727,760\n",
      "Trainable params: 2,727,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 277us/sample - loss: 1.6095 - acc: 0.4910\n",
      "Loss: 1.6094556549504044 Accuracy: 0.49096572\n",
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_32_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                905232    \n",
      "=================================================================\n",
      "Total params: 931,696\n",
      "Trainable params: 931,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 352us/sample - loss: 1.2243 - acc: 0.6276\n",
      "Loss: 1.2243124568202415 Accuracy: 0.627622\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_32_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_24 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 18624)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18624)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                298000    \n",
      "=================================================================\n",
      "Total params: 350,096\n",
      "Trainable params: 350,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 389us/sample - loss: 0.7812 - acc: 0.7772\n",
      "Loss: 0.7812266974805672 Accuracy: 0.77715474\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_32_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_27 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 558, 64)           51264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                190480    \n",
      "=================================================================\n",
      "Total params: 293,840\n",
      "Trainable params: 293,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 418us/sample - loss: 0.4359 - acc: 0.8731\n",
      "Loss: 0.4358552090351703 Accuracy: 0.8731049\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_32_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_31 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 558, 64)           51264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 162, 64)           102464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3456)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                55312     \n",
      "=================================================================\n",
      "Total params: 261,136\n",
      "Trainable params: 261,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 434us/sample - loss: 0.2233 - acc: 0.9358\n",
      "Loss: 0.22331035707846114 Accuracy: 0.9358255\n",
      "\n",
      "1D_CNN_6_only_conv_pool_3_ch_32_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 1744, 32)          25632     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 582, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 558, 64)           51264     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 162, 64)           102464    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 54, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 30, 128)           204928    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                20496     \n",
      "=================================================================\n",
      "Total params: 431,248\n",
      "Trainable params: 431,248\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 461us/sample - loss: 0.2374 - acc: 0.9375\n",
      "Loss: 0.23735378314339606 Accuracy: 0.937487\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_32_DO'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_pool_3_ch_32_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=25, filters=32, strides=1, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=32*(2**int((i+1)/2)), strides=1))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                2726928   \n",
      "=================================================================\n",
      "Total params: 2,727,888\n",
      "Trainable params: 2,727,824\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_43 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                905232    \n",
      "=================================================================\n",
      "Total params: 931,952\n",
      "Trainable params: 931,824\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 37248)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                595984    \n",
      "=================================================================\n",
      "Total params: 674,224\n",
      "Trainable params: 673,968\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                190480    \n",
      "=================================================================\n",
      "Total params: 371,440\n",
      "Trainable params: 371,056\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                110608    \n",
      "=================================================================\n",
      "Total params: 497,008\n",
      "Trainable params: 496,368\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 30, 128)           409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 30, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                20496     \n",
      "=================================================================\n",
      "Total params: 817,136\n",
      "Trainable params: 816,240\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_32_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1413 - acc: 0.3751\n",
      "Epoch 00001: val_loss improved from inf to 1.77901, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_BN_checkpoint/001-1.7790.hdf5\n",
      "36805/36805 [==============================] - 29s 798us/sample - loss: 2.1414 - acc: 0.3751 - val_loss: 1.7790 - val_acc: 0.4661\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1800 - acc: 0.6332\n",
      "Epoch 00002: val_loss improved from 1.77901 to 1.70061, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_BN_checkpoint/002-1.7006.hdf5\n",
      "36805/36805 [==============================] - 27s 729us/sample - loss: 1.1800 - acc: 0.6332 - val_loss: 1.7006 - val_acc: 0.4969\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8344 - acc: 0.7430\n",
      "Epoch 00003: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 731us/sample - loss: 0.8345 - acc: 0.7429 - val_loss: 1.7853 - val_acc: 0.5020\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.8172\n",
      "Epoch 00004: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 730us/sample - loss: 0.6152 - acc: 0.8171 - val_loss: 1.9567 - val_acc: 0.4971\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4641 - acc: 0.8661\n",
      "Epoch 00005: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 732us/sample - loss: 0.4641 - acc: 0.8661 - val_loss: 2.0130 - val_acc: 0.5036\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3405 - acc: 0.9088\n",
      "Epoch 00006: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.3405 - acc: 0.9088 - val_loss: 2.1259 - val_acc: 0.4990\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2748 - acc: 0.9318\n",
      "Epoch 00007: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.2749 - acc: 0.9318 - val_loss: 2.3084 - val_acc: 0.4922\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9480\n",
      "Epoch 00008: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.2222 - acc: 0.9480 - val_loss: 2.4755 - val_acc: 0.4833\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9522\n",
      "Epoch 00009: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.2011 - acc: 0.9522 - val_loss: 2.6231 - val_acc: 0.4976\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9526\n",
      "Epoch 00010: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 728us/sample - loss: 0.1911 - acc: 0.9526 - val_loss: 2.8049 - val_acc: 0.4859\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9722\n",
      "Epoch 00011: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.1336 - acc: 0.9722 - val_loss: 2.8474 - val_acc: 0.4838\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9710\n",
      "Epoch 00012: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.1332 - acc: 0.9710 - val_loss: 2.8691 - val_acc: 0.4836\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9779\n",
      "Epoch 00013: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.1122 - acc: 0.9779 - val_loss: 2.9673 - val_acc: 0.4850\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9758\n",
      "Epoch 00014: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.1241 - acc: 0.9758 - val_loss: 3.1253 - val_acc: 0.4854\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9776\n",
      "Epoch 00015: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.1078 - acc: 0.9776 - val_loss: 3.0889 - val_acc: 0.4950\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9841\n",
      "Epoch 00016: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0794 - acc: 0.9841 - val_loss: 3.1697 - val_acc: 0.4934\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9865\n",
      "Epoch 00017: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.0774 - acc: 0.9866 - val_loss: 3.2412 - val_acc: 0.4969\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9863\n",
      "Epoch 00018: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0737 - acc: 0.9863 - val_loss: 3.4549 - val_acc: 0.4831\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9740\n",
      "Epoch 00019: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 727us/sample - loss: 0.1060 - acc: 0.9741 - val_loss: 3.5322 - val_acc: 0.4799\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9795\n",
      "Epoch 00020: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0959 - acc: 0.9795 - val_loss: 3.5334 - val_acc: 0.4927\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9890\n",
      "Epoch 00021: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0640 - acc: 0.9889 - val_loss: 3.4415 - val_acc: 0.4934\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9882\n",
      "Epoch 00022: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.0658 - acc: 0.9882 - val_loss: 3.6054 - val_acc: 0.4824\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9869\n",
      "Epoch 00023: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.0687 - acc: 0.9869 - val_loss: 3.7874 - val_acc: 0.4696\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9851\n",
      "Epoch 00024: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0746 - acc: 0.9851 - val_loss: 3.7111 - val_acc: 0.4864\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9916\n",
      "Epoch 00025: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.0525 - acc: 0.9916 - val_loss: 3.8998 - val_acc: 0.4740\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9909\n",
      "Epoch 00026: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 726us/sample - loss: 0.0560 - acc: 0.9909 - val_loss: 3.8169 - val_acc: 0.4822\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9893\n",
      "Epoch 00027: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 721us/sample - loss: 0.0588 - acc: 0.9893 - val_loss: 3.8859 - val_acc: 0.4903\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9925\n",
      "Epoch 00028: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 26s 720us/sample - loss: 0.0480 - acc: 0.9925 - val_loss: 3.9114 - val_acc: 0.4885\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9877\n",
      "Epoch 00029: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0598 - acc: 0.9877 - val_loss: 4.0093 - val_acc: 0.4831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9862\n",
      "Epoch 00030: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 26s 719us/sample - loss: 0.0687 - acc: 0.9863 - val_loss: 4.1212 - val_acc: 0.4757\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9907\n",
      "Epoch 00031: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0516 - acc: 0.9907 - val_loss: 4.0333 - val_acc: 0.4917\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9893\n",
      "Epoch 00032: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 720us/sample - loss: 0.0571 - acc: 0.9893 - val_loss: 4.1279 - val_acc: 0.4833\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9868\n",
      "Epoch 00033: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0690 - acc: 0.9868 - val_loss: 4.1455 - val_acc: 0.4731\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9957\n",
      "Epoch 00034: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0364 - acc: 0.9957 - val_loss: 4.1298 - val_acc: 0.4878\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9967\n",
      "Epoch 00035: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0334 - acc: 0.9967 - val_loss: 4.0445 - val_acc: 0.4882\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9903\n",
      "Epoch 00036: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 26s 719us/sample - loss: 0.0547 - acc: 0.9903 - val_loss: 4.3060 - val_acc: 0.4789\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9867\n",
      "Epoch 00037: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0650 - acc: 0.9867 - val_loss: 4.3097 - val_acc: 0.4824\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9865\n",
      "Epoch 00038: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0632 - acc: 0.9864 - val_loss: 4.3118 - val_acc: 0.4824\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9949\n",
      "Epoch 00039: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0358 - acc: 0.9949 - val_loss: 4.1783 - val_acc: 0.4871\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9957\n",
      "Epoch 00040: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 725us/sample - loss: 0.0339 - acc: 0.9957 - val_loss: 4.3151 - val_acc: 0.4768\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9942\n",
      "Epoch 00041: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0410 - acc: 0.9942 - val_loss: 4.4240 - val_acc: 0.4796\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9905\n",
      "Epoch 00042: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0522 - acc: 0.9905 - val_loss: 4.4999 - val_acc: 0.4731\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9887\n",
      "Epoch 00043: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 724us/sample - loss: 0.0584 - acc: 0.9887 - val_loss: 4.3796 - val_acc: 0.4817\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9962\n",
      "Epoch 00044: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0325 - acc: 0.9963 - val_loss: 4.4046 - val_acc: 0.4796\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9948\n",
      "Epoch 00045: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0401 - acc: 0.9948 - val_loss: 4.5397 - val_acc: 0.4612\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9930\n",
      "Epoch 00046: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0428 - acc: 0.9930 - val_loss: 4.6047 - val_acc: 0.4710\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9946\n",
      "Epoch 00047: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0366 - acc: 0.9946 - val_loss: 4.6387 - val_acc: 0.4715\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9883\n",
      "Epoch 00048: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0588 - acc: 0.9883 - val_loss: 4.7388 - val_acc: 0.4750\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9930\n",
      "Epoch 00049: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 721us/sample - loss: 0.0433 - acc: 0.9930 - val_loss: 4.4878 - val_acc: 0.4850\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9951\n",
      "Epoch 00050: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0368 - acc: 0.9951 - val_loss: 4.5799 - val_acc: 0.4768\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9981\n",
      "Epoch 00051: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 723us/sample - loss: 0.0249 - acc: 0.9981 - val_loss: 4.4817 - val_acc: 0.4875\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9984\n",
      "Epoch 00052: val_loss did not improve from 1.70061\n",
      "36805/36805 [==============================] - 27s 722us/sample - loss: 0.0238 - acc: 0.9984 - val_loss: 4.6772 - val_acc: 0.4787\n",
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_32_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 386us/sample - loss: 1.7975 - acc: 0.4629\n",
      "Loss: 1.797541138712367 Accuracy: 0.46292835\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2171 - acc: 0.4126\n",
      "Epoch 00001: val_loss improved from inf to 2.68389, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_BN_checkpoint/001-2.6839.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 2.2170 - acc: 0.4126 - val_loss: 2.6839 - val_acc: 0.3170\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1924 - acc: 0.6522\n",
      "Epoch 00002: val_loss improved from 2.68389 to 1.65701, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_BN_checkpoint/002-1.6570.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 1.1925 - acc: 0.6522 - val_loss: 1.6570 - val_acc: 0.5539\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7627 - acc: 0.7675\n",
      "Epoch 00003: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.7628 - acc: 0.7675 - val_loss: 1.7943 - val_acc: 0.5521\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.8556\n",
      "Epoch 00004: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.4755 - acc: 0.8556 - val_loss: 1.7427 - val_acc: 0.5779\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9205\n",
      "Epoch 00005: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2873 - acc: 0.9205 - val_loss: 1.6588 - val_acc: 0.6033\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9544\n",
      "Epoch 00006: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1887 - acc: 0.9544 - val_loss: 1.6971 - val_acc: 0.6063\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9775\n",
      "Epoch 00007: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1215 - acc: 0.9775 - val_loss: 1.7696 - val_acc: 0.6075\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9867\n",
      "Epoch 00008: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0869 - acc: 0.9867 - val_loss: 1.8729 - val_acc: 0.6166\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9890\n",
      "Epoch 00009: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0777 - acc: 0.9890 - val_loss: 1.9868 - val_acc: 0.5968\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9883\n",
      "Epoch 00010: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0714 - acc: 0.9883 - val_loss: 2.0645 - val_acc: 0.6005\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9877\n",
      "Epoch 00011: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0664 - acc: 0.9877 - val_loss: 2.3662 - val_acc: 0.5674\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9806\n",
      "Epoch 00012: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0840 - acc: 0.9806 - val_loss: 2.3269 - val_acc: 0.5968\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9871\n",
      "Epoch 00013: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0626 - acc: 0.9871 - val_loss: 2.2514 - val_acc: 0.6017\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9834\n",
      "Epoch 00014: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0719 - acc: 0.9833 - val_loss: 2.5892 - val_acc: 0.5733\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9717\n",
      "Epoch 00015: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1140 - acc: 0.9717 - val_loss: 2.5037 - val_acc: 0.5980\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9939\n",
      "Epoch 00016: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0379 - acc: 0.9939 - val_loss: 2.3654 - val_acc: 0.6108\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9971\n",
      "Epoch 00017: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0294 - acc: 0.9971 - val_loss: 2.3809 - val_acc: 0.6070\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9965\n",
      "Epoch 00018: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0293 - acc: 0.9965 - val_loss: 2.4171 - val_acc: 0.6077\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9952\n",
      "Epoch 00019: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0343 - acc: 0.9952 - val_loss: 2.5532 - val_acc: 0.5980\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9867\n",
      "Epoch 00020: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0572 - acc: 0.9866 - val_loss: 2.6861 - val_acc: 0.6049\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9852\n",
      "Epoch 00021: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0622 - acc: 0.9852 - val_loss: 2.9549 - val_acc: 0.5802\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9910\n",
      "Epoch 00022: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0440 - acc: 0.9910 - val_loss: 2.6570 - val_acc: 0.6089\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9940\n",
      "Epoch 00023: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0349 - acc: 0.9940 - val_loss: 2.8491 - val_acc: 0.6026\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9941\n",
      "Epoch 00024: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0338 - acc: 0.9941 - val_loss: 2.8907 - val_acc: 0.5945\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9952\n",
      "Epoch 00025: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0320 - acc: 0.9952 - val_loss: 3.0096 - val_acc: 0.5863\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9923\n",
      "Epoch 00026: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0412 - acc: 0.9923 - val_loss: 2.9169 - val_acc: 0.5921\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9940\n",
      "Epoch 00027: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0344 - acc: 0.9940 - val_loss: 2.9334 - val_acc: 0.5940\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9935\n",
      "Epoch 00028: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0351 - acc: 0.9935 - val_loss: 3.6219 - val_acc: 0.5325\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9898\n",
      "Epoch 00029: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0456 - acc: 0.9898 - val_loss: 3.0988 - val_acc: 0.5847\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9920\n",
      "Epoch 00030: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0391 - acc: 0.9920 - val_loss: 2.9436 - val_acc: 0.6112\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9966\n",
      "Epoch 00031: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0258 - acc: 0.9966 - val_loss: 2.9876 - val_acc: 0.6024\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9962\n",
      "Epoch 00032: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0280 - acc: 0.9962 - val_loss: 3.6048 - val_acc: 0.5658\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9910\n",
      "Epoch 00033: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0440 - acc: 0.9910 - val_loss: 3.1973 - val_acc: 0.5966\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9929\n",
      "Epoch 00034: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0348 - acc: 0.9929 - val_loss: 3.1383 - val_acc: 0.6052\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9951\n",
      "Epoch 00035: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0300 - acc: 0.9951 - val_loss: 3.4862 - val_acc: 0.5800\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9953\n",
      "Epoch 00036: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0302 - acc: 0.9953 - val_loss: 3.2119 - val_acc: 0.5977\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9937\n",
      "Epoch 00037: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0344 - acc: 0.9938 - val_loss: 3.2446 - val_acc: 0.5954\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9960\n",
      "Epoch 00038: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0275 - acc: 0.9960 - val_loss: 3.2557 - val_acc: 0.5928\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9922\n",
      "Epoch 00039: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0402 - acc: 0.9922 - val_loss: 3.5632 - val_acc: 0.5791\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9929\n",
      "Epoch 00040: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0368 - acc: 0.9929 - val_loss: 3.3173 - val_acc: 0.5996\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9929\n",
      "Epoch 00041: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0356 - acc: 0.9929 - val_loss: 3.2657 - val_acc: 0.5993\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9955\n",
      "Epoch 00042: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0277 - acc: 0.9955 - val_loss: 3.2758 - val_acc: 0.6131\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9953\n",
      "Epoch 00043: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0288 - acc: 0.9953 - val_loss: 3.3070 - val_acc: 0.6049\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9958\n",
      "Epoch 00044: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0288 - acc: 0.9958 - val_loss: 3.5576 - val_acc: 0.5891\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9959\n",
      "Epoch 00045: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0281 - acc: 0.9958 - val_loss: 3.3343 - val_acc: 0.5993\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9923\n",
      "Epoch 00046: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0380 - acc: 0.9923 - val_loss: 3.4823 - val_acc: 0.5935\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9959\n",
      "Epoch 00047: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0264 - acc: 0.9959 - val_loss: 3.1244 - val_acc: 0.6166\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9975\n",
      "Epoch 00048: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0220 - acc: 0.9975 - val_loss: 3.5036 - val_acc: 0.5970\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9955\n",
      "Epoch 00049: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0287 - acc: 0.9955 - val_loss: 3.8350 - val_acc: 0.5677\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9957\n",
      "Epoch 00050: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0276 - acc: 0.9957 - val_loss: 3.5577 - val_acc: 0.5879\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9969\n",
      "Epoch 00051: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0228 - acc: 0.9969 - val_loss: 3.5497 - val_acc: 0.5989\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9942\n",
      "Epoch 00052: val_loss did not improve from 1.65701\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0337 - acc: 0.9942 - val_loss: 3.7556 - val_acc: 0.5821\n",
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_32_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 520us/sample - loss: 1.7067 - acc: 0.5265\n",
      "Loss: 1.7066909554096275 Accuracy: 0.5264797\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8393 - acc: 0.4732\n",
      "Epoch 00001: val_loss improved from inf to 4.48454, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_BN_checkpoint/001-4.4845.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 1.8391 - acc: 0.4732 - val_loss: 4.4845 - val_acc: 0.2441\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0994 - acc: 0.6792\n",
      "Epoch 00002: val_loss improved from 4.48454 to 1.21671, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_BN_checkpoint/002-1.2167.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.0994 - acc: 0.6791 - val_loss: 1.2167 - val_acc: 0.6678\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8153 - acc: 0.7606\n",
      "Epoch 00003: val_loss improved from 1.21671 to 1.04461, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_BN_checkpoint/003-1.0446.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.8155 - acc: 0.7606 - val_loss: 1.0446 - val_acc: 0.7128\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.8257\n",
      "Epoch 00004: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5841 - acc: 0.8257 - val_loss: 1.0876 - val_acc: 0.7116\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4071 - acc: 0.8776\n",
      "Epoch 00005: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4072 - acc: 0.8775 - val_loss: 1.0488 - val_acc: 0.7249\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.9222\n",
      "Epoch 00006: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2685 - acc: 0.9221 - val_loss: 1.0806 - val_acc: 0.7331\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1834 - acc: 0.9524\n",
      "Epoch 00007: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1834 - acc: 0.9524 - val_loss: 1.1231 - val_acc: 0.7386\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9763\n",
      "Epoch 00008: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1075 - acc: 0.9763 - val_loss: 1.0710 - val_acc: 0.7456\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9815\n",
      "Epoch 00009: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0858 - acc: 0.9816 - val_loss: 1.0735 - val_acc: 0.7466\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9871\n",
      "Epoch 00010: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0677 - acc: 0.9871 - val_loss: 1.2111 - val_acc: 0.7312\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9872\n",
      "Epoch 00011: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0620 - acc: 0.9872 - val_loss: 1.4093 - val_acc: 0.7154\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9853\n",
      "Epoch 00012: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0661 - acc: 0.9853 - val_loss: 1.2308 - val_acc: 0.7342\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9836\n",
      "Epoch 00013: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0674 - acc: 0.9836 - val_loss: 1.3208 - val_acc: 0.7261\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9879\n",
      "Epoch 00014: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0534 - acc: 0.9879 - val_loss: 1.3017 - val_acc: 0.7475\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9867\n",
      "Epoch 00015: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0555 - acc: 0.9867 - val_loss: 1.3340 - val_acc: 0.7480\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9851\n",
      "Epoch 00016: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0588 - acc: 0.9851 - val_loss: 1.3129 - val_acc: 0.7577\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9930\n",
      "Epoch 00017: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0356 - acc: 0.9930 - val_loss: 1.3536 - val_acc: 0.7517\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9912\n",
      "Epoch 00018: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0393 - acc: 0.9912 - val_loss: 1.4674 - val_acc: 0.7421\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9914\n",
      "Epoch 00019: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0380 - acc: 0.9914 - val_loss: 1.3465 - val_acc: 0.7459\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9919\n",
      "Epoch 00020: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0376 - acc: 0.9919 - val_loss: 1.4609 - val_acc: 0.7342\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9919\n",
      "Epoch 00021: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0370 - acc: 0.9919 - val_loss: 1.5623 - val_acc: 0.7265\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9869\n",
      "Epoch 00022: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0522 - acc: 0.9869 - val_loss: 1.5350 - val_acc: 0.7314\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9951\n",
      "Epoch 00023: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0267 - acc: 0.9951 - val_loss: 1.4229 - val_acc: 0.7615\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9955\n",
      "Epoch 00024: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0256 - acc: 0.9955 - val_loss: 1.4713 - val_acc: 0.7459\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9874\n",
      "Epoch 00025: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0492 - acc: 0.9874 - val_loss: 1.6035 - val_acc: 0.7345\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9943\n",
      "Epoch 00026: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0291 - acc: 0.9943 - val_loss: 1.6454 - val_acc: 0.7242\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9960\n",
      "Epoch 00027: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0235 - acc: 0.9960 - val_loss: 1.5242 - val_acc: 0.7533\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9899\n",
      "Epoch 00028: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0431 - acc: 0.9899 - val_loss: 1.5744 - val_acc: 0.7480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9940\n",
      "Epoch 00029: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0279 - acc: 0.9940 - val_loss: 1.6215 - val_acc: 0.7487\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9942\n",
      "Epoch 00030: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0282 - acc: 0.9942 - val_loss: 1.5059 - val_acc: 0.7591\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9909\n",
      "Epoch 00031: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0373 - acc: 0.9909 - val_loss: 1.6981 - val_acc: 0.7335\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9953\n",
      "Epoch 00032: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0242 - acc: 0.9953 - val_loss: 1.6062 - val_acc: 0.7459\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9935\n",
      "Epoch 00033: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0300 - acc: 0.9935 - val_loss: 1.7935 - val_acc: 0.7321\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9949\n",
      "Epoch 00034: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0258 - acc: 0.9949 - val_loss: 1.6865 - val_acc: 0.7354\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9921\n",
      "Epoch 00035: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0353 - acc: 0.9921 - val_loss: 1.5138 - val_acc: 0.7699\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9973\n",
      "Epoch 00036: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0181 - acc: 0.9973 - val_loss: 1.4712 - val_acc: 0.7673\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9958\n",
      "Epoch 00037: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0221 - acc: 0.9958 - val_loss: 1.6340 - val_acc: 0.7505\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9911\n",
      "Epoch 00038: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0374 - acc: 0.9911 - val_loss: 1.6103 - val_acc: 0.7659\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9965\n",
      "Epoch 00039: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0204 - acc: 0.9965 - val_loss: 1.7318 - val_acc: 0.7456\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9911\n",
      "Epoch 00040: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0401 - acc: 0.9911 - val_loss: 1.6799 - val_acc: 0.7512\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9974\n",
      "Epoch 00041: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0181 - acc: 0.9974 - val_loss: 1.6148 - val_acc: 0.7584\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9973\n",
      "Epoch 00042: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0184 - acc: 0.9973 - val_loss: 1.9499 - val_acc: 0.7319\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9904\n",
      "Epoch 00043: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0399 - acc: 0.9903 - val_loss: 1.7116 - val_acc: 0.7559\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9926\n",
      "Epoch 00044: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0322 - acc: 0.9926 - val_loss: 1.7352 - val_acc: 0.7463\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9946\n",
      "Epoch 00045: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0268 - acc: 0.9946 - val_loss: 1.6263 - val_acc: 0.7682\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9946\n",
      "Epoch 00046: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0262 - acc: 0.9946 - val_loss: 1.6955 - val_acc: 0.7668\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9975\n",
      "Epoch 00047: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0173 - acc: 0.9975 - val_loss: 1.6368 - val_acc: 0.7692\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9967\n",
      "Epoch 00048: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0194 - acc: 0.9967 - val_loss: 1.7115 - val_acc: 0.7678\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9961\n",
      "Epoch 00049: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0229 - acc: 0.9960 - val_loss: 2.1448 - val_acc: 0.7191\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9921\n",
      "Epoch 00050: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0353 - acc: 0.9921 - val_loss: 1.6544 - val_acc: 0.7615\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9975\n",
      "Epoch 00051: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0177 - acc: 0.9975 - val_loss: 1.7260 - val_acc: 0.7559\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9923\n",
      "Epoch 00052: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0362 - acc: 0.9922 - val_loss: 1.8104 - val_acc: 0.7482\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9956\n",
      "Epoch 00053: val_loss did not improve from 1.04461\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0235 - acc: 0.9956 - val_loss: 1.7548 - val_acc: 0.7584\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_32_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcFNW5+P/P6Z6e7pmeYTb2zQFRdhhWUQQXgntwCxKjUbNo/MarMSQmJDFeTeKNSUw05qcxuEWMcbmigtHrloBoFCMgCLLIDsM2C8wwS/dML8/vj9M9C7MwWzMz3c/79apXdVdXV52qrn7q1KlT5xgRQSmlVPxzdHYClFJKnRga8JVSKkFowFdKqQShAV8ppRKEBnyllEoQGvCVUipBaMBXSqkEoQFfKaUShAZ8pZRKEEmdnYC6evbsKbm5uZ2dDKWU6jZWr15dJCK9WjJvlwr4ubm5rFq1qrOToZRS3YYxZndL59UiHaWUShAa8JVSKkFowFdKqQTRpcrwGxMIBMjPz8fv93d2Urolj8fDwIEDcblcnZ0UpVQn6/IBPz8/n/T0dHJzczHGdHZyuhURobi4mPz8fIYMGdLZyVFKdbIuX6Tj9/vJycnRYN8GxhhycnL06kgpBXSDgA9osG8H3XdKqahuEfCPa/9+KC3t7FQopVSXFh8B/+BBOHo0JosuKSnhkUceadN3L7roIkpKSlo8/913383999/fpnUppdTxxEfAdzggHI7JopsL+MFgsNnvvvHGG2RmZsYiWUop1Woa8I9jwYIFbN++nby8PO644w6WL1/OjBkzmDNnDqNGjQLgsssuY9KkSYwePZqFCxfWfDc3N5eioiJ27drFyJEjufHGGxk9ejTnnXcePp+v2fWuXbuWadOmMW7cOC6//HKOHDkCwEMPPcSoUaMYN24cX/3qVwF47733yMvLIy8vjwkTJlBWVhaTfaGU6t66fLXMurZuvZ3y8rUNP6isgHIHlKS0eplpaXmccsqDTX5+3333sWHDBtautetdvnw5a9asYcOGDTVVHZ988kmys7Px+XxMmTKFK6+8kpycnGPSvpXnnnuOxx57jKuuuorFixdz7bXXNrne6667jj/96U+cddZZ3HXXXdxzzz08+OCD3HfffezcuRO3211TXHT//ffz8MMPM336dMrLy/F4PK3eD0qp+BcfOXxObE2UqVOn1qvX/tBDDzF+/HimTZvG3r172bp1a4PvDBkyhLy8PAAmTZrErl27mlx+aWkpJSUlnHXWWQBcf/31rFixAoBx48ZxzTXX8Le//Y2kJHu+nj59OvPnz+ehhx6ipKSkZrpSStXVrSJDkznxLVtABEaMOCHp8Hq9Na+XL1/Ou+++y0cffURqaipnn312o/Xe3W53zWun03ncIp2mvP7666xYsYLXXnuNe++9l/Xr17NgwQIuvvhi3njjDaZPn85bb73FiBO0L5RS3Ud85PBjWIafnp7ebJl4aWkpWVlZpKamsnnzZlauXNnudWZkZJCVlcX7778PwDPPPMNZZ51FOBxm7969nHPOOfzmN7+htLSU8vJytm/fztixY/nxj3/MlClT2Lx5c7vToJSKP90qh9+kGAb8nJwcpk+fzpgxY7jwwgu5+OKL631+wQUX8OijjzJy5EiGDx/OtGnTOmS9Tz/9NDfffDOVlZUMHTqUp556ilAoxLXXXktpaSkiwm233UZmZiY///nPWbZsGQ6Hg9GjR3PhhRd2SBqUUvHFiEhnp6HG5MmT5dgOUDZt2sTIkSOb/+LOnVBWBuPGxTB13VeL9qFSqlsyxqwWkcktmVeLdJRSKkFowFdKqQQRXwG/CxVPKaVUVxM/AR80l6+UUs3QgK+UUgkiPgK+02nHGvCVUqpJ8RHwu1gOPy0trVXTlVLqRNCAr5RSCUID/nEsWLCAhx9+uOZ9tJOS8vJyZs2axcSJExk7dixLlixp8TJFhDvuuIMxY8YwduxYXnjhBQAOHDjAzJkzycvLY8yYMbz//vuEQiFuuOGGmnkfeOCBDt9GpVRiiHnTCsYYJ7AK2Ccil7RrYbffDmsbaR45FILKSkhJgda2FJmXBw823TzyvHnzuP3227nlllsAePHFF3nrrbfweDy88sor9OjRg6KiIqZNm8acOXNa1Ifsyy+/zNq1a1m3bh1FRUVMmTKFmTNn8ve//53zzz+fn/3sZ4RCISorK1m7di379u1jw4YNAK3qQUsppeo6EW3pfA/YBPSI2Rpi2FH3hAkTKCgoYP/+/RQWFpKVlcWgQYMIBAL89Kc/ZcWKFTgcDvbt28ehQ4fo27fvcZf5wQcfcPXVV+N0OunTpw9nnXUWn3zyCVOmTOGb3/wmgUCAyy67jLy8PIYOHcqOHTu49dZbufjiiznvvPNitq1KqfgW04BvjBkIXAzcC8xv9wKbyon7/bBhAwwZAsd0PNIR5s6dy0svvcTBgweZN28eAM8++yyFhYWsXr0al8tFbm5uo80it8bMmTNZsWIFr7/+OjfccAPz58/nuuuuY926dbz11ls8+uijvPjiizz55JMdsVlKqQQT6zL8B4EfAbG9mxrjm7bz5s3j+eef56WXXmLu3LmAbRa5d+/euFwuli1bxu7du1u8vBkzZvDCCy8QCoUoLCxkxYoVTJ06ld27d9OnTx9uvPFGvv3tb7NmzRqKiooIh8NceeWV/OpXv2LNmjUx2UalVPyLWQ7fGHMJUCAiq40xZzcz303ATQCDBw9u28piHPBHjx5NWVkZAwYMoF+/fgBcc801fPnLX2bs2LFMnjy5VR2OXH755Xz00UeMHz8eYwy//e1v6du3L08//TS/+93vcLlcpKWlsWjRIvbt28c3vvENwpFt+/Wvfx2TbVRKxb+YNY9sjPk18HUgCHiwZfgvi0iTHbm2uXnkcBjWrIH+/e2g6tHmkZWKX12ieWQR+YmIDBSRXOCrwL+aC/bt4nDYG7daD18ppZoUH/XwQZtIVkqp4zghXRyKyHJgeUxXogFfKaWapTl8pZRKEBrwlVIqQWjAV0qpBKEB/zhKSkp45JFH2vTdiy66SNu+UUp1GRrwj6O5gB8MBpv97htvvEFmZmaHp0kppdpCA/5xLFiwgO3bt5OXl8cdd9zB8uXLmTFjBnPmzGHUqFEAXHbZZUyaNInRo0ezcOHCmu/m5uZSVFTErl27GDlyJDfeeCOjR4/mvPPOw+fzNVjXa6+9xmmnncaECRP40pe+xKFDhwAoLy/nG9/4BmPHjmXcuHEsXrwYgDfffJOJEycyfvx4Zs2a1eHbrpSKLyekWmZHaap1ZAD8AyAUBG/rlnmc1pG577772LBhA2sjK16+fDlr1qxhw4YNDBkyBIAnn3yS7OxsfD4fU6ZM4corryTnmEbctm7dynPPPcdjjz3GVVddxeLFi7n22vrPoZ155pmsXLkSYwyPP/44v/3tb/n973/PL3/5SzIyMli/fj0AR44cobCwkBtvvJEVK1YwZMgQDh8+3LoNV0olnG4V8JtlgBg1E3GsqVOn1gR7gIceeohXXnkFgL1797J169YGAX/IkCHk5eUBMGnSJHbt2tVgufn5+cybN48DBw5QXV1ds453332X559/vma+rKwsXnvtNWbOnFkzT3Z2doduo1Iq/nSrgN9cTpz8Ijh0CCZNink6vN7ay4jly5fz7rvv8tFHH5GamsrZZ5/daDPJbre75rXT6Wy0SOfWW29l/vz5zJkzh+XLl3P33XfHJP1KqcQUX2X4Ih2ey09PT6esrKzJz0tLS8nKyiI1NZXNmzezcuXKNq+rtLSUAQMGAPD000/XTJ89e3a9bhaPHDnCtGnTWLFiBTt37gTQIh2l1HHFV8CHDr9xm5OTw/Tp0xkzZgx33HFHg88vuOACgsEgI0eOZMGCBUybNq3N67r77ruZO3cukyZNomfPnjXT77zzTo4cOcKYMWMYP348y5Yto1evXixcuJArrriC8ePH13TMopRSTYlZ88ht0ebmkQEKCmDPHhg/HlyuGKWwe9LmkZWKX12ieeQTLsadoCilVHenAV8ppRJE/AR8p9OONeArpVSj4ifgR3P4oVDnpkMppbqo+Av4msNXSqlGacBXSqkEoQE/BtLS0jo7CUop1YAGfKWUShAa8I9jwYIF9Zo1uPvuu7n//vspLy9n1qxZTJw4kbFjx7JkyZLjLqupZpQba+a4qSaRlVKqrbpV42m3v3k7aw821T4yUFYGbjckJ7d4mXl983jwgqZbZZs3bx633347t9xyCwAvvvgib731Fh6Ph1deeYUePXpQVFTEtGnTmDNnDsaYJpfVWDPK4XC40WaOG2sSWSml2qNbBfwW6eCmIiZMmEBBQQH79++nsLCQrKwsBg0aRCAQ4Kc//SkrVqzA4XCwb98+Dh06RN++fZtcVmPNKBcWFjbazHFjTSIrpVR7dKuA31xOHLC9o2Rnw+DBHbreuXPn8tJLL3Hw4MGaRsqeffZZCgsLWb16NS6Xi9zc3EabRY5qaTPKSikVK/FThg8x6+Zw3rx5PP/887z00kvMnTsXsE0Z9+7dG5fLxbJly9i9e3ezy2iqGeWmmjlurElkpZRqj/gL+DF40nb06NGUlZUxYMAA+vXrB8A111zDqlWrGDt2LIsWLWLEiBHNLqOpZpSbaua4sSaRlVKqPeKneWSAjRtt08innBKD1HVf2jyyUvErMZtHhpgV6SilVDzQgK+UUgmiWwT8Fhc7acBvoCsV2SmlOleXD/gej4fi4uKWBS4N+PWICMXFxXg8ns5OilKqC+jy9fAHDhxIfn4+hYWFx5+5uBh8Pkjq8pt1wng8HgYOHNjZyVBKdQFdPjK6XK6ap1CP6/bb4amnoLQ0tolSSqluqMsX6bSK1wuVlZ2dCqWU6pLiK+CnpkIwCNXVnZ0SpZTqcmIW8I0xHmPMf4wx64wxnxtj7onVumqkptqx5vKVUqqBWObwq4BzRWQ8kAdcYIyZFsP12SId0ICvlFKNiNlNW7H1KMsjb12RIbaVwqM5/IqKmK5GKaW6o5iW4RtjnMaYtUAB8I6IfBzL9WmRjlJKNS2mAV9EQiKSBwwEphpjxhw7jzHmJmPMKmPMqhbVtW+OFukopVSTTkgtHREpAZYBFzTy2UIRmSwik3v16tW+FWmRjlJKNSmWtXR6GWMyI69TgNnA5litD9AiHaWUakYsn7TtBzxtjHFiTywvisg/Yri+2iIdzeErpVQDsayl8xkwIVbLb5Tm8JVSqknx9aSt3rRVSqkmxVfA15u2SinVpPgK+B4PGKM5fKWUakR8BXxjbC5fA75SSjUQXwEfbMDXIh2llGogPgO+5vCVUqqB+Av42gmKUko1Kv4CvhbpKKVUo+Iv4GsOXymlGhV/AV9z+Eop1aj4DPiaw1dKqQbiL+BrkY5SSjUq/gK+FukopVSj4jPgaw5fKaUaiL+AHy3Skdj2l66UUt1N/AX81FQb7P3+zk6JUkp1KfEZ8EGLdZRS6hjxF/C1ExSllGpU/AV87QRFKaUaFX8BX3P4SinVqPgL+JrDV0qpRrUo4BtjvmeM6WGsJ4wxa4wx58U6cW2iN22VUqpRLc3hf1NEjgLnAVnA14H7Ypaq9tAiHaWUalRLA76JjC8CnhGRz+tM61q0SEcppRrV0oC/2hjzNjbgv2WMSQfCsUtWO2iRjlJKNSqphfN9C8gDdohIpTEmG/hG7JLVDlqko5RSjWppDv90YIuIlBhjrgXuBEpjl6x20CIdpZRqVEsD/p+BSmPMeOAHwHZgUcxS1R7JyZCUpDl8pZQ6RksDflBEBLgU+P9E5GEgPXbJaidtE18ppRpoaRl+mTHmJ9jqmDOMMQ7AFbtktZO2ia+UUg20NIc/D6jC1sc/CAwEfhezVLWXdnOolFINtCjgR4L8s0CGMeYSwC8iXbMMH7RIRymlGtHSphWuAv4DzAWuAj42xnwllglrFy3SUUp1lOpqmDQJ/v73zk5Ju7W0SOdnwBQRuV5ErgOmAj+PXbLaSYt0lFId5f33Yc0aWNR1CzVaqqUB3yEiBXXeF7fiuyeeFukopTrKkiV2vGJFt+86taVB+01jzFvGmBuMMTcArwNvxC5Z7aRFOkqpjiACS5dCdjb4fPDhh52donZp6U3bO4CFwLjIsFBEftzcd4wxg4wxy4wxG40xnxtjvtf+5LaQFukopTrC+vWwezfcead9oPOddzo7Re3S4mIZEVksIvMjwyst+EoQ+IGIjAKmAbcYY0a1NaGtokU6SqmOsHQpGANf+xpMmxbfAd8YU2aMOdrIUGaMOdrcd0XkgIisibwuAzYBAzou6c3QHL5SqiMsXQqnnQZ9+sDs2fbmbXFxZ6eqzZoN+CKSLiI9GhnSRaRHS1dijMkFJgAfN/LZTcaYVcaYVYWFha1Nf+NSU+3NlVCoY5anlEo8+/fDJ5/AnDn2/ezZtkz/n//s3HS1Q8xr2hhj0oDFwO2RXrPqEZGFIjJZRCb36tWrY1YabTHT5+uY5SmlYmfVKigp6exUNPSPf9hxNOBPmQIZGd26WCemAd8Y48IG+2dF5OVYrqsebRNfqe7hwAE4/XS44YbOTklDS5fC0KEwKnLrMSkJzjnHBnyRzk1bG8Us4BtjDPAEsElE/hCr9TRK28RXqnv4618hGLR13Ves6OzU1Covh3fftbl7U6c319mzba2dbds6L23tEMsc/nRs65rnGmPWRoaLYri+WtrNoVJdXzgMjz9uc/gDB8IPf2indQXvvANVVbXFOVGzZ9d+3g3FLOCLyAciYkRknIjkRYYT87CWFuko1fUtWwY7dsAtt8C999obpC+80NmpspYuhcxMOPPM+tOHDYOTTtKA31nC4QD79v2ZkpI6l4NapKNU1/fYY5CVBVdeCddeC3l58JOfdH7zBaGQvWF78cXgOqbbD2PgvPPgX/+yRVHdTLcP+MYksWPHTygoeK52ohbpKNW1FRXBK6/A178OHg84HPD739vy8T/9qXPTtnKlTd+xxTlRs2fD0aP2iqQ1QqFOr8MfBwHfkJY2jvLy9bUTtUhHxasvvrCtN3Z3ixbZZodvvLF22rnn2lz1vffagNtZli61Ofvzz2/883PPtTn91hTrrF1rH+Dq2RNmzbInu064Quj2AR/A6x1HRcVnSLSqlBbpqHh0+LANNjNnwl13dZ0bnK0lAgsX2qYKxoyp/9lvfwtlZfDLX3ZO2sAG/LPPtnXuG5OTY9vHb0nA9/lgwQKYPBn27oUf/MDW8LniClvl83/+BwoKjr+cDhIXAT8tbRyhUBl+/247QXP4Kt6IwM03w6FDcPnlNiBedpktWuhuPvgAtmypn7uPGjXKTn/kEdi69cSn7YsvYPPmpotzombPtkU/ZWVNz/Ovf8HYsfCb38D118OmTXD//bB9u83hDx8OP/sZDBpk72GcgHsXcRHwvd6xAFRUfGYnaA5fxZtnnoH//V/4xS9g8WJbzv3GGzaX/MUXnZOmJUtscF6+vHUPIj32GKSnw7x5jX9+zz22XH/BAlvuvWWL3faf/xwuvRTOOMPW8ImFpUvt+Mtfbn6+2bNtkczy5Q0/KyiAb33LFt2AbYrhiSdsE8tgH+C67DJ7hbBpE3znO7YIy+PpsM1okoh0mWHSpEnSFoHAUVm2DNm161d2QjAoAiL33NOm5Sl1woTDInv3Nj/Pjh0i6ekiM2faYztq2TKRnj1FMjJE3ngjpsls4C9/ETHGDiAybJjIffeJHDjQ/PcOHxbxeES+853m5/vVr+xyPR47BhGnU2TkSJHcXJGkJJFHHjl+OsPh+vusOVu22OWPH3/8ef1+kdRUkVtvrZ1WVmZjTlqaTeuCBSKVlS1bdzjcsvkaAaySFsbYTg/ydYe2BnwRkY8+GiobNlxVO8HtFvnxj9u8PKVOiHvusX/DG2+0AeNYgYDIGWeI9OghsmtXw8937rQByhiRhx+OeXIlHK4NxhddJFJUJLJokT0ZgQ3El18u8vbbjQexP/3JzrdqVfPrqagQ+fa3RebPF/nrX0XWrBHx+exnJSV23SDy//6fSHV14+l89VWRMWNsYP7ud21Ab0xxscj3vmfTnp4u8vLLLdsXF1wgMmKEXf8jj4j06WPTdMUVIps3t2wZHSAhA/769ZfJxx+PqJ2QlSXyX//V5uUpFXOffGJzgqNH24B98ski//53/Xl++Uv7N/3b35peTnm5yCWXiDgcNtcfK6GQDYwgcu21DQPt5s0iP/qRSO/edp6pU0X+8Y/awB8Oi4wbJzJxYvvTEgzadYHIOefYE0/Uu+/adYPIKaeIfO1rIsnJdh9/+ct2H4XDIlVVIg88YGOFw2GvOg4dankafv97u46hQ+34zDNFPvyw/dvWSgkZ8Hfs+LksW+aQYDByCTVggMg3v9nm5akEcuCAyKOP2hzb3LkiR47Efp2VlTZ3OHCgXd+KFbaowuEQ+elPbTD6+GN7Qrj66uMv7+hRkeHDbS5z//62pSkQEHnrLZH//MfmsOuqrrZBHkRuv90G/6ZUVYksXGi3B2yAf/VVkZUr7fs//7lt6WvMokU2mA8ZIvL88yLnnmvXMWiQyBNP2G0Ssb/xz39ui8BAZMIEezIAkfPOE1m/vvXr3rTJ/l6jR4u89lq7imXaIyED/qFD/yvLliFHj0YuFU89VeSrX23z8lSc27ZN5He/s8Ul0XLooUNFXC6RsWPbFjTz80Xuv9+eOJ57rvl5b7/drvOdd2qnlZbaTEo0IA0bJjJ4cMtPQOvXi6Sk2OKVaKBrjWiawO6TU04RufJKW+x0wQV2+r33tjywVVeLPPmkvXIBW7SSmmq3syN99JFI3752Hb16ifzxj7XFP8eqrBR57DF7pZGXZ+99tCdQ797d8nsEMZKQAb+iYossW4bs3/+UnZCXZy/flKorHBb5/vdrA1teng1on31mP3v7bRGv1+ZOt249/vJKSmxO8txza08c0SKNpoLjv/5lP697w6+ul1+2OVFjRJYvb932LVpkl93a+1dPPSU1ZeIvvyxy9922LHrYMJsOh8PeqG2LQEDk6adteXqs7qvl54s8/njj90HiXEIG/HA4KO+9lyJbt37fTpg+XWTWrDYvT3Wy4uLWlae2RDgscttt9rC/+WZb+6UxH38skpNjA/eaNQ0/DwREXn/dFv+43XZ5J58sctdd9sag32/LjaM3Y+vmtktKbHHDqac2LDapq6DApqMtvvMdu+4lS1o2/8qVtlhk1qzGrwzKy0UKC9uWFhVzCRnwRURWrZosn34aCfKzZ4ucfnq7lqc6yTPP2Et/sEUaV15pq/y9+64NmG1RN9jPn3/8y/hNm2xg7tGj9kboli22ql3//nY5PXvaXPrKlQ2XFw6L/Oxndr4LL7Rl7CIi119vy+XbGsxbwuez5eaZmSLbtzc/7759Iv362eKsujc+VbeRsAF/06Zvygcf9LJvLr3UltOp7sPnq82dzpxpy9jnzautBREtW54/v3Xlpq0N9lF79th62W63yGmnSU1d8EsuEVm82N6cPJ6//MV+Z8IEW3UP7M3DWNuxwwb8iRObLs/2+ex2eb1tu2mpuoSEDfh79z4oy5YhVVUH7SX1sGHtWp46gXbsEJk0yR6SP/pRw6KFoiKRN9+sval5ySW1uebmtDXY113vjBkio0aJ/OY3bbuZ+8YbNqhGa6y05ETREZYssevMzRX5wQ9slcFo7Zpw2F5tQMvrnasuKWED/uHD/5Jly5Di4rftQxv9+rVreeoEWbrU5kYzMmz1veN5+GGbax4/3ubCmxIKtS/Yd6TVq0XmzLFFRSfS4sW2SMnlsvuhf3+RW24R+eEP7fu77z6x6VEdLmEDflVVoSxbhuzZc7/9o2dktGt5qpWCQZuTHDzYlmsfTygkcuedUlMN8XjlzXW9+aYtX+/b19Ybr2vTJpGf/MSWwXeFYN8VlJTYh7euuMJW3QT7RGxz9elVt9CagJ8U+9Z6Tpzk5J4kJ/ejvPwz8A7Q1jJPpIoKuOYa26BWZqZtxvfll5tuU9zvhxtusF3affOb8PDDrWs86vzz4cMP4ZJL4Kyz4NFHbcuRixbZjimcTjvPH/5ge1Sq2xF1IsrIsL/PNdfY3+qjj2D6dNvxiEoYcfdrR9vGJzUVAgE7xIvSUvi//2tdy4QnwoEDNui+9ho89BBs3AinnGJbHHzuuYbzFxXBl75kg/1vfmM7sm5LS4GjR8PHH9uu8a6/Hm691f7ef/gD5OfD66/DV76iwf5YXq/d/ykpnZ0SdYLFXcBPSxtHRcVGwiluOyFecvkiNnd20UXw5JOdnZpa69fbnnw2b7a5+1tvhX794L334PTTbZrrdlm3daudvmqVDfg/+lH7AnLv3rbd8WeegXXr4NNP4fvfh759279tSsWZuCrSAZvDF6km4KrADTbgN9VzTXfyzDM2x9q3rw2qp53WsLegE+2tt2DuXNu2+fvvw4QJtZ9lZNjPr74abrsNCgttEcull9rP//Uv2655R/B4bAcSSqlmxWEO33aG4ncU2gnx0AnK/v3wve/BmWfC6tW1nUd09NVLefnx+9ncv9+Wl194oe1/dOhQW6xSN9hHeTy244pvfcv20DRjhu0EYuXKjgv2SqkWi7scfmrqCIxJwuc8SAZ0/yIdEbjpJqiqskU5/fvDs8/CeefZnPPjjzf93bfegs8+g2HDbJn6ySfXL7c9eNDmzN97D1assMUzycl23pEja4eBA+3nS5bYG6JglzV/vu2FKD296TQkJdkejgYPth05P/aY7RNUKXXCxV3AdzjcpKaOwEe+ndDdA/6iRbYo54EHbCAGe8Ptpz+Fe++Fc86x5eR1lZTYk8Ezz9SfbowN3sOG2Zz6li12utdrc9xXXmn316ZNNji//HL9jrJPO82u89JLbd+jLS17N8Z2uq2U6lRxF/AhUlNH3rVvunORzr59tUU5t91W/7O777Y585tvhilT4NRT7fS337bVHA8ehP/+b7jlFti1y94sjQ7bttmg/61vwcyZMHEiuFwN119VZefftcvO079/jDdYKRVLcRrwx1Lo/Lt9011z+NGinOpqeOqphvWlk5Lg73+3VRLnzYN334U777Tl6yNHwquvwuTJdt67Jt1QAAAgAElEQVRevexJobXcbntjuLNvDiulOkRcBvy0tHEcilbr7q45/EWL4I034MEHbW68MYMGwV//CnPm2Nd+P/zwh/YGaVvqtSul4lrc1dIBW6QTisa7ffs6NS1tsmuXLcqZMcNWwWzOl79sb5yefLIt4vnd7zTYK6UaFZcB3+0eQKhfJr7xvW1Zd/TmZHewbx/MmmVvdD75ZMseff/FL2wNmxkzYp8+pVS3FZcB3xiDN3082/5noM3tXnll9yjaOXTIBvvCQlulsqmiHKWUaoO4DPhgH8AqSf8CefZvtm2Xm2/uem3Q1HX4MMyeDXv22GqYU6d2doqUUnEmbgO+1zuOUKgc/4xTbLHO3/4GCxfGboWlpbbWzFe/Ct/9rn0itjXfPf98+OILWLpUi2aUUjERtwE/LW0cAOXl62x1xfPPt3XZmwrE1dWwfXvrrgIKC+GJJ2yDZr162Qegli+31SgnT7Z11//8ZxvQm1Jebr+/di289JJ9qEoppWLASBcq5pg8ebKsWrWqQ5YVCvn46KOBZGTMYOzYV22TvBMn2nbSV6+2bbr4fLasfPFi27RvaSkMGGDbiLn4Ylue7vXWLrSkBP79b9vMwPvv2zZkwmHIzbX3Ca64AqZNs+2yP/usbUZg3TrbVPPcufbhqEDAtlcTbbr53/+2zRW88IJtylcppVrBGLNaRCa3aN5YBXxjzJPAJUCBiLToyZ2ODPgAO3f+N7t3/4IpUz7H6x0F//mPfWp1+nTbrO7rr9ubuVlZtrmASZNsDv3tt6GszD54dPbZtoGwDz+07dKI2KdSJ0+2J4QrrrAPPzXWzICIbQb4scdsu/Dl5Xa6MXYZLpc9ofzhDw2bR1BKqRboKgF/JlAOLOqsgF9dXcTKlYPp3XseI0Y8ZSc+8ohtbqB3b7j8cpszP/vs+k0LVFfbHPzrr9th3z7bhvuMGbYpgqlTba69NYJBCIXsE7JOZ4dto1IqsXWJgB9JSC7wj84K+ABbt97G/v2Pctpp2/F4BtmJ27fbYhgNvO0SPXQ6s0MpEfuAcWmpPZ9G02Q7bbWPMfToAWlpzT/SEF2Oz1d7bg6F6p+n09LskJzc9AVdMGiXE21z7ti/l8tlLxyTGnnGPfp9n88uIxCwh6jTaeeP5hWMsWkKh2vTGQrZ7XO5bPpcLju/MbXbVllZO/h8dp0OR+06ouvxeGyjqikpDbc1GKy/nGDQ5n2ig9tdO7+Inae83F4wN9f6dmqqbXQ1+lsd768ZDtf+NsFg7evGhEJ2X1ZX146rq+0yHA6b3mPHjb1OTrbb5/HYsdttp4dC9fdJRYVthsrjsdvl9dpxSordrnDYfl5dbcdVVXbaSSc1v81NaU3A7/SmFYwxNwE3AQwePLjDlz9w4Hz27XuE/PwHGDbsD3biySd3+Hqac/QobNhga15WVDQ8OKLToq8rKuwfsqlzcd0/f93XjQ3hsP2zHztED3an047rvo4uN7oMY+yftbTU3saIjqPNFB07f90/a91tiAbhukNzXK7aQJKSYscej903JSW1Q0t6sTTG9smSmWnHHk9tIDp61I6bChiN7f+0NPtHjgbTuvu1JeoGEKfT/ul9vpZ/v6WSko7fxUFzjLH7KjnZpq+6uvn5HY7ai9+KirbXhPZ67T6G2tte0VtfwWDXqWHd2v3rdDZ+nPXta3sKjbVOD/gishBYCDaH39HLT0nJpXfvr7J//0JOOulOXK7sjl5FDRHYsQPWrLHF/dFh167mv+fx2AM8OkSDXGM50miAqZurqfv62MGY2tyax1Obe4seeOGwHQKB2oB1bO42HLa5r4wMe087I8MO6em1udK680fXG3Xs62OHpvZlIFCbG607zsmx5+xo8M7MtDnDaI42ukxjbNqPHq1/oiottcsaMMBuQ3To0cPum7on0+gJLBi0J4iKCjuODg5H7X6NDtEgfuz2R7cpmruL5vCCwfq/TXTsctXfr9HfWaQ2XXVz6NHfsW5uNhCof+KsewKFhsdL9ArF56u90ogG+uh36x6jTqf9vG5GJhro09Nrr4rS0+33kpMb/60rK2tPvNFxWVnt7a5oxqbu62OHaI78WNGTa/TqJ/ra4bDrDodrx9HX0aHuZ9HfK3pyj+bOj83JR690qqoaZu6qq2tP9NGx2918lxIdqdMD/okwePCPKCh4ln37HiE3984OW25VlQ3u//63vaf74Yf2YVmwB9Pw4bbSzk03wdix9ix+7J8mJaVlrScopVR7JUTAT0sbR3b2Rezb90cGDZqP09nKG651FBfDK6/Aiy/a2plVVXb6ySfbTqjOOMO2RDxqVP3OpZRSqrPFLOAbY54DzgZ6GmPygf8WkSditb7jGTz4x6xdexYHDz7FgAG3tOq7R47Y5uVffNE2Ox8M2gB/yy22lufpp9vcu1JKdWUxC/gicnWslt0WGRkz6NFjGnv33k+/ft/B4Wh+00MhWx3/scfgH/+wZaFDhsAPfgBXXWX77O7M2ilKKdVaCVGkA7YFzUGDfsznn19OYeGL9OnztUbn27XLtozw5JOQn29bTLj1VttEzuTJGuSVUt1XwgR8gJ4955CaOoI9e35L795XYyLRWwTeeQd+/3s7Btv0zoMP2v5FGqtZoJRS3U1C1Q8xxsGgQT+iomIdRUVLELG9CJ5+ug3wn38Od90FO3fC//2ffQhXg71SKl4kVA4foE+fa9mz53c89dSbvPjiHFavdnDSSfCXv8D119s6sUrFi+LKYsqqy3A5XLicrppxsjOZZGf85GZEhLLqMgCcxonT4cRpnDiMA2MMgVCAYDhIMBwkELavwxJuMK/T4cTr8tZc/cebhAv477/v4tZbV7J+fQ8GDy7hiScy+frX6zel09HCEqaiuoJAOEBYwogIYQkTFvtYZc/UnricMUxAHSJCQUUBpVWliAiC1BuXVpVSXFlMsa+Y4spiDvsOU+IvIdmZjDfZS1pyWr0hOyWbnJQcO07NISUppd6fRUSoDlVTFarCYRwd+mc6VH6Ij/I/4t97/s26Q+vISslicI/BnJR5EoMzBtcMWZ6sNq/zQNkBVuav5LDvMN5kL6muVLyuyDjZi8M4avZf9LcNSYgSfwlFlUUUVRZRWFFIUWURZdVlnJJ9ChP7TWRCvwn0S+vXZLoCoQDVoWq8yd5GP29Kqb+UFbtX8M+d/+SfO//JhoINTc6bk5JDbmYuQ7KGkJuRS25mLv3S+1FYUcie0j3sPbqXPaV72FO6hxJ/CUOzhjKi5wiG5wxneM/hjOg5gn5p/agMVFIZqKQiUEFFdQUVgQrKq8s5WnW0wdArtReT+k9iUr9J5GbmNtj+sITZfng76w6tY3PRZtxONzmpOfWOsxRXCtsOb+Pzgs/ZWLiRjUUb2Vi4kRJ/Sav2VVOGZA7huvHX8fVxX+fk7Mafyt9xZAevbHqFt3e8TVjCeF1evMnemmMjLTmNHu4eZLgzyPBk1IzdTjeHfYdrjo3o4DAO/nTRnzok/c2J2+aRj1VQAHfcAYsW2WZ0vv3t+znjjP9h+vTNJCf3bvQ7IkKxr5iCigJK/CX1hlJ/KUerjtYc5JXBygYHe1lVmR1Hch5NMRj6p/dnUMYgG6R61AarkzJP4qSMk8j0ZNb7c1RUV7Dt8Da2Hd7G1sNbOeI7UnNgZXoya4ajVUfZVLSJjYUba8at+WMkOZLIcGcQCAcory6vOUk1xe10k+5OpzpUjT/opzpU/1n8lKQU+qT1obe3N328fejj7UNOak6jfw4RwRf0URmoxBfw4Qv6KKsq49ODn/Lh3g/ZfmR7zTrH9B7D0aqj7CndQ1WoqsE29Pb2rj+k9iYnNYeeqT3pmdqTnBT7uqy6jJX5K1mZv5KP8j9iT+meFu+r5mSnZON1edl7dG/NtD7ePkzoN4FTs0/liP8IB8sP1gxFlUUIQnpyOv3T+zOgxwA7Th9AD3cPexINVlEdqq45oX526DNW7V9FSEJ4kjycOfhMzs09l75pfQmEAwRCgZqxP+hnX9k+dpXsYmfJTnaX7K6335zGyYAeA2qOwwx3BtuPbGdL0RZ2l+5u9fanJaeRnpxOUWURgXCgZp9M6jeJCX0nUOIvYd2hdawvWE9loLLFy81JyWF079GM7jWaIZlDMMYQljChcMiOJYSI1FzdJDmSSHIk4XK6MBhCEqqZPyQhqkPV9mS5458IwvRB07l+/PXMHT2XfUf38fKml3l588usPbgWgDG9x5CWnGZPeJH/f3R8vP8K2P9+VkoWQ7OG8smNn7R6v0IXajyttWIR8MNh20fJj38MZT4/l/7gTXKmvEN1uJDiwpdI844kO+scnMZJIBzgYPlBDpQfYH/Zfg6UHag5OBuT5Eiqd2aPjtPd6aQnp9PD3aN27E4n2ZmMweAwjpohLGEOlh9kz9E9NbmpvaV7GwSttOQ0Tso4iQxPBjuP7ORAef2GN9xOd4Pv1NXb25uRPUfaoddIeqb2BOwBZ4ypGfdw9yAnJYec1BxyUmwgrr25LfiD/nontSO+IxT77JVA9IqgrLoMt9ONO8ldM/YkeQiEAhRUFFBQWcCh8kMUVBRwqOIQh32HG5wYmtPH24fpg6dzxsAzOGPQGUzsNxF3krsmjQUVBbX78uheu85GhopA0/0cD+oxiNMHnc60AdM4fdDpDXKy0T94WMIYY3/T6G9rjCHTk0mv1F70TO1JVkoWSZFqwGVVZaw7tI41B9bw6cFPWXNgDTuO7CAnJYe+aX3rDZ4kDwfLD7KvbB/7y/az76gdR49Jl8OFO8ldUzwzJHMIs4bMYtbQWZw+8PSafdISYQlzqPwQB8oP0Nvbm75pfWvSfKzKQCVbi7eypXgLh8oP1bvyqftfyHBn0MPdg7TkNJwO29ZEVbCK9QXrWb1/Nav2r2L1gdWsL1hPenI64/uOZ3wfO4zrM45RvUYRklDNcRW96qwIVDA0ayije42ml7dXi7exNfKP5vPsZ8/y9Lqn2VS0qea/ajCcMegMrhh5BZePuJwhWUMa/b6IUBGooNRfSmlVac24KlhVL6OR5cmq2TdtpQE/4rPP4Kb/V83Hhe/QZ9YLVAxaQnngKOnJ6XiTvQSCpQRDPhzODMICToeTvml96Z/en35p/eif3p/+6f3p7e1NlieLTE8mGZ7aHLQnydNhaa2rbtDaXbrbjkt2s+eovbQekjmEU7JPYVj2ME7JseO05DSqglWUVpXWXIUc8R3Bm+xlZM+R5KTmxCStHcUf9Nf8KY5WHaXUb3sJS3WlkuJKseMkO85Oye6QYiF/0E9xZXHNZXWxrxiXw8XUAVMZ0GNAu5cfC2EJEwgFbOYhTsqZg+EgTuPsktsjIqw+sJrFGxdzUuZJXDr8Uvql9+vsZNWjAR9YszbElJ/9EBn3NOI5QqYnkytGXMG8MfM4J/ccXE4XgcBhPv74FNLS8hg//t0uecAppVRzulXzyLEQDMLVC94jfPqDXDjkMm6Z9m1mnzy7Qa0Elyub3Nx72LbtVoqLl9Kz56WdlGKllIq9uKyH/8c/wheOV3EZD//71b9x8akXN1kFrX//m0lNHcW2bT8gHG66DFwppbq7uAv4O3bAnT8XUia8yoWnnHfcam0ORxLDhv0Bv387+fmxrxallFKdJa4Cvgh85zvg6P8pvuS9XDbishZ9Lzv7fLKzL2b37l/i93dMNTyllOpq4irgP/20bb747JtfxWEcXHLqJS3+7rBhDwJhNm68mnAzVTGVUqq7ipuAf+gQzJ9v26fP9y7hzMFntqqObmrqME49dSFHj37Izp0d1yuWUkp1FXET8G+7zfYZedcDO/is4DMuG96y4py6+vS5mn79bmLv3t9SXPxGDFKplFKdJy4C/tKltjequ+6CDYElAFw6om1VLIcNexCvdxybNl2H35/fkclUSqlO1e0D/tGj8N3v2k7C77gDXt3yKuP6jGNo1tA2Lc/pTGH06BcJh/1s2nQ14XCwg1OslFKdo9sH/NRU2+3g449DaaCQD/Z8wKXD2/cAVWrqcIYP/wulpR+wa9ddHZRSpZTqXN3+SdukJPj+9+3rpz79B2EJt7g6ZnP69LmGkpLl7NnzazIyZpKTc0G7l6mUUp2p2+fw63p1y6sM6jGICX0ndMjyhg17CK93LJs2XUNFxecdskyllOoscRPwK6oreHv721w24rIOawTN6UxhzJhXcDjcrFv3JSort3XIcpVSqjPETcB/e/vb+IP+DinOqSsl5WTGj3+XcDjAunWz9ElcpVS3FTcBf8mWJWR5spgxeEaHL9vrHcX48W8TDJaybt0sqqoOHP9LSinVxcRFwA+Gg7z2xWtccuolMesbNj19IuPG/R9VVQdYt242gUBxTNajlFKxEhcB/4M9H3DYd7jDi3OOlZFxOmPHvobfv511684nGCyN6fqUUqojxUXAf3Xzq3iSPJx/8vkxX1dW1jmMHr2YiorPWLv2bMrL18V8nUop1RG6fcAXEV7d/Cqzh84+btv3HSUn5yLGjHmVqqr9rF49mR07fkYo5D8h61ZKqbbq9gHfF/Tx5VO/zHXjrzuh683JuYipUzfRp8+17NnzP6xaNZ6SkvdPaBqUUqo14rYT8xPp8OF3+OKLm/D7d9G//80MHXofSUkZnZ0spVQCaE0n5t0+h98VZGfPZsqUDQwcOJ/9+xfy8cfDOXDgCURCnZ00pZSqoQG/gzidXoYN+z0TJ35MSsrJbNnybVavnqLFPEqpLkMDfgfr0WMyEyZ8wMiRfycQKGLt2pl8/vlV+Hy7OjtpSqkE1+1by+yKjDH06XM1PXteyt6997Nnz30UFS0lK+scUlNH4fWOIjV1FKmpI3G5Mjs7uUqpBKEBP4aczlRyc++ib99vsmfPvRw9+jElJcsJh2urcCYn9yMl5RRSUk4mJeVkPJ7oeAhJST1wOJJbtC57810i9w3CiIQQCeNwuHE4YvP0sVKqe4lpwDfGXAD8EXACj4vIfbFcX1fl8Qzk1FP/DIBICL9/NxUVG6ms3Ehl5SZ8vm0cPvwm1dUN2+gxJgmHw4vTaQeHw004XEU47I8M9rVIdRNrNyQn9yE5eQBu9wDc7oG43QNwOFIQCdYZAogECYerEakmHK6qMw6RkjIUr3csXu9YUlOHt/hE1BHC4WqqqvKpqtpLVdV+3O4BpKXlkZTUo9XLEhH8/t0EAoWkpJyMy5UdgxQr1TXFLOAbY5zAw8BsIB/4xBizVEQ2xmqd3YExTlJShpKSMhS4pN5noVAlPt8O/P7t+P27CYXKCIUqaoZwuIJwuAqHwxPJuXtqBmOSsbvcgTFOjHEATkKhMqqq9lFdvQ+/fyelpR8QDB5uIm1JGJOMw5GMMW4cjmQcDjcARUUvIxKMzOciNXU4KSnDAalz0qmKnCACNemoTY8TMICJNF9tjvs+ECiiqmov1dWHgIbVh1NShpGWNpG0tAmkpY3D6UyLrK923eGwn4qKz6mo+Izy8s+oqFhPKHS0ZhkuV09SUoaTmmoHt3twzcnVnmC9OJ2pBIMlVFZ+gc/3Rc3Y59uKMcl4PINxuwfhdg/G4xmE2z0Qh8MDRK+8an5hgsFSAoHDBIOHa8ahUGXkpNwPt7t/zdjpzCAcroz8/uU1x4BIqN5vHx3C4aqa5QYCxQSDhwkGj+B0ZpCSMgSPZwgez1A8nlycTk+D/RkOBwmHK6iqysfv30tV1R78/j1UVe0hGDyC2z0osowhNctzOFLx+bZF9suWmv0jEsLrHYXXO5rU1NF4vaNwuwc12XR5OFxFZeVWKis31mSGfL5tGJNEUlIGTmcGSUm1Q/R3cThSI79VKg5HSuT4cdQ7nhwON0lJmSQlZZGUlInD0bKwJyKIBCLHdxWBQBHV1QfrDcFgMS5XH1JShuLx2P+12z0AY5yEwwH8/l2R/WOHQKCI5OTeJCf3JTm5X2Qcfd2rRelqj5jVwzfGnA7cLSLnR97/BEBEft3Ud7prPfzuJhTyIVIdCfB2sIGy6X4EwuFqKiu3UFGxnoqK9ZSXr6/5Q9aefNw4HG6McSESprZoKVrMFMYG7mjxkzT7PikpOxJkogF1EG53P/z+PZSXr6Gs7FPKy9fg9+887jY7nRmkpY3F6x1HWto4XK4+kT/hFiorbbAKBA61YO8Z3O7BpKaeSkrKMEQCkaC4F79/D+FwRQuWAeDE5comKSkbpzOF6uoCqqsPAuEWfr8FKTVuXK4sgsGSesWIAC5XH4xx1LtabHzdTtzuASQlZVJVtZdg8Eiz60xO7k9q6qmAg8rKjZFtiizJmY7LlVPnJBgdhyMt0EarMZtIEeepQJhgsLRmCIVKCYXKW70v6m2RM52kpKxGrnKjQ+0VbnOMScblyqa6urBO2m2GyOXqFcmo1E53OtNwuXoRCBQ22IakpGzOPLNtDTK2ph5+LIt0BgB767zPB06L4fpUCzmdKUBKq77jcCSTljaWtLSxsUlUK3i9o8nJubDmfSBwhMrKjZE/afREEwZCGJNEaurIZnOXtcspobr6QE1Ouu7VldOZFrmqGRbZfw2JCMFgCVVV+yJXOVF2vcaYSE4zG6czrUF6REJUVxdSXb2f6uoDBIOlda4y0mquOmzuMRqofYTDfkIhHw6HG5crh6SkbFyunJp0ioSprj6E378zcgW5k6oq26+DvTqse8JOwe0eEDnJDiY5uV+9HHEwWIrPtxO/3w6hUAUpKcMi++YUkpLSj9mnxVRUbKSi4nMqKzfWaXCwdp8AuN2DSE0didc7ipSUU5vcx9HtCYUqI79RZeT3qiQc9kVOJjZjEc1A2CufIzWDvbI6QjjsxxhXZIhmfpx1rnCjGZjkyL7tWSdH3pekpEyMMYTDwcgJfwc+3w58vu0EAodwuweRkjIsMpyMy9W7ZnuDwXICgUNUVR2guvpggxNyrMQyh/8V4AIR+Xbk/deB00Tkv46Z7ybgJoDBgwdP2r17d0zSo5RS8airPGm7DxhU5/3AyLR6RGShiEwWkcm9esW+DEsppRJVLAP+J8Apxpghxphk4KvA0hiuTymlVDNiVoYvIkFjzH8Bb2GrZT4pIp/Han1KKaWaF9N6+CLyBvBGLNehlFKqZbQtHaWUShAa8JVSKkFowFdKqQShAV8ppRJEl+ri0BhTCLT1yaueQFEHJqerSpTthMTZ1kTZTkicbT2R23mSiLToIaYuFfDbwxizqqVPm3VnibKdkDjbmijbCYmzrV11O7VIRymlEoQGfKWUShDxFPAXdnYCTpBE2U5InG1NlO2ExNnWLrmdcVOGr5RSqnnxlMNXSinVjG4f8I0xFxhjthhjthljFnR2ejqSMeZJY0yBMWZDnWnZxph3jDFbI+OszkxjRzDGDDLGLDPGbDTGfG6M+V5kejxuq8cY8x9jzLrItt4TmT7EGPNx5Dh+IdLCbLdnjHEaYz41xvwj8j5et3OXMWa9MWatMWZVZFqXO367dcCv02/uhcAo4GpjzKjOTVWH+itwwTHTFgD/FJFTgH9G3nd3QeAHIjIKmAbcEvkd43Fbq4BzRWQ8kAdcYIyZBvwGeEBEhgFHgG91Yho70veATXXex+t2ApwjInl1qmN2ueO3Wwd8YCqwTUR2iO2A8nng0k5OU4cRkRXAsT2OXwo8HXn9NHDZCU1UDIjIARFZE3ldhg0QA4jPbRURiXZo6ooMApwLvBSZHhfbaowZCFwMPB55b4jD7WxGlzt+u3vAb6zf3AGdlJYTpY+IHIi8Pgj06czEdDRjTC4wAfiYON3WSDHHWqAAeAfYDpSISDAyS7wcxw8CP6K2d/Qc4nM7wZ603zbGrI502wpd8PiNaXv4KrZERIwxcVPNyhiTBiwGbheRo3U7+Y6nbRWREJBnjMkEXgFGdHKSOpwx5hKgQERWG2PO7uz0nABnisg+Y0xv4B1jzOa6H3aV47e75/Bb1G9unDlkjOkHEBkXdHJ6OoQxxoUN9s+KyMuRyXG5rVEiUgIsA04HMo0x0QxYPBzH04E5xphd2KLWc4E/En/bCYCI7IuMC7An8al0weO3uwf8ROw3dylwfeT19cCSTkxLh4iU7T4BbBKRP9T5KB63tVckZ48xJgWYjb1nsQz4SmS2br+tIvITERkoIrnY/+W/ROQa4mw7AYwxXmNMevQ1cB6wgS54/Hb7B6+MMRdhywqj/ebe28lJ6jDGmOeAs7Et7x0C/ht4FXgRGIxtWfQqETn2xm63Yow5E3gfWE9tee9PseX48bat47A38JzYDNeLIvILY8xQbE44G/gUuFZEqjovpR0nUqTzQxG5JB63M7JNr0TeJgF/F5F7jTE5dLHjt9sHfKWUUi3T3Yt0lFJKtZAGfKWUShAa8JVSKkFowFdKqQShAV8ppRKEBnylOoAx5uxoi5BKdVUa8JVSKkFowFcJxRhzbaQ9+rXGmL9EGjIrN8Y8EGmf/p/GmF6RefOMMSuNMZ8ZY16JtmdujBlmjHk30qb9GmPMyZHFpxljXjLGbDbGPGvqNgakVBegAV8lDGPMSGAeMF1E8oAQcA3gBVaJyGjgPewTzQCLgB+LyDjsU8DR6c8CD0fatD8DiLaIOAG4Hds3w1BsezJKdRnaWqZKJLOAScAnkcx3CrZBqzDwQmSevwEvG2MygEwReS8y/WngfyNtpgwQkVcARMQPEFnef0QkP/J+LZALfBD7zVKqZTTgq0RigKdF5Cf1Jhrz82Pma2t7I3XbhAmh/y/VxWiRjkok/wS+EmmzPNrn6EnY/0G0BcevAR+ISClwxBgzIzL968B7kR658o0xl0WW4TbGpJ7QrVCqjTQHohKGiGw0xtyJ7ZnIAQSAW4AKYGrkswJsOT/YJm0fjQT0HcA3ItO/DvzFGPOLyDLmnsDNUKrNtLVMlfCMMeUiktbZ6VAq1rRIRymlEoTm8JVSKkFoDl8ppRKEBnyllEoQGvCVUipBaMBXSqkEoQFfKaUShAZ8pZRKEP8/1q2ZZPEAAAADSURBVPOLdbZQRxgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 601us/sample - loss: 1.1312 - acc: 0.6856\n",
      "Loss: 1.1312228388504075 Accuracy: 0.68556595\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6385 - acc: 0.4965\n",
      "Epoch 00001: val_loss improved from inf to 10.06618, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/001-10.0662.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 1.6384 - acc: 0.4966 - val_loss: 10.0662 - val_acc: 0.1058\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9465 - acc: 0.7163\n",
      "Epoch 00002: val_loss improved from 10.06618 to 0.95020, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/002-0.9502.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.9464 - acc: 0.7163 - val_loss: 0.9502 - val_acc: 0.7221\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6786 - acc: 0.8017\n",
      "Epoch 00003: val_loss improved from 0.95020 to 0.82882, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/003-0.8288.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.6785 - acc: 0.8017 - val_loss: 0.8288 - val_acc: 0.7598\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4999 - acc: 0.8550\n",
      "Epoch 00004: val_loss improved from 0.82882 to 0.57846, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/004-0.5785.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.4998 - acc: 0.8550 - val_loss: 0.5785 - val_acc: 0.8421\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3775 - acc: 0.8899\n",
      "Epoch 00005: val_loss improved from 0.57846 to 0.51636, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/005-0.5164.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3775 - acc: 0.8899 - val_loss: 0.5164 - val_acc: 0.8570\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2929 - acc: 0.9156\n",
      "Epoch 00006: val_loss improved from 0.51636 to 0.51174, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/006-0.5117.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2929 - acc: 0.9156 - val_loss: 0.5117 - val_acc: 0.8512\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9379\n",
      "Epoch 00007: val_loss did not improve from 0.51174\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2162 - acc: 0.9379 - val_loss: 0.5700 - val_acc: 0.8486\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9547\n",
      "Epoch 00008: val_loss improved from 0.51174 to 0.49497, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_BN_checkpoint/008-0.4950.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1610 - acc: 0.9547 - val_loss: 0.4950 - val_acc: 0.8649\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9728\n",
      "Epoch 00009: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1111 - acc: 0.9727 - val_loss: 0.5668 - val_acc: 0.8491\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9697\n",
      "Epoch 00010: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1118 - acc: 0.9697 - val_loss: 0.5207 - val_acc: 0.8633\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9873\n",
      "Epoch 00011: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0601 - acc: 0.9873 - val_loss: 0.6162 - val_acc: 0.8509\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9915\n",
      "Epoch 00012: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0451 - acc: 0.9915 - val_loss: 0.5248 - val_acc: 0.8686\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9896\n",
      "Epoch 00013: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0479 - acc: 0.9896 - val_loss: 0.5468 - val_acc: 0.8677\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9923\n",
      "Epoch 00014: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0376 - acc: 0.9923 - val_loss: 0.7055 - val_acc: 0.8304\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9927\n",
      "Epoch 00015: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0353 - acc: 0.9927 - val_loss: 0.5486 - val_acc: 0.8656\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9903\n",
      "Epoch 00016: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0397 - acc: 0.9903 - val_loss: 0.6137 - val_acc: 0.8579\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9921\n",
      "Epoch 00017: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0341 - acc: 0.9921 - val_loss: 0.6259 - val_acc: 0.8675\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9916\n",
      "Epoch 00018: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0347 - acc: 0.9916 - val_loss: 0.6437 - val_acc: 0.8551\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9939\n",
      "Epoch 00019: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0277 - acc: 0.9939 - val_loss: 0.5572 - val_acc: 0.8814\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9971\n",
      "Epoch 00020: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0145 - acc: 0.9971 - val_loss: 0.6835 - val_acc: 0.8556\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9952\n",
      "Epoch 00021: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0195 - acc: 0.9951 - val_loss: 0.6958 - val_acc: 0.8579\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9898\n",
      "Epoch 00022: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0349 - acc: 0.9898 - val_loss: 0.5787 - val_acc: 0.8849\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9939\n",
      "Epoch 00023: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0257 - acc: 0.9939 - val_loss: 0.6286 - val_acc: 0.8791\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9960\n",
      "Epoch 00024: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0170 - acc: 0.9960 - val_loss: 0.6421 - val_acc: 0.8719\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9939\n",
      "Epoch 00025: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0238 - acc: 0.9939 - val_loss: 0.6145 - val_acc: 0.8791\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9973\n",
      "Epoch 00026: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0142 - acc: 0.9973 - val_loss: 0.6262 - val_acc: 0.8833\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9985\n",
      "Epoch 00027: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0079 - acc: 0.9985 - val_loss: 0.6208 - val_acc: 0.8710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9927\n",
      "Epoch 00028: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0269 - acc: 0.9926 - val_loss: 0.6608 - val_acc: 0.8598\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9923\n",
      "Epoch 00029: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0290 - acc: 0.9923 - val_loss: 0.8369 - val_acc: 0.8365\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9968\n",
      "Epoch 00030: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0133 - acc: 0.9968 - val_loss: 0.7658 - val_acc: 0.8544\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9950\n",
      "Epoch 00031: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0193 - acc: 0.9950 - val_loss: 0.6728 - val_acc: 0.8705\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9985\n",
      "Epoch 00032: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0078 - acc: 0.9985 - val_loss: 0.6995 - val_acc: 0.8721\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9988\n",
      "Epoch 00033: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0073 - acc: 0.9988 - val_loss: 0.6362 - val_acc: 0.8828\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9975\n",
      "Epoch 00034: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0108 - acc: 0.9975 - val_loss: 0.7203 - val_acc: 0.8696\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9935\n",
      "Epoch 00035: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0228 - acc: 0.9935 - val_loss: 0.7434 - val_acc: 0.8623\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9952\n",
      "Epoch 00036: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0171 - acc: 0.9952 - val_loss: 0.7428 - val_acc: 0.8684\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9973\n",
      "Epoch 00037: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0113 - acc: 0.9973 - val_loss: 0.6091 - val_acc: 0.8849\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9982\n",
      "Epoch 00038: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0072 - acc: 0.9982 - val_loss: 0.6185 - val_acc: 0.8828\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9979\n",
      "Epoch 00039: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0093 - acc: 0.9979 - val_loss: 0.7403 - val_acc: 0.8619\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9945\n",
      "Epoch 00040: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0191 - acc: 0.9945 - val_loss: 0.6911 - val_acc: 0.8735\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9968\n",
      "Epoch 00041: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0121 - acc: 0.9968 - val_loss: 0.5899 - val_acc: 0.8868\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 00042: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0056 - acc: 0.9989 - val_loss: 0.6477 - val_acc: 0.8814\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9954\n",
      "Epoch 00043: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0178 - acc: 0.9954 - val_loss: 0.7579 - val_acc: 0.8658\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0162 - acc: 0.9956 - val_loss: 0.7238 - val_acc: 0.8828\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9987\n",
      "Epoch 00045: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0067 - acc: 0.9987 - val_loss: 0.6016 - val_acc: 0.8910\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 00046: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0080 - acc: 0.9981 - val_loss: 0.8295 - val_acc: 0.8507\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9930\n",
      "Epoch 00047: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0249 - acc: 0.9930 - val_loss: 0.6721 - val_acc: 0.8838\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9981\n",
      "Epoch 00048: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0078 - acc: 0.9981 - val_loss: 0.6542 - val_acc: 0.8901\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9984\n",
      "Epoch 00049: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0071 - acc: 0.9984 - val_loss: 0.6170 - val_acc: 0.8901\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9991\n",
      "Epoch 00050: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0048 - acc: 0.9991 - val_loss: 0.6191 - val_acc: 0.8977\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9956\n",
      "Epoch 00051: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0161 - acc: 0.9956 - val_loss: 0.7153 - val_acc: 0.8786\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9970\n",
      "Epoch 00052: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0102 - acc: 0.9969 - val_loss: 0.7863 - val_acc: 0.8542\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9932\n",
      "Epoch 00053: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0239 - acc: 0.9932 - val_loss: 0.6649 - val_acc: 0.8896\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 00054: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0031 - acc: 0.9996 - val_loss: 0.6215 - val_acc: 0.8984\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 00055: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0032 - acc: 0.9996 - val_loss: 0.6129 - val_acc: 0.8994\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9945\n",
      "Epoch 00056: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0185 - acc: 0.9945 - val_loss: 0.7580 - val_acc: 0.8698\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9971\n",
      "Epoch 00057: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0112 - acc: 0.9971 - val_loss: 0.6926 - val_acc: 0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9992\n",
      "Epoch 00058: val_loss did not improve from 0.49497\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0041 - acc: 0.9992 - val_loss: 0.6372 - val_acc: 0.8917\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_32_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 658us/sample - loss: 0.5865 - acc: 0.8355\n",
      "Loss: 0.5865089924659809 Accuracy: 0.835514\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4487 - acc: 0.5533\n",
      "Epoch 00001: val_loss improved from inf to 2.22242, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/001-2.2224.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 1.4486 - acc: 0.5533 - val_loss: 2.2224 - val_acc: 0.3946\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6899 - acc: 0.7938\n",
      "Epoch 00002: val_loss improved from 2.22242 to 0.66348, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/002-0.6635.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.6899 - acc: 0.7938 - val_loss: 0.6635 - val_acc: 0.8083\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8677\n",
      "Epoch 00003: val_loss improved from 0.66348 to 0.48569, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/003-0.4857.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.4461 - acc: 0.8677 - val_loss: 0.4857 - val_acc: 0.8593\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.9050\n",
      "Epoch 00004: val_loss improved from 0.48569 to 0.38029, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/004-0.3803.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.3243 - acc: 0.9050 - val_loss: 0.3803 - val_acc: 0.8847\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2499 - acc: 0.9254\n",
      "Epoch 00005: val_loss improved from 0.38029 to 0.33846, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/005-0.3385.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2500 - acc: 0.9254 - val_loss: 0.3385 - val_acc: 0.8984\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9415\n",
      "Epoch 00006: val_loss improved from 0.33846 to 0.30391, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/006-0.3039.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1955 - acc: 0.9415 - val_loss: 0.3039 - val_acc: 0.9096\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9581\n",
      "Epoch 00007: val_loss did not improve from 0.30391\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1463 - acc: 0.9581 - val_loss: 0.3068 - val_acc: 0.9136\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9660\n",
      "Epoch 00008: val_loss did not improve from 0.30391\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1167 - acc: 0.9660 - val_loss: 0.3562 - val_acc: 0.9031\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9780\n",
      "Epoch 00009: val_loss did not improve from 0.30391\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0822 - acc: 0.9780 - val_loss: 0.4302 - val_acc: 0.8866\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9855\n",
      "Epoch 00010: val_loss improved from 0.30391 to 0.29436, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/010-0.2944.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0589 - acc: 0.9855 - val_loss: 0.2944 - val_acc: 0.9187\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9851\n",
      "Epoch 00011: val_loss did not improve from 0.29436\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0571 - acc: 0.9850 - val_loss: 0.4120 - val_acc: 0.8935\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9833\n",
      "Epoch 00012: val_loss did not improve from 0.29436\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0604 - acc: 0.9833 - val_loss: 0.3365 - val_acc: 0.9092\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9928\n",
      "Epoch 00013: val_loss did not improve from 0.29436\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0314 - acc: 0.9928 - val_loss: 0.3609 - val_acc: 0.9110\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9858\n",
      "Epoch 00014: val_loss did not improve from 0.29436\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0520 - acc: 0.9858 - val_loss: 0.3269 - val_acc: 0.9210\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9918\n",
      "Epoch 00015: val_loss improved from 0.29436 to 0.27293, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_BN_checkpoint/015-0.2729.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0329 - acc: 0.9918 - val_loss: 0.2729 - val_acc: 0.9329\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9954\n",
      "Epoch 00016: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0202 - acc: 0.9954 - val_loss: 0.3541 - val_acc: 0.9178\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9962\n",
      "Epoch 00017: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0187 - acc: 0.9962 - val_loss: 0.3597 - val_acc: 0.9096\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9900\n",
      "Epoch 00018: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0349 - acc: 0.9900 - val_loss: 0.3285 - val_acc: 0.9159\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9903\n",
      "Epoch 00019: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0342 - acc: 0.9903 - val_loss: 0.3161 - val_acc: 0.9236\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9983\n",
      "Epoch 00020: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0099 - acc: 0.9983 - val_loss: 0.3138 - val_acc: 0.9238\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9960\n",
      "Epoch 00021: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0158 - acc: 0.9960 - val_loss: 0.5196 - val_acc: 0.8868\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9885\n",
      "Epoch 00022: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0394 - acc: 0.9885 - val_loss: 0.3515 - val_acc: 0.9173\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9973\n",
      "Epoch 00023: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0120 - acc: 0.9973 - val_loss: 0.3453 - val_acc: 0.9269\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9978\n",
      "Epoch 00024: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0090 - acc: 0.9978 - val_loss: 0.3761 - val_acc: 0.9192\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9943\n",
      "Epoch 00025: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0205 - acc: 0.9943 - val_loss: 0.3617 - val_acc: 0.9152\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9965\n",
      "Epoch 00026: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0136 - acc: 0.9965 - val_loss: 0.4213 - val_acc: 0.9036\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9973\n",
      "Epoch 00027: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0124 - acc: 0.9973 - val_loss: 0.4256 - val_acc: 0.9005\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9951\n",
      "Epoch 00028: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0174 - acc: 0.9950 - val_loss: 0.4099 - val_acc: 0.9171\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9918\n",
      "Epoch 00029: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0273 - acc: 0.9918 - val_loss: 0.3135 - val_acc: 0.9315\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9986\n",
      "Epoch 00030: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0066 - acc: 0.9986 - val_loss: 0.3098 - val_acc: 0.9313\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9994\n",
      "Epoch 00031: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0043 - acc: 0.9993 - val_loss: 0.3006 - val_acc: 0.9350\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9923\n",
      "Epoch 00032: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0249 - acc: 0.9923 - val_loss: 0.3250 - val_acc: 0.9357\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9984\n",
      "Epoch 00033: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0076 - acc: 0.9984 - val_loss: 0.3200 - val_acc: 0.9352\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9919\n",
      "Epoch 00034: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0255 - acc: 0.9919 - val_loss: 0.3225 - val_acc: 0.9324\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9964\n",
      "Epoch 00035: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0147 - acc: 0.9964 - val_loss: 0.3390 - val_acc: 0.9248\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9978\n",
      "Epoch 00036: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0085 - acc: 0.9978 - val_loss: 0.3474 - val_acc: 0.9245\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9974\n",
      "Epoch 00037: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0099 - acc: 0.9974 - val_loss: 0.3752 - val_acc: 0.9164\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9918\n",
      "Epoch 00038: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0240 - acc: 0.9918 - val_loss: 0.3989 - val_acc: 0.9161\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 00039: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0056 - acc: 0.9988 - val_loss: 0.3031 - val_acc: 0.9331\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9993\n",
      "Epoch 00040: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0034 - acc: 0.9993 - val_loss: 0.3072 - val_acc: 0.9308\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9959\n",
      "Epoch 00041: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0154 - acc: 0.9959 - val_loss: 0.4217 - val_acc: 0.9154\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978\n",
      "Epoch 00042: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0076 - acc: 0.9978 - val_loss: 0.3735 - val_acc: 0.9243\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9938\n",
      "Epoch 00043: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0209 - acc: 0.9938 - val_loss: 0.3168 - val_acc: 0.9341\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 00044: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0048 - acc: 0.9986 - val_loss: 0.3388 - val_acc: 0.9315\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9987\n",
      "Epoch 00045: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0057 - acc: 0.9987 - val_loss: 0.3517 - val_acc: 0.9276\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00046: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.3928 - val_acc: 0.9215\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9931\n",
      "Epoch 00047: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0211 - acc: 0.9931 - val_loss: 0.3108 - val_acc: 0.9357\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9987\n",
      "Epoch 00048: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0052 - acc: 0.9987 - val_loss: 0.3204 - val_acc: 0.9348\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 00049: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0031 - acc: 0.9993 - val_loss: 0.3410 - val_acc: 0.9299\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 00050: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0085 - acc: 0.9977 - val_loss: 0.3595 - val_acc: 0.9255\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9963\n",
      "Epoch 00051: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.6437 - val_acc: 0.8796\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9944\n",
      "Epoch 00052: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0184 - acc: 0.9944 - val_loss: 0.3390 - val_acc: 0.9359\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9992\n",
      "Epoch 00053: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0032 - acc: 0.9992 - val_loss: 0.3119 - val_acc: 0.9415\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 00054: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.3280 - val_acc: 0.9336\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 00055: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0147 - acc: 0.9953 - val_loss: 0.3493 - val_acc: 0.9306\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9956\n",
      "Epoch 00056: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0132 - acc: 0.9956 - val_loss: 0.3250 - val_acc: 0.9348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9992\n",
      "Epoch 00057: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0037 - acc: 0.9992 - val_loss: 0.3068 - val_acc: 0.9399\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 00058: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.3182 - val_acc: 0.9394\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9963\n",
      "Epoch 00059: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0120 - acc: 0.9963 - val_loss: 0.4735 - val_acc: 0.9096\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00060: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0110 - acc: 0.9967 - val_loss: 0.3087 - val_acc: 0.9436\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00061: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0050 - acc: 0.9987 - val_loss: 0.3882 - val_acc: 0.9280\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00062: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.3592 - val_acc: 0.9320\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9985\n",
      "Epoch 00063: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0058 - acc: 0.9985 - val_loss: 0.4588 - val_acc: 0.9138\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9955\n",
      "Epoch 00064: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0136 - acc: 0.9955 - val_loss: 0.3073 - val_acc: 0.9390\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9982\n",
      "Epoch 00065: val_loss did not improve from 0.27293\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0067 - acc: 0.9982 - val_loss: 0.3279 - val_acc: 0.9362\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_32_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 701us/sample - loss: 0.3645 - acc: 0.9070\n",
      "Loss: 0.3644524740095822 Accuracy: 0.90695745\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3669 - acc: 0.5779\n",
      "Epoch 00001: val_loss improved from inf to 3.76779, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/001-3.7678.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.3668 - acc: 0.5779 - val_loss: 3.7678 - val_acc: 0.2297\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5848 - acc: 0.8225\n",
      "Epoch 00002: val_loss improved from 3.76779 to 0.48234, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/002-0.4823.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5848 - acc: 0.8225 - val_loss: 0.4823 - val_acc: 0.8537\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8845\n",
      "Epoch 00003: val_loss improved from 0.48234 to 0.36287, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/003-0.3629.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3843 - acc: 0.8845 - val_loss: 0.3629 - val_acc: 0.8901\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2758 - acc: 0.9193\n",
      "Epoch 00004: val_loss improved from 0.36287 to 0.28885, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/004-0.2889.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2758 - acc: 0.9193 - val_loss: 0.2889 - val_acc: 0.9124\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2175 - acc: 0.9354\n",
      "Epoch 00005: val_loss improved from 0.28885 to 0.24758, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/005-0.2476.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2175 - acc: 0.9354 - val_loss: 0.2476 - val_acc: 0.9259\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9507\n",
      "Epoch 00006: val_loss did not improve from 0.24758\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1684 - acc: 0.9507 - val_loss: 0.2832 - val_acc: 0.9126\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9580\n",
      "Epoch 00007: val_loss did not improve from 0.24758\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1400 - acc: 0.9580 - val_loss: 0.2880 - val_acc: 0.9129\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9650\n",
      "Epoch 00008: val_loss did not improve from 0.24758\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1198 - acc: 0.9650 - val_loss: 0.3419 - val_acc: 0.8938\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9702\n",
      "Epoch 00009: val_loss did not improve from 0.24758\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1021 - acc: 0.9702 - val_loss: 0.3365 - val_acc: 0.9059\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9740\n",
      "Epoch 00010: val_loss improved from 0.24758 to 0.22578, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/010-0.2258.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0915 - acc: 0.9740 - val_loss: 0.2258 - val_acc: 0.9357\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9850\n",
      "Epoch 00011: val_loss did not improve from 0.22578\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0587 - acc: 0.9849 - val_loss: 0.2466 - val_acc: 0.9283\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9830\n",
      "Epoch 00012: val_loss did not improve from 0.22578\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0641 - acc: 0.9830 - val_loss: 0.2286 - val_acc: 0.9352\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9798\n",
      "Epoch 00013: val_loss did not improve from 0.22578\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0715 - acc: 0.9798 - val_loss: 0.2398 - val_acc: 0.9290\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9920\n",
      "Epoch 00014: val_loss did not improve from 0.22578\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0340 - acc: 0.9920 - val_loss: 0.2359 - val_acc: 0.9306\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9908\n",
      "Epoch 00015: val_loss did not improve from 0.22578\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0371 - acc: 0.9908 - val_loss: 0.2857 - val_acc: 0.9189\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9834\n",
      "Epoch 00016: val_loss improved from 0.22578 to 0.21242, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/016-0.2124.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0593 - acc: 0.9834 - val_loss: 0.2124 - val_acc: 0.9429\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9901\n",
      "Epoch 00017: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0397 - acc: 0.9901 - val_loss: 0.2511 - val_acc: 0.9327\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9940\n",
      "Epoch 00018: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0244 - acc: 0.9940 - val_loss: 0.2260 - val_acc: 0.9392\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9944\n",
      "Epoch 00019: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0235 - acc: 0.9944 - val_loss: 0.2449 - val_acc: 0.9317\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9920\n",
      "Epoch 00020: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0296 - acc: 0.9920 - val_loss: 0.2611 - val_acc: 0.9334\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9928\n",
      "Epoch 00021: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0270 - acc: 0.9928 - val_loss: 0.2535 - val_acc: 0.9301\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9927\n",
      "Epoch 00022: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0283 - acc: 0.9927 - val_loss: 0.2449 - val_acc: 0.9362\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9934\n",
      "Epoch 00023: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0246 - acc: 0.9934 - val_loss: 0.2899 - val_acc: 0.9317\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9953\n",
      "Epoch 00024: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0184 - acc: 0.9953 - val_loss: 0.2604 - val_acc: 0.9320\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9923\n",
      "Epoch 00025: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0289 - acc: 0.9923 - val_loss: 0.2775 - val_acc: 0.9276\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9966\n",
      "Epoch 00026: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0146 - acc: 0.9966 - val_loss: 0.2255 - val_acc: 0.9392\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9956\n",
      "Epoch 00027: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0172 - acc: 0.9956 - val_loss: 0.3071 - val_acc: 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9939\n",
      "Epoch 00028: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0224 - acc: 0.9939 - val_loss: 0.2213 - val_acc: 0.9429\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9966\n",
      "Epoch 00029: val_loss did not improve from 0.21242\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0141 - acc: 0.9966 - val_loss: 0.3078 - val_acc: 0.9231\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9918\n",
      "Epoch 00030: val_loss improved from 0.21242 to 0.20155, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/030-0.2015.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0284 - acc: 0.9918 - val_loss: 0.2015 - val_acc: 0.9450\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9975\n",
      "Epoch 00031: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0108 - acc: 0.9975 - val_loss: 0.2308 - val_acc: 0.9418\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9922\n",
      "Epoch 00032: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0267 - acc: 0.9922 - val_loss: 0.2556 - val_acc: 0.9378\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9943\n",
      "Epoch 00033: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0220 - acc: 0.9943 - val_loss: 0.2224 - val_acc: 0.9455\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9991\n",
      "Epoch 00034: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0059 - acc: 0.9991 - val_loss: 0.2063 - val_acc: 0.9499\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9986\n",
      "Epoch 00035: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0068 - acc: 0.9986 - val_loss: 0.2466 - val_acc: 0.9441\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9945\n",
      "Epoch 00036: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0196 - acc: 0.9945 - val_loss: 0.2345 - val_acc: 0.9404\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9977\n",
      "Epoch 00037: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0100 - acc: 0.9977 - val_loss: 0.2101 - val_acc: 0.9488\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9971\n",
      "Epoch 00038: val_loss did not improve from 0.20155\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0125 - acc: 0.9971 - val_loss: 0.2391 - val_acc: 0.9439\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9932\n",
      "Epoch 00039: val_loss improved from 0.20155 to 0.20046, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/039-0.2005.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0239 - acc: 0.9932 - val_loss: 0.2005 - val_acc: 0.9495\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 00040: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0055 - acc: 0.9989 - val_loss: 0.2026 - val_acc: 0.9464\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9986\n",
      "Epoch 00041: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0060 - acc: 0.9986 - val_loss: 0.2921 - val_acc: 0.9313\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9926\n",
      "Epoch 00042: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0264 - acc: 0.9926 - val_loss: 0.2140 - val_acc: 0.9450\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9986\n",
      "Epoch 00043: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0063 - acc: 0.9986 - val_loss: 0.2210 - val_acc: 0.9457\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 00044: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0061 - acc: 0.9985 - val_loss: 0.2408 - val_acc: 0.9448\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9976\n",
      "Epoch 00045: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0086 - acc: 0.9976 - val_loss: 0.2843 - val_acc: 0.9297\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9963\n",
      "Epoch 00046: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0132 - acc: 0.9963 - val_loss: 0.2501 - val_acc: 0.9434\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9969\n",
      "Epoch 00047: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0113 - acc: 0.9969 - val_loss: 0.2617 - val_acc: 0.9357\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9976\n",
      "Epoch 00048: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0098 - acc: 0.9976 - val_loss: 0.2366 - val_acc: 0.9427\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 00049: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0154 - acc: 0.9954 - val_loss: 0.2252 - val_acc: 0.9469\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 00050: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0050 - acc: 0.9989 - val_loss: 0.2428 - val_acc: 0.9401\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9986\n",
      "Epoch 00051: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0060 - acc: 0.9986 - val_loss: 0.2207 - val_acc: 0.9483\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9968\n",
      "Epoch 00052: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0117 - acc: 0.9968 - val_loss: 0.2230 - val_acc: 0.9471\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9968\n",
      "Epoch 00053: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0110 - acc: 0.9968 - val_loss: 0.2460 - val_acc: 0.9429\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9982\n",
      "Epoch 00054: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0076 - acc: 0.9982 - val_loss: 0.2076 - val_acc: 0.9525\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9960\n",
      "Epoch 00055: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0140 - acc: 0.9960 - val_loss: 0.2117 - val_acc: 0.9481\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 00056: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0049 - acc: 0.9987 - val_loss: 0.3007 - val_acc: 0.9359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9984\n",
      "Epoch 00057: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0061 - acc: 0.9984 - val_loss: 0.2455 - val_acc: 0.9467\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 00058: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0070 - acc: 0.9983 - val_loss: 0.2546 - val_acc: 0.9385\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9967\n",
      "Epoch 00059: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0111 - acc: 0.9967 - val_loss: 0.2870 - val_acc: 0.9355\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9958\n",
      "Epoch 00060: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0137 - acc: 0.9958 - val_loss: 0.2376 - val_acc: 0.9448\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9974\n",
      "Epoch 00061: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0095 - acc: 0.9974 - val_loss: 0.2115 - val_acc: 0.9522\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9992\n",
      "Epoch 00062: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0037 - acc: 0.9992 - val_loss: 0.2217 - val_acc: 0.9499\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 00063: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0027 - acc: 0.9993 - val_loss: 0.2012 - val_acc: 0.9541\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9996\n",
      "Epoch 00064: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0024 - acc: 0.9996 - val_loss: 0.2178 - val_acc: 0.9495\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 00065: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0149 - acc: 0.9955 - val_loss: 0.2560 - val_acc: 0.9390\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 00066: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0074 - acc: 0.9980 - val_loss: 0.2332 - val_acc: 0.9469\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9978\n",
      "Epoch 00067: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0079 - acc: 0.9978 - val_loss: 0.2259 - val_acc: 0.9504\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 00068: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.2131 - val_acc: 0.9529\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9992\n",
      "Epoch 00069: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0040 - acc: 0.9992 - val_loss: 0.3118 - val_acc: 0.9355\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9957\n",
      "Epoch 00070: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0142 - acc: 0.9957 - val_loss: 0.2393 - val_acc: 0.9464\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9966\n",
      "Epoch 00071: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0121 - acc: 0.9966 - val_loss: 0.2222 - val_acc: 0.9518\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 00072: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0038 - acc: 0.9991 - val_loss: 0.2358 - val_acc: 0.9485\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993\n",
      "Epoch 00073: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0023 - acc: 0.9993 - val_loss: 0.2222 - val_acc: 0.9504\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9985\n",
      "Epoch 00074: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0050 - acc: 0.9985 - val_loss: 0.2459 - val_acc: 0.9439\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 00075: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0060 - acc: 0.9982 - val_loss: 0.2581 - val_acc: 0.9439\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 00076: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0069 - acc: 0.9982 - val_loss: 0.2224 - val_acc: 0.9485\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00077: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.2150 - val_acc: 0.9536\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 00078: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 0.2376 - val_acc: 0.9499\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9989\n",
      "Epoch 00079: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0049 - acc: 0.9989 - val_loss: 0.2306 - val_acc: 0.9497\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9990\n",
      "Epoch 00080: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.2488 - val_acc: 0.9485\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9944\n",
      "Epoch 00081: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0191 - acc: 0.9944 - val_loss: 0.2117 - val_acc: 0.9532\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00082: val_loss did not improve from 0.20046\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.2070 - val_acc: 0.9534\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00083: val_loss improved from 0.20046 to 0.19960, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/083-0.1996.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1996 - val_acc: 0.9550\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00084: val_loss did not improve from 0.19960\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2140 - val_acc: 0.9562\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00085: val_loss did not improve from 0.19960\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0051 - acc: 0.9987 - val_loss: 0.2287 - val_acc: 0.9497\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 00086: val_loss did not improve from 0.19960\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0096 - acc: 0.9970 - val_loss: 0.2170 - val_acc: 0.9509\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00087: val_loss did not improve from 0.19960\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2407 - val_acc: 0.9499\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 00088: val_loss did not improve from 0.19960\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0022 - acc: 0.9994 - val_loss: 0.2352 - val_acc: 0.9506\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 00089: val_loss did not improve from 0.19960\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0137 - acc: 0.9959 - val_loss: 0.2137 - val_acc: 0.9518\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 00090: val_loss improved from 0.19960 to 0.19887, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/090-0.1989.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1989 - val_acc: 0.9557\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00091: val_loss did not improve from 0.19887\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1997 - val_acc: 0.9562\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 00092: val_loss did not improve from 0.19887\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0121 - acc: 0.9963 - val_loss: 0.2294 - val_acc: 0.9446\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 00093: val_loss did not improve from 0.19887\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0089 - acc: 0.9972 - val_loss: 0.2112 - val_acc: 0.9518\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 00094: val_loss did not improve from 0.19887\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0035 - acc: 0.9991 - val_loss: 0.2024 - val_acc: 0.9534\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00095: val_loss improved from 0.19887 to 0.19712, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_BN_checkpoint/095-0.1971.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.1971 - val_acc: 0.9532\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.8956e-04 - acc: 0.9998\n",
      "Epoch 00096: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 9.2937e-04 - acc: 0.9998 - val_loss: 0.2002 - val_acc: 0.9548\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9975\n",
      "Epoch 00097: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0093 - acc: 0.9975 - val_loss: 0.2654 - val_acc: 0.9422\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 00098: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0023 - acc: 0.9992 - val_loss: 0.2141 - val_acc: 0.9539\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00099: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.2516 - val_acc: 0.9455\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9972\n",
      "Epoch 00100: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0089 - acc: 0.9972 - val_loss: 0.2611 - val_acc: 0.9450\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9990\n",
      "Epoch 00101: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0039 - acc: 0.9990 - val_loss: 0.2464 - val_acc: 0.9481\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9985\n",
      "Epoch 00102: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 0.2360 - val_acc: 0.9511\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 00103: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.2330 - val_acc: 0.9460\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9977\n",
      "Epoch 00104: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0080 - acc: 0.9977 - val_loss: 0.2175 - val_acc: 0.9541\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00105: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0019 - acc: 0.9996 - val_loss: 0.2042 - val_acc: 0.9581\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00106: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.2061 - val_acc: 0.9590\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 00107: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.2337 - val_acc: 0.9515\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 00108: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0054 - acc: 0.9984 - val_loss: 0.2497 - val_acc: 0.9481\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 00109: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0040 - acc: 0.9989 - val_loss: 0.2197 - val_acc: 0.9522\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9980\n",
      "Epoch 00110: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0074 - acc: 0.9980 - val_loss: 0.2328 - val_acc: 0.9506\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00111: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.2235 - val_acc: 0.9511\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 00112: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.2291 - val_acc: 0.9495\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9990\n",
      "Epoch 00113: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0030 - acc: 0.9990 - val_loss: 0.2210 - val_acc: 0.9567\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 00114: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0020 - acc: 0.9994 - val_loss: 0.2302 - val_acc: 0.9536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 00115: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.2623 - val_acc: 0.9474\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9983\n",
      "Epoch 00116: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0053 - acc: 0.9983 - val_loss: 0.2474 - val_acc: 0.9502\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 00117: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 0.2544 - val_acc: 0.9497\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9970\n",
      "Epoch 00118: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0107 - acc: 0.9970 - val_loss: 0.2204 - val_acc: 0.9539\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 00119: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0020 - acc: 0.9994 - val_loss: 0.2318 - val_acc: 0.9499\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 00120: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 0.2338 - val_acc: 0.9525\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 00121: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.2477 - val_acc: 0.9478\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 00122: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0068 - acc: 0.9980 - val_loss: 0.2205 - val_acc: 0.9529\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00123: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.2237 - val_acc: 0.9548\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.9044e-04 - acc: 0.9998\n",
      "Epoch 00124: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0011 - acc: 0.9998 - val_loss: 0.2146 - val_acc: 0.9553\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 00125: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0079 - acc: 0.9977 - val_loss: 0.2210 - val_acc: 0.9541\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00126: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.2157 - val_acc: 0.9539\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00127: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.2268 - val_acc: 0.9534\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 00128: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0031 - acc: 0.9992 - val_loss: 0.2418 - val_acc: 0.9478\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9988\n",
      "Epoch 00129: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0038 - acc: 0.9988 - val_loss: 0.2387 - val_acc: 0.9550\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9979\n",
      "Epoch 00130: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0069 - acc: 0.9978 - val_loss: 0.2218 - val_acc: 0.9550\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9977\n",
      "Epoch 00131: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0079 - acc: 0.9977 - val_loss: 0.2283 - val_acc: 0.9527\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00132: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.2163 - val_acc: 0.9539\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.6164e-04 - acc: 0.9999\n",
      "Epoch 00133: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 7.6159e-04 - acc: 0.9999 - val_loss: 0.2185 - val_acc: 0.9529\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 00134: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0017 - acc: 0.9995 - val_loss: 0.2569 - val_acc: 0.9469\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9993\n",
      "Epoch 00135: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0024 - acc: 0.9993 - val_loss: 0.2730 - val_acc: 0.9432\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 00136: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 0.2933 - val_acc: 0.9408\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9987\n",
      "Epoch 00137: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0038 - acc: 0.9987 - val_loss: 0.2393 - val_acc: 0.9485\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 00138: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 0.2439 - val_acc: 0.9522\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00139: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.2319 - val_acc: 0.9534\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 00140: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2318 - val_acc: 0.9557\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5004e-04 - acc: 0.9999\n",
      "Epoch 00141: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 5.5041e-04 - acc: 0.9999 - val_loss: 0.2286 - val_acc: 0.9546\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9995\n",
      "Epoch 00142: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0021 - acc: 0.9995 - val_loss: 0.2693 - val_acc: 0.9492\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 00143: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0071 - acc: 0.9982 - val_loss: 0.2460 - val_acc: 0.9485\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 00144: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0084 - acc: 0.9973 - val_loss: 0.2058 - val_acc: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00145: val_loss did not improve from 0.19712\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.2268 - val_acc: 0.9555\n",
      "\n",
      "1D_CNN_6_only_conv_pool_3_ch_32_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 752us/sample - loss: 0.2536 - acc: 0.9475\n",
      "Loss: 0.2536296891936353 Accuracy: 0.9474559\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_32_BN'.format(i)\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_32_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_32_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                2726928   \n",
      "=================================================================\n",
      "Total params: 2,727,888\n",
      "Trainable params: 2,727,824\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 493us/sample - loss: 1.7975 - acc: 0.4629\n",
      "Loss: 1.797541138712367 Accuracy: 0.46292835\n",
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_32_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_64 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                905232    \n",
      "=================================================================\n",
      "Total params: 931,952\n",
      "Trainable params: 931,824\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 613us/sample - loss: 1.7067 - acc: 0.5265\n",
      "Loss: 1.7066909554096275 Accuracy: 0.5264797\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_32_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 37248)             0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                595984    \n",
      "=================================================================\n",
      "Total params: 674,224\n",
      "Trainable params: 673,968\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 698us/sample - loss: 1.1312 - acc: 0.6856\n",
      "Loss: 1.1312228388504075 Accuracy: 0.68556595\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_32_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_69 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                190480    \n",
      "=================================================================\n",
      "Total params: 371,440\n",
      "Trainable params: 371,056\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 742us/sample - loss: 0.5865 - acc: 0.8355\n",
      "Loss: 0.5865089924659809 Accuracy: 0.835514\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_32_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                110608    \n",
      "=================================================================\n",
      "Total params: 497,008\n",
      "Trainable params: 496,368\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 782us/sample - loss: 0.3645 - acc: 0.9070\n",
      "Loss: 0.3644524740095822 Accuracy: 0.90695745\n",
      "\n",
      "1D_CNN_6_only_conv_pool_3_ch_32_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 30, 128)           409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 30, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                20496     \n",
      "=================================================================\n",
      "Total params: 817,136\n",
      "Trainable params: 816,240\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 823us/sample - loss: 0.2536 - acc: 0.9475\n",
      "Loss: 0.2536296891936353 Accuracy: 0.9474559\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_32_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_pool_3_ch_32_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=25, filters=32, strides=1, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=32*(2**int((i+1)/2)), strides=1))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_84 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 16)                2726928   \n",
      "=================================================================\n",
      "Total params: 2,727,888\n",
      "Trainable params: 2,727,824\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_85 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_25 (Flatten)         (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 16)                905232    \n",
      "=================================================================\n",
      "Total params: 931,952\n",
      "Trainable params: 931,824\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_87 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_26 (Flatten)         (None, 37248)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 37248)             0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 16)                595984    \n",
      "=================================================================\n",
      "Total params: 674,224\n",
      "Trainable params: 673,968\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_27 (Flatten)         (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 16)                190480    \n",
      "=================================================================\n",
      "Total params: 371,440\n",
      "Trainable params: 371,056\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_28 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 16)                110608    \n",
      "=================================================================\n",
      "Total params: 497,008\n",
      "Trainable params: 496,368\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_99 (Conv1D)           (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 30, 128)           409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 30, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_29 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 16)                20496     \n",
      "=================================================================\n",
      "Total params: 817,136\n",
      "Trainable params: 816,240\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2920 - acc: 0.3385\n",
      "Epoch 00001: val_loss improved from inf to 1.84707, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_BN_checkpoint/001-1.8471.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 2.2919 - acc: 0.3385 - val_loss: 1.8471 - val_acc: 0.4451\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3616 - acc: 0.5732\n",
      "Epoch 00002: val_loss improved from 1.84707 to 1.71161, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_BN_checkpoint/002-1.7116.hdf5\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 1.3616 - acc: 0.5732 - val_loss: 1.7116 - val_acc: 0.4936\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0553 - acc: 0.6658\n",
      "Epoch 00003: val_loss improved from 1.71161 to 1.69418, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_32_DO_BN_checkpoint/003-1.6942.hdf5\n",
      "36805/36805 [==============================] - 30s 828us/sample - loss: 1.0552 - acc: 0.6658 - val_loss: 1.6942 - val_acc: 0.5078\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8515 - acc: 0.7291\n",
      "Epoch 00004: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 819us/sample - loss: 0.8519 - acc: 0.7290 - val_loss: 1.7104 - val_acc: 0.5176\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7228 - acc: 0.7701\n",
      "Epoch 00005: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 818us/sample - loss: 0.7227 - acc: 0.7701 - val_loss: 1.7852 - val_acc: 0.5197\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6049 - acc: 0.8069\n",
      "Epoch 00006: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 821us/sample - loss: 0.6048 - acc: 0.8069 - val_loss: 1.8391 - val_acc: 0.5192\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.8337\n",
      "Epoch 00007: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.5234 - acc: 0.8337 - val_loss: 1.9351 - val_acc: 0.5157\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8568\n",
      "Epoch 00008: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 815us/sample - loss: 0.4588 - acc: 0.8568 - val_loss: 2.0648 - val_acc: 0.5215\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4060 - acc: 0.8749\n",
      "Epoch 00009: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.4059 - acc: 0.8750 - val_loss: 2.0745 - val_acc: 0.5183\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3629 - acc: 0.8857\n",
      "Epoch 00010: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.3629 - acc: 0.8857 - val_loss: 2.1634 - val_acc: 0.5087\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.8974\n",
      "Epoch 00011: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.3305 - acc: 0.8974 - val_loss: 2.2613 - val_acc: 0.5073\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3017 - acc: 0.9070\n",
      "Epoch 00012: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.3017 - acc: 0.9070 - val_loss: 2.3028 - val_acc: 0.5160\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2729 - acc: 0.9180\n",
      "Epoch 00013: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2728 - acc: 0.9179 - val_loss: 2.4214 - val_acc: 0.5087\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2589 - acc: 0.9215\n",
      "Epoch 00014: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.2589 - acc: 0.9215 - val_loss: 2.4331 - val_acc: 0.5262\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9279\n",
      "Epoch 00015: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.2414 - acc: 0.9279 - val_loss: 2.4945 - val_acc: 0.5120\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2336 - acc: 0.9302\n",
      "Epoch 00016: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 814us/sample - loss: 0.2336 - acc: 0.9303 - val_loss: 2.5242 - val_acc: 0.5199\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9328\n",
      "Epoch 00017: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.2206 - acc: 0.9328 - val_loss: 2.5567 - val_acc: 0.5229\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9400\n",
      "Epoch 00018: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.2044 - acc: 0.9400 - val_loss: 2.6580 - val_acc: 0.5171\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9435\n",
      "Epoch 00019: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.1924 - acc: 0.9435 - val_loss: 2.7849 - val_acc: 0.5076\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9440\n",
      "Epoch 00020: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.1893 - acc: 0.9440 - val_loss: 2.7592 - val_acc: 0.5085\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9442\n",
      "Epoch 00021: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1916 - acc: 0.9442 - val_loss: 2.7789 - val_acc: 0.5183\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9497\n",
      "Epoch 00022: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1712 - acc: 0.9497 - val_loss: 2.8361 - val_acc: 0.5241\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9492\n",
      "Epoch 00023: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1756 - acc: 0.9492 - val_loss: 2.9296 - val_acc: 0.5157\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9544\n",
      "Epoch 00024: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 813us/sample - loss: 0.1604 - acc: 0.9543 - val_loss: 2.8984 - val_acc: 0.5150\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9549\n",
      "Epoch 00025: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.1550 - acc: 0.9549 - val_loss: 2.9078 - val_acc: 0.5220\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9561\n",
      "Epoch 00026: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.1487 - acc: 0.9560 - val_loss: 2.9656 - val_acc: 0.5255\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9588\n",
      "Epoch 00027: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.1410 - acc: 0.9588 - val_loss: 2.9319 - val_acc: 0.5264\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9573\n",
      "Epoch 00028: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.1500 - acc: 0.9574 - val_loss: 3.0275 - val_acc: 0.5153\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9583\n",
      "Epoch 00029: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1490 - acc: 0.9582 - val_loss: 3.0738 - val_acc: 0.5162\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9627\n",
      "Epoch 00030: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.1367 - acc: 0.9626 - val_loss: 3.0989 - val_acc: 0.5169\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9581\n",
      "Epoch 00031: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.1455 - acc: 0.9581 - val_loss: 3.1661 - val_acc: 0.5185\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9610\n",
      "Epoch 00032: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1351 - acc: 0.9610 - val_loss: 3.1551 - val_acc: 0.5234\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9678\n",
      "Epoch 00033: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1176 - acc: 0.9678 - val_loss: 3.1530 - val_acc: 0.5250\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9657\n",
      "Epoch 00034: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1233 - acc: 0.9657 - val_loss: 3.2079 - val_acc: 0.5171\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9619\n",
      "Epoch 00035: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1298 - acc: 0.9619 - val_loss: 3.2290 - val_acc: 0.5215\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9666\n",
      "Epoch 00036: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1176 - acc: 0.9666 - val_loss: 3.2198 - val_acc: 0.5225\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9667\n",
      "Epoch 00037: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1211 - acc: 0.9667 - val_loss: 3.2930 - val_acc: 0.5255\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9687\n",
      "Epoch 00038: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 808us/sample - loss: 0.1137 - acc: 0.9687 - val_loss: 3.2544 - val_acc: 0.5285\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9678\n",
      "Epoch 00039: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1140 - acc: 0.9678 - val_loss: 3.2871 - val_acc: 0.5295\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9683\n",
      "Epoch 00040: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1139 - acc: 0.9683 - val_loss: 3.4562 - val_acc: 0.5169\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9671\n",
      "Epoch 00041: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1186 - acc: 0.9671 - val_loss: 3.4486 - val_acc: 0.5181\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9689\n",
      "Epoch 00042: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1141 - acc: 0.9689 - val_loss: 3.5023 - val_acc: 0.5139\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9705\n",
      "Epoch 00043: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1053 - acc: 0.9705 - val_loss: 3.4151 - val_acc: 0.5162\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9702\n",
      "Epoch 00044: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1078 - acc: 0.9702 - val_loss: 3.3666 - val_acc: 0.5195\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1024 - acc: 0.9718\n",
      "Epoch 00045: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.1025 - acc: 0.9718 - val_loss: 3.4450 - val_acc: 0.5250\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9722\n",
      "Epoch 00046: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1027 - acc: 0.9722 - val_loss: 3.4719 - val_acc: 0.5250\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9727\n",
      "Epoch 00047: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 807us/sample - loss: 0.1014 - acc: 0.9727 - val_loss: 3.4993 - val_acc: 0.5225\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9691\n",
      "Epoch 00048: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 812us/sample - loss: 0.1127 - acc: 0.9692 - val_loss: 3.5257 - val_acc: 0.5222\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9724\n",
      "Epoch 00049: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1003 - acc: 0.9724 - val_loss: 3.6355 - val_acc: 0.5139\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9729\n",
      "Epoch 00050: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 810us/sample - loss: 0.1015 - acc: 0.9729 - val_loss: 3.6221 - val_acc: 0.5132\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9723\n",
      "Epoch 00051: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.1020 - acc: 0.9723 - val_loss: 3.5880 - val_acc: 0.5192\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9756\n",
      "Epoch 00052: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 811us/sample - loss: 0.0906 - acc: 0.9756 - val_loss: 3.6043 - val_acc: 0.5248\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9748\n",
      "Epoch 00053: val_loss did not improve from 1.69418\n",
      "36805/36805 [==============================] - 30s 809us/sample - loss: 0.0953 - acc: 0.9747 - val_loss: 3.5454 - val_acc: 0.5253\n",
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_32_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 583us/sample - loss: 1.7332 - acc: 0.4833\n",
      "Loss: 1.733176219277664 Accuracy: 0.4832814\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.9358 - acc: 0.3300\n",
      "Epoch 00001: val_loss improved from inf to 2.85286, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_BN_checkpoint/001-2.8529.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 2.9360 - acc: 0.3300 - val_loss: 2.8529 - val_acc: 0.2986\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8536 - acc: 0.5334\n",
      "Epoch 00002: val_loss improved from 2.85286 to 1.72303, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_BN_checkpoint/002-1.7230.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.8537 - acc: 0.5334 - val_loss: 1.7230 - val_acc: 0.5590\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4508 - acc: 0.6185\n",
      "Epoch 00003: val_loss improved from 1.72303 to 1.49895, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_BN_checkpoint/003-1.4990.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.4507 - acc: 0.6185 - val_loss: 1.4990 - val_acc: 0.6112\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1835 - acc: 0.6763\n",
      "Epoch 00004: val_loss improved from 1.49895 to 1.48129, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_BN_checkpoint/004-1.4813.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.1834 - acc: 0.6763 - val_loss: 1.4813 - val_acc: 0.6308\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9778 - acc: 0.7241\n",
      "Epoch 00005: val_loss did not improve from 1.48129\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.9782 - acc: 0.7241 - val_loss: 1.5021 - val_acc: 0.6366\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8394 - acc: 0.7588\n",
      "Epoch 00006: val_loss did not improve from 1.48129\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8394 - acc: 0.7588 - val_loss: 1.6325 - val_acc: 0.6191\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7056 - acc: 0.7929\n",
      "Epoch 00007: val_loss improved from 1.48129 to 1.44124, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_32_DO_BN_checkpoint/007-1.4412.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7057 - acc: 0.7928 - val_loss: 1.4412 - val_acc: 0.6585\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5944 - acc: 0.8197\n",
      "Epoch 00008: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5945 - acc: 0.8197 - val_loss: 1.6625 - val_acc: 0.6224\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5121 - acc: 0.8455\n",
      "Epoch 00009: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5120 - acc: 0.8455 - val_loss: 1.4770 - val_acc: 0.6688\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8618\n",
      "Epoch 00010: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4465 - acc: 0.8617 - val_loss: 1.5301 - val_acc: 0.6746\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4003 - acc: 0.8748\n",
      "Epoch 00011: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4002 - acc: 0.8748 - val_loss: 1.5583 - val_acc: 0.6778\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3502 - acc: 0.8914\n",
      "Epoch 00012: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3505 - acc: 0.8913 - val_loss: 1.5693 - val_acc: 0.6795\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.9023\n",
      "Epoch 00013: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3162 - acc: 0.9023 - val_loss: 1.7426 - val_acc: 0.6611\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2925 - acc: 0.9108\n",
      "Epoch 00014: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2926 - acc: 0.9107 - val_loss: 1.9440 - val_acc: 0.6413\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9166\n",
      "Epoch 00015: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2717 - acc: 0.9166 - val_loss: 1.6360 - val_acc: 0.6844\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9256\n",
      "Epoch 00016: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2432 - acc: 0.9256 - val_loss: 1.8341 - val_acc: 0.6792\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2427 - acc: 0.9277\n",
      "Epoch 00017: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2429 - acc: 0.9276 - val_loss: 1.9068 - val_acc: 0.6657\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9311\n",
      "Epoch 00018: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2262 - acc: 0.9311 - val_loss: 1.8056 - val_acc: 0.6748\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2109 - acc: 0.9380\n",
      "Epoch 00019: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2110 - acc: 0.9379 - val_loss: 1.7791 - val_acc: 0.6762\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9417\n",
      "Epoch 00020: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1955 - acc: 0.9417 - val_loss: 1.7582 - val_acc: 0.6981\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9448\n",
      "Epoch 00021: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1904 - acc: 0.9448 - val_loss: 1.7325 - val_acc: 0.6932\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9470\n",
      "Epoch 00022: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1793 - acc: 0.9470 - val_loss: 1.7012 - val_acc: 0.7128\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9504\n",
      "Epoch 00023: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1721 - acc: 0.9504 - val_loss: 1.7417 - val_acc: 0.7028\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9496\n",
      "Epoch 00024: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1770 - acc: 0.9496 - val_loss: 1.9785 - val_acc: 0.6778\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9522\n",
      "Epoch 00025: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1656 - acc: 0.9522 - val_loss: 2.0112 - val_acc: 0.6765\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9534\n",
      "Epoch 00026: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1623 - acc: 0.9534 - val_loss: 1.9446 - val_acc: 0.6890\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9587\n",
      "Epoch 00027: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1450 - acc: 0.9587 - val_loss: 2.1988 - val_acc: 0.6783\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9588\n",
      "Epoch 00028: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1533 - acc: 0.9588 - val_loss: 1.9434 - val_acc: 0.6997\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9610\n",
      "Epoch 00029: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1415 - acc: 0.9609 - val_loss: 1.8409 - val_acc: 0.7123\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9580\n",
      "Epoch 00030: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1543 - acc: 0.9580 - val_loss: 1.9833 - val_acc: 0.6942\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9639\n",
      "Epoch 00031: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1299 - acc: 0.9638 - val_loss: 1.8821 - val_acc: 0.7212\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9604\n",
      "Epoch 00032: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1440 - acc: 0.9604 - val_loss: 2.2366 - val_acc: 0.6720\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9641\n",
      "Epoch 00033: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1303 - acc: 0.9641 - val_loss: 1.9472 - val_acc: 0.7049\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9646\n",
      "Epoch 00034: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1311 - acc: 0.9646 - val_loss: 2.1753 - val_acc: 0.6806\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9657\n",
      "Epoch 00035: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1228 - acc: 0.9657 - val_loss: 2.0432 - val_acc: 0.6997\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9654\n",
      "Epoch 00036: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1321 - acc: 0.9654 - val_loss: 2.4720 - val_acc: 0.6527\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9668\n",
      "Epoch 00037: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1231 - acc: 0.9668 - val_loss: 1.9632 - val_acc: 0.7219\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1205 - acc: 0.9676\n",
      "Epoch 00038: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1204 - acc: 0.9676 - val_loss: 2.1727 - val_acc: 0.7018\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9701\n",
      "Epoch 00039: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1140 - acc: 0.9701 - val_loss: 2.0539 - val_acc: 0.7079\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9677\n",
      "Epoch 00040: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1223 - acc: 0.9677 - val_loss: 1.9049 - val_acc: 0.7268\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9705\n",
      "Epoch 00041: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1118 - acc: 0.9704 - val_loss: 2.1421 - val_acc: 0.6997\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9688\n",
      "Epoch 00042: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1215 - acc: 0.9688 - val_loss: 2.0223 - val_acc: 0.7240\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9703\n",
      "Epoch 00043: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1148 - acc: 0.9703 - val_loss: 2.7530 - val_acc: 0.6406\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9712\n",
      "Epoch 00044: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1116 - acc: 0.9712 - val_loss: 1.9822 - val_acc: 0.7247\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9740\n",
      "Epoch 00045: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1027 - acc: 0.9740 - val_loss: 2.2287 - val_acc: 0.6939\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9719\n",
      "Epoch 00046: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1084 - acc: 0.9719 - val_loss: 1.9993 - val_acc: 0.7256\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9742\n",
      "Epoch 00047: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1024 - acc: 0.9742 - val_loss: 2.1373 - val_acc: 0.7119\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9698\n",
      "Epoch 00048: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1167 - acc: 0.9698 - val_loss: 2.1167 - val_acc: 0.7174\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9733\n",
      "Epoch 00049: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1039 - acc: 0.9732 - val_loss: 2.1821 - val_acc: 0.7088\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9736\n",
      "Epoch 00050: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1028 - acc: 0.9736 - val_loss: 2.0142 - val_acc: 0.7307\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9745\n",
      "Epoch 00051: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1019 - acc: 0.9745 - val_loss: 2.2355 - val_acc: 0.7077\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9759\n",
      "Epoch 00052: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1003 - acc: 0.9759 - val_loss: 2.0959 - val_acc: 0.7277\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9765\n",
      "Epoch 00053: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0961 - acc: 0.9765 - val_loss: 2.0789 - val_acc: 0.7272\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9746\n",
      "Epoch 00054: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1011 - acc: 0.9746 - val_loss: 2.0101 - val_acc: 0.7247\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9745\n",
      "Epoch 00055: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1033 - acc: 0.9745 - val_loss: 1.9678 - val_acc: 0.7356\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9770\n",
      "Epoch 00056: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0901 - acc: 0.9770 - val_loss: 2.1349 - val_acc: 0.7135\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9774\n",
      "Epoch 00057: val_loss did not improve from 1.44124\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0900 - acc: 0.9774 - val_loss: 2.0407 - val_acc: 0.7209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_32_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 705us/sample - loss: 1.5087 - acc: 0.6314\n",
      "Loss: 1.5087162107941023 Accuracy: 0.63136035\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6270 - acc: 0.3812\n",
      "Epoch 00001: val_loss improved from inf to 6.11845, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_BN_checkpoint/001-6.1184.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 2.6271 - acc: 0.3812 - val_loss: 6.1184 - val_acc: 0.1537\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6258 - acc: 0.5779\n",
      "Epoch 00002: val_loss improved from 6.11845 to 1.13443, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_BN_checkpoint/002-1.1344.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.6256 - acc: 0.5779 - val_loss: 1.1344 - val_acc: 0.6949\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3201 - acc: 0.6552\n",
      "Epoch 00003: val_loss improved from 1.13443 to 1.11800, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_BN_checkpoint/003-1.1180.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.3202 - acc: 0.6552 - val_loss: 1.1180 - val_acc: 0.7039\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0985 - acc: 0.7058\n",
      "Epoch 00004: val_loss improved from 1.11800 to 0.94073, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_BN_checkpoint/004-0.9407.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.0984 - acc: 0.7058 - val_loss: 0.9407 - val_acc: 0.7489\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9370 - acc: 0.7452\n",
      "Epoch 00005: val_loss improved from 0.94073 to 0.86492, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_BN_checkpoint/005-0.8649.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.9373 - acc: 0.7451 - val_loss: 0.8649 - val_acc: 0.7692\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8109 - acc: 0.7759\n",
      "Epoch 00006: val_loss did not improve from 0.86492\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.8111 - acc: 0.7758 - val_loss: 0.9894 - val_acc: 0.7545\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6975 - acc: 0.8036\n",
      "Epoch 00007: val_loss did not improve from 0.86492\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.6976 - acc: 0.8036 - val_loss: 0.8782 - val_acc: 0.7897\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6077 - acc: 0.8252\n",
      "Epoch 00008: val_loss improved from 0.86492 to 0.79160, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_32_DO_BN_checkpoint/008-0.7916.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.6077 - acc: 0.8252 - val_loss: 0.7916 - val_acc: 0.8048\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5041 - acc: 0.8517\n",
      "Epoch 00009: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5041 - acc: 0.8517 - val_loss: 0.8932 - val_acc: 0.7906\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4538 - acc: 0.8639\n",
      "Epoch 00010: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4539 - acc: 0.8638 - val_loss: 0.8149 - val_acc: 0.8097\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3889 - acc: 0.8809\n",
      "Epoch 00011: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3889 - acc: 0.8809 - val_loss: 1.0555 - val_acc: 0.7745\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3349 - acc: 0.8948\n",
      "Epoch 00012: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3350 - acc: 0.8948 - val_loss: 0.8528 - val_acc: 0.8088\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3076 - acc: 0.9049\n",
      "Epoch 00013: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3076 - acc: 0.9049 - val_loss: 0.8272 - val_acc: 0.8202\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2649 - acc: 0.9175\n",
      "Epoch 00014: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2650 - acc: 0.9175 - val_loss: 0.8050 - val_acc: 0.8209\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9258\n",
      "Epoch 00015: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2387 - acc: 0.9258 - val_loss: 1.3251 - val_acc: 0.7398\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9340\n",
      "Epoch 00016: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2106 - acc: 0.9340 - val_loss: 1.2958 - val_acc: 0.7596\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9393\n",
      "Epoch 00017: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1982 - acc: 0.9393 - val_loss: 0.9023 - val_acc: 0.8188\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9422\n",
      "Epoch 00018: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1857 - acc: 0.9422 - val_loss: 0.8919 - val_acc: 0.8192\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1749 - acc: 0.9460\n",
      "Epoch 00019: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1751 - acc: 0.9459 - val_loss: 1.1736 - val_acc: 0.7729\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9492\n",
      "Epoch 00020: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1681 - acc: 0.9492 - val_loss: 0.8980 - val_acc: 0.8220\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9572\n",
      "Epoch 00021: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1402 - acc: 0.9572 - val_loss: 1.1489 - val_acc: 0.7913\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9576\n",
      "Epoch 00022: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1415 - acc: 0.9576 - val_loss: 1.0234 - val_acc: 0.8148\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9582\n",
      "Epoch 00023: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1381 - acc: 0.9582 - val_loss: 0.9820 - val_acc: 0.8293\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9616\n",
      "Epoch 00024: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1269 - acc: 0.9616 - val_loss: 1.0277 - val_acc: 0.8074\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9630\n",
      "Epoch 00025: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1231 - acc: 0.9630 - val_loss: 1.0311 - val_acc: 0.8155\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9629\n",
      "Epoch 00026: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1206 - acc: 0.9628 - val_loss: 0.9017 - val_acc: 0.8388\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9650\n",
      "Epoch 00027: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1197 - acc: 0.9650 - val_loss: 0.9929 - val_acc: 0.8199\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9649\n",
      "Epoch 00028: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1200 - acc: 0.9649 - val_loss: 0.9805 - val_acc: 0.8304\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9693\n",
      "Epoch 00029: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1052 - acc: 0.9693 - val_loss: 1.0152 - val_acc: 0.8197\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9708\n",
      "Epoch 00030: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0973 - acc: 0.9708 - val_loss: 0.9574 - val_acc: 0.8330\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9699\n",
      "Epoch 00031: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1055 - acc: 0.9699 - val_loss: 0.9641 - val_acc: 0.8390\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9710\n",
      "Epoch 00032: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1003 - acc: 0.9710 - val_loss: 1.1352 - val_acc: 0.8216\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9703\n",
      "Epoch 00033: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1045 - acc: 0.9702 - val_loss: 1.0155 - val_acc: 0.8234\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9718\n",
      "Epoch 00034: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1021 - acc: 0.9718 - val_loss: 0.9565 - val_acc: 0.8449\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9737\n",
      "Epoch 00035: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0940 - acc: 0.9737 - val_loss: 1.0243 - val_acc: 0.8269\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9750\n",
      "Epoch 00036: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0903 - acc: 0.9750 - val_loss: 0.9888 - val_acc: 0.8421\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9774\n",
      "Epoch 00037: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0841 - acc: 0.9774 - val_loss: 1.0447 - val_acc: 0.8302\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9780\n",
      "Epoch 00038: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0805 - acc: 0.9780 - val_loss: 0.9896 - val_acc: 0.8365\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9770\n",
      "Epoch 00039: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0834 - acc: 0.9770 - val_loss: 1.0696 - val_acc: 0.8276\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9769\n",
      "Epoch 00040: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0831 - acc: 0.9769 - val_loss: 1.0001 - val_acc: 0.8334\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9747\n",
      "Epoch 00041: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0918 - acc: 0.9747 - val_loss: 1.4157 - val_acc: 0.7869\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9776\n",
      "Epoch 00042: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0817 - acc: 0.9775 - val_loss: 1.1124 - val_acc: 0.8314\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9764\n",
      "Epoch 00043: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0872 - acc: 0.9764 - val_loss: 1.0577 - val_acc: 0.8332\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9792\n",
      "Epoch 00044: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0783 - acc: 0.9791 - val_loss: 1.0300 - val_acc: 0.8395\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9790\n",
      "Epoch 00045: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0783 - acc: 0.9790 - val_loss: 1.1202 - val_acc: 0.8265\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9794\n",
      "Epoch 00046: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0771 - acc: 0.9794 - val_loss: 1.0866 - val_acc: 0.8258\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9801\n",
      "Epoch 00047: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0755 - acc: 0.9800 - val_loss: 1.0725 - val_acc: 0.8323\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9795\n",
      "Epoch 00048: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0775 - acc: 0.9795 - val_loss: 1.1389 - val_acc: 0.8369\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9812\n",
      "Epoch 00049: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0724 - acc: 0.9812 - val_loss: 1.0936 - val_acc: 0.8297\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9821\n",
      "Epoch 00050: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0669 - acc: 0.9820 - val_loss: 1.0543 - val_acc: 0.8411\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9790\n",
      "Epoch 00051: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0846 - acc: 0.9791 - val_loss: 1.1613 - val_acc: 0.8286\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9830\n",
      "Epoch 00052: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0679 - acc: 0.9830 - val_loss: 1.0374 - val_acc: 0.8465\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9830\n",
      "Epoch 00053: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0662 - acc: 0.9829 - val_loss: 1.2684 - val_acc: 0.8169\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9784\n",
      "Epoch 00054: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0837 - acc: 0.9783 - val_loss: 1.2544 - val_acc: 0.8132\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9802\n",
      "Epoch 00055: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0748 - acc: 0.9802 - val_loss: 1.0077 - val_acc: 0.8544\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9830\n",
      "Epoch 00056: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0659 - acc: 0.9830 - val_loss: 1.0583 - val_acc: 0.8418\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9827\n",
      "Epoch 00057: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0657 - acc: 0.9827 - val_loss: 1.0383 - val_acc: 0.8537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9831\n",
      "Epoch 00058: val_loss did not improve from 0.79160\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0682 - acc: 0.9831 - val_loss: 1.1026 - val_acc: 0.8355\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_32_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 801us/sample - loss: 0.9034 - acc: 0.7657\n",
      "Loss: 0.9033839555172906 Accuracy: 0.7657321\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4298 - acc: 0.3574\n",
      "Epoch 00001: val_loss improved from inf to 8.00436, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/001-8.0044.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 2.4299 - acc: 0.3573 - val_loss: 8.0044 - val_acc: 0.1463\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4786 - acc: 0.5759\n",
      "Epoch 00002: val_loss improved from 8.00436 to 0.97784, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/002-0.9778.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.4788 - acc: 0.5759 - val_loss: 0.9778 - val_acc: 0.7112\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1490 - acc: 0.6696\n",
      "Epoch 00003: val_loss did not improve from 0.97784\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 1.1490 - acc: 0.6696 - val_loss: 1.1961 - val_acc: 0.6529\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8995 - acc: 0.7385\n",
      "Epoch 00004: val_loss improved from 0.97784 to 0.65505, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/004-0.6550.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.8994 - acc: 0.7385 - val_loss: 0.6550 - val_acc: 0.8067\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7604 - acc: 0.7809\n",
      "Epoch 00005: val_loss improved from 0.65505 to 0.63115, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/005-0.6312.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.7604 - acc: 0.7809 - val_loss: 0.6312 - val_acc: 0.8195\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6369 - acc: 0.8133\n",
      "Epoch 00006: val_loss did not improve from 0.63115\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.6368 - acc: 0.8134 - val_loss: 0.6851 - val_acc: 0.8169\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5502 - acc: 0.8371\n",
      "Epoch 00007: val_loss did not improve from 0.63115\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.5503 - acc: 0.8370 - val_loss: 0.7339 - val_acc: 0.8020\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4911 - acc: 0.8537\n",
      "Epoch 00008: val_loss improved from 0.63115 to 0.44196, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/008-0.4420.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4911 - acc: 0.8537 - val_loss: 0.4420 - val_acc: 0.8812\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8671\n",
      "Epoch 00009: val_loss improved from 0.44196 to 0.40998, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/009-0.4100.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.4441 - acc: 0.8671 - val_loss: 0.4100 - val_acc: 0.8947\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8826\n",
      "Epoch 00010: val_loss did not improve from 0.40998\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.3893 - acc: 0.8825 - val_loss: 0.4111 - val_acc: 0.8863\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3513 - acc: 0.8932\n",
      "Epoch 00011: val_loss improved from 0.40998 to 0.39094, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/011-0.3909.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.3513 - acc: 0.8932 - val_loss: 0.3909 - val_acc: 0.8998\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3148 - acc: 0.9060\n",
      "Epoch 00012: val_loss did not improve from 0.39094\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3152 - acc: 0.9059 - val_loss: 0.4531 - val_acc: 0.8870\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.9055\n",
      "Epoch 00013: val_loss did not improve from 0.39094\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3033 - acc: 0.9054 - val_loss: 0.4103 - val_acc: 0.8875\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2603 - acc: 0.9180\n",
      "Epoch 00014: val_loss did not improve from 0.39094\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2604 - acc: 0.9179 - val_loss: 0.4337 - val_acc: 0.8873\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9252\n",
      "Epoch 00015: val_loss improved from 0.39094 to 0.36845, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/015-0.3685.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.2383 - acc: 0.9253 - val_loss: 0.3685 - val_acc: 0.9043\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9318\n",
      "Epoch 00016: val_loss did not improve from 0.36845\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2148 - acc: 0.9319 - val_loss: 0.4057 - val_acc: 0.8961\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9375\n",
      "Epoch 00017: val_loss did not improve from 0.36845\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1959 - acc: 0.9375 - val_loss: 0.3778 - val_acc: 0.9089\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9431\n",
      "Epoch 00018: val_loss improved from 0.36845 to 0.35209, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_32_DO_BN_checkpoint/018-0.3521.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1780 - acc: 0.9431 - val_loss: 0.3521 - val_acc: 0.9147\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9442\n",
      "Epoch 00019: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.1717 - acc: 0.9441 - val_loss: 0.4915 - val_acc: 0.8796\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9460\n",
      "Epoch 00020: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1690 - acc: 0.9460 - val_loss: 0.3725 - val_acc: 0.9131\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9555\n",
      "Epoch 00021: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1370 - acc: 0.9555 - val_loss: 0.3663 - val_acc: 0.9085\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9547\n",
      "Epoch 00022: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1375 - acc: 0.9547 - val_loss: 0.3639 - val_acc: 0.9180\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9599\n",
      "Epoch 00023: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1222 - acc: 0.9599 - val_loss: 0.3616 - val_acc: 0.9152\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9614\n",
      "Epoch 00024: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1190 - acc: 0.9613 - val_loss: 0.5034 - val_acc: 0.8840\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9599\n",
      "Epoch 00025: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1220 - acc: 0.9599 - val_loss: 0.3669 - val_acc: 0.9178\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9667\n",
      "Epoch 00026: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0995 - acc: 0.9667 - val_loss: 0.4691 - val_acc: 0.8959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9673\n",
      "Epoch 00027: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0993 - acc: 0.9673 - val_loss: 0.3697 - val_acc: 0.9199\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9704\n",
      "Epoch 00028: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0899 - acc: 0.9704 - val_loss: 0.3724 - val_acc: 0.9117\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0903 - acc: 0.9704\n",
      "Epoch 00029: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0903 - acc: 0.9704 - val_loss: 0.4061 - val_acc: 0.9075\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9707\n",
      "Epoch 00030: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0901 - acc: 0.9707 - val_loss: 0.3838 - val_acc: 0.9159\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9735\n",
      "Epoch 00031: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0798 - acc: 0.9735 - val_loss: 0.4191 - val_acc: 0.9040\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9728\n",
      "Epoch 00032: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0793 - acc: 0.9727 - val_loss: 0.4388 - val_acc: 0.9082\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9710\n",
      "Epoch 00033: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0891 - acc: 0.9710 - val_loss: 0.3604 - val_acc: 0.9175\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9778\n",
      "Epoch 00034: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0673 - acc: 0.9778 - val_loss: 0.3712 - val_acc: 0.9161\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9799\n",
      "Epoch 00035: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0629 - acc: 0.9799 - val_loss: 0.4027 - val_acc: 0.9099\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9778\n",
      "Epoch 00036: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0686 - acc: 0.9777 - val_loss: 0.4525 - val_acc: 0.9157\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9773\n",
      "Epoch 00037: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0701 - acc: 0.9773 - val_loss: 0.3655 - val_acc: 0.9215\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9814\n",
      "Epoch 00038: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0586 - acc: 0.9814 - val_loss: 0.4206 - val_acc: 0.9113\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9806\n",
      "Epoch 00039: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0611 - acc: 0.9806 - val_loss: 0.4184 - val_acc: 0.9159\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9800\n",
      "Epoch 00040: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0603 - acc: 0.9800 - val_loss: 0.3966 - val_acc: 0.9168\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9816\n",
      "Epoch 00041: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0560 - acc: 0.9815 - val_loss: 0.4141 - val_acc: 0.9187\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9811\n",
      "Epoch 00042: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0599 - acc: 0.9811 - val_loss: 0.4827 - val_acc: 0.8977\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9836\n",
      "Epoch 00043: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0499 - acc: 0.9835 - val_loss: 0.4098 - val_acc: 0.9108\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9817\n",
      "Epoch 00044: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0577 - acc: 0.9816 - val_loss: 0.4062 - val_acc: 0.9154\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9813\n",
      "Epoch 00045: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0590 - acc: 0.9812 - val_loss: 0.4226 - val_acc: 0.9166\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9812\n",
      "Epoch 00046: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0564 - acc: 0.9812 - val_loss: 0.4068 - val_acc: 0.9206\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9844\n",
      "Epoch 00047: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0468 - acc: 0.9844 - val_loss: 0.4313 - val_acc: 0.9124\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9816\n",
      "Epoch 00048: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0568 - acc: 0.9816 - val_loss: 0.5116 - val_acc: 0.9106\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9845\n",
      "Epoch 00049: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0493 - acc: 0.9845 - val_loss: 0.4308 - val_acc: 0.9201\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9855\n",
      "Epoch 00050: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0460 - acc: 0.9854 - val_loss: 0.4077 - val_acc: 0.9164\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9810\n",
      "Epoch 00051: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0626 - acc: 0.9810 - val_loss: 0.4315 - val_acc: 0.9152\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9834\n",
      "Epoch 00052: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0529 - acc: 0.9834 - val_loss: 0.4050 - val_acc: 0.9241\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9887\n",
      "Epoch 00053: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0377 - acc: 0.9886 - val_loss: 0.4324 - val_acc: 0.9164\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9845\n",
      "Epoch 00054: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0467 - acc: 0.9845 - val_loss: 0.4851 - val_acc: 0.9140\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9880\n",
      "Epoch 00055: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0383 - acc: 0.9880 - val_loss: 0.4419 - val_acc: 0.9213\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9862\n",
      "Epoch 00056: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0404 - acc: 0.9862 - val_loss: 0.4862 - val_acc: 0.9115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9873\n",
      "Epoch 00057: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0403 - acc: 0.9873 - val_loss: 0.5471 - val_acc: 0.9052\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9855\n",
      "Epoch 00058: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0459 - acc: 0.9855 - val_loss: 0.4509 - val_acc: 0.9164\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9870\n",
      "Epoch 00059: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0427 - acc: 0.9869 - val_loss: 0.4669 - val_acc: 0.9187\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9862\n",
      "Epoch 00060: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0444 - acc: 0.9862 - val_loss: 0.4549 - val_acc: 0.9231\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9852\n",
      "Epoch 00061: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0443 - acc: 0.9852 - val_loss: 0.4895 - val_acc: 0.9103\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9885\n",
      "Epoch 00062: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0377 - acc: 0.9885 - val_loss: 0.4414 - val_acc: 0.9189\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9871\n",
      "Epoch 00063: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0385 - acc: 0.9871 - val_loss: 0.4409 - val_acc: 0.9192\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9889\n",
      "Epoch 00064: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0350 - acc: 0.9889 - val_loss: 0.4463 - val_acc: 0.9164\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9881\n",
      "Epoch 00065: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0366 - acc: 0.9881 - val_loss: 0.4426 - val_acc: 0.9224\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9891\n",
      "Epoch 00066: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0350 - acc: 0.9891 - val_loss: 0.4348 - val_acc: 0.9175\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9885\n",
      "Epoch 00067: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0372 - acc: 0.9885 - val_loss: 0.5627 - val_acc: 0.9064\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9872\n",
      "Epoch 00068: val_loss did not improve from 0.35209\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0408 - acc: 0.9872 - val_loss: 0.5089 - val_acc: 0.9038\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_32_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 858us/sample - loss: 0.4129 - acc: 0.8879\n",
      "Loss: 0.4129287703881506 Accuracy: 0.88785046\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2990 - acc: 0.3801\n",
      "Epoch 00001: val_loss improved from inf to 6.66314, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/001-6.6631.hdf5\n",
      "36805/36805 [==============================] - 78s 2ms/sample - loss: 2.2989 - acc: 0.3801 - val_loss: 6.6631 - val_acc: 0.1491\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2134 - acc: 0.6423\n",
      "Epoch 00002: val_loss improved from 6.66314 to 1.01406, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/002-1.0141.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 1.2137 - acc: 0.6422 - val_loss: 1.0141 - val_acc: 0.7077\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8214 - acc: 0.7548\n",
      "Epoch 00003: val_loss improved from 1.01406 to 0.46881, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/003-0.4688.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.8215 - acc: 0.7548 - val_loss: 0.4688 - val_acc: 0.8665\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.8159\n",
      "Epoch 00004: val_loss improved from 0.46881 to 0.46078, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/004-0.4608.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6098 - acc: 0.8158 - val_loss: 0.4608 - val_acc: 0.8700\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4844 - acc: 0.8527\n",
      "Epoch 00005: val_loss improved from 0.46078 to 0.35014, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/005-0.3501.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.4844 - acc: 0.8527 - val_loss: 0.3501 - val_acc: 0.9052\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3972 - acc: 0.8789\n",
      "Epoch 00006: val_loss did not improve from 0.35014\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3972 - acc: 0.8789 - val_loss: 0.3577 - val_acc: 0.9040\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8978\n",
      "Epoch 00007: val_loss improved from 0.35014 to 0.26133, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/007-0.2613.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3363 - acc: 0.8977 - val_loss: 0.2613 - val_acc: 0.9301\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2895 - acc: 0.9087\n",
      "Epoch 00008: val_loss improved from 0.26133 to 0.24810, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/008-0.2481.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2895 - acc: 0.9087 - val_loss: 0.2481 - val_acc: 0.9292\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.9209\n",
      "Epoch 00009: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2506 - acc: 0.9209 - val_loss: 0.2954 - val_acc: 0.9248\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9289\n",
      "Epoch 00010: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.2247 - acc: 0.9289 - val_loss: 0.3193 - val_acc: 0.9161\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9377\n",
      "Epoch 00011: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1951 - acc: 0.9378 - val_loss: 0.2548 - val_acc: 0.9313\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9461\n",
      "Epoch 00012: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1630 - acc: 0.9461 - val_loss: 0.2630 - val_acc: 0.9238\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9493\n",
      "Epoch 00013: val_loss did not improve from 0.24810\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1561 - acc: 0.9493 - val_loss: 0.2524 - val_acc: 0.9331\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9563\n",
      "Epoch 00014: val_loss improved from 0.24810 to 0.23912, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/014-0.2391.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1375 - acc: 0.9563 - val_loss: 0.2391 - val_acc: 0.9364\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9595\n",
      "Epoch 00015: val_loss improved from 0.23912 to 0.21381, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_32_DO_BN_checkpoint/015-0.2138.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1237 - acc: 0.9594 - val_loss: 0.2138 - val_acc: 0.9448\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9601\n",
      "Epoch 00016: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1190 - acc: 0.9601 - val_loss: 0.4498 - val_acc: 0.8882\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9616\n",
      "Epoch 00017: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1158 - acc: 0.9616 - val_loss: 0.2204 - val_acc: 0.9385\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9696\n",
      "Epoch 00018: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0918 - acc: 0.9696 - val_loss: 0.2606 - val_acc: 0.9348\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9716\n",
      "Epoch 00019: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0856 - acc: 0.9716 - val_loss: 0.2320 - val_acc: 0.9390\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9751\n",
      "Epoch 00020: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0764 - acc: 0.9750 - val_loss: 0.2537 - val_acc: 0.9408\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9738\n",
      "Epoch 00021: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0810 - acc: 0.9738 - val_loss: 0.2516 - val_acc: 0.9327\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9772\n",
      "Epoch 00022: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0678 - acc: 0.9771 - val_loss: 0.3077 - val_acc: 0.9264\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9771\n",
      "Epoch 00023: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0678 - acc: 0.9770 - val_loss: 0.2211 - val_acc: 0.9455\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9745\n",
      "Epoch 00024: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0777 - acc: 0.9745 - val_loss: 0.2537 - val_acc: 0.9373\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9842\n",
      "Epoch 00025: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0497 - acc: 0.9842 - val_loss: 0.2828 - val_acc: 0.9311\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9803\n",
      "Epoch 00026: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0580 - acc: 0.9803 - val_loss: 0.2204 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9841\n",
      "Epoch 00027: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0500 - acc: 0.9841 - val_loss: 0.2497 - val_acc: 0.9425\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9839\n",
      "Epoch 00028: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0489 - acc: 0.9839 - val_loss: 0.2930 - val_acc: 0.9341\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9840\n",
      "Epoch 00029: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0491 - acc: 0.9840 - val_loss: 0.2728 - val_acc: 0.9415\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9817\n",
      "Epoch 00030: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0562 - acc: 0.9816 - val_loss: 0.4350 - val_acc: 0.9029\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9839\n",
      "Epoch 00031: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0494 - acc: 0.9838 - val_loss: 0.2508 - val_acc: 0.9495\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9843\n",
      "Epoch 00032: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0481 - acc: 0.9843 - val_loss: 0.2409 - val_acc: 0.9422\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9888\n",
      "Epoch 00033: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0349 - acc: 0.9888 - val_loss: 0.2216 - val_acc: 0.9506\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9889\n",
      "Epoch 00034: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0337 - acc: 0.9889 - val_loss: 0.2784 - val_acc: 0.9413\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9887\n",
      "Epoch 00035: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0343 - acc: 0.9887 - val_loss: 0.2820 - val_acc: 0.9376\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9879\n",
      "Epoch 00036: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0383 - acc: 0.9879 - val_loss: 0.2414 - val_acc: 0.9478\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9904\n",
      "Epoch 00037: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0297 - acc: 0.9904 - val_loss: 0.2372 - val_acc: 0.9488\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9890\n",
      "Epoch 00038: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0332 - acc: 0.9890 - val_loss: 0.2591 - val_acc: 0.9427\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9905\n",
      "Epoch 00039: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0292 - acc: 0.9905 - val_loss: 0.2496 - val_acc: 0.9481\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9899\n",
      "Epoch 00040: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0323 - acc: 0.9899 - val_loss: 0.2813 - val_acc: 0.9457\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9902\n",
      "Epoch 00041: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0304 - acc: 0.9902 - val_loss: 0.2876 - val_acc: 0.9387\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9849\n",
      "Epoch 00042: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0480 - acc: 0.9849 - val_loss: 0.2895 - val_acc: 0.9394\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9923\n",
      "Epoch 00043: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0246 - acc: 0.9923 - val_loss: 0.2232 - val_acc: 0.9532\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9920\n",
      "Epoch 00044: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0235 - acc: 0.9920 - val_loss: 0.2347 - val_acc: 0.9522\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9925\n",
      "Epoch 00045: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0241 - acc: 0.9925 - val_loss: 0.2502 - val_acc: 0.9497\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9927\n",
      "Epoch 00046: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0236 - acc: 0.9926 - val_loss: 0.2819 - val_acc: 0.9485\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9894\n",
      "Epoch 00047: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0343 - acc: 0.9894 - val_loss: 0.2739 - val_acc: 0.9443\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9885\n",
      "Epoch 00048: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0355 - acc: 0.9885 - val_loss: 0.2615 - val_acc: 0.9497\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9930\n",
      "Epoch 00049: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0212 - acc: 0.9930 - val_loss: 0.2816 - val_acc: 0.9425\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9866\n",
      "Epoch 00050: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0402 - acc: 0.9866 - val_loss: 0.2428 - val_acc: 0.9532\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9940\n",
      "Epoch 00051: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0195 - acc: 0.9940 - val_loss: 0.2429 - val_acc: 0.9513\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945\n",
      "Epoch 00052: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0184 - acc: 0.9945 - val_loss: 0.3339 - val_acc: 0.9259\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9935\n",
      "Epoch 00053: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0196 - acc: 0.9935 - val_loss: 0.2520 - val_acc: 0.9518\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9930\n",
      "Epoch 00054: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0219 - acc: 0.9930 - val_loss: 0.2955 - val_acc: 0.9366\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9909\n",
      "Epoch 00055: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0275 - acc: 0.9909 - val_loss: 0.2660 - val_acc: 0.9457\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9925\n",
      "Epoch 00056: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0228 - acc: 0.9925 - val_loss: 0.2409 - val_acc: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9934\n",
      "Epoch 00057: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0215 - acc: 0.9934 - val_loss: 0.2530 - val_acc: 0.9511\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9903\n",
      "Epoch 00058: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0301 - acc: 0.9903 - val_loss: 0.2474 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9946\n",
      "Epoch 00059: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0172 - acc: 0.9945 - val_loss: 0.2141 - val_acc: 0.9609\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9909\n",
      "Epoch 00060: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0272 - acc: 0.9908 - val_loss: 0.2477 - val_acc: 0.9492\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9941\n",
      "Epoch 00061: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0176 - acc: 0.9941 - val_loss: 0.2605 - val_acc: 0.9476\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9941\n",
      "Epoch 00062: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0190 - acc: 0.9941 - val_loss: 0.2723 - val_acc: 0.9460\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9907\n",
      "Epoch 00063: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0295 - acc: 0.9907 - val_loss: 0.2509 - val_acc: 0.9515\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9950\n",
      "Epoch 00064: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0161 - acc: 0.9950 - val_loss: 0.2334 - val_acc: 0.9567\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9962\n",
      "Epoch 00065: val_loss did not improve from 0.21381\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0128 - acc: 0.9962 - val_loss: 0.3890 - val_acc: 0.9278\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_32_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 913us/sample - loss: 0.2675 - acc: 0.9242\n",
      "Loss: 0.2674995232686818 Accuracy: 0.92419523\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1653 - acc: 0.4034\n",
      "Epoch 00001: val_loss improved from inf to 4.76863, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/001-4.7686.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 2.1654 - acc: 0.4034 - val_loss: 4.7686 - val_acc: 0.2003\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0654 - acc: 0.6701\n",
      "Epoch 00002: val_loss improved from 4.76863 to 0.67890, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/002-0.6789.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 1.0658 - acc: 0.6700 - val_loss: 0.6789 - val_acc: 0.7866\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7033 - acc: 0.7839\n",
      "Epoch 00003: val_loss improved from 0.67890 to 0.50154, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/003-0.5015.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.7036 - acc: 0.7839 - val_loss: 0.5015 - val_acc: 0.8484\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5250 - acc: 0.8385\n",
      "Epoch 00004: val_loss improved from 0.50154 to 0.37887, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/004-0.3789.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.5250 - acc: 0.8385 - val_loss: 0.3789 - val_acc: 0.8826\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4108 - acc: 0.8741\n",
      "Epoch 00005: val_loss improved from 0.37887 to 0.36483, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/005-0.3648.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.4110 - acc: 0.8741 - val_loss: 0.3648 - val_acc: 0.8933\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8932\n",
      "Epoch 00006: val_loss improved from 0.36483 to 0.31087, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/006-0.3109.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3406 - acc: 0.8932 - val_loss: 0.3109 - val_acc: 0.9080\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.9088\n",
      "Epoch 00007: val_loss improved from 0.31087 to 0.28424, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/007-0.2842.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2924 - acc: 0.9087 - val_loss: 0.2842 - val_acc: 0.9159\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9184\n",
      "Epoch 00008: val_loss improved from 0.28424 to 0.25824, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/008-0.2582.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2608 - acc: 0.9184 - val_loss: 0.2582 - val_acc: 0.9231\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9308\n",
      "Epoch 00009: val_loss improved from 0.25824 to 0.21406, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/009-0.2141.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2189 - acc: 0.9308 - val_loss: 0.2141 - val_acc: 0.9401\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9372\n",
      "Epoch 00010: val_loss improved from 0.21406 to 0.20665, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/010-0.2067.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1967 - acc: 0.9372 - val_loss: 0.2067 - val_acc: 0.9378\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9464\n",
      "Epoch 00011: val_loss improved from 0.20665 to 0.19443, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/011-0.1944.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1709 - acc: 0.9464 - val_loss: 0.1944 - val_acc: 0.9415\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1571 - acc: 0.9497\n",
      "Epoch 00012: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1572 - acc: 0.9497 - val_loss: 0.2356 - val_acc: 0.9355\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9512\n",
      "Epoch 00013: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1513 - acc: 0.9512 - val_loss: 0.2329 - val_acc: 0.9329\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9606\n",
      "Epoch 00014: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1274 - acc: 0.9606 - val_loss: 0.2061 - val_acc: 0.9406\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9657\n",
      "Epoch 00015: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1089 - acc: 0.9657 - val_loss: 0.2112 - val_acc: 0.9369\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9645\n",
      "Epoch 00016: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1103 - acc: 0.9645 - val_loss: 0.2374 - val_acc: 0.9355\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9697\n",
      "Epoch 00017: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0939 - acc: 0.9697 - val_loss: 0.1962 - val_acc: 0.9401\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9666\n",
      "Epoch 00018: val_loss did not improve from 0.19443\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1056 - acc: 0.9666 - val_loss: 0.5120 - val_acc: 0.8826\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9637\n",
      "Epoch 00019: val_loss improved from 0.19443 to 0.18971, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/019-0.1897.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1146 - acc: 0.9637 - val_loss: 0.1897 - val_acc: 0.9506\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9743\n",
      "Epoch 00020: val_loss did not improve from 0.18971\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0788 - acc: 0.9743 - val_loss: 0.3645 - val_acc: 0.9143\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9739\n",
      "Epoch 00021: val_loss did not improve from 0.18971\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0818 - acc: 0.9739 - val_loss: 0.1917 - val_acc: 0.9511\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9795\n",
      "Epoch 00022: val_loss did not improve from 0.18971\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0670 - acc: 0.9795 - val_loss: 0.1908 - val_acc: 0.9504\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9808\n",
      "Epoch 00023: val_loss improved from 0.18971 to 0.16928, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_32_DO_BN_checkpoint/023-0.1693.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0609 - acc: 0.9808 - val_loss: 0.1693 - val_acc: 0.9529\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9752\n",
      "Epoch 00024: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0776 - acc: 0.9752 - val_loss: 0.1779 - val_acc: 0.9518\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9793\n",
      "Epoch 00025: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0625 - acc: 0.9793 - val_loss: 0.2723 - val_acc: 0.9315\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9842\n",
      "Epoch 00026: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0489 - acc: 0.9842 - val_loss: 0.2065 - val_acc: 0.9520\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9854- ETA: 0s - loss: 0.0456 - acc\n",
      "Epoch 00027: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0458 - acc: 0.9853 - val_loss: 0.2343 - val_acc: 0.9376\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9828\n",
      "Epoch 00028: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0553 - acc: 0.9828 - val_loss: 0.2341 - val_acc: 0.9492\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9801\n",
      "Epoch 00029: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0603 - acc: 0.9801 - val_loss: 0.2026 - val_acc: 0.9522\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9831\n",
      "Epoch 00030: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0534 - acc: 0.9831 - val_loss: 0.1821 - val_acc: 0.9550\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9896\n",
      "Epoch 00031: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0343 - acc: 0.9896 - val_loss: 0.1867 - val_acc: 0.9546\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9827\n",
      "Epoch 00032: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0531 - acc: 0.9827 - val_loss: 0.1998 - val_acc: 0.9471\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9856\n",
      "Epoch 00033: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0446 - acc: 0.9856 - val_loss: 0.1736 - val_acc: 0.9548\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9894\n",
      "Epoch 00034: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0340 - acc: 0.9894 - val_loss: 0.1910 - val_acc: 0.9534\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9888\n",
      "Epoch 00035: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0351 - acc: 0.9888 - val_loss: 0.1900 - val_acc: 0.9555\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9896\n",
      "Epoch 00036: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0311 - acc: 0.9896 - val_loss: 0.1806 - val_acc: 0.9532\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9894\n",
      "Epoch 00037: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0339 - acc: 0.9894 - val_loss: 0.2067 - val_acc: 0.9490\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9859\n",
      "Epoch 00038: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0451 - acc: 0.9859 - val_loss: 0.2360 - val_acc: 0.9425\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9909\n",
      "Epoch 00039: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0285 - acc: 0.9909 - val_loss: 0.2725 - val_acc: 0.9436\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9917\n",
      "Epoch 00040: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0278 - acc: 0.9917 - val_loss: 0.2153 - val_acc: 0.9492\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9905\n",
      "Epoch 00041: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0313 - acc: 0.9905 - val_loss: 0.2909 - val_acc: 0.9317\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9912\n",
      "Epoch 00042: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0287 - acc: 0.9912 - val_loss: 0.2531 - val_acc: 0.9497\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9882\n",
      "Epoch 00043: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0369 - acc: 0.9882 - val_loss: 0.1866 - val_acc: 0.9557\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9927\n",
      "Epoch 00044: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0252 - acc: 0.9927 - val_loss: 0.2047 - val_acc: 0.9520\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0201 - acc: 0.9938 - val_loss: 0.2317 - val_acc: 0.9499\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9904\n",
      "Epoch 00046: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0300 - acc: 0.9904 - val_loss: 0.3007 - val_acc: 0.9390\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9923\n",
      "Epoch 00047: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0249 - acc: 0.9922 - val_loss: 0.3666 - val_acc: 0.9182\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9902\n",
      "Epoch 00048: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0317 - acc: 0.9902 - val_loss: 0.2285 - val_acc: 0.9518\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9922\n",
      "Epoch 00049: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0252 - acc: 0.9921 - val_loss: 0.2147 - val_acc: 0.9520\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9885\n",
      "Epoch 00050: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0351 - acc: 0.9885 - val_loss: 0.2260 - val_acc: 0.9483\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9956\n",
      "Epoch 00051: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0166 - acc: 0.9956 - val_loss: 0.1949 - val_acc: 0.9564\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 00052: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0179 - acc: 0.9946 - val_loss: 0.2795 - val_acc: 0.9390\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9930\n",
      "Epoch 00053: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0230 - acc: 0.9929 - val_loss: 0.2414 - val_acc: 0.9525\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9916\n",
      "Epoch 00054: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0262 - acc: 0.9916 - val_loss: 0.2434 - val_acc: 0.9490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9899\n",
      "Epoch 00055: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0323 - acc: 0.9899 - val_loss: 0.1893 - val_acc: 0.9567\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9957\n",
      "Epoch 00056: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0144 - acc: 0.9957 - val_loss: 0.1957 - val_acc: 0.9588\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9942\n",
      "Epoch 00057: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0179 - acc: 0.9942 - val_loss: 0.2179 - val_acc: 0.9536\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9897\n",
      "Epoch 00058: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0321 - acc: 0.9897 - val_loss: 0.2051 - val_acc: 0.9557\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9955\n",
      "Epoch 00059: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0143 - acc: 0.9955 - val_loss: 0.1898 - val_acc: 0.9609\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9927\n",
      "Epoch 00060: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0245 - acc: 0.9927 - val_loss: 0.2595 - val_acc: 0.9450\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9948\n",
      "Epoch 00061: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0186 - acc: 0.9948 - val_loss: 0.2172 - val_acc: 0.9555\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9960\n",
      "Epoch 00062: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0126 - acc: 0.9960 - val_loss: 0.1899 - val_acc: 0.9578\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9935\n",
      "Epoch 00063: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0206 - acc: 0.9935 - val_loss: 0.2540 - val_acc: 0.9497\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9908\n",
      "Epoch 00064: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0305 - acc: 0.9908 - val_loss: 0.1987 - val_acc: 0.9569\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9961\n",
      "Epoch 00065: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.2158 - val_acc: 0.9553\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9920\n",
      "Epoch 00066: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0261 - acc: 0.9920 - val_loss: 0.1922 - val_acc: 0.9592\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9961\n",
      "Epoch 00067: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0127 - acc: 0.9961 - val_loss: 0.2011 - val_acc: 0.9522\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9955\n",
      "Epoch 00068: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0148 - acc: 0.9955 - val_loss: 0.2093 - val_acc: 0.9578\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 00069: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0119 - acc: 0.9964 - val_loss: 0.2105 - val_acc: 0.9511\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9902\n",
      "Epoch 00070: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0310 - acc: 0.9901 - val_loss: 0.2322 - val_acc: 0.9539\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9920\n",
      "Epoch 00071: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0274 - acc: 0.9920 - val_loss: 0.2146 - val_acc: 0.9560\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9948\n",
      "Epoch 00072: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0170 - acc: 0.9948 - val_loss: 0.1967 - val_acc: 0.9597\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 00073: val_loss did not improve from 0.16928\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0092 - acc: 0.9976 - val_loss: 0.2091 - val_acc: 0.9574\n",
      "\n",
      "1D_CNN_6_only_conv_pool_3_ch_32_DO_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 964us/sample - loss: 0.2220 - acc: 0.9379\n",
      "Loss: 0.22201685277070088 Accuracy: 0.9379024\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_32_DO_BN'.format(i)\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_32_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_32_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_105 (Conv1D)          (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_30 (Flatten)         (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 170432)            0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 16)                2726928   \n",
      "=================================================================\n",
      "Total params: 2,727,888\n",
      "Trainable params: 2,727,824\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 703us/sample - loss: 1.7332 - acc: 0.4833\n",
      "Loss: 1.733176219277664 Accuracy: 0.4832814\n",
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_32_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_31 (Flatten)         (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 56576)             0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 16)                905232    \n",
      "=================================================================\n",
      "Total params: 931,952\n",
      "Trainable params: 931,824\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 845us/sample - loss: 1.5087 - acc: 0.6314\n",
      "Loss: 1.5087162107941023 Accuracy: 0.63136035\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_32_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_108 (Conv1D)          (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_32 (Flatten)         (None, 37248)             0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 37248)             0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 16)                595984    \n",
      "=================================================================\n",
      "Total params: 674,224\n",
      "Trainable params: 673,968\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 922us/sample - loss: 0.9034 - acc: 0.7657\n",
      "Loss: 0.9033839555172906 Accuracy: 0.7657321\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_32_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_111 (Conv1D)          (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_33 (Flatten)         (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 11904)             0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 16)                190480    \n",
      "=================================================================\n",
      "Total params: 371,440\n",
      "Trainable params: 371,056\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 965us/sample - loss: 0.4129 - acc: 0.8879\n",
      "Loss: 0.4129287703881506 Accuracy: 0.88785046\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_32_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_115 (Conv1D)          (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_34 (Flatten)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 6912)              0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 16)                110608    \n",
      "=================================================================\n",
      "Total params: 497,008\n",
      "Trainable params: 496,368\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2675 - acc: 0.9242\n",
      "Loss: 0.2674995232686818 Accuracy: 0.92419523\n",
      "\n",
      "1D_CNN_6_only_conv_pool_3_ch_32_DO_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 15976, 32)         832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 15976, 32)         128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 5326, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 5302, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 5302, 32)          128       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 1768, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 1744, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 1744, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 582, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 558, 64)           102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 558, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 186, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 162, 128)          204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 162, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 54, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 30, 128)           409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 30, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 16)                20496     \n",
      "=================================================================\n",
      "Total params: 817,136\n",
      "Trainable params: 816,240\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2220 - acc: 0.9379\n",
      "Loss: 0.22201685277070088 Accuracy: 0.9379024\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_32_DO_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
