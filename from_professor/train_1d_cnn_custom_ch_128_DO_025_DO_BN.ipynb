{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_128_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=128, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=128*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,805,712\n",
      "Trainable params: 3,804,944\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,461,392\n",
      "Trainable params: 1,460,368\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,221,008\n",
      "Trainable params: 1,219,472\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,009,296\n",
      "Trainable params: 1,007,248\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,158,032\n",
      "Trainable params: 1,155,472\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,429,648\n",
      "Trainable params: 1,426,576\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,075,280\n",
      "Trainable params: 2,071,184\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_128_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6232 - acc: 0.3611\n",
      "Epoch 00001: val_loss improved from inf to 4.35084, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_3_conv_checkpoint/001-4.3508.hdf5\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 4.6227 - acc: 0.3611 - val_loss: 4.3508 - val_acc: 0.3909\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9939 - acc: 0.5027\n",
      "Epoch 00002: val_loss did not improve from 4.35084\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.9939 - acc: 0.5028 - val_loss: 4.5791 - val_acc: 0.3979\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.6962 - acc: 0.5819\n",
      "Epoch 00003: val_loss improved from 4.35084 to 4.12953, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_3_conv_checkpoint/003-4.1295.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.6966 - acc: 0.5819 - val_loss: 4.1295 - val_acc: 0.4833\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5138 - acc: 0.6345\n",
      "Epoch 00004: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.5142 - acc: 0.6345 - val_loss: 4.6151 - val_acc: 0.4361\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3447 - acc: 0.6849\n",
      "Epoch 00005: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.3442 - acc: 0.6849 - val_loss: 4.5201 - val_acc: 0.4621\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2787 - acc: 0.7053\n",
      "Epoch 00006: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.2784 - acc: 0.7053 - val_loss: 4.5432 - val_acc: 0.4826\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2153 - acc: 0.7250\n",
      "Epoch 00007: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.2150 - acc: 0.7250 - val_loss: 5.2011 - val_acc: 0.4023\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1783 - acc: 0.7395\n",
      "Epoch 00008: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.1792 - acc: 0.7394 - val_loss: 4.6207 - val_acc: 0.4894\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1236 - acc: 0.7558\n",
      "Epoch 00009: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.1232 - acc: 0.7558 - val_loss: 5.1108 - val_acc: 0.4260\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1111 - acc: 0.7596\n",
      "Epoch 00010: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.1110 - acc: 0.7596 - val_loss: 5.5532 - val_acc: 0.4258\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3588 - acc: 0.6967\n",
      "Epoch 00011: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3587 - acc: 0.6968 - val_loss: 5.8033 - val_acc: 0.4717\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3702 - acc: 0.6968\n",
      "Epoch 00012: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3697 - acc: 0.6968 - val_loss: 5.8618 - val_acc: 0.4605\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3606 - acc: 0.6992\n",
      "Epoch 00013: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3605 - acc: 0.6992 - val_loss: 6.3585 - val_acc: 0.4291\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3267 - acc: 0.7083\n",
      "Epoch 00014: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3270 - acc: 0.7083 - val_loss: 5.6537 - val_acc: 0.5015\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3393 - acc: 0.7050\n",
      "Epoch 00015: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3387 - acc: 0.7051 - val_loss: 5.7574 - val_acc: 0.4941\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3084 - acc: 0.7137\n",
      "Epoch 00016: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3087 - acc: 0.7137 - val_loss: 5.5361 - val_acc: 0.5257\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3291 - acc: 0.7091\n",
      "Epoch 00017: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3291 - acc: 0.7091 - val_loss: 5.7487 - val_acc: 0.5031\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3365 - acc: 0.7072\n",
      "Epoch 00018: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3364 - acc: 0.7072 - val_loss: 6.1739 - val_acc: 0.4656\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3046 - acc: 0.7155\n",
      "Epoch 00019: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3046 - acc: 0.7154 - val_loss: 6.0637 - val_acc: 0.4773\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3237 - acc: 0.7126\n",
      "Epoch 00020: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3232 - acc: 0.7126 - val_loss: 6.1874 - val_acc: 0.4633\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2893 - acc: 0.7208\n",
      "Epoch 00021: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2896 - acc: 0.7207 - val_loss: 5.8532 - val_acc: 0.5120\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3237 - acc: 0.7131\n",
      "Epoch 00022: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3239 - acc: 0.7131 - val_loss: 5.9810 - val_acc: 0.4994\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2897 - acc: 0.7204\n",
      "Epoch 00023: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2892 - acc: 0.7204 - val_loss: 5.8167 - val_acc: 0.5139\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2968 - acc: 0.7185\n",
      "Epoch 00024: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2967 - acc: 0.7185 - val_loss: 6.2270 - val_acc: 0.4768\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2797 - acc: 0.7223\n",
      "Epoch 00025: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2796 - acc: 0.7223 - val_loss: 5.8238 - val_acc: 0.5208\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3131 - acc: 0.7163\n",
      "Epoch 00026: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.3143 - acc: 0.7162 - val_loss: 6.0499 - val_acc: 0.4864\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2867 - acc: 0.7219\n",
      "Epoch 00027: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2861 - acc: 0.7219 - val_loss: 5.8982 - val_acc: 0.5076\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2934 - acc: 0.7201\n",
      "Epoch 00028: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2932 - acc: 0.7201 - val_loss: 6.1485 - val_acc: 0.4957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2727 - acc: 0.7256\n",
      "Epoch 00029: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2730 - acc: 0.7256 - val_loss: 6.0568 - val_acc: 0.4976\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2738 - acc: 0.7246\n",
      "Epoch 00030: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2741 - acc: 0.7245 - val_loss: 5.8020 - val_acc: 0.5262\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2951 - acc: 0.7193\n",
      "Epoch 00031: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2945 - acc: 0.7193 - val_loss: 6.3867 - val_acc: 0.4766\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2672 - acc: 0.7270\n",
      "Epoch 00032: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2675 - acc: 0.7270 - val_loss: 6.0494 - val_acc: 0.5066\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2751 - acc: 0.7251\n",
      "Epoch 00033: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 4.2754 - acc: 0.7251 - val_loss: 6.0686 - val_acc: 0.5099\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2710 - acc: 0.7269\n",
      "Epoch 00034: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2713 - acc: 0.7269 - val_loss: 6.4700 - val_acc: 0.4805\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2911 - acc: 0.7219\n",
      "Epoch 00035: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2909 - acc: 0.7219 - val_loss: 6.4447 - val_acc: 0.4764\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2591 - acc: 0.7290\n",
      "Epoch 00036: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2603 - acc: 0.7289 - val_loss: 6.2249 - val_acc: 0.4969\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2714 - acc: 0.7254\n",
      "Epoch 00037: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2713 - acc: 0.7254 - val_loss: 6.2183 - val_acc: 0.4913\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2679 - acc: 0.7280\n",
      "Epoch 00038: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2678 - acc: 0.7280 - val_loss: 6.1746 - val_acc: 0.5038\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2687 - acc: 0.7271\n",
      "Epoch 00039: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2681 - acc: 0.7272 - val_loss: 6.3133 - val_acc: 0.4866\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2648 - acc: 0.7279\n",
      "Epoch 00040: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2643 - acc: 0.7279 - val_loss: 6.9974 - val_acc: 0.4472\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2768 - acc: 0.7248\n",
      "Epoch 00041: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2771 - acc: 0.7248 - val_loss: 6.3498 - val_acc: 0.4966\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2632 - acc: 0.7280\n",
      "Epoch 00042: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.2637 - acc: 0.7280 - val_loss: 6.5381 - val_acc: 0.4815\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1788 - acc: 0.7269\n",
      "Epoch 00043: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 4.1791 - acc: 0.7269 - val_loss: 5.7260 - val_acc: 0.5125\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7544 - acc: 0.7446\n",
      "Epoch 00044: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.7546 - acc: 0.7446 - val_loss: 5.9230 - val_acc: 0.4931\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.6699 - acc: 0.7604\n",
      "Epoch 00045: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.6703 - acc: 0.7604 - val_loss: 5.6577 - val_acc: 0.5174\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2187 - acc: 0.7819\n",
      "Epoch 00046: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 3.2196 - acc: 0.7818 - val_loss: 4.8504 - val_acc: 0.5292\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4013 - acc: 0.8297\n",
      "Epoch 00047: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.4014 - acc: 0.8297 - val_loss: 4.6229 - val_acc: 0.5337\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3477 - acc: 0.8420\n",
      "Epoch 00048: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.3479 - acc: 0.8420 - val_loss: 4.7155 - val_acc: 0.5369\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3529 - acc: 0.8407\n",
      "Epoch 00049: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.3530 - acc: 0.8406 - val_loss: 4.7160 - val_acc: 0.5409\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3332 - acc: 0.8477\n",
      "Epoch 00050: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.3329 - acc: 0.8477 - val_loss: 4.5750 - val_acc: 0.5593\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3494 - acc: 0.8435\n",
      "Epoch 00051: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.3491 - acc: 0.8435 - val_loss: 4.9947 - val_acc: 0.5239\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3353 - acc: 0.8466\n",
      "Epoch 00052: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.3354 - acc: 0.8466 - val_loss: 4.6003 - val_acc: 0.5602\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3311 - acc: 0.8484\n",
      "Epoch 00053: val_loss did not improve from 4.12953\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.3307 - acc: 0.8484 - val_loss: 4.7737 - val_acc: 0.5481\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 4.1991 - acc: 0.4696\n",
      "Loss: 4.199091407294586 Accuracy: 0.46957424\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8331 - acc: 0.4470\n",
      "Epoch 00001: val_loss improved from inf to 1.60420, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv_checkpoint/001-1.6042.hdf5\n",
      "36805/36805 [==============================] - 186s 5ms/sample - loss: 1.8329 - acc: 0.4470 - val_loss: 1.6042 - val_acc: 0.5041\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2090 - acc: 0.6295\n",
      "Epoch 00002: val_loss improved from 1.60420 to 1.22562, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv_checkpoint/002-1.2256.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 1.2092 - acc: 0.6295 - val_loss: 1.2256 - val_acc: 0.6245\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9825 - acc: 0.6999\n",
      "Epoch 00003: val_loss improved from 1.22562 to 1.16766, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv_checkpoint/003-1.1677.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.9825 - acc: 0.7000 - val_loss: 1.1677 - val_acc: 0.6473\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8042 - acc: 0.7530\n",
      "Epoch 00004: val_loss improved from 1.16766 to 1.09209, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv_checkpoint/004-1.0921.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.8042 - acc: 0.7529 - val_loss: 1.0921 - val_acc: 0.6730\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6739 - acc: 0.7893\n",
      "Epoch 00005: val_loss did not improve from 1.09209\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.6738 - acc: 0.7893 - val_loss: 1.1260 - val_acc: 0.6725\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5515 - acc: 0.8277\n",
      "Epoch 00006: val_loss did not improve from 1.09209\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.5516 - acc: 0.8277 - val_loss: 1.1752 - val_acc: 0.6713\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4836 - acc: 0.8493\n",
      "Epoch 00007: val_loss did not improve from 1.09209\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.4836 - acc: 0.8494 - val_loss: 1.1177 - val_acc: 0.7016\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3695 - acc: 0.8847\n",
      "Epoch 00008: val_loss improved from 1.09209 to 1.06396, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv_checkpoint/008-1.0640.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.3695 - acc: 0.8847 - val_loss: 1.0640 - val_acc: 0.7186\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3123 - acc: 0.9035\n",
      "Epoch 00009: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.3124 - acc: 0.9035 - val_loss: 1.2129 - val_acc: 0.6811\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9166\n",
      "Epoch 00010: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2678 - acc: 0.9166 - val_loss: 1.5035 - val_acc: 0.6317\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9257\n",
      "Epoch 00011: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2380 - acc: 0.9257 - val_loss: 1.2588 - val_acc: 0.7021\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9389\n",
      "Epoch 00012: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.2011 - acc: 0.9389 - val_loss: 1.1590 - val_acc: 0.7237\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9448\n",
      "Epoch 00013: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1843 - acc: 0.9448 - val_loss: 1.2747 - val_acc: 0.7014\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9530\n",
      "Epoch 00014: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1576 - acc: 0.9530 - val_loss: 1.3151 - val_acc: 0.7126\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9565\n",
      "Epoch 00015: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1461 - acc: 0.9565 - val_loss: 1.3565 - val_acc: 0.6986\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9536\n",
      "Epoch 00016: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1503 - acc: 0.9536 - val_loss: 1.3172 - val_acc: 0.7137\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9635\n",
      "Epoch 00017: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1236 - acc: 0.9635 - val_loss: 1.6247 - val_acc: 0.6648\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9682\n",
      "Epoch 00018: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1084 - acc: 0.9681 - val_loss: 1.3634 - val_acc: 0.6995\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9589\n",
      "Epoch 00019: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1396 - acc: 0.9589 - val_loss: 1.5116 - val_acc: 0.6837\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9693\n",
      "Epoch 00020: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1024 - acc: 0.9692 - val_loss: 1.7623 - val_acc: 0.6697\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9687\n",
      "Epoch 00021: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.1037 - acc: 0.9687 - val_loss: 1.4029 - val_acc: 0.7158\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9759\n",
      "Epoch 00022: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0820 - acc: 0.9759 - val_loss: 1.3989 - val_acc: 0.7279\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9749\n",
      "Epoch 00023: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0866 - acc: 0.9749 - val_loss: 1.5071 - val_acc: 0.7119\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9744\n",
      "Epoch 00024: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0873 - acc: 0.9744 - val_loss: 1.5171 - val_acc: 0.7133\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9749\n",
      "Epoch 00025: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0877 - acc: 0.9749 - val_loss: 1.5060 - val_acc: 0.7100\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9789\n",
      "Epoch 00026: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0759 - acc: 0.9789 - val_loss: 1.4135 - val_acc: 0.7342\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9755\n",
      "Epoch 00027: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0838 - acc: 0.9755 - val_loss: 1.6607 - val_acc: 0.7002\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9786\n",
      "Epoch 00028: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0730 - acc: 0.9786 - val_loss: 1.7047 - val_acc: 0.6969\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9821\n",
      "Epoch 00029: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0644 - acc: 0.9821 - val_loss: 1.4504 - val_acc: 0.7331\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9826\n",
      "Epoch 00030: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0622 - acc: 0.9826 - val_loss: 1.4589 - val_acc: 0.7275\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9830\n",
      "Epoch 00031: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0588 - acc: 0.9830 - val_loss: 1.5725 - val_acc: 0.7195\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9769\n",
      "Epoch 00032: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0822 - acc: 0.9769 - val_loss: 1.4658 - val_acc: 0.7324\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9814\n",
      "Epoch 00033: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0657 - acc: 0.9814 - val_loss: 1.4942 - val_acc: 0.7242\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9876\n",
      "Epoch 00034: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0487 - acc: 0.9876 - val_loss: 1.4539 - val_acc: 0.7370\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9823\n",
      "Epoch 00035: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0624 - acc: 0.9823 - val_loss: 1.5273 - val_acc: 0.7354\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9840\n",
      "Epoch 00036: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0554 - acc: 0.9840 - val_loss: 1.6140 - val_acc: 0.7209\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9813\n",
      "Epoch 00037: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0664 - acc: 0.9813 - val_loss: 1.5106 - val_acc: 0.7354\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9840\n",
      "Epoch 00038: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0573 - acc: 0.9839 - val_loss: 1.5088 - val_acc: 0.7303\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9851\n",
      "Epoch 00039: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0516 - acc: 0.9851 - val_loss: 1.6582 - val_acc: 0.7200\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9846\n",
      "Epoch 00040: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0532 - acc: 0.9846 - val_loss: 1.6579 - val_acc: 0.7319\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9877\n",
      "Epoch 00041: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0449 - acc: 0.9877 - val_loss: 1.7750 - val_acc: 0.7067\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9878\n",
      "Epoch 00042: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0471 - acc: 0.9878 - val_loss: 1.6414 - val_acc: 0.7233\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9864\n",
      "Epoch 00043: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0501 - acc: 0.9864 - val_loss: 1.5821 - val_acc: 0.7347\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9849\n",
      "Epoch 00044: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0535 - acc: 0.9849 - val_loss: 1.5948 - val_acc: 0.7398\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9869\n",
      "Epoch 00045: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0492 - acc: 0.9869 - val_loss: 1.9894 - val_acc: 0.6946\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9880\n",
      "Epoch 00046: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0429 - acc: 0.9880 - val_loss: 1.6938 - val_acc: 0.7354\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9865\n",
      "Epoch 00047: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0489 - acc: 0.9865 - val_loss: 1.8727 - val_acc: 0.6986\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9850\n",
      "Epoch 00048: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0548 - acc: 0.9850 - val_loss: 1.6615 - val_acc: 0.7265\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9887\n",
      "Epoch 00049: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0407 - acc: 0.9887 - val_loss: 1.5950 - val_acc: 0.7354\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9889\n",
      "Epoch 00050: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0412 - acc: 0.9889 - val_loss: 1.5865 - val_acc: 0.7391\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9904\n",
      "Epoch 00051: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0375 - acc: 0.9904 - val_loss: 1.5520 - val_acc: 0.7382\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9893\n",
      "Epoch 00052: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0395 - acc: 0.9892 - val_loss: 1.7331 - val_acc: 0.7300\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9851\n",
      "Epoch 00053: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0596 - acc: 0.9851 - val_loss: 1.6906 - val_acc: 0.7277\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9917\n",
      "Epoch 00054: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 0.0318 - acc: 0.9917 - val_loss: 1.7213 - val_acc: 0.7312\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9903\n",
      "Epoch 00055: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0370 - acc: 0.9903 - val_loss: 1.6788 - val_acc: 0.7312\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9887\n",
      "Epoch 00056: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0409 - acc: 0.9887 - val_loss: 1.7243 - val_acc: 0.7249\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9902\n",
      "Epoch 00057: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0378 - acc: 0.9902 - val_loss: 1.7700 - val_acc: 0.7235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9913\n",
      "Epoch 00058: val_loss did not improve from 1.06396\n",
      "36805/36805 [==============================] - 182s 5ms/sample - loss: 0.0338 - acc: 0.9913 - val_loss: 1.8412 - val_acc: 0.7254\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.1581 - acc: 0.6816\n",
      "Loss: 1.158068077239911 Accuracy: 0.68161994\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7217 - acc: 0.4803\n",
      "Epoch 00001: val_loss improved from inf to 1.29551, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv_checkpoint/001-1.2955.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 1.7216 - acc: 0.4803 - val_loss: 1.2955 - val_acc: 0.5793\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0780 - acc: 0.6672\n",
      "Epoch 00002: val_loss improved from 1.29551 to 1.03579, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv_checkpoint/002-1.0358.hdf5\n",
      "36805/36805 [==============================] - 190s 5ms/sample - loss: 1.0779 - acc: 0.6672 - val_loss: 1.0358 - val_acc: 0.6879\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8810 - acc: 0.7340\n",
      "Epoch 00003: val_loss improved from 1.03579 to 0.85735, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv_checkpoint/003-0.8574.hdf5\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.8810 - acc: 0.7340 - val_loss: 0.8574 - val_acc: 0.7433\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7563 - acc: 0.7716\n",
      "Epoch 00004: val_loss did not improve from 0.85735\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.7563 - acc: 0.7716 - val_loss: 0.9445 - val_acc: 0.7300\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6572 - acc: 0.8005\n",
      "Epoch 00005: val_loss did not improve from 0.85735\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.6572 - acc: 0.8004 - val_loss: 0.9043 - val_acc: 0.7293\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5777 - acc: 0.8236\n",
      "Epoch 00006: val_loss did not improve from 0.85735\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.5777 - acc: 0.8236 - val_loss: 1.1075 - val_acc: 0.6890\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5107 - acc: 0.8461\n",
      "Epoch 00007: val_loss improved from 0.85735 to 0.78180, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv_checkpoint/007-0.7818.hdf5\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.5107 - acc: 0.8462 - val_loss: 0.7818 - val_acc: 0.7799\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8634\n",
      "Epoch 00008: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.4461 - acc: 0.8634 - val_loss: 0.8185 - val_acc: 0.7778\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8797\n",
      "Epoch 00009: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.3890 - acc: 0.8797 - val_loss: 0.8886 - val_acc: 0.7543\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.8945\n",
      "Epoch 00010: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.3374 - acc: 0.8944 - val_loss: 0.7828 - val_acc: 0.7838\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2999 - acc: 0.9082\n",
      "Epoch 00011: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.2999 - acc: 0.9082 - val_loss: 0.7861 - val_acc: 0.7876\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2590 - acc: 0.9197\n",
      "Epoch 00012: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.2593 - acc: 0.9197 - val_loss: 0.7844 - val_acc: 0.7948\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9294\n",
      "Epoch 00013: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.2301 - acc: 0.9293 - val_loss: 0.9168 - val_acc: 0.7689\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9335\n",
      "Epoch 00014: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.2127 - acc: 0.9335 - val_loss: 0.9209 - val_acc: 0.7652\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9461\n",
      "Epoch 00015: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1787 - acc: 0.9461 - val_loss: 0.9448 - val_acc: 0.7720\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9487\n",
      "Epoch 00016: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1744 - acc: 0.9487 - val_loss: 0.9002 - val_acc: 0.7773\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9530\n",
      "Epoch 00017: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1535 - acc: 0.9530 - val_loss: 0.9372 - val_acc: 0.7766\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9603\n",
      "Epoch 00018: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1336 - acc: 0.9602 - val_loss: 1.0159 - val_acc: 0.7708\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1310 - acc: 0.9613\n",
      "Epoch 00019: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1309 - acc: 0.9613 - val_loss: 0.8940 - val_acc: 0.7980\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9621\n",
      "Epoch 00020: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1234 - acc: 0.9621 - val_loss: 0.8320 - val_acc: 0.8125\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9643\n",
      "Epoch 00021: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1205 - acc: 0.9643 - val_loss: 0.9674 - val_acc: 0.7794\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9652\n",
      "Epoch 00022: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.1154 - acc: 0.9651 - val_loss: 0.8680 - val_acc: 0.8034\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9710\n",
      "Epoch 00023: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0985 - acc: 0.9710 - val_loss: 0.9865 - val_acc: 0.7859\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9739\n",
      "Epoch 00024: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0911 - acc: 0.9738 - val_loss: 1.0723 - val_acc: 0.7673\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9736\n",
      "Epoch 00025: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0909 - acc: 0.9736 - val_loss: 0.9407 - val_acc: 0.8041\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9740\n",
      "Epoch 00026: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0895 - acc: 0.9740 - val_loss: 0.9154 - val_acc: 0.7983\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9735\n",
      "Epoch 00027: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0899 - acc: 0.9735 - val_loss: 0.9011 - val_acc: 0.7971\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9754\n",
      "Epoch 00028: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0812 - acc: 0.9754 - val_loss: 1.0703 - val_acc: 0.7806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9804\n",
      "Epoch 00029: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0699 - acc: 0.9803 - val_loss: 1.2046 - val_acc: 0.7480\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9712\n",
      "Epoch 00030: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0991 - acc: 0.9713 - val_loss: 0.9482 - val_acc: 0.8027\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9815\n",
      "Epoch 00031: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0688 - acc: 0.9815 - val_loss: 0.8759 - val_acc: 0.8178\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9848\n",
      "Epoch 00032: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0587 - acc: 0.9848 - val_loss: 0.9363 - val_acc: 0.8118\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9811\n",
      "Epoch 00033: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0663 - acc: 0.9811 - val_loss: 1.0435 - val_acc: 0.8022\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9815\n",
      "Epoch 00034: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0657 - acc: 0.9815 - val_loss: 1.0156 - val_acc: 0.7992\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9799\n",
      "Epoch 00035: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0692 - acc: 0.9799 - val_loss: 0.9678 - val_acc: 0.8050\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9816\n",
      "Epoch 00036: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0656 - acc: 0.9816 - val_loss: 0.8872 - val_acc: 0.8155\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9825\n",
      "Epoch 00037: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0626 - acc: 0.9825 - val_loss: 1.3577 - val_acc: 0.7536\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9863\n",
      "Epoch 00038: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0510 - acc: 0.9863 - val_loss: 0.8863 - val_acc: 0.8244\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9849\n",
      "Epoch 00039: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0545 - acc: 0.9849 - val_loss: 1.0286 - val_acc: 0.8011\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9796\n",
      "Epoch 00040: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0733 - acc: 0.9796 - val_loss: 0.9717 - val_acc: 0.8106\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9816\n",
      "Epoch 00041: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0660 - acc: 0.9816 - val_loss: 0.9678 - val_acc: 0.8157\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9844\n",
      "Epoch 00042: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0579 - acc: 0.9844 - val_loss: 0.9079 - val_acc: 0.8211\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9903\n",
      "Epoch 00043: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0401 - acc: 0.9902 - val_loss: 1.3563 - val_acc: 0.7659\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9772\n",
      "Epoch 00044: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0839 - acc: 0.9772 - val_loss: 1.0279 - val_acc: 0.8018\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9849\n",
      "Epoch 00045: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0553 - acc: 0.9849 - val_loss: 1.0906 - val_acc: 0.7973\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9915\n",
      "Epoch 00046: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0356 - acc: 0.9914 - val_loss: 1.1834 - val_acc: 0.7838\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9759\n",
      "Epoch 00047: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0909 - acc: 0.9759 - val_loss: 0.9621 - val_acc: 0.8206\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9923\n",
      "Epoch 00048: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0326 - acc: 0.9923 - val_loss: 0.9508 - val_acc: 0.8211\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9902\n",
      "Epoch 00049: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0406 - acc: 0.9902 - val_loss: 1.0623 - val_acc: 0.8018\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9874\n",
      "Epoch 00050: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0484 - acc: 0.9874 - val_loss: 1.0568 - val_acc: 0.8109\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9897\n",
      "Epoch 00051: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0392 - acc: 0.9897 - val_loss: 1.0894 - val_acc: 0.7941\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9865\n",
      "Epoch 00052: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0490 - acc: 0.9865 - val_loss: 1.1451 - val_acc: 0.7929\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9910\n",
      "Epoch 00053: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0371 - acc: 0.9910 - val_loss: 1.2390 - val_acc: 0.7962\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9859\n",
      "Epoch 00054: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0518 - acc: 0.9859 - val_loss: 1.0943 - val_acc: 0.8064\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9861\n",
      "Epoch 00055: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0500 - acc: 0.9861 - val_loss: 1.1757 - val_acc: 0.7959\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9885\n",
      "Epoch 00056: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0435 - acc: 0.9885 - val_loss: 1.0994 - val_acc: 0.8137\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9876\n",
      "Epoch 00057: val_loss did not improve from 0.78180\n",
      "36805/36805 [==============================] - 189s 5ms/sample - loss: 0.0444 - acc: 0.9876 - val_loss: 1.2314 - val_acc: 0.7990\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.8222 - acc: 0.7713\n",
      "Loss: 0.8222332463705156 Accuracy: 0.77133954\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6026 - acc: 0.4996\n",
      "Epoch 00001: val_loss improved from inf to 1.35593, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/001-1.3559.hdf5\n",
      "36805/36805 [==============================] - 201s 5ms/sample - loss: 1.6025 - acc: 0.4996 - val_loss: 1.3559 - val_acc: 0.5707\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9593 - acc: 0.7030\n",
      "Epoch 00002: val_loss improved from 1.35593 to 0.94519, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/002-0.9452.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.9593 - acc: 0.7030 - val_loss: 0.9452 - val_acc: 0.7079\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7592 - acc: 0.7679\n",
      "Epoch 00003: val_loss improved from 0.94519 to 0.77015, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/003-0.7701.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.7592 - acc: 0.7679 - val_loss: 0.7701 - val_acc: 0.7713\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6390 - acc: 0.8080\n",
      "Epoch 00004: val_loss improved from 0.77015 to 0.67754, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/004-0.6775.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.6390 - acc: 0.8080 - val_loss: 0.6775 - val_acc: 0.8064\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5461 - acc: 0.8386\n",
      "Epoch 00005: val_loss improved from 0.67754 to 0.58509, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/005-0.5851.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.5461 - acc: 0.8387 - val_loss: 0.5851 - val_acc: 0.8355\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4821 - acc: 0.8563\n",
      "Epoch 00006: val_loss improved from 0.58509 to 0.56530, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/006-0.5653.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.4820 - acc: 0.8563 - val_loss: 0.5653 - val_acc: 0.8318\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4273 - acc: 0.8720\n",
      "Epoch 00007: val_loss did not improve from 0.56530\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.4274 - acc: 0.8719 - val_loss: 0.7105 - val_acc: 0.8006\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3866 - acc: 0.8836\n",
      "Epoch 00008: val_loss improved from 0.56530 to 0.52999, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/008-0.5300.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.3865 - acc: 0.8836 - val_loss: 0.5300 - val_acc: 0.8498\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3410 - acc: 0.8954\n",
      "Epoch 00009: val_loss did not improve from 0.52999\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.3411 - acc: 0.8954 - val_loss: 0.5824 - val_acc: 0.8353\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.9070\n",
      "Epoch 00010: val_loss did not improve from 0.52999\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.3124 - acc: 0.9071 - val_loss: 0.6196 - val_acc: 0.8202\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2786 - acc: 0.9157\n",
      "Epoch 00011: val_loss did not improve from 0.52999\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.2788 - acc: 0.9156 - val_loss: 0.5570 - val_acc: 0.8507\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9214\n",
      "Epoch 00012: val_loss improved from 0.52999 to 0.49874, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/012-0.4987.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.2616 - acc: 0.9214 - val_loss: 0.4987 - val_acc: 0.8637\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9317\n",
      "Epoch 00013: val_loss did not improve from 0.49874\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.2265 - acc: 0.9316 - val_loss: 0.5399 - val_acc: 0.8516\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9362\n",
      "Epoch 00014: val_loss improved from 0.49874 to 0.43236, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/014-0.4324.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.2132 - acc: 0.9361 - val_loss: 0.4324 - val_acc: 0.8880\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9435\n",
      "Epoch 00015: val_loss did not improve from 0.43236\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1913 - acc: 0.9435 - val_loss: 0.4550 - val_acc: 0.8873\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9485\n",
      "Epoch 00016: val_loss did not improve from 0.43236\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1743 - acc: 0.9485 - val_loss: 0.4798 - val_acc: 0.8658\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9531\n",
      "Epoch 00017: val_loss did not improve from 0.43236\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1551 - acc: 0.9531 - val_loss: 0.4779 - val_acc: 0.8777\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9566\n",
      "Epoch 00018: val_loss did not improve from 0.43236\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1465 - acc: 0.9566 - val_loss: 0.4541 - val_acc: 0.8824\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9602\n",
      "Epoch 00019: val_loss improved from 0.43236 to 0.43049, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv_checkpoint/019-0.4305.hdf5\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1337 - acc: 0.9601 - val_loss: 0.4305 - val_acc: 0.8910\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9605\n",
      "Epoch 00020: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1302 - acc: 0.9605 - val_loss: 0.5741 - val_acc: 0.8521\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9677\n",
      "Epoch 00021: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1103 - acc: 0.9676 - val_loss: 0.5185 - val_acc: 0.8714\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9654\n",
      "Epoch 00022: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 193s 5ms/sample - loss: 0.1129 - acc: 0.9654 - val_loss: 0.5021 - val_acc: 0.8777\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9712\n",
      "Epoch 00023: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0968 - acc: 0.9712 - val_loss: 0.4920 - val_acc: 0.8714\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9730\n",
      "Epoch 00024: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0935 - acc: 0.9730 - val_loss: 0.4881 - val_acc: 0.8807\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9780\n",
      "Epoch 00025: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0780 - acc: 0.9780 - val_loss: 0.5004 - val_acc: 0.8793\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9782\n",
      "Epoch 00026: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0760 - acc: 0.9782 - val_loss: 0.7341 - val_acc: 0.8339\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9685\n",
      "Epoch 00027: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0995 - acc: 0.9685 - val_loss: 0.4891 - val_acc: 0.8847\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9781\n",
      "Epoch 00028: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0757 - acc: 0.9781 - val_loss: 0.8291 - val_acc: 0.8209\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9841\n",
      "Epoch 00029: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0584 - acc: 0.9841 - val_loss: 0.4864 - val_acc: 0.8849\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9843\n",
      "Epoch 00030: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0574 - acc: 0.9843 - val_loss: 0.4906 - val_acc: 0.8945\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9799\n",
      "Epoch 00031: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0667 - acc: 0.9799 - val_loss: 0.5358 - val_acc: 0.8838\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9835\n",
      "Epoch 00032: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0588 - acc: 0.9835 - val_loss: 0.4552 - val_acc: 0.8975\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9815\n",
      "Epoch 00033: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0638 - acc: 0.9815 - val_loss: 0.6153 - val_acc: 0.8698\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9813\n",
      "Epoch 00034: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0659 - acc: 0.9813 - val_loss: 0.4906 - val_acc: 0.8912\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9862\n",
      "Epoch 00035: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0496 - acc: 0.9862 - val_loss: 0.4694 - val_acc: 0.8877\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9847\n",
      "Epoch 00036: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0528 - acc: 0.9847 - val_loss: 0.6105 - val_acc: 0.8649\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9862\n",
      "Epoch 00037: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0481 - acc: 0.9863 - val_loss: 0.5855 - val_acc: 0.8672\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9885\n",
      "Epoch 00038: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0432 - acc: 0.9885 - val_loss: 0.5718 - val_acc: 0.8735\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9867\n",
      "Epoch 00039: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0472 - acc: 0.9867 - val_loss: 0.6698 - val_acc: 0.8591\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9894\n",
      "Epoch 00040: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0392 - acc: 0.9894 - val_loss: 0.6697 - val_acc: 0.8609\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9861\n",
      "Epoch 00041: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0481 - acc: 0.9861 - val_loss: 0.5338 - val_acc: 0.8849\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9871\n",
      "Epoch 00042: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0481 - acc: 0.9871 - val_loss: 0.4427 - val_acc: 0.9005\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9910\n",
      "Epoch 00043: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0332 - acc: 0.9909 - val_loss: 0.7127 - val_acc: 0.8465\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9807\n",
      "Epoch 00044: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0655 - acc: 0.9807 - val_loss: 0.5134 - val_acc: 0.8898\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9908\n",
      "Epoch 00045: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0348 - acc: 0.9908 - val_loss: 0.4558 - val_acc: 0.8998\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9904\n",
      "Epoch 00046: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0340 - acc: 0.9904 - val_loss: 0.4749 - val_acc: 0.9026\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9860\n",
      "Epoch 00047: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0522 - acc: 0.9860 - val_loss: 0.4960 - val_acc: 0.8980\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9930\n",
      "Epoch 00048: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0279 - acc: 0.9930 - val_loss: 0.4420 - val_acc: 0.9103\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9931\n",
      "Epoch 00049: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0266 - acc: 0.9931 - val_loss: 0.5272 - val_acc: 0.8970\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9892\n",
      "Epoch 00050: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0367 - acc: 0.9892 - val_loss: 0.5704 - val_acc: 0.8919\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9881\n",
      "Epoch 00051: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0409 - acc: 0.9881 - val_loss: 0.5759 - val_acc: 0.8849\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9912\n",
      "Epoch 00052: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0341 - acc: 0.9912 - val_loss: 0.5992 - val_acc: 0.8842\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9934\n",
      "Epoch 00053: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0259 - acc: 0.9934 - val_loss: 0.4745 - val_acc: 0.9040\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9898\n",
      "Epoch 00054: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0358 - acc: 0.9898 - val_loss: 0.5816 - val_acc: 0.8861\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9889\n",
      "Epoch 00055: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0397 - acc: 0.9889 - val_loss: 0.4848 - val_acc: 0.9015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9913\n",
      "Epoch 00056: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0311 - acc: 0.9912 - val_loss: 0.5878 - val_acc: 0.8880\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9849\n",
      "Epoch 00057: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0555 - acc: 0.9848 - val_loss: 0.5641 - val_acc: 0.8880\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9913\n",
      "Epoch 00058: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0326 - acc: 0.9913 - val_loss: 0.4819 - val_acc: 0.9043\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9962\n",
      "Epoch 00059: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0184 - acc: 0.9963 - val_loss: 0.4602 - val_acc: 0.9050\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9925\n",
      "Epoch 00060: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0292 - acc: 0.9924 - val_loss: 0.6110 - val_acc: 0.8761\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9864\n",
      "Epoch 00061: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0447 - acc: 0.9864 - val_loss: 0.4712 - val_acc: 0.9071\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9946\n",
      "Epoch 00062: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0213 - acc: 0.9946 - val_loss: 0.5009 - val_acc: 0.9040\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9955\n",
      "Epoch 00063: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0193 - acc: 0.9955 - val_loss: 0.5437 - val_acc: 0.8931\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9918\n",
      "Epoch 00064: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0280 - acc: 0.9918 - val_loss: 0.5168 - val_acc: 0.8977\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9904\n",
      "Epoch 00065: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0343 - acc: 0.9904 - val_loss: 0.5188 - val_acc: 0.8947\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9937\n",
      "Epoch 00066: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0241 - acc: 0.9937 - val_loss: 0.5900 - val_acc: 0.8908\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9933\n",
      "Epoch 00067: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0240 - acc: 0.9933 - val_loss: 0.5740 - val_acc: 0.8970\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9940\n",
      "Epoch 00068: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0233 - acc: 0.9940 - val_loss: 0.5567 - val_acc: 0.8968\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9924\n",
      "Epoch 00069: val_loss did not improve from 0.43049\n",
      "36805/36805 [==============================] - 192s 5ms/sample - loss: 0.0279 - acc: 0.9924 - val_loss: 0.5303 - val_acc: 0.8996\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.5021 - acc: 0.8615\n",
      "Loss: 0.5021360106804909 Accuracy: 0.8614746\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5243 - acc: 0.5246\n",
      "Epoch 00001: val_loss improved from inf to 1.25092, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/001-1.2509.hdf5\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 1.5242 - acc: 0.5246 - val_loss: 1.2509 - val_acc: 0.6382\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8114 - acc: 0.7536\n",
      "Epoch 00002: val_loss improved from 1.25092 to 0.75560, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/002-0.7556.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.8114 - acc: 0.7536 - val_loss: 0.7556 - val_acc: 0.7773\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5820 - acc: 0.8280\n",
      "Epoch 00003: val_loss improved from 0.75560 to 0.47105, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/003-0.4711.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.5820 - acc: 0.8280 - val_loss: 0.4711 - val_acc: 0.8619\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8655\n",
      "Epoch 00004: val_loss improved from 0.47105 to 0.41459, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/004-0.4146.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.4560 - acc: 0.8655 - val_loss: 0.4146 - val_acc: 0.8873\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8899\n",
      "Epoch 00005: val_loss improved from 0.41459 to 0.37585, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/005-0.3759.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.3753 - acc: 0.8899 - val_loss: 0.3759 - val_acc: 0.8952\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.9022\n",
      "Epoch 00006: val_loss improved from 0.37585 to 0.34887, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/006-0.3489.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.3302 - acc: 0.9022 - val_loss: 0.3489 - val_acc: 0.9010\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9181\n",
      "Epoch 00007: val_loss did not improve from 0.34887\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.2801 - acc: 0.9181 - val_loss: 0.3559 - val_acc: 0.8973\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2378 - acc: 0.9293\n",
      "Epoch 00008: val_loss improved from 0.34887 to 0.32172, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/008-0.3217.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.2381 - acc: 0.9292 - val_loss: 0.3217 - val_acc: 0.9096\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9308\n",
      "Epoch 00009: val_loss improved from 0.32172 to 0.26304, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/009-0.2630.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.2294 - acc: 0.9307 - val_loss: 0.2630 - val_acc: 0.9297\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9415\n",
      "Epoch 00010: val_loss did not improve from 0.26304\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1984 - acc: 0.9415 - val_loss: 0.2854 - val_acc: 0.9164\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1748 - acc: 0.9473\n",
      "Epoch 00011: val_loss did not improve from 0.26304\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1749 - acc: 0.9472 - val_loss: 0.2811 - val_acc: 0.9241\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9453\n",
      "Epoch 00012: val_loss did not improve from 0.26304\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1795 - acc: 0.9453 - val_loss: 0.3315 - val_acc: 0.9110\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9566\n",
      "Epoch 00013: val_loss improved from 0.26304 to 0.23899, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/013-0.2390.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1442 - acc: 0.9566 - val_loss: 0.2390 - val_acc: 0.9311\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9597\n",
      "Epoch 00014: val_loss did not improve from 0.23899\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1309 - acc: 0.9597 - val_loss: 0.2795 - val_acc: 0.9241\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9618\n",
      "Epoch 00015: val_loss did not improve from 0.23899\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1266 - acc: 0.9618 - val_loss: 0.2495 - val_acc: 0.9345\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9625\n",
      "Epoch 00016: val_loss did not improve from 0.23899\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1202 - acc: 0.9625 - val_loss: 0.2405 - val_acc: 0.9350\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9696\n",
      "Epoch 00017: val_loss improved from 0.23899 to 0.21953, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/017-0.2195.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.1027 - acc: 0.9697 - val_loss: 0.2195 - val_acc: 0.9427\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9729\n",
      "Epoch 00018: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0905 - acc: 0.9729 - val_loss: 0.2477 - val_acc: 0.9329\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9724\n",
      "Epoch 00019: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0925 - acc: 0.9724 - val_loss: 0.2253 - val_acc: 0.9315\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9775\n",
      "Epoch 00020: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0758 - acc: 0.9775 - val_loss: 0.2697 - val_acc: 0.9280\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9785\n",
      "Epoch 00021: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0728 - acc: 0.9785 - val_loss: 0.3844 - val_acc: 0.8998\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9784\n",
      "Epoch 00022: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0692 - acc: 0.9784 - val_loss: 0.3057 - val_acc: 0.9229\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9823\n",
      "Epoch 00023: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0619 - acc: 0.9823 - val_loss: 0.2500 - val_acc: 0.9343\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9840\n",
      "Epoch 00024: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0562 - acc: 0.9840 - val_loss: 0.2232 - val_acc: 0.9427\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9804\n",
      "Epoch 00025: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0658 - acc: 0.9804 - val_loss: 0.2244 - val_acc: 0.9441\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9872\n",
      "Epoch 00026: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0455 - acc: 0.9872 - val_loss: 0.2927 - val_acc: 0.9311\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9858\n",
      "Epoch 00027: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0477 - acc: 0.9858 - val_loss: 0.3621 - val_acc: 0.9012\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9856\n",
      "Epoch 00028: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0507 - acc: 0.9856 - val_loss: 0.2979 - val_acc: 0.9266\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9867\n",
      "Epoch 00029: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0462 - acc: 0.9867 - val_loss: 0.2743 - val_acc: 0.9283\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9874\n",
      "Epoch 00030: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0433 - acc: 0.9874 - val_loss: 0.2503 - val_acc: 0.9429\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9890\n",
      "Epoch 00031: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0379 - acc: 0.9890 - val_loss: 0.2489 - val_acc: 0.9425\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9889\n",
      "Epoch 00032: val_loss did not improve from 0.21953\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0379 - acc: 0.9889 - val_loss: 0.2591 - val_acc: 0.9378\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9907\n",
      "Epoch 00033: val_loss improved from 0.21953 to 0.21119, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv_checkpoint/033-0.2112.hdf5\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0338 - acc: 0.9907 - val_loss: 0.2112 - val_acc: 0.9448\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9871\n",
      "Epoch 00034: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0434 - acc: 0.9871 - val_loss: 0.2573 - val_acc: 0.9369\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9933\n",
      "Epoch 00035: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0260 - acc: 0.9933 - val_loss: 0.2965 - val_acc: 0.9341\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9901\n",
      "Epoch 00036: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0354 - acc: 0.9901 - val_loss: 0.2282 - val_acc: 0.9429\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9928\n",
      "Epoch 00037: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0261 - acc: 0.9928 - val_loss: 0.2445 - val_acc: 0.9471\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9905\n",
      "Epoch 00038: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0320 - acc: 0.9905 - val_loss: 0.4077 - val_acc: 0.9113\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9921\n",
      "Epoch 00039: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0271 - acc: 0.9921 - val_loss: 0.2640 - val_acc: 0.9378\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9934\n",
      "Epoch 00040: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0230 - acc: 0.9934 - val_loss: 0.5090 - val_acc: 0.8984\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9924\n",
      "Epoch 00041: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0272 - acc: 0.9924 - val_loss: 0.3349 - val_acc: 0.9227\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9934\n",
      "Epoch 00042: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0230 - acc: 0.9933 - val_loss: 0.2883 - val_acc: 0.9315\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9897\n",
      "Epoch 00043: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0340 - acc: 0.9897 - val_loss: 0.2464 - val_acc: 0.9450\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9917\n",
      "Epoch 00044: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0294 - acc: 0.9917 - val_loss: 0.2728 - val_acc: 0.9387\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9939\n",
      "Epoch 00045: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0213 - acc: 0.9939 - val_loss: 0.2416 - val_acc: 0.9467\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9955\n",
      "Epoch 00046: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0167 - acc: 0.9955 - val_loss: 0.2508 - val_acc: 0.9490\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9944\n",
      "Epoch 00047: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0200 - acc: 0.9944 - val_loss: 0.2654 - val_acc: 0.9425\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9949\n",
      "Epoch 00048: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0195 - acc: 0.9949 - val_loss: 0.2608 - val_acc: 0.9408\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9918\n",
      "Epoch 00049: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0280 - acc: 0.9918 - val_loss: 0.3565 - val_acc: 0.9154\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9927\n",
      "Epoch 00050: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0251 - acc: 0.9927 - val_loss: 0.2398 - val_acc: 0.9467\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9964\n",
      "Epoch 00051: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0138 - acc: 0.9964 - val_loss: 0.2881 - val_acc: 0.9394\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9947\n",
      "Epoch 00052: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0174 - acc: 0.9947 - val_loss: 0.2780 - val_acc: 0.9383\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9949\n",
      "Epoch 00053: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0185 - acc: 0.9949 - val_loss: 0.3429 - val_acc: 0.9227\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9954\n",
      "Epoch 00054: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0178 - acc: 0.9953 - val_loss: 0.2199 - val_acc: 0.9495\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9930\n",
      "Epoch 00055: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0230 - acc: 0.9930 - val_loss: 0.2137 - val_acc: 0.9539\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9961\n",
      "Epoch 00056: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0147 - acc: 0.9961 - val_loss: 0.2720 - val_acc: 0.9462\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9972\n",
      "Epoch 00057: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0113 - acc: 0.9972 - val_loss: 0.3755 - val_acc: 0.9276\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9893\n",
      "Epoch 00058: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0357 - acc: 0.9893 - val_loss: 0.2353 - val_acc: 0.9464\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9974\n",
      "Epoch 00059: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0105 - acc: 0.9974 - val_loss: 0.2620 - val_acc: 0.9471\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9936\n",
      "Epoch 00060: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0223 - acc: 0.9936 - val_loss: 0.2531 - val_acc: 0.9471\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9979\n",
      "Epoch 00061: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0089 - acc: 0.9979 - val_loss: 0.2322 - val_acc: 0.9527\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9960\n",
      "Epoch 00062: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0133 - acc: 0.9960 - val_loss: 0.3207 - val_acc: 0.9334\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9947\n",
      "Epoch 00063: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0186 - acc: 0.9947 - val_loss: 0.2403 - val_acc: 0.9485\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9965\n",
      "Epoch 00064: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0140 - acc: 0.9965 - val_loss: 0.2617 - val_acc: 0.9462\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9916\n",
      "Epoch 00065: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0263 - acc: 0.9916 - val_loss: 0.3054 - val_acc: 0.9408\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9976\n",
      "Epoch 00066: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0099 - acc: 0.9976 - val_loss: 0.2316 - val_acc: 0.9525\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 00067: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0085 - acc: 0.9980 - val_loss: 0.2420 - val_acc: 0.9499\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9954\n",
      "Epoch 00068: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0152 - acc: 0.9954 - val_loss: 0.2661 - val_acc: 0.9434\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9955\n",
      "Epoch 00069: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0157 - acc: 0.9955 - val_loss: 0.3080 - val_acc: 0.9369\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9948\n",
      "Epoch 00070: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0179 - acc: 0.9948 - val_loss: 0.2121 - val_acc: 0.9550\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9971\n",
      "Epoch 00071: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0111 - acc: 0.9971 - val_loss: 0.2237 - val_acc: 0.9541\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9983\n",
      "Epoch 00072: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0075 - acc: 0.9983 - val_loss: 0.2359 - val_acc: 0.9525\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9962\n",
      "Epoch 00073: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0135 - acc: 0.9962 - val_loss: 0.2865 - val_acc: 0.9418\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9970\n",
      "Epoch 00074: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0116 - acc: 0.9970 - val_loss: 0.2612 - val_acc: 0.9488\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9918\n",
      "Epoch 00075: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0270 - acc: 0.9918 - val_loss: 0.2518 - val_acc: 0.9476\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 00076: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0056 - acc: 0.9989 - val_loss: 0.2121 - val_acc: 0.9560\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9981\n",
      "Epoch 00077: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0073 - acc: 0.9981 - val_loss: 0.3610 - val_acc: 0.9287\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 00078: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0098 - acc: 0.9971 - val_loss: 0.3212 - val_acc: 0.9399\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9964\n",
      "Epoch 00079: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0127 - acc: 0.9964 - val_loss: 0.3275 - val_acc: 0.9380\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9960\n",
      "Epoch 00080: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0149 - acc: 0.9960 - val_loss: 0.2265 - val_acc: 0.9543\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 00081: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0098 - acc: 0.9971 - val_loss: 0.2536 - val_acc: 0.9513\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9986\n",
      "Epoch 00082: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0067 - acc: 0.9986 - val_loss: 0.2242 - val_acc: 0.9548\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9943\n",
      "Epoch 00083: val_loss did not improve from 0.21119\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0173 - acc: 0.9943 - val_loss: 0.3120 - val_acc: 0.9348\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2766 - acc: 0.9300\n",
      "Loss: 0.27657951956473653 Accuracy: 0.9300104\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3808 - acc: 0.5734\n",
      "Epoch 00001: val_loss improved from inf to 1.02336, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/001-1.0234.hdf5\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 1.3807 - acc: 0.5733 - val_loss: 1.0234 - val_acc: 0.6723\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.8255\n",
      "Epoch 00002: val_loss improved from 1.02336 to 0.41072, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/002-0.4107.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.5869 - acc: 0.8256 - val_loss: 0.4107 - val_acc: 0.8789\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8828\n",
      "Epoch 00003: val_loss improved from 0.41072 to 0.28846, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/003-0.2885.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.3910 - acc: 0.8828 - val_loss: 0.2885 - val_acc: 0.9182\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.9093\n",
      "Epoch 00004: val_loss improved from 0.28846 to 0.23701, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/004-0.2370.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.3041 - acc: 0.9093 - val_loss: 0.2370 - val_acc: 0.9322\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9261\n",
      "Epoch 00005: val_loss did not improve from 0.23701\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.2471 - acc: 0.9261 - val_loss: 0.3024 - val_acc: 0.9099\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9333\n",
      "Epoch 00006: val_loss did not improve from 0.23701\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.2186 - acc: 0.9333 - val_loss: 0.3297 - val_acc: 0.9080\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9469\n",
      "Epoch 00007: val_loss improved from 0.23701 to 0.21141, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/007-0.2114.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1772 - acc: 0.9469 - val_loss: 0.2114 - val_acc: 0.9371\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9541\n",
      "Epoch 00008: val_loss improved from 0.21141 to 0.20284, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/008-0.2028.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1537 - acc: 0.9541 - val_loss: 0.2028 - val_acc: 0.9448\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9589\n",
      "Epoch 00009: val_loss improved from 0.20284 to 0.17994, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/009-0.1799.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1377 - acc: 0.9589 - val_loss: 0.1799 - val_acc: 0.9483\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9605\n",
      "Epoch 00010: val_loss did not improve from 0.17994\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1257 - acc: 0.9605 - val_loss: 0.1960 - val_acc: 0.9429\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9636\n",
      "Epoch 00011: val_loss improved from 0.17994 to 0.14067, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/011-0.1407.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1180 - acc: 0.9636 - val_loss: 0.1407 - val_acc: 0.9630\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9703\n",
      "Epoch 00012: val_loss did not improve from 0.14067\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0986 - acc: 0.9703 - val_loss: 0.1422 - val_acc: 0.9560\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9748\n",
      "Epoch 00013: val_loss did not improve from 0.14067\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0848 - acc: 0.9748 - val_loss: 0.2408 - val_acc: 0.9327\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9754\n",
      "Epoch 00014: val_loss improved from 0.14067 to 0.13785, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/014-0.1378.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0817 - acc: 0.9754 - val_loss: 0.1378 - val_acc: 0.9581\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9799\n",
      "Epoch 00015: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0712 - acc: 0.9799 - val_loss: 0.1736 - val_acc: 0.9522\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9794\n",
      "Epoch 00016: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0676 - acc: 0.9794 - val_loss: 0.2413 - val_acc: 0.9394\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9774\n",
      "Epoch 00017: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0720 - acc: 0.9773 - val_loss: 0.1832 - val_acc: 0.9467\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9782\n",
      "Epoch 00018: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0697 - acc: 0.9782 - val_loss: 0.1435 - val_acc: 0.9576\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9852\n",
      "Epoch 00019: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0484 - acc: 0.9852 - val_loss: 0.1564 - val_acc: 0.9576\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9873\n",
      "Epoch 00020: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0449 - acc: 0.9873 - val_loss: 0.1586 - val_acc: 0.9553\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9838\n",
      "Epoch 00021: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0556 - acc: 0.9838 - val_loss: 0.1974 - val_acc: 0.9448\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9907\n",
      "Epoch 00022: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0348 - acc: 0.9907 - val_loss: 0.1709 - val_acc: 0.9557\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9903\n",
      "Epoch 00023: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0340 - acc: 0.9903 - val_loss: 0.1399 - val_acc: 0.9639\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9901\n",
      "Epoch 00024: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0361 - acc: 0.9901 - val_loss: 0.1759 - val_acc: 0.9522\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9904\n",
      "Epoch 00025: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0340 - acc: 0.9903 - val_loss: 0.1981 - val_acc: 0.9408\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9877\n",
      "Epoch 00026: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0415 - acc: 0.9877 - val_loss: 0.1526 - val_acc: 0.9576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9927\n",
      "Epoch 00027: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0269 - acc: 0.9927 - val_loss: 0.2282 - val_acc: 0.9362\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9939\n",
      "Epoch 00028: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0219 - acc: 0.9939 - val_loss: 0.1606 - val_acc: 0.9599\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9926\n",
      "Epoch 00029: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0268 - acc: 0.9926 - val_loss: 0.2384 - val_acc: 0.9383\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9928\n",
      "Epoch 00030: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0259 - acc: 0.9928 - val_loss: 0.2235 - val_acc: 0.9478\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9930\n",
      "Epoch 00031: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0238 - acc: 0.9930 - val_loss: 0.2538 - val_acc: 0.9385\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9946\n",
      "Epoch 00032: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0197 - acc: 0.9946 - val_loss: 0.1536 - val_acc: 0.9576\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9944\n",
      "Epoch 00033: val_loss did not improve from 0.13785\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0201 - acc: 0.9944 - val_loss: 0.2198 - val_acc: 0.9439\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9953\n",
      "Epoch 00034: val_loss improved from 0.13785 to 0.12377, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/034-0.1238.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0173 - acc: 0.9953 - val_loss: 0.1238 - val_acc: 0.9679\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9943\n",
      "Epoch 00035: val_loss did not improve from 0.12377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0196 - acc: 0.9943 - val_loss: 0.2241 - val_acc: 0.9506\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9953\n",
      "Epoch 00036: val_loss did not improve from 0.12377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0166 - acc: 0.9953 - val_loss: 0.1933 - val_acc: 0.9504\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9950\n",
      "Epoch 00037: val_loss did not improve from 0.12377\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0187 - acc: 0.9950 - val_loss: 0.1831 - val_acc: 0.9522\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9912\n",
      "Epoch 00038: val_loss improved from 0.12377 to 0.12292, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/038-0.1229.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0294 - acc: 0.9912 - val_loss: 0.1229 - val_acc: 0.9665\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9964\n",
      "Epoch 00039: val_loss did not improve from 0.12292\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0139 - acc: 0.9964 - val_loss: 0.1452 - val_acc: 0.9639\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9979\n",
      "Epoch 00040: val_loss did not improve from 0.12292\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0090 - acc: 0.9979 - val_loss: 0.2206 - val_acc: 0.9483\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9910\n",
      "Epoch 00041: val_loss improved from 0.12292 to 0.12196, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/041-0.1220.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0289 - acc: 0.9910 - val_loss: 0.1220 - val_acc: 0.9681\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9977\n",
      "Epoch 00042: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0100 - acc: 0.9977 - val_loss: 0.1741 - val_acc: 0.9583\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9970\n",
      "Epoch 00043: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0118 - acc: 0.9970 - val_loss: 0.1958 - val_acc: 0.9520\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9973\n",
      "Epoch 00044: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0103 - acc: 0.9973 - val_loss: 0.1594 - val_acc: 0.9597\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 00045: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0185 - acc: 0.9942 - val_loss: 0.1514 - val_acc: 0.9637\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9965\n",
      "Epoch 00046: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0129 - acc: 0.9964 - val_loss: 0.1536 - val_acc: 0.9639\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9952\n",
      "Epoch 00047: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0177 - acc: 0.9952 - val_loss: 0.1549 - val_acc: 0.9634\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9979\n",
      "Epoch 00048: val_loss did not improve from 0.12196\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0086 - acc: 0.9979 - val_loss: 0.1672 - val_acc: 0.9639\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9914\n",
      "Epoch 00049: val_loss improved from 0.12196 to 0.11901, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv_checkpoint/049-0.1190.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0285 - acc: 0.9914 - val_loss: 0.1190 - val_acc: 0.9686\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 00050: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0089 - acc: 0.9976 - val_loss: 0.1987 - val_acc: 0.9546\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9985\n",
      "Epoch 00051: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0065 - acc: 0.9985 - val_loss: 0.1814 - val_acc: 0.9609\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 00052: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0103 - acc: 0.9970 - val_loss: 0.1403 - val_acc: 0.9644\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 00053: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0093 - acc: 0.9976 - val_loss: 0.1899 - val_acc: 0.9571\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9931\n",
      "Epoch 00054: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0222 - acc: 0.9931 - val_loss: 0.1532 - val_acc: 0.9641\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9982\n",
      "Epoch 00055: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0074 - acc: 0.9982 - val_loss: 0.1664 - val_acc: 0.9613\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 00056: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0089 - acc: 0.9977 - val_loss: 0.1642 - val_acc: 0.9602\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9929\n",
      "Epoch 00057: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0242 - acc: 0.9929 - val_loss: 0.1259 - val_acc: 0.9700\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 00058: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1248 - val_acc: 0.9693\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9987\n",
      "Epoch 00059: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0050 - acc: 0.9988 - val_loss: 0.1551 - val_acc: 0.9618\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 00060: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0112 - acc: 0.9966 - val_loss: 0.1894 - val_acc: 0.9522\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 00061: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0103 - acc: 0.9970 - val_loss: 0.1759 - val_acc: 0.9630\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9983\n",
      "Epoch 00062: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0067 - acc: 0.9983 - val_loss: 0.2116 - val_acc: 0.9511\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9978\n",
      "Epoch 00063: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.1842 - val_acc: 0.9606\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9945\n",
      "Epoch 00064: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0189 - acc: 0.9945 - val_loss: 0.1975 - val_acc: 0.9543\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 00065: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1311 - val_acc: 0.9690\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9964\n",
      "Epoch 00066: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0125 - acc: 0.9964 - val_loss: 0.1393 - val_acc: 0.9686\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9993\n",
      "Epoch 00067: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0035 - acc: 0.9993 - val_loss: 0.1299 - val_acc: 0.9693\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 00068: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0093 - acc: 0.9972 - val_loss: 0.1347 - val_acc: 0.9690\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9983\n",
      "Epoch 00069: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0064 - acc: 0.9983 - val_loss: 0.2131 - val_acc: 0.9555\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9962\n",
      "Epoch 00070: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0122 - acc: 0.9962 - val_loss: 0.1306 - val_acc: 0.9695\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9986\n",
      "Epoch 00071: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0052 - acc: 0.9986 - val_loss: 0.1231 - val_acc: 0.9686\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 00072: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0108 - acc: 0.9967 - val_loss: 0.1557 - val_acc: 0.9667\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 00073: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0060 - acc: 0.9983 - val_loss: 0.1774 - val_acc: 0.9625\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9971\n",
      "Epoch 00074: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0097 - acc: 0.9971 - val_loss: 0.1736 - val_acc: 0.9611\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9982\n",
      "Epoch 00075: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0070 - acc: 0.9982 - val_loss: 0.1488 - val_acc: 0.9644\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 00076: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0076 - acc: 0.9977 - val_loss: 0.2174 - val_acc: 0.9583\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9965\n",
      "Epoch 00077: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0114 - acc: 0.9965 - val_loss: 0.1369 - val_acc: 0.9655\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 00078: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0129 - acc: 0.9963 - val_loss: 0.1989 - val_acc: 0.9576\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9961\n",
      "Epoch 00079: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0144 - acc: 0.9961 - val_loss: 0.1474 - val_acc: 0.9660\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 00080: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0036 - acc: 0.9993 - val_loss: 0.1349 - val_acc: 0.9702\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00081: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.1669 - val_acc: 0.9658\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9983\n",
      "Epoch 00082: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0062 - acc: 0.9982 - val_loss: 0.2125 - val_acc: 0.9555\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9952\n",
      "Epoch 00083: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0153 - acc: 0.9952 - val_loss: 0.1467 - val_acc: 0.9662\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9994\n",
      "Epoch 00084: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0030 - acc: 0.9994 - val_loss: 0.1357 - val_acc: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00085: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1648 - val_acc: 0.9686\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 00086: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.2290 - val_acc: 0.9548\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 00087: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0143 - acc: 0.9958 - val_loss: 0.1561 - val_acc: 0.9653\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9990\n",
      "Epoch 00088: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0031 - acc: 0.9990 - val_loss: 0.1865 - val_acc: 0.9630\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9983\n",
      "Epoch 00089: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1646 - val_acc: 0.9646\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 00090: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0041 - acc: 0.9989 - val_loss: 0.1386 - val_acc: 0.9683\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9989\n",
      "Epoch 00091: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0032 - acc: 0.9989 - val_loss: 0.2701 - val_acc: 0.9443\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 00092: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0107 - acc: 0.9967 - val_loss: 0.1376 - val_acc: 0.9686\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 00093: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0043 - acc: 0.9988 - val_loss: 0.1788 - val_acc: 0.9632\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9969\n",
      "Epoch 00094: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0097 - acc: 0.9969 - val_loss: 0.1397 - val_acc: 0.9681\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9989\n",
      "Epoch 00095: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0041 - acc: 0.9989 - val_loss: 0.1385 - val_acc: 0.9702\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 00096: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0038 - acc: 0.9990 - val_loss: 0.1386 - val_acc: 0.9695\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9983\n",
      "Epoch 00097: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0057 - acc: 0.9983 - val_loss: 0.1528 - val_acc: 0.9674\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00098: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1386 - val_acc: 0.9713\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9978\n",
      "Epoch 00099: val_loss did not improve from 0.11901\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0071 - acc: 0.9978 - val_loss: 0.1778 - val_acc: 0.9658\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.1698 - acc: 0.9558\n",
      "Loss: 0.16982969287144617 Accuracy: 0.9557632\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9833 - acc: 0.6957\n",
      "Epoch 00001: val_loss improved from inf to 0.71304, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/001-0.7130.hdf5\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.9831 - acc: 0.6957 - val_loss: 0.7130 - val_acc: 0.7815\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3607 - acc: 0.8864\n",
      "Epoch 00002: val_loss improved from 0.71304 to 0.28746, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/002-0.2875.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.3608 - acc: 0.8863 - val_loss: 0.2875 - val_acc: 0.9131\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9194\n",
      "Epoch 00003: val_loss improved from 0.28746 to 0.20487, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/003-0.2049.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.2556 - acc: 0.9194 - val_loss: 0.2049 - val_acc: 0.9390\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9381\n",
      "Epoch 00004: val_loss did not improve from 0.20487\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.2008 - acc: 0.9381 - val_loss: 0.2419 - val_acc: 0.9264\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9493\n",
      "Epoch 00005: val_loss improved from 0.20487 to 0.19791, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/005-0.1979.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1622 - acc: 0.9493 - val_loss: 0.1979 - val_acc: 0.9448\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9561\n",
      "Epoch 00006: val_loss improved from 0.19791 to 0.17830, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/006-0.1783.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1374 - acc: 0.9561 - val_loss: 0.1783 - val_acc: 0.9462\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9636\n",
      "Epoch 00007: val_loss improved from 0.17830 to 0.17499, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/007-0.1750.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1157 - acc: 0.9635 - val_loss: 0.1750 - val_acc: 0.9439\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9652\n",
      "Epoch 00008: val_loss improved from 0.17499 to 0.16176, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/008-0.1618.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.1108 - acc: 0.9652 - val_loss: 0.1618 - val_acc: 0.9541\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9728\n",
      "Epoch 00009: val_loss did not improve from 0.16176\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0889 - acc: 0.9728 - val_loss: 0.1671 - val_acc: 0.9513\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9753\n",
      "Epoch 00010: val_loss did not improve from 0.16176\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0778 - acc: 0.9753 - val_loss: 0.1727 - val_acc: 0.9515\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9781\n",
      "Epoch 00011: val_loss did not improve from 0.16176\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0696 - acc: 0.9781 - val_loss: 0.1781 - val_acc: 0.9497\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9821\n",
      "Epoch 00012: val_loss improved from 0.16176 to 0.15165, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/012-0.1517.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0583 - acc: 0.9821 - val_loss: 0.1517 - val_acc: 0.9527\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9830\n",
      "Epoch 00013: val_loss improved from 0.15165 to 0.14089, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/013-0.1409.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0541 - acc: 0.9830 - val_loss: 0.1409 - val_acc: 0.9585\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9864\n",
      "Epoch 00014: val_loss did not improve from 0.14089\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0448 - acc: 0.9864 - val_loss: 0.1632 - val_acc: 0.9560\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9843\n",
      "Epoch 00015: val_loss did not improve from 0.14089\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0494 - acc: 0.9843 - val_loss: 0.1575 - val_acc: 0.9548\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9874\n",
      "Epoch 00016: val_loss did not improve from 0.14089\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0409 - acc: 0.9874 - val_loss: 0.2124 - val_acc: 0.9420\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9895\n",
      "Epoch 00017: val_loss improved from 0.14089 to 0.13594, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/017-0.1359.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0355 - acc: 0.9895 - val_loss: 0.1359 - val_acc: 0.9632\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9890\n",
      "Epoch 00018: val_loss did not improve from 0.13594\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0356 - acc: 0.9891 - val_loss: 0.1599 - val_acc: 0.9606\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9915\n",
      "Epoch 00019: val_loss did not improve from 0.13594\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0294 - acc: 0.9914 - val_loss: 0.1793 - val_acc: 0.9539\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9866\n",
      "Epoch 00020: val_loss did not improve from 0.13594\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0435 - acc: 0.9866 - val_loss: 0.1374 - val_acc: 0.9651\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9936\n",
      "Epoch 00021: val_loss did not improve from 0.13594\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0223 - acc: 0.9936 - val_loss: 0.1436 - val_acc: 0.9627\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9928\n",
      "Epoch 00022: val_loss did not improve from 0.13594\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0237 - acc: 0.9928 - val_loss: 0.1924 - val_acc: 0.9495\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9940\n",
      "Epoch 00023: val_loss did not improve from 0.13594\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0219 - acc: 0.9940 - val_loss: 0.1798 - val_acc: 0.9569\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9874\n",
      "Epoch 00024: val_loss improved from 0.13594 to 0.12343, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/024-0.1234.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0406 - acc: 0.9874 - val_loss: 0.1234 - val_acc: 0.9667\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9960\n",
      "Epoch 00025: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0159 - acc: 0.9960 - val_loss: 0.1395 - val_acc: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9960\n",
      "Epoch 00026: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0152 - acc: 0.9960 - val_loss: 0.3406 - val_acc: 0.9299\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9940\n",
      "Epoch 00027: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0204 - acc: 0.9940 - val_loss: 0.1526 - val_acc: 0.9616\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9964\n",
      "Epoch 00028: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0137 - acc: 0.9964 - val_loss: 0.1551 - val_acc: 0.9637\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9945\n",
      "Epoch 00029: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0190 - acc: 0.9945 - val_loss: 0.1344 - val_acc: 0.9672\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9951\n",
      "Epoch 00030: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0177 - acc: 0.9951 - val_loss: 0.1548 - val_acc: 0.9672\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9954\n",
      "Epoch 00031: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0158 - acc: 0.9954 - val_loss: 0.1482 - val_acc: 0.9611\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9947\n",
      "Epoch 00032: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0168 - acc: 0.9947 - val_loss: 0.1628 - val_acc: 0.9639\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 00033: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0141 - acc: 0.9958 - val_loss: 0.1811 - val_acc: 0.9562\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9985\n",
      "Epoch 00034: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0068 - acc: 0.9985 - val_loss: 0.1357 - val_acc: 0.9662\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9928\n",
      "Epoch 00035: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0233 - acc: 0.9928 - val_loss: 0.1381 - val_acc: 0.9655\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 00036: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0102 - acc: 0.9971 - val_loss: 0.1881 - val_acc: 0.9581\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9949\n",
      "Epoch 00037: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0175 - acc: 0.9949 - val_loss: 0.1407 - val_acc: 0.9660\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9937\n",
      "Epoch 00038: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0217 - acc: 0.9937 - val_loss: 0.1407 - val_acc: 0.9660\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9952\n",
      "Epoch 00039: val_loss did not improve from 0.12343\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0171 - acc: 0.9952 - val_loss: 0.1349 - val_acc: 0.9674\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9961\n",
      "Epoch 00040: val_loss improved from 0.12343 to 0.12074, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/040-0.1207.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0153 - acc: 0.9961 - val_loss: 0.1207 - val_acc: 0.9737\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9983\n",
      "Epoch 00041: val_loss improved from 0.12074 to 0.11970, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/041-0.1197.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1197 - val_acc: 0.9700\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9950\n",
      "Epoch 00042: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0174 - acc: 0.9950 - val_loss: 0.1387 - val_acc: 0.9697\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9981\n",
      "Epoch 00043: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0075 - acc: 0.9981 - val_loss: 0.1619 - val_acc: 0.9632\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9968\n",
      "Epoch 00044: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0107 - acc: 0.9968 - val_loss: 0.1401 - val_acc: 0.9672\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 00045: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.1580 - val_acc: 0.9658\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9970\n",
      "Epoch 00046: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0100 - acc: 0.9970 - val_loss: 0.1207 - val_acc: 0.9706\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9971\n",
      "Epoch 00047: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0099 - acc: 0.9971 - val_loss: 0.1625 - val_acc: 0.9609\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9958\n",
      "Epoch 00048: val_loss did not improve from 0.11970\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0147 - acc: 0.9958 - val_loss: 0.1331 - val_acc: 0.9688\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9988\n",
      "Epoch 00049: val_loss improved from 0.11970 to 0.11408, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/049-0.1141.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0053 - acc: 0.9988 - val_loss: 0.1141 - val_acc: 0.9720\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9987\n",
      "Epoch 00050: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0048 - acc: 0.9987 - val_loss: 0.1830 - val_acc: 0.9611\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0184 - acc: 0.9937 - val_loss: 0.1343 - val_acc: 0.9676\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9974\n",
      "Epoch 00052: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0095 - acc: 0.9974 - val_loss: 0.1498 - val_acc: 0.9653\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9978\n",
      "Epoch 00053: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0074 - acc: 0.9978 - val_loss: 0.1777 - val_acc: 0.9613\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9955\n",
      "Epoch 00054: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0144 - acc: 0.9955 - val_loss: 0.1253 - val_acc: 0.9683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 00055: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0064 - acc: 0.9986 - val_loss: 0.1156 - val_acc: 0.9725\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00056: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1410 - val_acc: 0.9662\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9970\n",
      "Epoch 00057: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0107 - acc: 0.9970 - val_loss: 0.1518 - val_acc: 0.9646\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9982\n",
      "Epoch 00058: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0062 - acc: 0.9982 - val_loss: 0.1553 - val_acc: 0.9669\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9979\n",
      "Epoch 00059: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0071 - acc: 0.9979 - val_loss: 0.1519 - val_acc: 0.9674\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 00060: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0118 - acc: 0.9965 - val_loss: 0.1442 - val_acc: 0.9695\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9992\n",
      "Epoch 00061: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0037 - acc: 0.9992 - val_loss: 0.1155 - val_acc: 0.9751\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9983\n",
      "Epoch 00062: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0061 - acc: 0.9983 - val_loss: 0.1667 - val_acc: 0.9634\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9952\n",
      "Epoch 00063: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0148 - acc: 0.9952 - val_loss: 0.1308 - val_acc: 0.9700\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9987\n",
      "Epoch 00064: val_loss did not improve from 0.11408\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0051 - acc: 0.9987 - val_loss: 0.1335 - val_acc: 0.9709\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00065: val_loss improved from 0.11408 to 0.11396, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/065-0.1140.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.1140 - val_acc: 0.9718\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9996\n",
      "Epoch 00066: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1278 - val_acc: 0.9723\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9945\n",
      "Epoch 00067: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0177 - acc: 0.9945 - val_loss: 0.1509 - val_acc: 0.9667\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00068: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0030 - acc: 0.9993 - val_loss: 0.1215 - val_acc: 0.9713\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00069: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1975 - val_acc: 0.9595\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 00070: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.1202 - val_acc: 0.9737\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9967\n",
      "Epoch 00071: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0115 - acc: 0.9967 - val_loss: 0.2013 - val_acc: 0.9576\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981\n",
      "Epoch 00072: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0069 - acc: 0.9981 - val_loss: 0.1446 - val_acc: 0.9665\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9988\n",
      "Epoch 00073: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0044 - acc: 0.9988 - val_loss: 0.1658 - val_acc: 0.9665\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9980\n",
      "Epoch 00074: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0060 - acc: 0.9980 - val_loss: 0.1232 - val_acc: 0.9737\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 00075: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0037 - acc: 0.9989 - val_loss: 0.1333 - val_acc: 0.9704\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9964\n",
      "Epoch 00076: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0114 - acc: 0.9964 - val_loss: 0.1511 - val_acc: 0.9662\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 00077: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0040 - acc: 0.9988 - val_loss: 0.1630 - val_acc: 0.9660\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9991\n",
      "Epoch 00078: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0036 - acc: 0.9991 - val_loss: 0.1808 - val_acc: 0.9618\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9975\n",
      "Epoch 00079: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0077 - acc: 0.9975 - val_loss: 0.1241 - val_acc: 0.9725\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00080: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.1799 - val_acc: 0.9648\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9967\n",
      "Epoch 00081: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0117 - acc: 0.9967 - val_loss: 0.1589 - val_acc: 0.9665\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00082: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1216 - val_acc: 0.9730\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00083: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1419 - val_acc: 0.9700\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9967\n",
      "Epoch 00084: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0102 - acc: 0.9967 - val_loss: 0.1549 - val_acc: 0.9637\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 00085: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0039 - acc: 0.9989 - val_loss: 0.1232 - val_acc: 0.9734\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 00086: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0043 - acc: 0.9988 - val_loss: 0.2148 - val_acc: 0.9571\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 00087: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0048 - acc: 0.9985 - val_loss: 0.1665 - val_acc: 0.9639\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9977\n",
      "Epoch 00088: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0076 - acc: 0.9977 - val_loss: 0.1819 - val_acc: 0.9634\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9989\n",
      "Epoch 00089: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0035 - acc: 0.9989 - val_loss: 0.1564 - val_acc: 0.9665\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9990\n",
      "Epoch 00090: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0037 - acc: 0.9990 - val_loss: 0.1406 - val_acc: 0.9697\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9990\n",
      "Epoch 00091: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0036 - acc: 0.9989 - val_loss: 0.1382 - val_acc: 0.9690\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 00092: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.1658 - val_acc: 0.9655\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9989\n",
      "Epoch 00093: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0038 - acc: 0.9989 - val_loss: 0.1422 - val_acc: 0.9693\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9996\n",
      "Epoch 00094: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0018 - acc: 0.9996 - val_loss: 0.1268 - val_acc: 0.9725\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 00095: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0023 - acc: 0.9992 - val_loss: 0.1334 - val_acc: 0.9734\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 00096: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0035 - acc: 0.9991 - val_loss: 0.1536 - val_acc: 0.9695\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9964\n",
      "Epoch 00097: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0107 - acc: 0.9964 - val_loss: 0.1944 - val_acc: 0.9637\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 00098: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0029 - acc: 0.9994 - val_loss: 0.1332 - val_acc: 0.9718\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9990\n",
      "Epoch 00099: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0041 - acc: 0.9990 - val_loss: 0.2384 - val_acc: 0.9574\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 00100: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0041 - acc: 0.9988 - val_loss: 0.1384 - val_acc: 0.9716\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9979\n",
      "Epoch 00101: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0074 - acc: 0.9979 - val_loss: 0.1487 - val_acc: 0.9709\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 00102: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0049 - acc: 0.9986 - val_loss: 0.1401 - val_acc: 0.9716\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9982\n",
      "Epoch 00103: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0055 - acc: 0.9982 - val_loss: 0.1329 - val_acc: 0.9711\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 00104: val_loss did not improve from 0.11396\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1242 - val_acc: 0.9741\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.4615e-04 - acc: 0.9997\n",
      "Epoch 00105: val_loss improved from 0.11396 to 0.11377, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/105-0.1138.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 8.4613e-04 - acc: 0.9997 - val_loss: 0.1138 - val_acc: 0.9741\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9984\n",
      "Epoch 00106: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0053 - acc: 0.9984 - val_loss: 0.1842 - val_acc: 0.9651\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9981\n",
      "Epoch 00107: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0077 - acc: 0.9981 - val_loss: 0.1295 - val_acc: 0.9725\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00108: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1390 - val_acc: 0.9688\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9983\n",
      "Epoch 00109: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0048 - acc: 0.9983 - val_loss: 0.1429 - val_acc: 0.9704\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9993\n",
      "Epoch 00110: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1222 - val_acc: 0.9744\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 00111: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0032 - acc: 0.9990 - val_loss: 0.1677 - val_acc: 0.9681\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9992\n",
      "Epoch 00112: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0030 - acc: 0.9992 - val_loss: 0.1565 - val_acc: 0.9695\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9983\n",
      "Epoch 00113: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0051 - acc: 0.9983 - val_loss: 0.1478 - val_acc: 0.9702\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9991\n",
      "Epoch 00114: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0033 - acc: 0.9991 - val_loss: 0.1644 - val_acc: 0.9672\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9985\n",
      "Epoch 00115: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0050 - acc: 0.9985 - val_loss: 0.1403 - val_acc: 0.9718\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9994\n",
      "Epoch 00116: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.1841 - val_acc: 0.9641\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9974\n",
      "Epoch 00117: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 0.1226 - val_acc: 0.9727\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 00118: val_loss did not improve from 0.11377\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1248 - val_acc: 0.9734\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00119: val_loss improved from 0.11377 to 0.10924, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv_checkpoint/119-0.1092.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.1092 - val_acc: 0.9760\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9991\n",
      "Epoch 00120: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0030 - acc: 0.9991 - val_loss: 0.1705 - val_acc: 0.9613\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9987\n",
      "Epoch 00121: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0037 - acc: 0.9988 - val_loss: 0.1347 - val_acc: 0.9711\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9996\n",
      "Epoch 00122: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.1570 - val_acc: 0.9676\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9982\n",
      "Epoch 00123: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0057 - acc: 0.9982 - val_loss: 0.1482 - val_acc: 0.9713\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9989\n",
      "Epoch 00124: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0037 - acc: 0.9989 - val_loss: 0.2094 - val_acc: 0.9616\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9987\n",
      "Epoch 00125: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0042 - acc: 0.9988 - val_loss: 0.1759 - val_acc: 0.9665\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9986\n",
      "Epoch 00126: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0041 - acc: 0.9986 - val_loss: 0.1398 - val_acc: 0.9711\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9983\n",
      "Epoch 00127: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0055 - acc: 0.9983 - val_loss: 0.1241 - val_acc: 0.9720\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 00128: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1161 - val_acc: 0.9746\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.0778e-04 - acc: 0.9998\n",
      "Epoch 00129: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 9.0766e-04 - acc: 0.9998 - val_loss: 0.1127 - val_acc: 0.9755\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6005e-04 - acc: 0.9999\n",
      "Epoch 00130: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 6.5996e-04 - acc: 0.9999 - val_loss: 0.1169 - val_acc: 0.9748\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9988\n",
      "Epoch 00131: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0043 - acc: 0.9988 - val_loss: 0.1568 - val_acc: 0.9704\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 00132: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0048 - acc: 0.9985 - val_loss: 0.1356 - val_acc: 0.9727\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00133: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1183 - val_acc: 0.9751\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 00134: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0021 - acc: 0.9993 - val_loss: 0.1821 - val_acc: 0.9618\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9979\n",
      "Epoch 00135: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0062 - acc: 0.9979 - val_loss: 0.1452 - val_acc: 0.9693\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9988\n",
      "Epoch 00136: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0031 - acc: 0.9988 - val_loss: 0.1376 - val_acc: 0.9737\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9992\n",
      "Epoch 00137: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0029 - acc: 0.9992 - val_loss: 0.1258 - val_acc: 0.9734\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9997\n",
      "Epoch 00138: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0012 - acc: 0.9997 - val_loss: 0.1212 - val_acc: 0.9758\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9986\n",
      "Epoch 00139: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0047 - acc: 0.9986 - val_loss: 0.1509 - val_acc: 0.9700\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 00140: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0014 - acc: 0.9997 - val_loss: 0.1209 - val_acc: 0.9739\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1936e-04 - acc: 0.9999\n",
      "Epoch 00141: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 6.1934e-04 - acc: 0.9999 - val_loss: 0.1374 - val_acc: 0.9711\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9983\n",
      "Epoch 00142: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0062 - acc: 0.9983 - val_loss: 0.1634 - val_acc: 0.9702\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9986\n",
      "Epoch 00143: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0045 - acc: 0.9986 - val_loss: 0.1192 - val_acc: 0.9758\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.7493e-04 - acc: 0.9997\n",
      "Epoch 00144: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 9.7480e-04 - acc: 0.9997 - val_loss: 0.1283 - val_acc: 0.9734\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9997\n",
      "Epoch 00145: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0011 - acc: 0.9997 - val_loss: 0.1500 - val_acc: 0.9697\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9985\n",
      "Epoch 00146: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 0.1414 - val_acc: 0.9711\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 00147: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1366 - val_acc: 0.9741\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.1889e-04 - acc: 0.9998\n",
      "Epoch 00148: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 9.1878e-04 - acc: 0.9998 - val_loss: 0.1340 - val_acc: 0.9727\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2091e-04 - acc: 0.9999\n",
      "Epoch 00149: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 4.2085e-04 - acc: 0.9999 - val_loss: 0.1461 - val_acc: 0.9744\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6341e-04 - acc: 0.9998\n",
      "Epoch 00150: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 6.6332e-04 - acc: 0.9998 - val_loss: 0.1204 - val_acc: 0.9748\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9973\n",
      "Epoch 00151: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0078 - acc: 0.9973 - val_loss: 0.1915 - val_acc: 0.9651\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 00152: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0025 - acc: 0.9992 - val_loss: 0.1378 - val_acc: 0.9725\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9992\n",
      "Epoch 00153: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0027 - acc: 0.9992 - val_loss: 0.1624 - val_acc: 0.9697\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9995\n",
      "Epoch 00154: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0017 - acc: 0.9995 - val_loss: 0.1573 - val_acc: 0.9672\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9994\n",
      "Epoch 00155: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0020 - acc: 0.9994 - val_loss: 0.1781 - val_acc: 0.9683\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9992\n",
      "Epoch 00156: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0028 - acc: 0.9992 - val_loss: 0.1375 - val_acc: 0.9746\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.7768e-04 - acc: 0.9999\n",
      "Epoch 00157: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 5.7761e-04 - acc: 0.9999 - val_loss: 0.1533 - val_acc: 0.9709\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 00158: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1604 - val_acc: 0.9716\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9981\n",
      "Epoch 00159: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 0.0056 - acc: 0.9981 - val_loss: 0.1529 - val_acc: 0.9679\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 00160: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0016 - acc: 0.9996 - val_loss: 0.1342 - val_acc: 0.9734\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9989\n",
      "Epoch 00161: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0039 - acc: 0.9989 - val_loss: 0.1320 - val_acc: 0.9720\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9992\n",
      "Epoch 00162: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0025 - acc: 0.9992 - val_loss: 0.1358 - val_acc: 0.9744\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.8722e-04 - acc: 0.9999\n",
      "Epoch 00163: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 4.8715e-04 - acc: 0.9999 - val_loss: 0.1198 - val_acc: 0.9753\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.0480e-04 - acc: 0.9997\n",
      "Epoch 00164: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 8.0470e-04 - acc: 0.9997 - val_loss: 0.1490 - val_acc: 0.9704\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.2575e-04 - acc: 0.9998\n",
      "Epoch 00165: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 9.9601e-04 - acc: 0.9997 - val_loss: 0.1755 - val_acc: 0.9679\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9981\n",
      "Epoch 00166: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0085 - acc: 0.9981 - val_loss: 0.1348 - val_acc: 0.9748\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9995\n",
      "Epoch 00167: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1335 - val_acc: 0.9739\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00168: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1271 - val_acc: 0.9744\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1456e-04 - acc: 0.9999\n",
      "Epoch 00169: val_loss did not improve from 0.10924\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 3.1452e-04 - acc: 0.9999 - val_loss: 0.1311 - val_acc: 0.9751\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.1470 - acc: 0.9678\n",
      "Loss: 0.1470132469479998 Accuracy: 0.9678089\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_ch_128_DO_025_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_128_DO_BN(conv_num=i)\n",
    "\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,805,712\n",
      "Trainable params: 3,804,944\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 4.1991 - acc: 0.4696\n",
      "Loss: 4.199091407294586 Accuracy: 0.46957424\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,461,392\n",
      "Trainable params: 1,460,368\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 1.1581 - acc: 0.6816\n",
      "Loss: 1.158068077239911 Accuracy: 0.68161994\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,221,008\n",
      "Trainable params: 1,219,472\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.8222 - acc: 0.7713\n",
      "Loss: 0.8222332463705156 Accuracy: 0.77133954\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,009,296\n",
      "Trainable params: 1,007,248\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.5021 - acc: 0.8615\n",
      "Loss: 0.5021360106804909 Accuracy: 0.8614746\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,158,032\n",
      "Trainable params: 1,155,472\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2766 - acc: 0.9300\n",
      "Loss: 0.27657951956473653 Accuracy: 0.9300104\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,429,648\n",
      "Trainable params: 1,426,576\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1698 - acc: 0.9558\n",
      "Loss: 0.16982969287144617 Accuracy: 0.9557632\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,075,280\n",
      "Trainable params: 2,071,184\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1470 - acc: 0.9678\n",
      "Loss: 0.1470132469479998 Accuracy: 0.9678089\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO_025_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,805,712\n",
      "Trainable params: 3,804,944\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 5.0938 - acc: 0.5124\n",
      "Loss: 5.093801811451976 Accuracy: 0.51235723\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,461,392\n",
      "Trainable params: 1,460,368\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 2.0799 - acc: 0.6866\n",
      "Loss: 2.079866018473545 Accuracy: 0.6866044\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,221,008\n",
      "Trainable params: 1,219,472\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.5641 - acc: 0.7445\n",
      "Loss: 1.5640950009582695 Accuracy: 0.74454826\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,009,296\n",
      "Trainable params: 1,007,248\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.6177 - acc: 0.8789\n",
      "Loss: 0.6177340093740917 Accuracy: 0.87892\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,158,032\n",
      "Trainable params: 1,155,472\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.3652 - acc: 0.9171\n",
      "Loss: 0.36520254226364696 Accuracy: 0.9171339\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,429,648\n",
      "Trainable params: 1,426,576\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1915 - acc: 0.9547\n",
      "Loss: 0.1914897294912034 Accuracy: 0.9547248\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,075,280\n",
      "Trainable params: 2,071,184\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1511 - acc: 0.9701\n",
      "Loss: 0.15111258443498643 Accuracy: 0.9700934\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
