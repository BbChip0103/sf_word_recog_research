{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN_2(conv_num=1):\n",
    "    kernel_size = 64\n",
    "    filter_size = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3*kernel_size, filters=filter_size, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        target_kernel_size = 3 * (kernel_size//(2**(i+1)))\n",
    "        model.add(Conv1D (kernel_size=target_kernel_size if target_kernel_size != 0 else 3, \n",
    "                          filters=filter_size*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())    \n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,492,624\n",
      "Trainable params: 18,444,496\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 7,232,400\n",
      "Trainable params: 6,549,520\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,877,648\n",
      "Trainable params: 2,649,808\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,459,472\n",
      "Trainable params: 1,383,184\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,304,976\n",
      "Trainable params: 1,253,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,066,000\n",
      "Trainable params: 1,048,336\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 1,003,152\n",
      "Trainable params: 996,496\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,017,104\n",
      "Trainable params: 1,013,776\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,109,008\n",
      "Trainable params: 1,105,936\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 12.6272 - acc: 0.1886\n",
      "Epoch 00001: val_loss improved from inf to 12.22745, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/001-12.2275.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 12.6273 - acc: 0.1886 - val_loss: 12.2275 - val_acc: 0.2127\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.2456 - acc: 0.2811\n",
      "Epoch 00002: val_loss improved from 12.22745 to 11.15144, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/002-11.1514.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 11.2463 - acc: 0.2811 - val_loss: 11.1514 - val_acc: 0.2888\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.5700 - acc: 0.3256\n",
      "Epoch 00003: val_loss improved from 11.15144 to 10.37287, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/003-10.3729.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 10.5708 - acc: 0.3256 - val_loss: 10.3729 - val_acc: 0.3345\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.0688 - acc: 0.3585\n",
      "Epoch 00004: val_loss improved from 10.37287 to 10.33316, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/004-10.3332.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 10.0696 - acc: 0.3584 - val_loss: 10.3332 - val_acc: 0.3394\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.6718 - acc: 0.3840\n",
      "Epoch 00005: val_loss improved from 10.33316 to 9.99519, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/005-9.9952.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 9.6723 - acc: 0.3840 - val_loss: 9.9952 - val_acc: 0.3601\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.4887 - acc: 0.3948\n",
      "Epoch 00006: val_loss improved from 9.99519 to 9.95627, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/006-9.9563.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 9.4887 - acc: 0.3948 - val_loss: 9.9563 - val_acc: 0.3636\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.1239 - acc: 0.4189\n",
      "Epoch 00007: val_loss improved from 9.95627 to 9.59822, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/007-9.5982.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 9.1245 - acc: 0.4188 - val_loss: 9.5982 - val_acc: 0.3881\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.9602 - acc: 0.4299\n",
      "Epoch 00008: val_loss improved from 9.59822 to 9.58851, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/008-9.5885.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 8.9595 - acc: 0.4299 - val_loss: 9.5885 - val_acc: 0.3909\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.6961 - acc: 0.4464\n",
      "Epoch 00009: val_loss improved from 9.58851 to 9.36928, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/009-9.3693.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 8.6967 - acc: 0.4463 - val_loss: 9.3693 - val_acc: 0.4002\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.6067 - acc: 0.4524\n",
      "Epoch 00010: val_loss improved from 9.36928 to 9.28240, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/010-9.2824.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 8.6077 - acc: 0.4524 - val_loss: 9.2824 - val_acc: 0.4095\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.3209 - acc: 0.4700\n",
      "Epoch 00011: val_loss improved from 9.28240 to 9.12377, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/011-9.1238.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 8.3211 - acc: 0.4700 - val_loss: 9.1238 - val_acc: 0.4144\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.1022 - acc: 0.4842\n",
      "Epoch 00012: val_loss did not improve from 9.12377\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 8.1024 - acc: 0.4841 - val_loss: 9.1366 - val_acc: 0.4172\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.9312 - acc: 0.4961\n",
      "Epoch 00013: val_loss did not improve from 9.12377\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.9324 - acc: 0.4961 - val_loss: 9.1562 - val_acc: 0.4172\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.8828 - acc: 0.4991\n",
      "Epoch 00014: val_loss improved from 9.12377 to 8.97934, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/014-8.9793.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.8826 - acc: 0.4991 - val_loss: 8.9793 - val_acc: 0.4307\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.6752 - acc: 0.5120\n",
      "Epoch 00015: val_loss did not improve from 8.97934\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.6750 - acc: 0.5119 - val_loss: 9.0977 - val_acc: 0.4212\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.5358 - acc: 0.5204\n",
      "Epoch 00016: val_loss did not improve from 8.97934\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.5365 - acc: 0.5203 - val_loss: 9.0430 - val_acc: 0.4237\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.3898 - acc: 0.5310\n",
      "Epoch 00017: val_loss improved from 8.97934 to 8.89004, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/017-8.8900.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.3910 - acc: 0.5309 - val_loss: 8.8900 - val_acc: 0.4328\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.2936 - acc: 0.5369\n",
      "Epoch 00018: val_loss did not improve from 8.89004\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.2934 - acc: 0.5369 - val_loss: 8.8967 - val_acc: 0.4344\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.2441 - acc: 0.5397\n",
      "Epoch 00019: val_loss improved from 8.89004 to 8.82004, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/019-8.8200.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 7.2440 - acc: 0.5397 - val_loss: 8.8200 - val_acc: 0.4396\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1508 - acc: 0.5460\n",
      "Epoch 00020: val_loss improved from 8.82004 to 8.74549, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/020-8.7455.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.1515 - acc: 0.5460 - val_loss: 8.7455 - val_acc: 0.4405\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1297 - acc: 0.5474\n",
      "Epoch 00021: val_loss did not improve from 8.74549\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 7.1309 - acc: 0.5473 - val_loss: 8.8415 - val_acc: 0.4363\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.9745 - acc: 0.5571\n",
      "Epoch 00022: val_loss improved from 8.74549 to 8.66025, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/022-8.6602.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.9754 - acc: 0.5571 - val_loss: 8.6602 - val_acc: 0.4489\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7392 - acc: 0.5717\n",
      "Epoch 00023: val_loss improved from 8.66025 to 8.50944, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/023-8.5094.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 6.7400 - acc: 0.5717 - val_loss: 8.5094 - val_acc: 0.4580\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7441 - acc: 0.5718\n",
      "Epoch 00024: val_loss did not improve from 8.50944\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 6.7440 - acc: 0.5718 - val_loss: 8.5573 - val_acc: 0.4517\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6809 - acc: 0.5754\n",
      "Epoch 00025: val_loss did not improve from 8.50944\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.6817 - acc: 0.5754 - val_loss: 8.5379 - val_acc: 0.4573\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.7123 - acc: 0.5733\n",
      "Epoch 00026: val_loss improved from 8.50944 to 8.43398, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/026-8.4340.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 6.7127 - acc: 0.5733 - val_loss: 8.4340 - val_acc: 0.4628\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.5540 - acc: 0.5846\n",
      "Epoch 00027: val_loss did not improve from 8.43398\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.5540 - acc: 0.5846 - val_loss: 8.5275 - val_acc: 0.4580\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.4411 - acc: 0.5915\n",
      "Epoch 00028: val_loss improved from 8.43398 to 8.42040, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/028-8.4204.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 6.4411 - acc: 0.5915 - val_loss: 8.4204 - val_acc: 0.4649\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3790 - acc: 0.5951\n",
      "Epoch 00029: val_loss did not improve from 8.42040\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.3790 - acc: 0.5951 - val_loss: 8.5129 - val_acc: 0.4575\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3210 - acc: 0.5989\n",
      "Epoch 00030: val_loss did not improve from 8.42040\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.3219 - acc: 0.5989 - val_loss: 8.4700 - val_acc: 0.4624\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2962 - acc: 0.6009\n",
      "Epoch 00031: val_loss improved from 8.42040 to 8.39846, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/031-8.3985.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 6.2962 - acc: 0.6009 - val_loss: 8.3985 - val_acc: 0.4619\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2727 - acc: 0.6026\n",
      "Epoch 00032: val_loss did not improve from 8.39846\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.2727 - acc: 0.6026 - val_loss: 8.4351 - val_acc: 0.4638\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1416 - acc: 0.6107\n",
      "Epoch 00033: val_loss did not improve from 8.39846\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.1420 - acc: 0.6107 - val_loss: 8.4451 - val_acc: 0.4638\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1194 - acc: 0.6124\n",
      "Epoch 00034: val_loss improved from 8.39846 to 8.24902, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/034-8.2490.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.1199 - acc: 0.6124 - val_loss: 8.2490 - val_acc: 0.4747\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.0720 - acc: 0.6148\n",
      "Epoch 00035: val_loss did not improve from 8.24902\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 6.0725 - acc: 0.6148 - val_loss: 8.2533 - val_acc: 0.4754\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9433 - acc: 0.6240\n",
      "Epoch 00036: val_loss did not improve from 8.24902\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.9429 - acc: 0.6240 - val_loss: 8.3744 - val_acc: 0.4663\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9097 - acc: 0.6264\n",
      "Epoch 00037: val_loss improved from 8.24902 to 8.18936, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/037-8.1894.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 5.9107 - acc: 0.6264 - val_loss: 8.1894 - val_acc: 0.4808\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9439 - acc: 0.6233\n",
      "Epoch 00038: val_loss did not improve from 8.18936\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.9449 - acc: 0.6232 - val_loss: 8.4176 - val_acc: 0.4626\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9748 - acc: 0.6208\n",
      "Epoch 00039: val_loss did not improve from 8.18936\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.9753 - acc: 0.6207 - val_loss: 8.6804 - val_acc: 0.4500\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.8745 - acc: 0.6281\n",
      "Epoch 00040: val_loss did not improve from 8.18936\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.8746 - acc: 0.6281 - val_loss: 8.3496 - val_acc: 0.4717\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.8267 - acc: 0.6307\n",
      "Epoch 00041: val_loss did not improve from 8.18936\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.8272 - acc: 0.6307 - val_loss: 8.3186 - val_acc: 0.4731\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.7534 - acc: 0.6358\n",
      "Epoch 00042: val_loss did not improve from 8.18936\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.7543 - acc: 0.6357 - val_loss: 8.2195 - val_acc: 0.4801\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.7586 - acc: 0.6360\n",
      "Epoch 00043: val_loss improved from 8.18936 to 8.14455, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/043-8.1445.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 5.7601 - acc: 0.6359 - val_loss: 8.1445 - val_acc: 0.4840\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.7062 - acc: 0.6392\n",
      "Epoch 00044: val_loss did not improve from 8.14455\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.7067 - acc: 0.6392 - val_loss: 8.3758 - val_acc: 0.4691\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6831 - acc: 0.6402\n",
      "Epoch 00045: val_loss did not improve from 8.14455\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.6828 - acc: 0.6402 - val_loss: 8.2137 - val_acc: 0.4808\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6415 - acc: 0.6433\n",
      "Epoch 00046: val_loss improved from 8.14455 to 8.08002, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/046-8.0800.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.6416 - acc: 0.6433 - val_loss: 8.0800 - val_acc: 0.4871\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6327 - acc: 0.6443\n",
      "Epoch 00047: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.6338 - acc: 0.6442 - val_loss: 8.2214 - val_acc: 0.4768\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6304 - acc: 0.6435\n",
      "Epoch 00048: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.6314 - acc: 0.6435 - val_loss: 8.1906 - val_acc: 0.4808\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.4985 - acc: 0.6526\n",
      "Epoch 00049: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.4991 - acc: 0.6525 - val_loss: 8.2011 - val_acc: 0.4801\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5096 - acc: 0.6518\n",
      "Epoch 00050: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.5101 - acc: 0.6518 - val_loss: 8.1655 - val_acc: 0.4817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6383 - acc: 0.6431\n",
      "Epoch 00051: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.6393 - acc: 0.6431 - val_loss: 8.2960 - val_acc: 0.4733\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.4989 - acc: 0.6528\n",
      "Epoch 00052: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.4994 - acc: 0.6528 - val_loss: 8.1504 - val_acc: 0.4857\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.4869 - acc: 0.6534\n",
      "Epoch 00053: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.4877 - acc: 0.6533 - val_loss: 8.1183 - val_acc: 0.4871\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.4295 - acc: 0.6571\n",
      "Epoch 00054: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.4296 - acc: 0.6571 - val_loss: 8.2836 - val_acc: 0.4771\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3054 - acc: 0.6651\n",
      "Epoch 00055: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.3060 - acc: 0.6650 - val_loss: 8.1531 - val_acc: 0.4831\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2568 - acc: 0.6679\n",
      "Epoch 00056: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.2583 - acc: 0.6678 - val_loss: 8.0858 - val_acc: 0.4866\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2981 - acc: 0.6652\n",
      "Epoch 00057: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.2978 - acc: 0.6652 - val_loss: 8.0950 - val_acc: 0.4875\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.4749 - acc: 0.6535\n",
      "Epoch 00058: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.4755 - acc: 0.6535 - val_loss: 8.2475 - val_acc: 0.4768\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3117 - acc: 0.6643\n",
      "Epoch 00059: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.3132 - acc: 0.6642 - val_loss: 8.1211 - val_acc: 0.4826\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2646 - acc: 0.6675\n",
      "Epoch 00060: val_loss did not improve from 8.08002\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.2649 - acc: 0.6675 - val_loss: 8.2003 - val_acc: 0.4803\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1729 - acc: 0.6735\n",
      "Epoch 00061: val_loss improved from 8.08002 to 8.04718, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/061-8.0472.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.1743 - acc: 0.6734 - val_loss: 8.0472 - val_acc: 0.4894\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1560 - acc: 0.6740\n",
      "Epoch 00062: val_loss improved from 8.04718 to 8.04382, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/062-8.0438.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.1558 - acc: 0.6740 - val_loss: 8.0438 - val_acc: 0.4906\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1972 - acc: 0.6716\n",
      "Epoch 00063: val_loss did not improve from 8.04382\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.1978 - acc: 0.6715 - val_loss: 8.3097 - val_acc: 0.4740\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1029 - acc: 0.6781\n",
      "Epoch 00064: val_loss improved from 8.04382 to 8.01162, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/064-8.0116.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 5.1036 - acc: 0.6780 - val_loss: 8.0116 - val_acc: 0.4896\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1268 - acc: 0.6761\n",
      "Epoch 00065: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.1274 - acc: 0.6760 - val_loss: 8.0748 - val_acc: 0.4894\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0402 - acc: 0.6821\n",
      "Epoch 00066: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.0409 - acc: 0.6821 - val_loss: 8.1575 - val_acc: 0.4852\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1008 - acc: 0.6786\n",
      "Epoch 00067: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.1016 - acc: 0.6785 - val_loss: 8.2384 - val_acc: 0.4780\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0764 - acc: 0.6798\n",
      "Epoch 00068: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.0775 - acc: 0.6798 - val_loss: 8.0270 - val_acc: 0.4903\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0411 - acc: 0.6816\n",
      "Epoch 00069: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.0413 - acc: 0.6816 - val_loss: 8.1701 - val_acc: 0.4812\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9756 - acc: 0.6864\n",
      "Epoch 00070: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.9766 - acc: 0.6863 - val_loss: 8.0679 - val_acc: 0.4868\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0146 - acc: 0.6829\n",
      "Epoch 00071: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.0152 - acc: 0.6829 - val_loss: 8.0876 - val_acc: 0.4854\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9283 - acc: 0.6886\n",
      "Epoch 00072: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.9290 - acc: 0.6885 - val_loss: 8.3219 - val_acc: 0.4740\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0034 - acc: 0.6842\n",
      "Epoch 00073: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 5.0041 - acc: 0.6841 - val_loss: 8.0694 - val_acc: 0.4885\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.8545 - acc: 0.6937\n",
      "Epoch 00074: val_loss did not improve from 8.01162\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.8556 - acc: 0.6936 - val_loss: 8.1753 - val_acc: 0.4822\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6829 - acc: 0.7033\n",
      "Epoch 00075: val_loss improved from 8.01162 to 7.97162, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/075-7.9716.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.6841 - acc: 0.7032 - val_loss: 7.9716 - val_acc: 0.4962\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7243 - acc: 0.7013\n",
      "Epoch 00076: val_loss improved from 7.97162 to 7.86534, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/076-7.8653.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.7246 - acc: 0.7012 - val_loss: 7.8653 - val_acc: 0.5003\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5878 - acc: 0.7101\n",
      "Epoch 00077: val_loss improved from 7.86534 to 7.73609, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/077-7.7361.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.5889 - acc: 0.7100 - val_loss: 7.7361 - val_acc: 0.5101\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5639 - acc: 0.7106\n",
      "Epoch 00078: val_loss improved from 7.73609 to 7.73575, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/078-7.7357.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.5650 - acc: 0.7105 - val_loss: 7.7357 - val_acc: 0.5101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.4705 - acc: 0.7172\n",
      "Epoch 00079: val_loss improved from 7.73575 to 7.58430, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/079-7.5843.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.4712 - acc: 0.7172 - val_loss: 7.5843 - val_acc: 0.5188\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5633 - acc: 0.7114\n",
      "Epoch 00080: val_loss did not improve from 7.58430\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.5640 - acc: 0.7113 - val_loss: 7.7438 - val_acc: 0.5071\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.4617 - acc: 0.7174\n",
      "Epoch 00081: val_loss improved from 7.58430 to 7.51669, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/081-7.5167.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.4620 - acc: 0.7174 - val_loss: 7.5167 - val_acc: 0.5211\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2845 - acc: 0.7287\n",
      "Epoch 00082: val_loss did not improve from 7.51669\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.2852 - acc: 0.7286 - val_loss: 7.5844 - val_acc: 0.5192\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.2349 - acc: 0.7318\n",
      "Epoch 00083: val_loss did not improve from 7.51669\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.2357 - acc: 0.7317 - val_loss: 7.6417 - val_acc: 0.5146\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1636 - acc: 0.7367\n",
      "Epoch 00084: val_loss did not improve from 7.51669\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.1643 - acc: 0.7366 - val_loss: 7.5535 - val_acc: 0.5211\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1271 - acc: 0.7387\n",
      "Epoch 00085: val_loss did not improve from 7.51669\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.1271 - acc: 0.7387 - val_loss: 7.5171 - val_acc: 0.5232\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1002 - acc: 0.7398\n",
      "Epoch 00086: val_loss improved from 7.51669 to 7.36014, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/086-7.3601.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.1000 - acc: 0.7398 - val_loss: 7.3601 - val_acc: 0.5332\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1417 - acc: 0.7377\n",
      "Epoch 00087: val_loss did not improve from 7.36014\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 4.1420 - acc: 0.7377 - val_loss: 7.5401 - val_acc: 0.5227\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.0469 - acc: 0.7437\n",
      "Epoch 00088: val_loss did not improve from 7.36014\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 4.0481 - acc: 0.7437 - val_loss: 7.3971 - val_acc: 0.5299\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9380 - acc: 0.7508\n",
      "Epoch 00089: val_loss improved from 7.36014 to 7.21904, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_1_conv_checkpoint/089-7.2190.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 3.9388 - acc: 0.7508 - val_loss: 7.2190 - val_acc: 0.5434\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9589 - acc: 0.7493\n",
      "Epoch 00090: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.9593 - acc: 0.7493 - val_loss: 7.4731 - val_acc: 0.5264\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9845 - acc: 0.7477\n",
      "Epoch 00091: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.9852 - acc: 0.7477 - val_loss: 7.4935 - val_acc: 0.5239\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9818 - acc: 0.7476\n",
      "Epoch 00092: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.9817 - acc: 0.7476 - val_loss: 7.4081 - val_acc: 0.5292\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9665 - acc: 0.7486\n",
      "Epoch 00093: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.9669 - acc: 0.7486 - val_loss: 7.3612 - val_acc: 0.5344\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.9269 - acc: 0.7515\n",
      "Epoch 00094: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.9272 - acc: 0.7514 - val_loss: 7.3966 - val_acc: 0.5334\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8076 - acc: 0.7589\n",
      "Epoch 00095: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.8086 - acc: 0.7588 - val_loss: 7.3576 - val_acc: 0.5330\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8210 - acc: 0.7582\n",
      "Epoch 00096: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.8218 - acc: 0.7581 - val_loss: 7.4401 - val_acc: 0.5285\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7361 - acc: 0.7632\n",
      "Epoch 00097: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.7369 - acc: 0.7631 - val_loss: 7.2569 - val_acc: 0.5386\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8630 - acc: 0.7551\n",
      "Epoch 00098: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.8630 - acc: 0.7551 - val_loss: 7.2918 - val_acc: 0.5376\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8085 - acc: 0.7588\n",
      "Epoch 00099: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.8089 - acc: 0.7587 - val_loss: 7.4520 - val_acc: 0.5283\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7888 - acc: 0.7600\n",
      "Epoch 00100: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 3.7887 - acc: 0.7600 - val_loss: 7.4299 - val_acc: 0.5290\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8942 - acc: 0.7537\n",
      "Epoch 00101: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.8941 - acc: 0.7537 - val_loss: 7.5065 - val_acc: 0.5220\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.8231 - acc: 0.7580\n",
      "Epoch 00102: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.8230 - acc: 0.7580 - val_loss: 7.3162 - val_acc: 0.5351\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7346 - acc: 0.7635\n",
      "Epoch 00103: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.7363 - acc: 0.7633 - val_loss: 7.4489 - val_acc: 0.5257\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7436 - acc: 0.7633\n",
      "Epoch 00104: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.7435 - acc: 0.7633 - val_loss: 7.3725 - val_acc: 0.5323\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7028 - acc: 0.7657\n",
      "Epoch 00105: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.7041 - acc: 0.7656 - val_loss: 7.4597 - val_acc: 0.5267\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.6669 - acc: 0.7678\n",
      "Epoch 00106: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.6668 - acc: 0.7678 - val_loss: 7.3735 - val_acc: 0.5323\n",
      "Epoch 107/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.6540 - acc: 0.7688\n",
      "Epoch 00107: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.6544 - acc: 0.7687 - val_loss: 7.2846 - val_acc: 0.5374\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5800 - acc: 0.7733\n",
      "Epoch 00108: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5808 - acc: 0.7732 - val_loss: 7.4155 - val_acc: 0.5309\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5812 - acc: 0.7735\n",
      "Epoch 00109: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5812 - acc: 0.7735 - val_loss: 7.4814 - val_acc: 0.5262\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7032 - acc: 0.7651\n",
      "Epoch 00110: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.7032 - acc: 0.7651 - val_loss: 7.3780 - val_acc: 0.5309\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5833 - acc: 0.7730\n",
      "Epoch 00111: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5832 - acc: 0.7730 - val_loss: 7.2908 - val_acc: 0.5372\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5501 - acc: 0.7753\n",
      "Epoch 00112: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5505 - acc: 0.7753 - val_loss: 7.3744 - val_acc: 0.5302\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5821 - acc: 0.7735\n",
      "Epoch 00113: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5825 - acc: 0.7735 - val_loss: 7.4907 - val_acc: 0.5257\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5566 - acc: 0.7749\n",
      "Epoch 00114: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5574 - acc: 0.7748 - val_loss: 7.5875 - val_acc: 0.5199\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.4863 - acc: 0.7794\n",
      "Epoch 00115: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.4876 - acc: 0.7793 - val_loss: 7.4237 - val_acc: 0.5299\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5378 - acc: 0.7764\n",
      "Epoch 00116: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5382 - acc: 0.7764 - val_loss: 7.5166 - val_acc: 0.5243\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5789 - acc: 0.7733\n",
      "Epoch 00117: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.5784 - acc: 0.7734 - val_loss: 7.5081 - val_acc: 0.5243\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.4155 - acc: 0.7841\n",
      "Epoch 00118: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.4160 - acc: 0.7841 - val_loss: 7.3951 - val_acc: 0.5313\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.4774 - acc: 0.7802\n",
      "Epoch 00119: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.4778 - acc: 0.7802 - val_loss: 7.4905 - val_acc: 0.5255\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.4603 - acc: 0.7814\n",
      "Epoch 00120: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.4607 - acc: 0.7813 - val_loss: 7.3934 - val_acc: 0.5325\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.4491 - acc: 0.7818\n",
      "Epoch 00121: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.4490 - acc: 0.7818 - val_loss: 7.3432 - val_acc: 0.5339\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3731 - acc: 0.7866\n",
      "Epoch 00122: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3735 - acc: 0.7866 - val_loss: 7.3833 - val_acc: 0.5332\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3533 - acc: 0.7879\n",
      "Epoch 00123: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3546 - acc: 0.7878 - val_loss: 7.3806 - val_acc: 0.5327\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3357 - acc: 0.7887\n",
      "Epoch 00124: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3365 - acc: 0.7887 - val_loss: 7.3572 - val_acc: 0.5330\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3573 - acc: 0.7874\n",
      "Epoch 00125: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3577 - acc: 0.7874 - val_loss: 7.4346 - val_acc: 0.5318\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2720 - acc: 0.7933\n",
      "Epoch 00126: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.2725 - acc: 0.7932 - val_loss: 7.3892 - val_acc: 0.5313\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2966 - acc: 0.7915\n",
      "Epoch 00127: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.2962 - acc: 0.7915 - val_loss: 7.5498 - val_acc: 0.5213\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3614 - acc: 0.7874\n",
      "Epoch 00128: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3618 - acc: 0.7874 - val_loss: 7.3818 - val_acc: 0.5304\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3285 - acc: 0.7896\n",
      "Epoch 00129: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3288 - acc: 0.7896 - val_loss: 7.3911 - val_acc: 0.5337\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3323 - acc: 0.7891\n",
      "Epoch 00130: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3331 - acc: 0.7891 - val_loss: 7.3813 - val_acc: 0.5330\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3844 - acc: 0.7861\n",
      "Epoch 00131: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3852 - acc: 0.7861 - val_loss: 7.3846 - val_acc: 0.5318\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3047 - acc: 0.7911\n",
      "Epoch 00132: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3052 - acc: 0.7911 - val_loss: 7.4579 - val_acc: 0.5274\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3448 - acc: 0.7880\n",
      "Epoch 00133: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3457 - acc: 0.7879 - val_loss: 7.2543 - val_acc: 0.5418\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3011 - acc: 0.7909\n",
      "Epoch 00134: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3015 - acc: 0.7909 - val_loss: 7.3848 - val_acc: 0.5325\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2174 - acc: 0.7968\n",
      "Epoch 00135: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.2174 - acc: 0.7968 - val_loss: 7.4426 - val_acc: 0.5304\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3146 - acc: 0.7907\n",
      "Epoch 00136: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.3155 - acc: 0.7907 - val_loss: 7.3748 - val_acc: 0.5332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2451 - acc: 0.7953\n",
      "Epoch 00137: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 3.2460 - acc: 0.7952 - val_loss: 7.3830 - val_acc: 0.5327\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2311 - acc: 0.7958\n",
      "Epoch 00138: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.2316 - acc: 0.7958 - val_loss: 7.3697 - val_acc: 0.5337\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2339 - acc: 0.7958\n",
      "Epoch 00139: val_loss did not improve from 7.21904\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 3.2344 - acc: 0.7958 - val_loss: 7.3711 - val_acc: 0.5341\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 646us/sample - loss: 7.7689 - acc: 0.5080\n",
      "Loss: 7.7689363844050545 Accuracy: 0.50799584\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.3732 - acc: 0.3733\n",
      "Epoch 00001: val_loss improved from inf to 4.68530, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_2_conv_checkpoint/001-4.6853.hdf5\n",
      "36805/36805 [==============================] - 180s 5ms/sample - loss: 4.3732 - acc: 0.3733 - val_loss: 4.6853 - val_acc: 0.3545\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1855 - acc: 0.5924\n",
      "Epoch 00002: val_loss improved from 4.68530 to 4.33780, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_2_conv_checkpoint/002-4.3378.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 3.1857 - acc: 0.5924 - val_loss: 4.3378 - val_acc: 0.4864\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3617 - acc: 0.6954\n",
      "Epoch 00003: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 2.3620 - acc: 0.6953 - val_loss: 4.4530 - val_acc: 0.5176\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8814 - acc: 0.7616\n",
      "Epoch 00004: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.8812 - acc: 0.7616 - val_loss: 4.6012 - val_acc: 0.4997\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4979 - acc: 0.8140\n",
      "Epoch 00005: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.4977 - acc: 0.8141 - val_loss: 4.4893 - val_acc: 0.5323\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2823 - acc: 0.8435\n",
      "Epoch 00006: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 1.2828 - acc: 0.8434 - val_loss: 4.6403 - val_acc: 0.5311\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2044 - acc: 0.8559\n",
      "Epoch 00007: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.2055 - acc: 0.8558 - val_loss: 5.6104 - val_acc: 0.4868\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1153 - acc: 0.8701\n",
      "Epoch 00008: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.1159 - acc: 0.8701 - val_loss: 4.6150 - val_acc: 0.5502\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0372 - acc: 0.8822\n",
      "Epoch 00009: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.0380 - acc: 0.8821 - val_loss: 5.9610 - val_acc: 0.4757\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0318 - acc: 0.8871\n",
      "Epoch 00010: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.0332 - acc: 0.8870 - val_loss: 4.7281 - val_acc: 0.5658\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0085 - acc: 0.8891\n",
      "Epoch 00011: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 1.0093 - acc: 0.8891 - val_loss: 5.0739 - val_acc: 0.5563\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8805 - acc: 0.9058\n",
      "Epoch 00012: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.8805 - acc: 0.9057 - val_loss: 5.2191 - val_acc: 0.5630\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8794 - acc: 0.9082\n",
      "Epoch 00013: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.8792 - acc: 0.9082 - val_loss: 5.0347 - val_acc: 0.5637\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8313 - acc: 0.9160\n",
      "Epoch 00014: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.8325 - acc: 0.9159 - val_loss: 4.9565 - val_acc: 0.5653\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7420 - acc: 0.9265\n",
      "Epoch 00015: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7420 - acc: 0.9265 - val_loss: 5.5012 - val_acc: 0.5481\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8233 - acc: 0.9182\n",
      "Epoch 00016: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.8237 - acc: 0.9181 - val_loss: 5.1924 - val_acc: 0.5712\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7513 - acc: 0.9276\n",
      "Epoch 00017: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7514 - acc: 0.9276 - val_loss: 5.7947 - val_acc: 0.5369\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7664 - acc: 0.9268\n",
      "Epoch 00018: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7663 - acc: 0.9268 - val_loss: 5.8629 - val_acc: 0.5276\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7356 - acc: 0.9303\n",
      "Epoch 00019: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7355 - acc: 0.9303 - val_loss: 5.7370 - val_acc: 0.5455\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7328 - acc: 0.9313\n",
      "Epoch 00020: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.7338 - acc: 0.9312 - val_loss: 5.9790 - val_acc: 0.5346\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7247 - acc: 0.9318\n",
      "Epoch 00021: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.7246 - acc: 0.9319 - val_loss: 5.8979 - val_acc: 0.5362\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6703 - acc: 0.9370\n",
      "Epoch 00022: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.6702 - acc: 0.9370 - val_loss: 5.5751 - val_acc: 0.5509\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6551 - acc: 0.9405\n",
      "Epoch 00023: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6555 - acc: 0.9405 - val_loss: 5.9232 - val_acc: 0.5367\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6854 - acc: 0.9391\n",
      "Epoch 00024: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.6854 - acc: 0.9391 - val_loss: 5.9052 - val_acc: 0.5488\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6929 - acc: 0.9371\n",
      "Epoch 00025: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.6929 - acc: 0.9371 - val_loss: 6.6583 - val_acc: 0.4936\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.9412\n",
      "Epoch 00026: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.6511 - acc: 0.9412 - val_loss: 5.9768 - val_acc: 0.5437\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5875 - acc: 0.9492\n",
      "Epoch 00027: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5882 - acc: 0.9491 - val_loss: 6.0106 - val_acc: 0.5434\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6131 - acc: 0.9458\n",
      "Epoch 00028: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6141 - acc: 0.9457 - val_loss: 6.9955 - val_acc: 0.4822\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6618 - acc: 0.9426\n",
      "Epoch 00029: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6617 - acc: 0.9426 - val_loss: 5.4583 - val_acc: 0.5770\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6172 - acc: 0.9468\n",
      "Epoch 00030: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6178 - acc: 0.9468 - val_loss: 6.1215 - val_acc: 0.5290\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6347 - acc: 0.9443\n",
      "Epoch 00031: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6352 - acc: 0.9442 - val_loss: 5.8845 - val_acc: 0.5539\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6342 - acc: 0.9468\n",
      "Epoch 00032: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6346 - acc: 0.9467 - val_loss: 5.9059 - val_acc: 0.5595\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6334 - acc: 0.9461\n",
      "Epoch 00033: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.6333 - acc: 0.9461 - val_loss: 5.6264 - val_acc: 0.5700\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5530 - acc: 0.9546\n",
      "Epoch 00034: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5530 - acc: 0.9545 - val_loss: 5.6746 - val_acc: 0.5688\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5962 - acc: 0.9491\n",
      "Epoch 00035: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5961 - acc: 0.9491 - val_loss: 6.0063 - val_acc: 0.5539\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5408 - acc: 0.9552\n",
      "Epoch 00036: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5407 - acc: 0.9553 - val_loss: 6.4618 - val_acc: 0.5211\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5271 - acc: 0.9559\n",
      "Epoch 00037: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5271 - acc: 0.9559 - val_loss: 5.8797 - val_acc: 0.5546\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5218 - acc: 0.9568\n",
      "Epoch 00038: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5218 - acc: 0.9568 - val_loss: 6.2299 - val_acc: 0.5372\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.9548\n",
      "Epoch 00039: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5562 - acc: 0.9548 - val_loss: 6.1552 - val_acc: 0.5437\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5538 - acc: 0.9546\n",
      "Epoch 00040: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5538 - acc: 0.9547 - val_loss: 7.0595 - val_acc: 0.4971\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5140 - acc: 0.9573\n",
      "Epoch 00041: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5143 - acc: 0.9573 - val_loss: 5.9555 - val_acc: 0.5600\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.9559\n",
      "Epoch 00042: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5374 - acc: 0.9558 - val_loss: 6.0048 - val_acc: 0.5593\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5589 - acc: 0.9542\n",
      "Epoch 00043: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.5588 - acc: 0.9542 - val_loss: 5.5987 - val_acc: 0.5858\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.9576\n",
      "Epoch 00044: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 0.5251 - acc: 0.9575 - val_loss: 6.4478 - val_acc: 0.5313\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4981 - acc: 0.9601\n",
      "Epoch 00045: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4985 - acc: 0.9601 - val_loss: 6.2498 - val_acc: 0.5476\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4634 - acc: 0.9643\n",
      "Epoch 00046: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4645 - acc: 0.9642 - val_loss: 6.4906 - val_acc: 0.5288\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5416 - acc: 0.9566\n",
      "Epoch 00047: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5420 - acc: 0.9566 - val_loss: 5.9569 - val_acc: 0.5681\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.9650\n",
      "Epoch 00048: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4453 - acc: 0.9650 - val_loss: 5.6560 - val_acc: 0.5870\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4628 - acc: 0.9640\n",
      "Epoch 00049: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4636 - acc: 0.9639 - val_loss: 5.7817 - val_acc: 0.5723\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5040 - acc: 0.9603\n",
      "Epoch 00050: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.5044 - acc: 0.9603 - val_loss: 5.9545 - val_acc: 0.5635\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4800 - acc: 0.9620\n",
      "Epoch 00051: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4803 - acc: 0.9620 - val_loss: 6.0227 - val_acc: 0.5628\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.9620\n",
      "Epoch 00052: val_loss did not improve from 4.33780\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 0.4818 - acc: 0.9619 - val_loss: 6.2510 - val_acc: 0.5460\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 4.4027 - acc: 0.4667\n",
      "Loss: 4.402662525642451 Accuracy: 0.46666667\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4923 - acc: 0.4124\n",
      "Epoch 00001: val_loss improved from inf to 2.34501, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_3_conv_checkpoint/001-2.3450.hdf5\n",
      "36805/36805 [==============================] - 207s 6ms/sample - loss: 2.4921 - acc: 0.4125 - val_loss: 2.3450 - val_acc: 0.4041\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6253 - acc: 0.6181\n",
      "Epoch 00002: val_loss did not improve from 2.34501\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 1.6252 - acc: 0.6181 - val_loss: 2.5557 - val_acc: 0.5008\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0618 - acc: 0.7340\n",
      "Epoch 00003: val_loss did not improve from 2.34501\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 1.0618 - acc: 0.7340 - val_loss: 2.9324 - val_acc: 0.5339\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7168 - acc: 0.8104\n",
      "Epoch 00004: val_loss improved from 2.34501 to 2.11866, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_3_conv_checkpoint/004-2.1187.hdf5\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.7167 - acc: 0.8104 - val_loss: 2.1187 - val_acc: 0.5632\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4808 - acc: 0.8720\n",
      "Epoch 00005: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.4811 - acc: 0.8720 - val_loss: 2.4215 - val_acc: 0.5255\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3932 - acc: 0.8957\n",
      "Epoch 00006: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.3933 - acc: 0.8956 - val_loss: 2.7019 - val_acc: 0.5199\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3046 - acc: 0.9220\n",
      "Epoch 00007: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.3051 - acc: 0.9219 - val_loss: 2.3815 - val_acc: 0.5656\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.9160\n",
      "Epoch 00008: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.3231 - acc: 0.9160 - val_loss: 2.6499 - val_acc: 0.5544\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.9324\n",
      "Epoch 00009: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.2700 - acc: 0.9323 - val_loss: 2.5104 - val_acc: 0.5959\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9322\n",
      "Epoch 00010: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.2669 - acc: 0.9322 - val_loss: 2.5604 - val_acc: 0.6031\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9532\n",
      "Epoch 00011: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1956 - acc: 0.9531 - val_loss: 3.0394 - val_acc: 0.5467\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1830 - acc: 0.9563\n",
      "Epoch 00012: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.1832 - acc: 0.9562 - val_loss: 2.7474 - val_acc: 0.5840\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9453\n",
      "Epoch 00013: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.2254 - acc: 0.9452 - val_loss: 2.5874 - val_acc: 0.6166\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9623\n",
      "Epoch 00014: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1620 - acc: 0.9623 - val_loss: 2.4915 - val_acc: 0.6087\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9583\n",
      "Epoch 00015: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.1825 - acc: 0.9582 - val_loss: 3.2012 - val_acc: 0.5667\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9576\n",
      "Epoch 00016: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1924 - acc: 0.9576 - val_loss: 2.9890 - val_acc: 0.5672\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9587\n",
      "Epoch 00017: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1786 - acc: 0.9587 - val_loss: 3.0347 - val_acc: 0.5984\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9719\n",
      "Epoch 00018: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.1293 - acc: 0.9719 - val_loss: 2.8330 - val_acc: 0.6115\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9721\n",
      "Epoch 00019: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.1324 - acc: 0.9722 - val_loss: 3.2537 - val_acc: 0.5907\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9729\n",
      "Epoch 00020: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1256 - acc: 0.9728 - val_loss: 3.6862 - val_acc: 0.5311\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2594 - acc: 0.9465\n",
      "Epoch 00021: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.2594 - acc: 0.9465 - val_loss: 3.1807 - val_acc: 0.5975\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9764\n",
      "Epoch 00022: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1173 - acc: 0.9764 - val_loss: 3.2345 - val_acc: 0.5877\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9726\n",
      "Epoch 00023: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1279 - acc: 0.9725 - val_loss: 3.4091 - val_acc: 0.5900\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9709\n",
      "Epoch 00024: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1374 - acc: 0.9709 - val_loss: 3.2187 - val_acc: 0.5956\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9801\n",
      "Epoch 00025: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0957 - acc: 0.9801 - val_loss: 3.7647 - val_acc: 0.5642\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9677\n",
      "Epoch 00026: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1537 - acc: 0.9676 - val_loss: 3.6825 - val_acc: 0.5644\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9792\n",
      "Epoch 00027: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1036 - acc: 0.9792 - val_loss: 4.2281 - val_acc: 0.5392\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9746\n",
      "Epoch 00028: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1298 - acc: 0.9746 - val_loss: 3.2419 - val_acc: 0.6108\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9776\n",
      "Epoch 00029: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 204s 6ms/sample - loss: 0.1111 - acc: 0.9776 - val_loss: 3.0219 - val_acc: 0.6273\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9756\n",
      "Epoch 00030: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1198 - acc: 0.9756 - val_loss: 3.0401 - val_acc: 0.6243\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9799\n",
      "Epoch 00031: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1056 - acc: 0.9799 - val_loss: 3.1434 - val_acc: 0.6324\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9829\n",
      "Epoch 00032: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0925 - acc: 0.9829 - val_loss: 3.2147 - val_acc: 0.6301\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9812\n",
      "Epoch 00033: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1026 - acc: 0.9812 - val_loss: 3.5260 - val_acc: 0.6073\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9835\n",
      "Epoch 00034: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0832 - acc: 0.9835 - val_loss: 3.5202 - val_acc: 0.6077\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9856\n",
      "Epoch 00035: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0760 - acc: 0.9856 - val_loss: 3.8581 - val_acc: 0.5775\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1341 - acc: 0.9760\n",
      "Epoch 00036: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1345 - acc: 0.9760 - val_loss: 3.4351 - val_acc: 0.6212\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9773\n",
      "Epoch 00037: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1238 - acc: 0.9772 - val_loss: 4.1266 - val_acc: 0.5551\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9820\n",
      "Epoch 00038: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1010 - acc: 0.9819 - val_loss: 3.6769 - val_acc: 0.6040\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9754\n",
      "Epoch 00039: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1320 - acc: 0.9754 - val_loss: 3.6282 - val_acc: 0.6082\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9856\n",
      "Epoch 00040: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0836 - acc: 0.9856 - val_loss: 3.7756 - val_acc: 0.6000\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9871\n",
      "Epoch 00041: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0732 - acc: 0.9871 - val_loss: 3.8022 - val_acc: 0.5949\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9808\n",
      "Epoch 00042: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1063 - acc: 0.9808 - val_loss: 3.6839 - val_acc: 0.5956\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9823\n",
      "Epoch 00043: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0997 - acc: 0.9823 - val_loss: 3.3818 - val_acc: 0.6327\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9849\n",
      "Epoch 00044: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0934 - acc: 0.9849 - val_loss: 3.6661 - val_acc: 0.6096\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9805\n",
      "Epoch 00045: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1113 - acc: 0.9804 - val_loss: 3.4590 - val_acc: 0.6212\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9851\n",
      "Epoch 00046: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0850 - acc: 0.9850 - val_loss: 4.0591 - val_acc: 0.5826\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9860\n",
      "Epoch 00047: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0806 - acc: 0.9860 - val_loss: 3.4369 - val_acc: 0.6355\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9852\n",
      "Epoch 00048: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0828 - acc: 0.9852 - val_loss: 3.4917 - val_acc: 0.6327\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9895\n",
      "Epoch 00049: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0663 - acc: 0.9894 - val_loss: 3.6451 - val_acc: 0.6217\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9779\n",
      "Epoch 00050: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.1294 - acc: 0.9779 - val_loss: 3.9919 - val_acc: 0.5891\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9907\n",
      "Epoch 00051: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0617 - acc: 0.9906 - val_loss: 3.2606 - val_acc: 0.6501\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9878\n",
      "Epoch 00052: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0709 - acc: 0.9878 - val_loss: 3.6724 - val_acc: 0.6166\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9857\n",
      "Epoch 00053: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0813 - acc: 0.9857 - val_loss: 3.4731 - val_acc: 0.6296\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9903\n",
      "Epoch 00054: val_loss did not improve from 2.11866\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.0596 - acc: 0.9903 - val_loss: 3.5144 - val_acc: 0.6327\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.2687 - acc: 0.5346\n",
      "Loss: 2.26870874704973 Accuracy: 0.53457946\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8907 - acc: 0.4565\n",
      "Epoch 00001: val_loss improved from inf to 1.73658, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_4_conv_checkpoint/001-1.7366.hdf5\n",
      "36805/36805 [==============================] - 213s 6ms/sample - loss: 1.8907 - acc: 0.4565 - val_loss: 1.7366 - val_acc: 0.4663\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2723 - acc: 0.6414\n",
      "Epoch 00002: val_loss improved from 1.73658 to 1.64464, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_4_conv_checkpoint/002-1.6446.hdf5\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 1.2723 - acc: 0.6414 - val_loss: 1.6446 - val_acc: 0.5611\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9831 - acc: 0.7242\n",
      "Epoch 00003: val_loss improved from 1.64464 to 1.04908, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_4_conv_checkpoint/003-1.0491.hdf5\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.9831 - acc: 0.7242 - val_loss: 1.0491 - val_acc: 0.7065\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7948 - acc: 0.7751\n",
      "Epoch 00004: val_loss did not improve from 1.04908\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.7948 - acc: 0.7751 - val_loss: 1.2275 - val_acc: 0.6678\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6411 - acc: 0.8162\n",
      "Epoch 00005: val_loss did not improve from 1.04908\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.6414 - acc: 0.8162 - val_loss: 1.5797 - val_acc: 0.6250\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5135 - acc: 0.8517\n",
      "Epoch 00006: val_loss improved from 1.04908 to 0.94706, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_4_conv_checkpoint/006-0.9471.hdf5\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.5135 - acc: 0.8517 - val_loss: 0.9471 - val_acc: 0.7636\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4170 - acc: 0.8787\n",
      "Epoch 00007: val_loss did not improve from 0.94706\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.4171 - acc: 0.8787 - val_loss: 1.0633 - val_acc: 0.7147\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3422 - acc: 0.9014\n",
      "Epoch 00008: val_loss improved from 0.94706 to 0.88020, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_4_conv_checkpoint/008-0.8802.hdf5\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.3421 - acc: 0.9014 - val_loss: 0.8802 - val_acc: 0.7754\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9251\n",
      "Epoch 00009: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.2611 - acc: 0.9251 - val_loss: 1.0891 - val_acc: 0.7286\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2404 - acc: 0.9300\n",
      "Epoch 00010: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.2407 - acc: 0.9300 - val_loss: 1.0696 - val_acc: 0.7452\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9442\n",
      "Epoch 00011: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.1972 - acc: 0.9441 - val_loss: 1.6299 - val_acc: 0.6625\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9483\n",
      "Epoch 00012: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.1855 - acc: 0.9482 - val_loss: 1.4222 - val_acc: 0.6988\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9597\n",
      "Epoch 00013: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.1487 - acc: 0.9597 - val_loss: 1.3207 - val_acc: 0.7251\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9567\n",
      "Epoch 00014: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.1596 - acc: 0.9567 - val_loss: 1.0385 - val_acc: 0.7894\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9663\n",
      "Epoch 00015: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.1237 - acc: 0.9662 - val_loss: 1.2863 - val_acc: 0.7207\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9713\n",
      "Epoch 00016: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.1113 - acc: 0.9713 - val_loss: 1.0445 - val_acc: 0.7773\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9675\n",
      "Epoch 00017: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 209s 6ms/sample - loss: 0.1187 - acc: 0.9675 - val_loss: 0.9829 - val_acc: 0.8039\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9794\n",
      "Epoch 00018: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.0838 - acc: 0.9794 - val_loss: 1.1336 - val_acc: 0.7717\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9644\n",
      "Epoch 00019: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1298 - acc: 0.9644 - val_loss: 1.1065 - val_acc: 0.7696\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9808\n",
      "Epoch 00020: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0790 - acc: 0.9808 - val_loss: 1.1498 - val_acc: 0.7694\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9710\n",
      "Epoch 00021: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1072 - acc: 0.9710 - val_loss: 1.1407 - val_acc: 0.7913\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9778\n",
      "Epoch 00022: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0906 - acc: 0.9778 - val_loss: 1.1626 - val_acc: 0.7808\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9836\n",
      "Epoch 00023: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0671 - acc: 0.9836 - val_loss: 1.2432 - val_acc: 0.7666\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9800\n",
      "Epoch 00024: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0787 - acc: 0.9800 - val_loss: 1.2739 - val_acc: 0.7487\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9786\n",
      "Epoch 00025: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0833 - acc: 0.9786 - val_loss: 1.4479 - val_acc: 0.7265\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9808\n",
      "Epoch 00026: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0760 - acc: 0.9808 - val_loss: 1.3481 - val_acc: 0.7615\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9831\n",
      "Epoch 00027: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0691 - acc: 0.9831 - val_loss: 1.3081 - val_acc: 0.7692\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9872\n",
      "Epoch 00028: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0534 - acc: 0.9872 - val_loss: 1.4152 - val_acc: 0.7515\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9837\n",
      "Epoch 00029: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0677 - acc: 0.9837 - val_loss: 1.5032 - val_acc: 0.7244\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9877\n",
      "Epoch 00030: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0546 - acc: 0.9877 - val_loss: 1.4254 - val_acc: 0.7345\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9802\n",
      "Epoch 00031: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0779 - acc: 0.9802 - val_loss: 1.2559 - val_acc: 0.7668\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9886\n",
      "Epoch 00032: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0499 - acc: 0.9886 - val_loss: 1.4427 - val_acc: 0.7533\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9864\n",
      "Epoch 00033: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0551 - acc: 0.9864 - val_loss: 1.4191 - val_acc: 0.7589\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9841\n",
      "Epoch 00034: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0646 - acc: 0.9841 - val_loss: 1.4820 - val_acc: 0.7487\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9898\n",
      "Epoch 00035: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.0487 - acc: 0.9897 - val_loss: 1.3981 - val_acc: 0.7727\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9809\n",
      "Epoch 00036: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0729 - acc: 0.9808 - val_loss: 2.0417 - val_acc: 0.6711\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9831\n",
      "Epoch 00037: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0660 - acc: 0.9831 - val_loss: 1.4373 - val_acc: 0.7626\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9893\n",
      "Epoch 00038: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0506 - acc: 0.9892 - val_loss: 1.3880 - val_acc: 0.7701\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9893\n",
      "Epoch 00039: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0466 - acc: 0.9893 - val_loss: 1.4471 - val_acc: 0.7615\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9915\n",
      "Epoch 00040: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0402 - acc: 0.9915 - val_loss: 1.7341 - val_acc: 0.7223\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9895\n",
      "Epoch 00041: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0443 - acc: 0.9895 - val_loss: 1.2885 - val_acc: 0.7866\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9914\n",
      "Epoch 00042: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0423 - acc: 0.9914 - val_loss: 1.3795 - val_acc: 0.7743\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9834\n",
      "Epoch 00043: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0680 - acc: 0.9833 - val_loss: 1.9272 - val_acc: 0.7002\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9888\n",
      "Epoch 00044: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0453 - acc: 0.9888 - val_loss: 1.4920 - val_acc: 0.7561\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9897\n",
      "Epoch 00045: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0457 - acc: 0.9897 - val_loss: 1.6814 - val_acc: 0.7512\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9890\n",
      "Epoch 00046: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0472 - acc: 0.9890 - val_loss: 1.5672 - val_acc: 0.7405\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9884\n",
      "Epoch 00047: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0467 - acc: 0.9883 - val_loss: 1.6821 - val_acc: 0.7403\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9923\n",
      "Epoch 00048: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0344 - acc: 0.9923 - val_loss: 1.7743 - val_acc: 0.7235\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9950\n",
      "Epoch 00049: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0274 - acc: 0.9950 - val_loss: 1.6000 - val_acc: 0.7566\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9904\n",
      "Epoch 00050: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0430 - acc: 0.9903 - val_loss: 1.5298 - val_acc: 0.7668\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9847\n",
      "Epoch 00051: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0623 - acc: 0.9847 - val_loss: 1.5536 - val_acc: 0.7638\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9930\n",
      "Epoch 00052: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0316 - acc: 0.9930 - val_loss: 1.3306 - val_acc: 0.7920\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9880\n",
      "Epoch 00053: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0494 - acc: 0.9879 - val_loss: 2.2413 - val_acc: 0.6727\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9885\n",
      "Epoch 00054: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0453 - acc: 0.9885 - val_loss: 1.4446 - val_acc: 0.7876\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9917\n",
      "Epoch 00055: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0374 - acc: 0.9917 - val_loss: 1.6443 - val_acc: 0.7501\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9936\n",
      "Epoch 00056: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.0320 - acc: 0.9936 - val_loss: 1.4875 - val_acc: 0.7757\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9880\n",
      "Epoch 00057: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0573 - acc: 0.9880 - val_loss: 1.6582 - val_acc: 0.7570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9917\n",
      "Epoch 00058: val_loss did not improve from 0.88020\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0346 - acc: 0.9916 - val_loss: 1.4226 - val_acc: 0.7904\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9789 - acc: 0.7423\n",
      "Loss: 0.9789011884948794 Accuracy: 0.74226373\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7633 - acc: 0.4760\n",
      "Epoch 00001: val_loss improved from inf to 1.91465, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/001-1.9147.hdf5\n",
      "36805/36805 [==============================] - 222s 6ms/sample - loss: 1.7635 - acc: 0.4760 - val_loss: 1.9147 - val_acc: 0.4472\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1184 - acc: 0.6732\n",
      "Epoch 00002: val_loss improved from 1.91465 to 1.54245, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/002-1.5425.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 1.1188 - acc: 0.6731 - val_loss: 1.5425 - val_acc: 0.6003\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8599 - acc: 0.7534\n",
      "Epoch 00003: val_loss improved from 1.54245 to 1.12546, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/003-1.1255.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.8599 - acc: 0.7533 - val_loss: 1.1255 - val_acc: 0.7032\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6972 - acc: 0.7991\n",
      "Epoch 00004: val_loss improved from 1.12546 to 1.11074, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/004-1.1107.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.6972 - acc: 0.7990 - val_loss: 1.1107 - val_acc: 0.6956\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5851 - acc: 0.8317\n",
      "Epoch 00005: val_loss improved from 1.11074 to 0.78012, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/005-0.7801.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.5852 - acc: 0.8316 - val_loss: 0.7801 - val_acc: 0.7806\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5110 - acc: 0.8506\n",
      "Epoch 00006: val_loss improved from 0.78012 to 0.75325, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/006-0.7532.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.5110 - acc: 0.8506 - val_loss: 0.7532 - val_acc: 0.7964\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8711\n",
      "Epoch 00007: val_loss did not improve from 0.75325\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.4372 - acc: 0.8710 - val_loss: 0.7949 - val_acc: 0.7990\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4014 - acc: 0.8815\n",
      "Epoch 00008: val_loss did not improve from 0.75325\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.4014 - acc: 0.8815 - val_loss: 0.8004 - val_acc: 0.7971\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3557 - acc: 0.8939\n",
      "Epoch 00009: val_loss improved from 0.75325 to 0.70906, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/009-0.7091.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.3560 - acc: 0.8938 - val_loss: 0.7091 - val_acc: 0.8209\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3275 - acc: 0.9015\n",
      "Epoch 00010: val_loss did not improve from 0.70906\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.3275 - acc: 0.9015 - val_loss: 0.7942 - val_acc: 0.8041\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.9151\n",
      "Epoch 00011: val_loss improved from 0.70906 to 0.64311, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/011-0.6431.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2821 - acc: 0.9151 - val_loss: 0.6431 - val_acc: 0.8337\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9190\n",
      "Epoch 00012: val_loss did not improve from 0.64311\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2707 - acc: 0.9191 - val_loss: 0.7763 - val_acc: 0.8109\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9345\n",
      "Epoch 00013: val_loss did not improve from 0.64311\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2142 - acc: 0.9345 - val_loss: 0.8268 - val_acc: 0.8139\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9365\n",
      "Epoch 00014: val_loss improved from 0.64311 to 0.63447, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_5_conv_checkpoint/014-0.6345.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2135 - acc: 0.9365 - val_loss: 0.6345 - val_acc: 0.8465\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9417\n",
      "Epoch 00015: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1925 - acc: 0.9417 - val_loss: 0.8806 - val_acc: 0.8015\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9451\n",
      "Epoch 00016: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1813 - acc: 0.9451 - val_loss: 1.5324 - val_acc: 0.7221\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9466\n",
      "Epoch 00017: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1722 - acc: 0.9466 - val_loss: 0.7352 - val_acc: 0.8300\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9627\n",
      "Epoch 00018: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1261 - acc: 0.9626 - val_loss: 0.6384 - val_acc: 0.8670\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9598\n",
      "Epoch 00019: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1287 - acc: 0.9598 - val_loss: 0.7386 - val_acc: 0.8418\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9592\n",
      "Epoch 00020: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1347 - acc: 0.9592 - val_loss: 0.6422 - val_acc: 0.8598\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9705\n",
      "Epoch 00021: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1016 - acc: 0.9705 - val_loss: 0.7105 - val_acc: 0.8488\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9677\n",
      "Epoch 00022: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1086 - acc: 0.9676 - val_loss: 0.9452 - val_acc: 0.8111\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9671\n",
      "Epoch 00023: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1080 - acc: 0.9672 - val_loss: 0.6778 - val_acc: 0.8616\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9735\n",
      "Epoch 00024: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0892 - acc: 0.9735 - val_loss: 0.7320 - val_acc: 0.8474\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9749\n",
      "Epoch 00025: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0847 - acc: 0.9749 - val_loss: 0.9533 - val_acc: 0.8225\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9605\n",
      "Epoch 00026: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1288 - acc: 0.9604 - val_loss: 1.1545 - val_acc: 0.7913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9746\n",
      "Epoch 00027: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0831 - acc: 0.9747 - val_loss: 0.7087 - val_acc: 0.8640\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9840\n",
      "Epoch 00028: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0601 - acc: 0.9841 - val_loss: 0.7881 - val_acc: 0.8418\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9822\n",
      "Epoch 00029: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0641 - acc: 0.9821 - val_loss: 0.7745 - val_acc: 0.8493\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9761\n",
      "Epoch 00030: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0822 - acc: 0.9761 - val_loss: 0.6702 - val_acc: 0.8670\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9815\n",
      "Epoch 00031: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0641 - acc: 0.9815 - val_loss: 0.9254 - val_acc: 0.8192\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9758\n",
      "Epoch 00032: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0790 - acc: 0.9758 - val_loss: 0.6900 - val_acc: 0.8614\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9840\n",
      "Epoch 00033: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0579 - acc: 0.9839 - val_loss: 0.7280 - val_acc: 0.8588\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9787\n",
      "Epoch 00034: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0773 - acc: 0.9787 - val_loss: 0.7112 - val_acc: 0.8588\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9800\n",
      "Epoch 00035: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0714 - acc: 0.9800 - val_loss: 0.8804 - val_acc: 0.8314\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9806\n",
      "Epoch 00036: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0686 - acc: 0.9805 - val_loss: 0.6685 - val_acc: 0.8749\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9856\n",
      "Epoch 00037: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0527 - acc: 0.9856 - val_loss: 0.7584 - val_acc: 0.8602\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9881\n",
      "Epoch 00038: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0454 - acc: 0.9881 - val_loss: 0.9353 - val_acc: 0.8255\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9812\n",
      "Epoch 00039: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0667 - acc: 0.9812 - val_loss: 0.6730 - val_acc: 0.8758\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9800\n",
      "Epoch 00040: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0719 - acc: 0.9799 - val_loss: 0.6559 - val_acc: 0.8791\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9846\n",
      "Epoch 00041: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0545 - acc: 0.9846 - val_loss: 0.7788 - val_acc: 0.8581\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9890\n",
      "Epoch 00042: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0418 - acc: 0.9890 - val_loss: 0.6552 - val_acc: 0.8831\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9831\n",
      "Epoch 00043: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0576 - acc: 0.9830 - val_loss: 0.8178 - val_acc: 0.8556\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9736\n",
      "Epoch 00044: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0944 - acc: 0.9735 - val_loss: 0.6888 - val_acc: 0.8747\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9905\n",
      "Epoch 00045: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0375 - acc: 0.9904 - val_loss: 0.8500 - val_acc: 0.8514\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9848\n",
      "Epoch 00046: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0543 - acc: 0.9848 - val_loss: 0.7001 - val_acc: 0.8798\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9940\n",
      "Epoch 00047: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0276 - acc: 0.9940 - val_loss: 0.9144 - val_acc: 0.8491\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9845\n",
      "Epoch 00048: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0570 - acc: 0.9844 - val_loss: 0.9180 - val_acc: 0.8353\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9797\n",
      "Epoch 00049: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0718 - acc: 0.9797 - val_loss: 0.8459 - val_acc: 0.8584\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9925\n",
      "Epoch 00050: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0306 - acc: 0.9925 - val_loss: 0.8072 - val_acc: 0.8686\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9940\n",
      "Epoch 00051: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0286 - acc: 0.9940 - val_loss: 1.1559 - val_acc: 0.8160\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9793\n",
      "Epoch 00052: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0733 - acc: 0.9793 - val_loss: 0.8375 - val_acc: 0.8551\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9901\n",
      "Epoch 00053: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0379 - acc: 0.9901 - val_loss: 0.7211 - val_acc: 0.8705\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9916\n",
      "Epoch 00054: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0322 - acc: 0.9916 - val_loss: 0.7906 - val_acc: 0.8677\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9835\n",
      "Epoch 00055: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0616 - acc: 0.9835 - val_loss: 0.8705 - val_acc: 0.8484\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9916\n",
      "Epoch 00056: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0321 - acc: 0.9915 - val_loss: 0.7683 - val_acc: 0.8719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9839\n",
      "Epoch 00057: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0616 - acc: 0.9839 - val_loss: 0.8152 - val_acc: 0.8535\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9936\n",
      "Epoch 00058: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0265 - acc: 0.9936 - val_loss: 0.7680 - val_acc: 0.8672\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9875\n",
      "Epoch 00059: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0470 - acc: 0.9874 - val_loss: 0.7409 - val_acc: 0.8761\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9860\n",
      "Epoch 00060: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0547 - acc: 0.9860 - val_loss: 0.7133 - val_acc: 0.8807\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9948\n",
      "Epoch 00061: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0218 - acc: 0.9948 - val_loss: 0.8986 - val_acc: 0.8574\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9905\n",
      "Epoch 00062: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0357 - acc: 0.9905 - val_loss: 0.7194 - val_acc: 0.8805\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9902\n",
      "Epoch 00063: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0383 - acc: 0.9901 - val_loss: 6.7909 - val_acc: 0.4260\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9823\n",
      "Epoch 00064: val_loss did not improve from 0.63447\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0705 - acc: 0.9822 - val_loss: 0.7437 - val_acc: 0.8770\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.7346 - acc: 0.8258\n",
      "Loss: 0.7346186304389501 Accuracy: 0.82575285\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7416 - acc: 0.4602\n",
      "Epoch 00001: val_loss improved from inf to 1.56320, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/001-1.5632.hdf5\n",
      "36805/36805 [==============================] - 226s 6ms/sample - loss: 1.7418 - acc: 0.4602 - val_loss: 1.5632 - val_acc: 0.5087\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0962 - acc: 0.6683\n",
      "Epoch 00002: val_loss improved from 1.56320 to 0.98896, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/002-0.9890.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 1.0961 - acc: 0.6683 - val_loss: 0.9890 - val_acc: 0.7016\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7970 - acc: 0.7645\n",
      "Epoch 00003: val_loss improved from 0.98896 to 0.86603, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/003-0.8660.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.7969 - acc: 0.7645 - val_loss: 0.8660 - val_acc: 0.7338\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.8204\n",
      "Epoch 00004: val_loss improved from 0.86603 to 0.76930, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/004-0.7693.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.6223 - acc: 0.8204 - val_loss: 0.7693 - val_acc: 0.7787\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5178 - acc: 0.8512\n",
      "Epoch 00005: val_loss did not improve from 0.76930\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.5180 - acc: 0.8512 - val_loss: 1.0775 - val_acc: 0.7126\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8657\n",
      "Epoch 00006: val_loss improved from 0.76930 to 0.49423, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/006-0.4942.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.4651 - acc: 0.8656 - val_loss: 0.4942 - val_acc: 0.8570\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8842\n",
      "Epoch 00007: val_loss did not improve from 0.49423\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3968 - acc: 0.8841 - val_loss: 0.6451 - val_acc: 0.8225\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3517 - acc: 0.8973\n",
      "Epoch 00008: val_loss did not improve from 0.49423\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3518 - acc: 0.8973 - val_loss: 0.7394 - val_acc: 0.7978\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.9063\n",
      "Epoch 00009: val_loss did not improve from 0.49423\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3248 - acc: 0.9063 - val_loss: 0.5995 - val_acc: 0.8334\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2989 - acc: 0.9114\n",
      "Epoch 00010: val_loss did not improve from 0.49423\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2990 - acc: 0.9113 - val_loss: 0.5664 - val_acc: 0.8411\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9255\n",
      "Epoch 00011: val_loss did not improve from 0.49423\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2561 - acc: 0.9255 - val_loss: 0.6024 - val_acc: 0.8430\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9278\n",
      "Epoch 00012: val_loss did not improve from 0.49423\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.2457 - acc: 0.9278 - val_loss: 0.6902 - val_acc: 0.8160\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2203 - acc: 0.9356\n",
      "Epoch 00013: val_loss improved from 0.49423 to 0.46878, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/013-0.4688.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2205 - acc: 0.9356 - val_loss: 0.4688 - val_acc: 0.8707\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9385\n",
      "Epoch 00014: val_loss improved from 0.46878 to 0.40031, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/014-0.4003.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.2066 - acc: 0.9385 - val_loss: 0.4003 - val_acc: 0.8959\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9443\n",
      "Epoch 00015: val_loss improved from 0.40031 to 0.38345, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/015-0.3835.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1871 - acc: 0.9443 - val_loss: 0.3835 - val_acc: 0.9005\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9505\n",
      "Epoch 00016: val_loss improved from 0.38345 to 0.37059, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/016-0.3706.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1672 - acc: 0.9505 - val_loss: 0.3706 - val_acc: 0.9033\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9557\n",
      "Epoch 00017: val_loss did not improve from 0.37059\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1482 - acc: 0.9556 - val_loss: 0.8326 - val_acc: 0.7936\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9531\n",
      "Epoch 00018: val_loss did not improve from 0.37059\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1586 - acc: 0.9531 - val_loss: 0.4262 - val_acc: 0.8935\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9606\n",
      "Epoch 00019: val_loss did not improve from 0.37059\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1344 - acc: 0.9606 - val_loss: 0.4258 - val_acc: 0.8945\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9661\n",
      "Epoch 00020: val_loss did not improve from 0.37059\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1157 - acc: 0.9661 - val_loss: 0.4689 - val_acc: 0.8800\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9670\n",
      "Epoch 00021: val_loss improved from 0.37059 to 0.34905, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/021-0.3491.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1139 - acc: 0.9670 - val_loss: 0.3491 - val_acc: 0.9166\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9697\n",
      "Epoch 00022: val_loss did not improve from 0.34905\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1047 - acc: 0.9697 - val_loss: 0.3619 - val_acc: 0.9094\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9718\n",
      "Epoch 00023: val_loss did not improve from 0.34905\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0976 - acc: 0.9718 - val_loss: 0.3924 - val_acc: 0.9089\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9756\n",
      "Epoch 00024: val_loss did not improve from 0.34905\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0850 - acc: 0.9756 - val_loss: 0.4089 - val_acc: 0.9089\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9682\n",
      "Epoch 00025: val_loss did not improve from 0.34905\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1080 - acc: 0.9682 - val_loss: 0.6945 - val_acc: 0.8334\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9746\n",
      "Epoch 00026: val_loss improved from 0.34905 to 0.32304, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/026-0.3230.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0875 - acc: 0.9746 - val_loss: 0.3230 - val_acc: 0.9199\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9815\n",
      "Epoch 00027: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0670 - acc: 0.9815 - val_loss: 0.4289 - val_acc: 0.8926\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9848\n",
      "Epoch 00028: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0589 - acc: 0.9847 - val_loss: 0.4698 - val_acc: 0.8887\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9802\n",
      "Epoch 00029: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0701 - acc: 0.9801 - val_loss: 0.5423 - val_acc: 0.8747\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9824\n",
      "Epoch 00030: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0649 - acc: 0.9824 - val_loss: 0.3838 - val_acc: 0.9138\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9782\n",
      "Epoch 00031: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0726 - acc: 0.9782 - val_loss: 0.3732 - val_acc: 0.9124\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9825\n",
      "Epoch 00032: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0629 - acc: 0.9825 - val_loss: 0.7649 - val_acc: 0.8509\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9865\n",
      "Epoch 00033: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0508 - acc: 0.9865 - val_loss: 0.4763 - val_acc: 0.8880\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9862\n",
      "Epoch 00034: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0507 - acc: 0.9861 - val_loss: 0.4092 - val_acc: 0.9124\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9731\n",
      "Epoch 00035: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0904 - acc: 0.9730 - val_loss: 0.3612 - val_acc: 0.9203\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9866\n",
      "Epoch 00036: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0485 - acc: 0.9866 - val_loss: 0.3335 - val_acc: 0.9224\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9918\n",
      "Epoch 00037: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0352 - acc: 0.9918 - val_loss: 0.5801 - val_acc: 0.8712\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9869\n",
      "Epoch 00038: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0490 - acc: 0.9869 - val_loss: 0.3546 - val_acc: 0.9175\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9903\n",
      "Epoch 00039: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0378 - acc: 0.9903 - val_loss: 0.4836 - val_acc: 0.8935\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9895\n",
      "Epoch 00040: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0402 - acc: 0.9895 - val_loss: 0.3950 - val_acc: 0.9119\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9854\n",
      "Epoch 00041: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0496 - acc: 0.9854 - val_loss: 0.3554 - val_acc: 0.9187\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9899\n",
      "Epoch 00042: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0393 - acc: 0.9899 - val_loss: 0.3436 - val_acc: 0.9227\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9873\n",
      "Epoch 00043: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0468 - acc: 0.9873 - val_loss: 0.3475 - val_acc: 0.9301\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9932\n",
      "Epoch 00044: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0288 - acc: 0.9932 - val_loss: 0.4555 - val_acc: 0.9003\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9839\n",
      "Epoch 00045: val_loss did not improve from 0.32304\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0584 - acc: 0.9838 - val_loss: 0.4407 - val_acc: 0.9087\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9874\n",
      "Epoch 00046: val_loss improved from 0.32304 to 0.32302, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_6_conv_checkpoint/046-0.3230.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0464 - acc: 0.9874 - val_loss: 0.3230 - val_acc: 0.9311\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9943\n",
      "Epoch 00047: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0250 - acc: 0.9943 - val_loss: 0.4331 - val_acc: 0.9066\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9887\n",
      "Epoch 00048: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0437 - acc: 0.9887 - val_loss: 0.3592 - val_acc: 0.9262\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9951\n",
      "Epoch 00049: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0220 - acc: 0.9951 - val_loss: 0.4421 - val_acc: 0.9126\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9917\n",
      "Epoch 00050: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0314 - acc: 0.9917 - val_loss: 0.4575 - val_acc: 0.9080\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9872\n",
      "Epoch 00051: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0478 - acc: 0.9872 - val_loss: 0.4163 - val_acc: 0.9138\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9950\n",
      "Epoch 00052: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0218 - acc: 0.9950 - val_loss: 0.4940 - val_acc: 0.9031\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9906\n",
      "Epoch 00053: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0371 - acc: 0.9906 - val_loss: 0.3983 - val_acc: 0.9173\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9942\n",
      "Epoch 00054: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0248 - acc: 0.9941 - val_loss: 0.3618 - val_acc: 0.9252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9910\n",
      "Epoch 00055: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0329 - acc: 0.9910 - val_loss: 0.3843 - val_acc: 0.9189\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9925\n",
      "Epoch 00056: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0311 - acc: 0.9925 - val_loss: 0.4120 - val_acc: 0.9192\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9933\n",
      "Epoch 00057: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0253 - acc: 0.9933 - val_loss: 0.3717 - val_acc: 0.9262\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9934\n",
      "Epoch 00058: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0265 - acc: 0.9933 - val_loss: 0.4072 - val_acc: 0.9136\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9900\n",
      "Epoch 00059: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0388 - acc: 0.9900 - val_loss: 0.4471 - val_acc: 0.9073\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9922\n",
      "Epoch 00060: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0283 - acc: 0.9921 - val_loss: 0.4212 - val_acc: 0.9171\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9942\n",
      "Epoch 00061: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0239 - acc: 0.9942 - val_loss: 0.4004 - val_acc: 0.9210\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9891\n",
      "Epoch 00062: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0399 - acc: 0.9891 - val_loss: 0.3721 - val_acc: 0.9222\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9954\n",
      "Epoch 00063: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0216 - acc: 0.9954 - val_loss: 0.4187 - val_acc: 0.9206\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9894\n",
      "Epoch 00064: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0381 - acc: 0.9893 - val_loss: 0.8324 - val_acc: 0.8495\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9900\n",
      "Epoch 00065: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0379 - acc: 0.9900 - val_loss: 0.4608 - val_acc: 0.9173\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9945\n",
      "Epoch 00066: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0206 - acc: 0.9945 - val_loss: 0.3589 - val_acc: 0.9255\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9921\n",
      "Epoch 00067: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0309 - acc: 0.9921 - val_loss: 0.4284 - val_acc: 0.9175\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9866\n",
      "Epoch 00068: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0468 - acc: 0.9866 - val_loss: 0.3556 - val_acc: 0.9327\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9977\n",
      "Epoch 00069: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0125 - acc: 0.9977 - val_loss: 0.3903 - val_acc: 0.9276\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9915\n",
      "Epoch 00070: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0317 - acc: 0.9915 - val_loss: 0.4003 - val_acc: 0.9257\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9936\n",
      "Epoch 00071: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0256 - acc: 0.9936 - val_loss: 0.4177 - val_acc: 0.9154\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9882\n",
      "Epoch 00072: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0443 - acc: 0.9882 - val_loss: 0.4172 - val_acc: 0.9210\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9969\n",
      "Epoch 00073: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0146 - acc: 0.9969 - val_loss: 0.4622 - val_acc: 0.9173\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9953\n",
      "Epoch 00074: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0204 - acc: 0.9953 - val_loss: 0.3789 - val_acc: 0.9294\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9944\n",
      "Epoch 00075: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0222 - acc: 0.9944 - val_loss: 0.3972 - val_acc: 0.9262\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9948\n",
      "Epoch 00076: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0212 - acc: 0.9947 - val_loss: 0.4963 - val_acc: 0.9043\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9931\n",
      "Epoch 00077: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0258 - acc: 0.9931 - val_loss: 0.3818 - val_acc: 0.9273\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9942\n",
      "Epoch 00078: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0232 - acc: 0.9942 - val_loss: 0.4326 - val_acc: 0.9182\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9940\n",
      "Epoch 00079: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0238 - acc: 0.9940 - val_loss: 0.3740 - val_acc: 0.9331\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9983\n",
      "Epoch 00080: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0096 - acc: 0.9983 - val_loss: 0.3525 - val_acc: 0.9352\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9977\n",
      "Epoch 00081: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0117 - acc: 0.9977 - val_loss: 0.4064 - val_acc: 0.9255\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9960\n",
      "Epoch 00082: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0183 - acc: 0.9960 - val_loss: 0.5567 - val_acc: 0.8989\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9926\n",
      "Epoch 00083: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0287 - acc: 0.9926 - val_loss: 0.8496 - val_acc: 0.8530\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 00084: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0307 - acc: 0.9916 - val_loss: 0.4313 - val_acc: 0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9936\n",
      "Epoch 00085: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0229 - acc: 0.9936 - val_loss: 0.3709 - val_acc: 0.9299\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9984\n",
      "Epoch 00086: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0095 - acc: 0.9984 - val_loss: 0.4157 - val_acc: 0.9217\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9926\n",
      "Epoch 00087: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0261 - acc: 0.9926 - val_loss: 0.3769 - val_acc: 0.9280\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9980\n",
      "Epoch 00088: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0106 - acc: 0.9980 - val_loss: 0.3994 - val_acc: 0.9248\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9960\n",
      "Epoch 00089: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0158 - acc: 0.9960 - val_loss: 0.4148 - val_acc: 0.9224\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9946\n",
      "Epoch 00090: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0205 - acc: 0.9946 - val_loss: 0.4290 - val_acc: 0.9194\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9970\n",
      "Epoch 00091: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0126 - acc: 0.9970 - val_loss: 0.4576 - val_acc: 0.9208\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9930\n",
      "Epoch 00092: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0236 - acc: 0.9930 - val_loss: 0.4468 - val_acc: 0.9187\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9965\n",
      "Epoch 00093: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0141 - acc: 0.9965 - val_loss: 0.3643 - val_acc: 0.9308\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9970\n",
      "Epoch 00094: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0138 - acc: 0.9970 - val_loss: 0.4562 - val_acc: 0.9124\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9934\n",
      "Epoch 00095: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0247 - acc: 0.9934 - val_loss: 0.4297 - val_acc: 0.9243\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9972\n",
      "Epoch 00096: val_loss did not improve from 0.32302\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0138 - acc: 0.9972 - val_loss: 0.6192 - val_acc: 0.8896\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3701 - acc: 0.9088\n",
      "Loss: 0.3701478431157977 Accuracy: 0.9088266\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8262 - acc: 0.4332\n",
      "Epoch 00001: val_loss improved from inf to 1.65572, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/001-1.6557.hdf5\n",
      "36805/36805 [==============================] - 231s 6ms/sample - loss: 1.8261 - acc: 0.4332 - val_loss: 1.6557 - val_acc: 0.4743\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0894 - acc: 0.6714\n",
      "Epoch 00002: val_loss improved from 1.65572 to 0.90594, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/002-0.9059.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 1.0893 - acc: 0.6714 - val_loss: 0.9059 - val_acc: 0.7261\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7851 - acc: 0.7719\n",
      "Epoch 00003: val_loss improved from 0.90594 to 0.71722, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/003-0.7172.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.7850 - acc: 0.7719 - val_loss: 0.7172 - val_acc: 0.7897\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5987 - acc: 0.8265\n",
      "Epoch 00004: val_loss improved from 0.71722 to 0.58493, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/004-0.5849.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.5988 - acc: 0.8265 - val_loss: 0.5849 - val_acc: 0.8367\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4983 - acc: 0.8552\n",
      "Epoch 00005: val_loss improved from 0.58493 to 0.54551, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/005-0.5455.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.4988 - acc: 0.8552 - val_loss: 0.5455 - val_acc: 0.8369\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4298 - acc: 0.8753\n",
      "Epoch 00006: val_loss improved from 0.54551 to 0.45081, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/006-0.4508.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.4298 - acc: 0.8753 - val_loss: 0.4508 - val_acc: 0.8744\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8938\n",
      "Epoch 00007: val_loss did not improve from 0.45081\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.3692 - acc: 0.8938 - val_loss: 0.5805 - val_acc: 0.8274\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.9057\n",
      "Epoch 00008: val_loss improved from 0.45081 to 0.35561, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/008-0.3556.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.3257 - acc: 0.9057 - val_loss: 0.3556 - val_acc: 0.9010\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2921 - acc: 0.9158\n",
      "Epoch 00009: val_loss did not improve from 0.35561\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2921 - acc: 0.9159 - val_loss: 0.5868 - val_acc: 0.8302\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9246\n",
      "Epoch 00010: val_loss did not improve from 0.35561\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2596 - acc: 0.9247 - val_loss: 0.7257 - val_acc: 0.7920\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2278 - acc: 0.9340\n",
      "Epoch 00011: val_loss did not improve from 0.35561\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.2279 - acc: 0.9339 - val_loss: 0.4070 - val_acc: 0.8863\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9377\n",
      "Epoch 00012: val_loss improved from 0.35561 to 0.27577, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/012-0.2758.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2130 - acc: 0.9377 - val_loss: 0.2758 - val_acc: 0.9187\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9465\n",
      "Epoch 00013: val_loss did not improve from 0.27577\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1897 - acc: 0.9465 - val_loss: 0.5222 - val_acc: 0.8598\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9482\n",
      "Epoch 00014: val_loss did not improve from 0.27577\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1743 - acc: 0.9482 - val_loss: 0.4572 - val_acc: 0.8859\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9563\n",
      "Epoch 00015: val_loss did not improve from 0.27577\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1521 - acc: 0.9563 - val_loss: 0.2819 - val_acc: 0.9241\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9575\n",
      "Epoch 00016: val_loss did not improve from 0.27577\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1469 - acc: 0.9575 - val_loss: 0.3042 - val_acc: 0.9164\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9568\n",
      "Epoch 00017: val_loss improved from 0.27577 to 0.22838, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/017-0.2284.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1481 - acc: 0.9568 - val_loss: 0.2284 - val_acc: 0.9364\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9659\n",
      "Epoch 00018: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1180 - acc: 0.9658 - val_loss: 0.2594 - val_acc: 0.9329\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9608\n",
      "Epoch 00019: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1353 - acc: 0.9608 - val_loss: 0.2514 - val_acc: 0.9317\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9710\n",
      "Epoch 00020: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1010 - acc: 0.9710 - val_loss: 0.2471 - val_acc: 0.9350\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9734\n",
      "Epoch 00021: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0922 - acc: 0.9734 - val_loss: 0.3266 - val_acc: 0.9087\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9754\n",
      "Epoch 00022: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0877 - acc: 0.9754 - val_loss: 0.2652 - val_acc: 0.9304\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9752\n",
      "Epoch 00023: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0880 - acc: 0.9752 - val_loss: 0.2726 - val_acc: 0.9266\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9787\n",
      "Epoch 00024: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0762 - acc: 0.9787 - val_loss: 0.2459 - val_acc: 0.9373\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9751\n",
      "Epoch 00025: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0851 - acc: 0.9750 - val_loss: 0.2432 - val_acc: 0.9350\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9801\n",
      "Epoch 00026: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0723 - acc: 0.9801 - val_loss: 0.3280 - val_acc: 0.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9799\n",
      "Epoch 00027: val_loss did not improve from 0.22838\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0709 - acc: 0.9798 - val_loss: 0.2617 - val_acc: 0.9290\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9794\n",
      "Epoch 00028: val_loss improved from 0.22838 to 0.22373, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/028-0.2237.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0736 - acc: 0.9794 - val_loss: 0.2237 - val_acc: 0.9378\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9824\n",
      "Epoch 00029: val_loss improved from 0.22373 to 0.22150, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/029-0.2215.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0624 - acc: 0.9824 - val_loss: 0.2215 - val_acc: 0.9446\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9843\n",
      "Epoch 00030: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0563 - acc: 0.9843 - val_loss: 0.2762 - val_acc: 0.9271\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9799\n",
      "Epoch 00031: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0693 - acc: 0.9799 - val_loss: 0.2569 - val_acc: 0.9331\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9902\n",
      "Epoch 00032: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0402 - acc: 0.9902 - val_loss: 0.4450 - val_acc: 0.8828\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9832\n",
      "Epoch 00033: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0594 - acc: 0.9832 - val_loss: 0.2419 - val_acc: 0.9378\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9866\n",
      "Epoch 00034: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0488 - acc: 0.9865 - val_loss: 0.2424 - val_acc: 0.9392\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9865\n",
      "Epoch 00035: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0493 - acc: 0.9864 - val_loss: 0.2742 - val_acc: 0.9383\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9880\n",
      "Epoch 00036: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0474 - acc: 0.9880 - val_loss: 0.2659 - val_acc: 0.9308\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9859\n",
      "Epoch 00037: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0503 - acc: 0.9859 - val_loss: 0.2595 - val_acc: 0.9352\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9937\n",
      "Epoch 00038: val_loss did not improve from 0.22150\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0278 - acc: 0.9937 - val_loss: 0.2585 - val_acc: 0.9369\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9835\n",
      "Epoch 00039: val_loss improved from 0.22150 to 0.20097, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/039-0.2010.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0572 - acc: 0.9835 - val_loss: 0.2010 - val_acc: 0.9509\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9880\n",
      "Epoch 00040: val_loss did not improve from 0.20097\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0435 - acc: 0.9879 - val_loss: 0.2954 - val_acc: 0.9320\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9899\n",
      "Epoch 00041: val_loss did not improve from 0.20097\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0396 - acc: 0.9898 - val_loss: 0.2706 - val_acc: 0.9334\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9824\n",
      "Epoch 00042: val_loss improved from 0.20097 to 0.19189, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_7_conv_checkpoint/042-0.1919.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0619 - acc: 0.9824 - val_loss: 0.1919 - val_acc: 0.9490\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9946\n",
      "Epoch 00043: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0243 - acc: 0.9946 - val_loss: 0.2274 - val_acc: 0.9432\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9939\n",
      "Epoch 00044: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0271 - acc: 0.9939 - val_loss: 0.2317 - val_acc: 0.9394\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9949\n",
      "Epoch 00045: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0236 - acc: 0.9949 - val_loss: 0.2624 - val_acc: 0.9334\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9864\n",
      "Epoch 00046: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0483 - acc: 0.9864 - val_loss: 0.2295 - val_acc: 0.9408\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9948\n",
      "Epoch 00047: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0235 - acc: 0.9948 - val_loss: 0.2517 - val_acc: 0.9415\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9919\n",
      "Epoch 00048: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0321 - acc: 0.9919 - val_loss: 0.2674 - val_acc: 0.9401\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0348 - acc: 0.9907 - val_loss: 0.2143 - val_acc: 0.9450\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9937\n",
      "Epoch 00050: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0267 - acc: 0.9936 - val_loss: 0.3119 - val_acc: 0.9345\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9911\n",
      "Epoch 00051: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0339 - acc: 0.9910 - val_loss: 0.2140 - val_acc: 0.9488\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9868\n",
      "Epoch 00052: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0478 - acc: 0.9868 - val_loss: 0.2134 - val_acc: 0.9457\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9964\n",
      "Epoch 00053: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0179 - acc: 0.9963 - val_loss: 0.2194 - val_acc: 0.9506\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9915\n",
      "Epoch 00054: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0324 - acc: 0.9915 - val_loss: 0.2324 - val_acc: 0.9467\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9978\n",
      "Epoch 00055: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0136 - acc: 0.9978 - val_loss: 0.2088 - val_acc: 0.9490\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9959\n",
      "Epoch 00056: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0179 - acc: 0.9959 - val_loss: 0.3032 - val_acc: 0.9341\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9936\n",
      "Epoch 00057: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0250 - acc: 0.9936 - val_loss: 0.2552 - val_acc: 0.9385\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9952\n",
      "Epoch 00058: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0198 - acc: 0.9952 - val_loss: 0.2421 - val_acc: 0.9443\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9964\n",
      "Epoch 00059: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0174 - acc: 0.9964 - val_loss: 0.3806 - val_acc: 0.9064\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9897\n",
      "Epoch 00060: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0362 - acc: 0.9897 - val_loss: 0.2979 - val_acc: 0.9313\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9975\n",
      "Epoch 00061: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0124 - acc: 0.9975 - val_loss: 0.2145 - val_acc: 0.9504\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9976\n",
      "Epoch 00062: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0127 - acc: 0.9976 - val_loss: 0.2690 - val_acc: 0.9404\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9881\n",
      "Epoch 00063: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0406 - acc: 0.9881 - val_loss: 0.2041 - val_acc: 0.9483\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9951\n",
      "Epoch 00064: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0209 - acc: 0.9951 - val_loss: 0.2333 - val_acc: 0.9483\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9937\n",
      "Epoch 00065: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0253 - acc: 0.9936 - val_loss: 0.2457 - val_acc: 0.9401\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9896\n",
      "Epoch 00066: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0369 - acc: 0.9896 - val_loss: 0.2093 - val_acc: 0.9522\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9975\n",
      "Epoch 00067: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0117 - acc: 0.9975 - val_loss: 0.2136 - val_acc: 0.9513\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9985\n",
      "Epoch 00068: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0089 - acc: 0.9985 - val_loss: 0.2248 - val_acc: 0.9499\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9960\n",
      "Epoch 00069: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0174 - acc: 0.9960 - val_loss: 0.3372 - val_acc: 0.9234\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9920\n",
      "Epoch 00070: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0296 - acc: 0.9920 - val_loss: 0.2798 - val_acc: 0.9350\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9966\n",
      "Epoch 00071: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0148 - acc: 0.9966 - val_loss: 0.2258 - val_acc: 0.9518\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9982\n",
      "Epoch 00072: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0093 - acc: 0.9982 - val_loss: 0.2922 - val_acc: 0.9390\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9940\n",
      "Epoch 00073: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0221 - acc: 0.9940 - val_loss: 0.2710 - val_acc: 0.9399\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9919\n",
      "Epoch 00074: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0285 - acc: 0.9919 - val_loss: 0.2094 - val_acc: 0.9499\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9979\n",
      "Epoch 00075: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0102 - acc: 0.9979 - val_loss: 0.2677 - val_acc: 0.9425\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9907\n",
      "Epoch 00076: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0338 - acc: 0.9907 - val_loss: 0.2181 - val_acc: 0.9513\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9986\n",
      "Epoch 00077: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0085 - acc: 0.9986 - val_loss: 0.2240 - val_acc: 0.9488\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9962\n",
      "Epoch 00078: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0159 - acc: 0.9962 - val_loss: 0.2486 - val_acc: 0.9429\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9949\n",
      "Epoch 00079: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0194 - acc: 0.9949 - val_loss: 0.2351 - val_acc: 0.9485\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9972\n",
      "Epoch 00080: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0132 - acc: 0.9972 - val_loss: 0.2282 - val_acc: 0.9450\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9985\n",
      "Epoch 00081: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0080 - acc: 0.9985 - val_loss: 0.2949 - val_acc: 0.9387\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9967\n",
      "Epoch 00082: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0134 - acc: 0.9967 - val_loss: 0.2200 - val_acc: 0.9488\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9924\n",
      "Epoch 00083: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0271 - acc: 0.9923 - val_loss: 0.2389 - val_acc: 0.9457\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9948\n",
      "Epoch 00084: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0184 - acc: 0.9948 - val_loss: 0.2254 - val_acc: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9966\n",
      "Epoch 00085: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0136 - acc: 0.9966 - val_loss: 0.2401 - val_acc: 0.9506\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9957\n",
      "Epoch 00086: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0163 - acc: 0.9957 - val_loss: 0.2104 - val_acc: 0.9515\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9987\n",
      "Epoch 00087: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0075 - acc: 0.9987 - val_loss: 0.2091 - val_acc: 0.9525\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9951\n",
      "Epoch 00088: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0186 - acc: 0.9951 - val_loss: 0.2514 - val_acc: 0.9490\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9983\n",
      "Epoch 00089: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0083 - acc: 0.9982 - val_loss: 0.3331 - val_acc: 0.9308\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9934\n",
      "Epoch 00090: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0224 - acc: 0.9934 - val_loss: 0.2904 - val_acc: 0.9406\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9939\n",
      "Epoch 00091: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0229 - acc: 0.9939 - val_loss: 0.2420 - val_acc: 0.9464\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9987\n",
      "Epoch 00092: val_loss did not improve from 0.19189\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0074 - acc: 0.9986 - val_loss: 0.2352 - val_acc: 0.9495\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2482 - acc: 0.9321\n",
      "Loss: 0.24817572193972665 Accuracy: 0.93208724\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7820 - acc: 0.4566\n",
      "Epoch 00001: val_loss improved from inf to 1.56385, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/001-1.5638.hdf5\n",
      "36805/36805 [==============================] - 235s 6ms/sample - loss: 1.7820 - acc: 0.4566 - val_loss: 1.5638 - val_acc: 0.5213\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9653 - acc: 0.7127\n",
      "Epoch 00002: val_loss improved from 1.56385 to 0.84992, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/002-0.8499.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.9653 - acc: 0.7126 - val_loss: 0.8499 - val_acc: 0.7396\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6597 - acc: 0.8113\n",
      "Epoch 00003: val_loss improved from 0.84992 to 0.64191, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/003-0.6419.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.6596 - acc: 0.8113 - val_loss: 0.6419 - val_acc: 0.8067\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4905 - acc: 0.8620\n",
      "Epoch 00004: val_loss improved from 0.64191 to 0.45989, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/004-0.4599.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.4907 - acc: 0.8620 - val_loss: 0.4599 - val_acc: 0.8733\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8886\n",
      "Epoch 00005: val_loss improved from 0.45989 to 0.33422, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/005-0.3342.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.3929 - acc: 0.8885 - val_loss: 0.3342 - val_acc: 0.9092\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.9090\n",
      "Epoch 00006: val_loss did not improve from 0.33422\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.3258 - acc: 0.9090 - val_loss: 0.3498 - val_acc: 0.8984\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2788 - acc: 0.9187\n",
      "Epoch 00007: val_loss did not improve from 0.33422\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.2788 - acc: 0.9187 - val_loss: 0.3887 - val_acc: 0.8814\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9311\n",
      "Epoch 00008: val_loss improved from 0.33422 to 0.27348, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/008-0.2735.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.2441 - acc: 0.9311 - val_loss: 0.2735 - val_acc: 0.9231\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9390\n",
      "Epoch 00009: val_loss improved from 0.27348 to 0.26448, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/009-0.2645.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.2127 - acc: 0.9390 - val_loss: 0.2645 - val_acc: 0.9217\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9444\n",
      "Epoch 00010: val_loss improved from 0.26448 to 0.22492, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/010-0.2249.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1959 - acc: 0.9444 - val_loss: 0.2249 - val_acc: 0.9373\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9508\n",
      "Epoch 00011: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1711 - acc: 0.9508 - val_loss: 0.2289 - val_acc: 0.9357\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9552\n",
      "Epoch 00012: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1589 - acc: 0.9552 - val_loss: 0.2264 - val_acc: 0.9350\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9592\n",
      "Epoch 00013: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1437 - acc: 0.9591 - val_loss: 0.2810 - val_acc: 0.9196\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9615\n",
      "Epoch 00014: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1378 - acc: 0.9615 - val_loss: 0.2542 - val_acc: 0.9301\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9649\n",
      "Epoch 00015: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1254 - acc: 0.9649 - val_loss: 0.2562 - val_acc: 0.9245\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9707\n",
      "Epoch 00016: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1066 - acc: 0.9707 - val_loss: 0.3337 - val_acc: 0.8935\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9737\n",
      "Epoch 00017: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0974 - acc: 0.9737 - val_loss: 0.2363 - val_acc: 0.9311\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9720\n",
      "Epoch 00018: val_loss did not improve from 0.22492\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0975 - acc: 0.9719 - val_loss: 0.2478 - val_acc: 0.9243\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9740\n",
      "Epoch 00019: val_loss improved from 0.22492 to 0.18400, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/019-0.1840.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0914 - acc: 0.9740 - val_loss: 0.1840 - val_acc: 0.9464\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9776\n",
      "Epoch 00020: val_loss improved from 0.18400 to 0.17442, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/020-0.1744.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0822 - acc: 0.9776 - val_loss: 0.1744 - val_acc: 0.9476\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9808\n",
      "Epoch 00021: val_loss improved from 0.17442 to 0.15234, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/021-0.1523.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0714 - acc: 0.9808 - val_loss: 0.1523 - val_acc: 0.9539\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9830\n",
      "Epoch 00022: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0638 - acc: 0.9830 - val_loss: 0.2794 - val_acc: 0.9166\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9839\n",
      "Epoch 00023: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0613 - acc: 0.9839 - val_loss: 0.2427 - val_acc: 0.9313\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9807\n",
      "Epoch 00024: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0721 - acc: 0.9807 - val_loss: 0.1861 - val_acc: 0.9474\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9879\n",
      "Epoch 00025: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0489 - acc: 0.9879 - val_loss: 0.2160 - val_acc: 0.9345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9857\n",
      "Epoch 00026: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0540 - acc: 0.9857 - val_loss: 0.2134 - val_acc: 0.9401\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9879\n",
      "Epoch 00027: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0489 - acc: 0.9879 - val_loss: 0.1950 - val_acc: 0.9446\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9842\n",
      "Epoch 00028: val_loss did not improve from 0.15234\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0589 - acc: 0.9842 - val_loss: 0.1636 - val_acc: 0.9543\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9931\n",
      "Epoch 00029: val_loss improved from 0.15234 to 0.14649, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/029-0.1465.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0322 - acc: 0.9931 - val_loss: 0.1465 - val_acc: 0.9555\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9923\n",
      "Epoch 00030: val_loss did not improve from 0.14649\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0332 - acc: 0.9923 - val_loss: 0.1770 - val_acc: 0.9511\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9904\n",
      "Epoch 00031: val_loss did not improve from 0.14649\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0371 - acc: 0.9904 - val_loss: 0.1797 - val_acc: 0.9529\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9920\n",
      "Epoch 00032: val_loss did not improve from 0.14649\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0333 - acc: 0.9920 - val_loss: 0.2334 - val_acc: 0.9336\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9931\n",
      "Epoch 00033: val_loss did not improve from 0.14649\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0301 - acc: 0.9931 - val_loss: 0.2004 - val_acc: 0.9448\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9938\n",
      "Epoch 00034: val_loss did not improve from 0.14649\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0268 - acc: 0.9938 - val_loss: 0.2021 - val_acc: 0.9497\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9908\n",
      "Epoch 00035: val_loss did not improve from 0.14649\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0380 - acc: 0.9907 - val_loss: 0.1773 - val_acc: 0.9543\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9879\n",
      "Epoch 00036: val_loss improved from 0.14649 to 0.14143, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_8_conv_checkpoint/036-0.1414.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0443 - acc: 0.9879 - val_loss: 0.1414 - val_acc: 0.9613\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9960\n",
      "Epoch 00037: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0217 - acc: 0.9959 - val_loss: 0.2493 - val_acc: 0.9322\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9918\n",
      "Epoch 00038: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0325 - acc: 0.9918 - val_loss: 0.1735 - val_acc: 0.9550\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9969\n",
      "Epoch 00039: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0161 - acc: 0.9969 - val_loss: 0.1978 - val_acc: 0.9520\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9963\n",
      "Epoch 00040: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0179 - acc: 0.9963 - val_loss: 0.3007 - val_acc: 0.9224\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9909\n",
      "Epoch 00041: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0337 - acc: 0.9909 - val_loss: 0.1747 - val_acc: 0.9534\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9970\n",
      "Epoch 00042: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0154 - acc: 0.9970 - val_loss: 0.1909 - val_acc: 0.9534\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9943\n",
      "Epoch 00043: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0249 - acc: 0.9943 - val_loss: 0.2100 - val_acc: 0.9429\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9958\n",
      "Epoch 00044: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0195 - acc: 0.9958 - val_loss: 0.2864 - val_acc: 0.9255\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9958\n",
      "Epoch 00045: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0192 - acc: 0.9958 - val_loss: 0.1842 - val_acc: 0.9548\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9952\n",
      "Epoch 00046: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0205 - acc: 0.9952 - val_loss: 0.1796 - val_acc: 0.9557\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9968\n",
      "Epoch 00047: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0147 - acc: 0.9968 - val_loss: 0.1856 - val_acc: 0.9511\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9898\n",
      "Epoch 00048: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0360 - acc: 0.9898 - val_loss: 0.1611 - val_acc: 0.9560\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9969\n",
      "Epoch 00049: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0145 - acc: 0.9969 - val_loss: 0.2913 - val_acc: 0.9311\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9907\n",
      "Epoch 00050: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0330 - acc: 0.9907 - val_loss: 0.1630 - val_acc: 0.9569\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9981\n",
      "Epoch 00051: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0110 - acc: 0.9981 - val_loss: 0.1963 - val_acc: 0.9492\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9962\n",
      "Epoch 00052: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0167 - acc: 0.9962 - val_loss: 0.1667 - val_acc: 0.9569\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9940\n",
      "Epoch 00053: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0221 - acc: 0.9940 - val_loss: 0.1568 - val_acc: 0.9592\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9986\n",
      "Epoch 00054: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0094 - acc: 0.9986 - val_loss: 0.1676 - val_acc: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9982\n",
      "Epoch 00055: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0096 - acc: 0.9982 - val_loss: 0.3297 - val_acc: 0.9136\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 00056: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0316 - acc: 0.9903 - val_loss: 0.1714 - val_acc: 0.9560\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9924\n",
      "Epoch 00057: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0279 - acc: 0.9924 - val_loss: 0.1771 - val_acc: 0.9567\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9948\n",
      "Epoch 00058: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0217 - acc: 0.9948 - val_loss: 0.1515 - val_acc: 0.9613\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9987\n",
      "Epoch 00059: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0077 - acc: 0.9986 - val_loss: 0.1776 - val_acc: 0.9536\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9921\n",
      "Epoch 00060: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0304 - acc: 0.9921 - val_loss: 0.1583 - val_acc: 0.9599\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9986\n",
      "Epoch 00061: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0078 - acc: 0.9986 - val_loss: 0.3200 - val_acc: 0.9189\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9987\n",
      "Epoch 00062: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0079 - acc: 0.9988 - val_loss: 0.1686 - val_acc: 0.9585\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9982\n",
      "Epoch 00063: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0085 - acc: 0.9982 - val_loss: 0.2163 - val_acc: 0.9509\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9930\n",
      "Epoch 00064: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0262 - acc: 0.9929 - val_loss: 0.2013 - val_acc: 0.9504\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9943\n",
      "Epoch 00065: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0203 - acc: 0.9942 - val_loss: 0.1738 - val_acc: 0.9557\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9956\n",
      "Epoch 00066: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0160 - acc: 0.9956 - val_loss: 0.4191 - val_acc: 0.9050\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9983\n",
      "Epoch 00067: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0078 - acc: 0.9983 - val_loss: 0.2011 - val_acc: 0.9502\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 00068: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0074 - acc: 0.9986 - val_loss: 0.1782 - val_acc: 0.9578\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9968\n",
      "Epoch 00069: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0130 - acc: 0.9968 - val_loss: 0.1989 - val_acc: 0.9541\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9964\n",
      "Epoch 00070: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0147 - acc: 0.9964 - val_loss: 0.1973 - val_acc: 0.9546\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9988\n",
      "Epoch 00071: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0070 - acc: 0.9988 - val_loss: 0.2664 - val_acc: 0.9404\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9946\n",
      "Epoch 00072: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0193 - acc: 0.9946 - val_loss: 0.1699 - val_acc: 0.9562\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9944\n",
      "Epoch 00073: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0198 - acc: 0.9944 - val_loss: 0.1805 - val_acc: 0.9550\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9984\n",
      "Epoch 00074: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0078 - acc: 0.9984 - val_loss: 0.1607 - val_acc: 0.9590\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9988\n",
      "Epoch 00075: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0064 - acc: 0.9988 - val_loss: 0.2034 - val_acc: 0.9520\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9938\n",
      "Epoch 00076: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0243 - acc: 0.9938 - val_loss: 0.1651 - val_acc: 0.9578\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
      "Epoch 00077: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0060 - acc: 0.9990 - val_loss: 0.1556 - val_acc: 0.9613\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9987\n",
      "Epoch 00078: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0059 - acc: 0.9988 - val_loss: 0.3245 - val_acc: 0.9317\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9971\n",
      "Epoch 00079: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0122 - acc: 0.9971 - val_loss: 0.2398 - val_acc: 0.9408\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9976\n",
      "Epoch 00080: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0099 - acc: 0.9975 - val_loss: 0.1926 - val_acc: 0.9567\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9951\n",
      "Epoch 00081: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0174 - acc: 0.9951 - val_loss: 0.1845 - val_acc: 0.9562\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9959\n",
      "Epoch 00082: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0159 - acc: 0.9959 - val_loss: 0.1759 - val_acc: 0.9576\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9994\n",
      "Epoch 00083: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0047 - acc: 0.9993 - val_loss: 0.1754 - val_acc: 0.9597\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9958\n",
      "Epoch 00084: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0158 - acc: 0.9958 - val_loss: 0.1943 - val_acc: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0050 - acc: 0.9993 - val_loss: 0.1765 - val_acc: 0.9590\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9980\n",
      "Epoch 00086: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0086 - acc: 0.9980 - val_loss: 0.1669 - val_acc: 0.9583\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1914 - acc: 0.9472\n",
      "Loss: 0.19141930490267983 Accuracy: 0.94724816\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3665 - acc: 0.5784\n",
      "Epoch 00001: val_loss improved from inf to 1.28232, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/001-1.2823.hdf5\n",
      "36805/36805 [==============================] - 241s 7ms/sample - loss: 1.3665 - acc: 0.5783 - val_loss: 1.2823 - val_acc: 0.5765\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5945 - acc: 0.8232\n",
      "Epoch 00002: val_loss improved from 1.28232 to 0.61571, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/002-0.6157.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.5945 - acc: 0.8232 - val_loss: 0.6157 - val_acc: 0.8153\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3915 - acc: 0.8838\n",
      "Epoch 00003: val_loss did not improve from 0.61571\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.3917 - acc: 0.8838 - val_loss: 0.6430 - val_acc: 0.8053\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2988 - acc: 0.9105\n",
      "Epoch 00004: val_loss improved from 0.61571 to 0.31378, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/004-0.3138.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.2989 - acc: 0.9105 - val_loss: 0.3138 - val_acc: 0.9080\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9279\n",
      "Epoch 00005: val_loss improved from 0.31378 to 0.26387, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/005-0.2639.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2438 - acc: 0.9279 - val_loss: 0.2639 - val_acc: 0.9138\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9409\n",
      "Epoch 00006: val_loss did not improve from 0.26387\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1996 - acc: 0.9409 - val_loss: 0.4129 - val_acc: 0.8712\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9492\n",
      "Epoch 00007: val_loss improved from 0.26387 to 0.25420, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/007-0.2542.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1713 - acc: 0.9492 - val_loss: 0.2542 - val_acc: 0.9236\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9543\n",
      "Epoch 00008: val_loss improved from 0.25420 to 0.22010, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/008-0.2201.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1535 - acc: 0.9542 - val_loss: 0.2201 - val_acc: 0.9317\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9621\n",
      "Epoch 00009: val_loss improved from 0.22010 to 0.17182, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/009-0.1718.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1319 - acc: 0.9621 - val_loss: 0.1718 - val_acc: 0.9502\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9640\n",
      "Epoch 00010: val_loss did not improve from 0.17182\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1236 - acc: 0.9640 - val_loss: 0.2031 - val_acc: 0.9371\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9647\n",
      "Epoch 00011: val_loss did not improve from 0.17182\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1178 - acc: 0.9646 - val_loss: 0.2537 - val_acc: 0.9220\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9613\n",
      "Epoch 00012: val_loss did not improve from 0.17182\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1285 - acc: 0.9612 - val_loss: 0.1890 - val_acc: 0.9413\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9722\n",
      "Epoch 00013: val_loss did not improve from 0.17182\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0954 - acc: 0.9722 - val_loss: 0.1875 - val_acc: 0.9448\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9793\n",
      "Epoch 00014: val_loss did not improve from 0.17182\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0749 - acc: 0.9793 - val_loss: 0.2031 - val_acc: 0.9404\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9814\n",
      "Epoch 00015: val_loss improved from 0.17182 to 0.15173, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/015-0.1517.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0672 - acc: 0.9814 - val_loss: 0.1517 - val_acc: 0.9527\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9816\n",
      "Epoch 00016: val_loss improved from 0.15173 to 0.14003, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/016-0.1400.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0662 - acc: 0.9816 - val_loss: 0.1400 - val_acc: 0.9578\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9843\n",
      "Epoch 00017: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0571 - acc: 0.9843 - val_loss: 0.2093 - val_acc: 0.9413\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9860\n",
      "Epoch 00018: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0536 - acc: 0.9860 - val_loss: 0.1645 - val_acc: 0.9518\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9863\n",
      "Epoch 00019: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0501 - acc: 0.9863 - val_loss: 0.1677 - val_acc: 0.9520\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9881\n",
      "Epoch 00020: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0457 - acc: 0.9881 - val_loss: 0.1973 - val_acc: 0.9420\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9896\n",
      "Epoch 00021: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0412 - acc: 0.9896 - val_loss: 0.2051 - val_acc: 0.9352\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9824\n",
      "Epoch 00022: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0592 - acc: 0.9824 - val_loss: 0.1415 - val_acc: 0.9599\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9885\n",
      "Epoch 00023: val_loss did not improve from 0.14003\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0431 - acc: 0.9884 - val_loss: 0.1651 - val_acc: 0.9499\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9886\n",
      "Epoch 00024: val_loss improved from 0.14003 to 0.12134, saving model to model/checkpoint/1D_CNN_custom_kernel_192_BN_9_conv_checkpoint/024-0.1213.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0441 - acc: 0.9886 - val_loss: 0.1213 - val_acc: 0.9623\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9951\n",
      "Epoch 00025: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0242 - acc: 0.9951 - val_loss: 0.1467 - val_acc: 0.9578\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9927\n",
      "Epoch 00026: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0297 - acc: 0.9927 - val_loss: 0.1576 - val_acc: 0.9550\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9941\n",
      "Epoch 00027: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0244 - acc: 0.9941 - val_loss: 0.1630 - val_acc: 0.9550\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9943\n",
      "Epoch 00028: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0244 - acc: 0.9942 - val_loss: 0.2410 - val_acc: 0.9271\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9862\n",
      "Epoch 00029: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0477 - acc: 0.9861 - val_loss: 0.1485 - val_acc: 0.9555\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9928\n",
      "Epoch 00030: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0293 - acc: 0.9927 - val_loss: 0.1285 - val_acc: 0.9641\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9931\n",
      "Epoch 00031: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0275 - acc: 0.9931 - val_loss: 0.1417 - val_acc: 0.9595\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9912\n",
      "Epoch 00032: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0323 - acc: 0.9912 - val_loss: 0.1272 - val_acc: 0.9665\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9973\n",
      "Epoch 00033: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0136 - acc: 0.9973 - val_loss: 0.1293 - val_acc: 0.9620\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9975\n",
      "Epoch 00034: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0134 - acc: 0.9975 - val_loss: 0.1397 - val_acc: 0.9623\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9961\n",
      "Epoch 00035: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0173 - acc: 0.9961 - val_loss: 0.1615 - val_acc: 0.9527\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9966\n",
      "Epoch 00036: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0151 - acc: 0.9966 - val_loss: 0.1732 - val_acc: 0.9527\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9945\n",
      "Epoch 00037: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0207 - acc: 0.9945 - val_loss: 0.1978 - val_acc: 0.9506\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9955\n",
      "Epoch 00038: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0183 - acc: 0.9955 - val_loss: 0.2042 - val_acc: 0.9415\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9911\n",
      "Epoch 00039: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0316 - acc: 0.9911 - val_loss: 0.1527 - val_acc: 0.9576\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9982\n",
      "Epoch 00040: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0099 - acc: 0.9982 - val_loss: 0.2109 - val_acc: 0.9457\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9927\n",
      "Epoch 00041: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0257 - acc: 0.9926 - val_loss: 0.1438 - val_acc: 0.9590\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9942\n",
      "Epoch 00042: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0219 - acc: 0.9942 - val_loss: 0.1338 - val_acc: 0.9634\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9987\n",
      "Epoch 00043: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0083 - acc: 0.9986 - val_loss: 0.1295 - val_acc: 0.9665\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9947\n",
      "Epoch 00044: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0202 - acc: 0.9947 - val_loss: 0.1347 - val_acc: 0.9620\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9979\n",
      "Epoch 00045: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0100 - acc: 0.9978 - val_loss: 0.1791 - val_acc: 0.9527\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9949\n",
      "Epoch 00046: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0196 - acc: 0.9949 - val_loss: 0.1493 - val_acc: 0.9611\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9989\n",
      "Epoch 00047: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0065 - acc: 0.9989 - val_loss: 0.1289 - val_acc: 0.9658\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9988\n",
      "Epoch 00048: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0064 - acc: 0.9988 - val_loss: 0.1561 - val_acc: 0.9602\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9938\n",
      "Epoch 00049: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0221 - acc: 0.9938 - val_loss: 0.2033 - val_acc: 0.9478\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9981\n",
      "Epoch 00050: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0086 - acc: 0.9981 - val_loss: 0.1910 - val_acc: 0.9534\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9980\n",
      "Epoch 00051: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0089 - acc: 0.9980 - val_loss: 0.1448 - val_acc: 0.9658\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9960\n",
      "Epoch 00052: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0149 - acc: 0.9960 - val_loss: 0.1670 - val_acc: 0.9550\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9913\n",
      "Epoch 00053: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0294 - acc: 0.9913 - val_loss: 0.1364 - val_acc: 0.9616\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9981\n",
      "Epoch 00054: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0090 - acc: 0.9981 - val_loss: 0.1327 - val_acc: 0.9653\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 00055: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0044 - acc: 0.9993 - val_loss: 0.1496 - val_acc: 0.9627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 00056: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0070 - acc: 0.9983 - val_loss: 0.1725 - val_acc: 0.9536\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9978\n",
      "Epoch 00057: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0089 - acc: 0.9978 - val_loss: 0.1560 - val_acc: 0.9588\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9981\n",
      "Epoch 00058: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0084 - acc: 0.9981 - val_loss: 0.1505 - val_acc: 0.9646\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 00059: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0135 - acc: 0.9959 - val_loss: 0.1673 - val_acc: 0.9548\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9979\n",
      "Epoch 00060: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0083 - acc: 0.9979 - val_loss: 0.2071 - val_acc: 0.9450\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9977\n",
      "Epoch 00061: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0094 - acc: 0.9977 - val_loss: 0.2346 - val_acc: 0.9397\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9957\n",
      "Epoch 00062: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0153 - acc: 0.9957 - val_loss: 0.1636 - val_acc: 0.9557\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9991\n",
      "Epoch 00063: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0042 - acc: 0.9991 - val_loss: 0.1531 - val_acc: 0.9616\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9987\n",
      "Epoch 00064: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0056 - acc: 0.9987 - val_loss: 0.1823 - val_acc: 0.9588\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9953\n",
      "Epoch 00065: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0160 - acc: 0.9953 - val_loss: 0.1470 - val_acc: 0.9627\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9982\n",
      "Epoch 00066: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0082 - acc: 0.9982 - val_loss: 0.1392 - val_acc: 0.9662\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 00067: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0050 - acc: 0.9989 - val_loss: 0.1411 - val_acc: 0.9660\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9979\n",
      "Epoch 00068: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0081 - acc: 0.9979 - val_loss: 0.1523 - val_acc: 0.9625\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9977\n",
      "Epoch 00069: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0090 - acc: 0.9977 - val_loss: 0.2194 - val_acc: 0.9506\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 00070: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0101 - acc: 0.9971 - val_loss: 0.1611 - val_acc: 0.9609\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9990\n",
      "Epoch 00071: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0049 - acc: 0.9990 - val_loss: 0.1470 - val_acc: 0.9665\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 00072: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0039 - acc: 0.9993 - val_loss: 0.1539 - val_acc: 0.9639\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 00073: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0087 - acc: 0.9977 - val_loss: 0.1766 - val_acc: 0.9560\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 00074: val_loss did not improve from 0.12134\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.1767 - val_acc: 0.9564\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1784 - acc: 0.9516\n",
      "Loss: 0.17835679398085594 Accuracy: 0.95160955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_kernel_192_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,492,624\n",
      "Trainable params: 18,444,496\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 861us/sample - loss: 7.7689 - acc: 0.5080\n",
      "Loss: 7.7689363844050545 Accuracy: 0.50799584\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 7,232,400\n",
      "Trainable params: 6,549,520\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 4.4027 - acc: 0.4667\n",
      "Loss: 4.402662525642451 Accuracy: 0.46666667\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,877,648\n",
      "Trainable params: 2,649,808\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.2687 - acc: 0.5346\n",
      "Loss: 2.26870874704973 Accuracy: 0.53457946\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,459,472\n",
      "Trainable params: 1,383,184\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.9789 - acc: 0.7423\n",
      "Loss: 0.9789011884948794 Accuracy: 0.74226373\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,304,976\n",
      "Trainable params: 1,253,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.7346 - acc: 0.8258\n",
      "Loss: 0.7346186304389501 Accuracy: 0.82575285\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,066,000\n",
      "Trainable params: 1,048,336\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.3701 - acc: 0.9088\n",
      "Loss: 0.3701478431157977 Accuracy: 0.9088266\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 1,003,152\n",
      "Trainable params: 996,496\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.2482 - acc: 0.9321\n",
      "Loss: 0.24817572193972665 Accuracy: 0.93208724\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,017,104\n",
      "Trainable params: 1,013,776\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1914 - acc: 0.9472\n",
      "Loss: 0.19141930490267983 Accuracy: 0.94724816\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,109,008\n",
      "Trainable params: 1,105,936\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1784 - acc: 0.9516\n",
      "Loss: 0.17835679398085594 Accuracy: 0.95160955\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_kernel_192_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,492,624\n",
      "Trainable params: 18,444,496\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 947us/sample - loss: 7.7016 - acc: 0.5124\n",
      "Loss: 7.701566530190029 Accuracy: 0.51235723\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 7,232,400\n",
      "Trainable params: 6,549,520\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 6.6508 - acc: 0.5225\n",
      "Loss: 6.650778605658194 Accuracy: 0.5225338\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,877,648\n",
      "Trainable params: 2,649,808\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 3.9757 - acc: 0.5877\n",
      "Loss: 3.975650365924538 Accuracy: 0.5877466\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,459,472\n",
      "Trainable params: 1,383,184\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.6357 - acc: 0.7576\n",
      "Loss: 1.6356533436265195 Accuracy: 0.7576324\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,304,976\n",
      "Trainable params: 1,253,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.9407 - acc: 0.8430\n",
      "Loss: 0.9407158060856202 Accuracy: 0.84299064\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,066,000\n",
      "Trainable params: 1,048,336\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.7368 - acc: 0.8598\n",
      "Loss: 0.736759395572441 Accuracy: 0.8598131\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 1,003,152\n",
      "Trainable params: 996,496\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3025 - acc: 0.9346\n",
      "Loss: 0.3025357089604049 Accuracy: 0.93457943\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,017,104\n",
      "Trainable params: 1,013,776\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2203 - acc: 0.9483\n",
      "Loss: 0.22028221896504316 Accuracy: 0.9482866\n",
      "\n",
      "1D_CNN_custom_kernel_192_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,109,008\n",
      "Trainable params: 1,105,936\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2526 - acc: 0.9402\n",
      "Loss: 0.2526039500189858 Accuracy: 0.9401869\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_kernel_192_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
