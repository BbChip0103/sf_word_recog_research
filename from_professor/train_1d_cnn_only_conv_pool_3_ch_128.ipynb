{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5,6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_pool_3_ch_128_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=25, filters=128, strides=1, \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "#     model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=128*(2**int((i+1)/2)), strides=1, \n",
    "                          activation='relu'))\n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 15976, 128)        3328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5326, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 681728)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 681728)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                10907664  \n",
      "=================================================================\n",
      "Total params: 10,910,992\n",
      "Trainable params: 10,910,992\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 15976, 128)        3328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5326, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5302, 128)         409728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1768, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 226304)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 226304)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                3620880   \n",
      "=================================================================\n",
      "Total params: 4,033,936\n",
      "Trainable params: 4,033,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 15976, 128)        3328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5326, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 5302, 128)         409728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1768, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1744, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 582, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 148992)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 148992)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2383888   \n",
      "=================================================================\n",
      "Total params: 3,616,400\n",
      "Trainable params: 3,616,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 15976, 128)        3328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5326, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 5302, 128)         409728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1768, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1744, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 582, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 558, 256)          1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 186, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 47616)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 47616)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                761872    \n",
      "=================================================================\n",
      "Total params: 3,633,040\n",
      "Trainable params: 3,633,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 15976, 128)        3328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5326, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5302, 128)         409728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1768, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 1744, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 582, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 558, 256)          1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 186, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 162, 512)          3277312   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 54, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                442384    \n",
      "=================================================================\n",
      "Total params: 6,590,864\n",
      "Trainable params: 6,590,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 15976, 128)        3328      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5326, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5302, 128)         409728    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1768, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1744, 256)         819456    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 582, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 558, 256)          1638656   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 186, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 162, 512)          3277312   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 54, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 30, 512)           6554112   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 10, 512)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                81936     \n",
      "=================================================================\n",
      "Total params: 12,784,528\n",
      "Trainable params: 12,784,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_128_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0247 - acc: 0.3697\n",
      "Epoch 00001: val_loss improved from inf to 1.63221, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_128_DO_checkpoint/001-1.6322.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 2.0246 - acc: 0.3697 - val_loss: 1.6322 - val_acc: 0.4938\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4087 - acc: 0.5668\n",
      "Epoch 00002: val_loss improved from 1.63221 to 1.49341, saving model to model/checkpoint/1D_CNN_1_only_conv_pool_3_ch_128_DO_checkpoint/002-1.4934.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.4086 - acc: 0.5669 - val_loss: 1.4934 - val_acc: 0.5397\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1713 - acc: 0.6435\n",
      "Epoch 00003: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.1713 - acc: 0.6434 - val_loss: 1.5109 - val_acc: 0.5316\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0100 - acc: 0.6958\n",
      "Epoch 00004: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.0100 - acc: 0.6958 - val_loss: 1.5065 - val_acc: 0.5318\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8834 - acc: 0.7365\n",
      "Epoch 00005: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.8834 - acc: 0.7365 - val_loss: 1.5301 - val_acc: 0.5250\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7785 - acc: 0.7724\n",
      "Epoch 00006: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.7785 - acc: 0.7724 - val_loss: 1.5860 - val_acc: 0.5232\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6889 - acc: 0.8009\n",
      "Epoch 00007: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6889 - acc: 0.8009 - val_loss: 1.5878 - val_acc: 0.5281\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6071 - acc: 0.8298\n",
      "Epoch 00008: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6071 - acc: 0.8298 - val_loss: 1.6658 - val_acc: 0.5190\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5405 - acc: 0.8503\n",
      "Epoch 00009: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5406 - acc: 0.8503 - val_loss: 1.6823 - val_acc: 0.5192\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8710\n",
      "Epoch 00010: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4789 - acc: 0.8710 - val_loss: 1.7133 - val_acc: 0.5260\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4292 - acc: 0.8882\n",
      "Epoch 00011: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4291 - acc: 0.8882 - val_loss: 1.7817 - val_acc: 0.5253\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3768 - acc: 0.9057\n",
      "Epoch 00012: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3768 - acc: 0.9057 - val_loss: 1.8251 - val_acc: 0.5288\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3440 - acc: 0.9161\n",
      "Epoch 00013: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3439 - acc: 0.9161 - val_loss: 1.8857 - val_acc: 0.5190\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.9295\n",
      "Epoch 00014: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3045 - acc: 0.9295 - val_loss: 1.9297 - val_acc: 0.5229\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2718 - acc: 0.9398\n",
      "Epoch 00015: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2718 - acc: 0.9398 - val_loss: 1.9782 - val_acc: 0.5222\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9445\n",
      "Epoch 00016: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2493 - acc: 0.9445 - val_loss: 2.0352 - val_acc: 0.5257\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2253 - acc: 0.9545\n",
      "Epoch 00017: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2253 - acc: 0.9545 - val_loss: 2.0743 - val_acc: 0.5176\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9555\n",
      "Epoch 00018: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2060 - acc: 0.9555 - val_loss: 2.1275 - val_acc: 0.5195\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9634\n",
      "Epoch 00019: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1853 - acc: 0.9634 - val_loss: 2.1871 - val_acc: 0.5162\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9686\n",
      "Epoch 00020: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1689 - acc: 0.9686 - val_loss: 2.2353 - val_acc: 0.5218\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9705\n",
      "Epoch 00021: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1576 - acc: 0.9705 - val_loss: 2.2557 - val_acc: 0.5162\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9727\n",
      "Epoch 00022: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1485 - acc: 0.9727 - val_loss: 2.3414 - val_acc: 0.5234\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9771\n",
      "Epoch 00023: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1345 - acc: 0.9771 - val_loss: 2.3889 - val_acc: 0.5143\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9765\n",
      "Epoch 00024: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1323 - acc: 0.9765 - val_loss: 2.3828 - val_acc: 0.5257\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9807\n",
      "Epoch 00025: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1162 - acc: 0.9807 - val_loss: 2.4232 - val_acc: 0.5234\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9831\n",
      "Epoch 00026: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1062 - acc: 0.9831 - val_loss: 2.4586 - val_acc: 0.5281\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9825\n",
      "Epoch 00027: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1078 - acc: 0.9825 - val_loss: 2.5427 - val_acc: 0.5236\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9852\n",
      "Epoch 00028: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0953 - acc: 0.9852 - val_loss: 2.5320 - val_acc: 0.5243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9859\n",
      "Epoch 00029: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0925 - acc: 0.9858 - val_loss: 2.6072 - val_acc: 0.5195\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9846\n",
      "Epoch 00030: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0949 - acc: 0.9846 - val_loss: 2.6435 - val_acc: 0.5271\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9862\n",
      "Epoch 00031: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0897 - acc: 0.9863 - val_loss: 2.6252 - val_acc: 0.5295\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9871\n",
      "Epoch 00032: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0798 - acc: 0.9871 - val_loss: 2.6571 - val_acc: 0.5213\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9877\n",
      "Epoch 00033: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0787 - acc: 0.9877 - val_loss: 2.7076 - val_acc: 0.5239\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9897\n",
      "Epoch 00034: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0706 - acc: 0.9897 - val_loss: 2.7100 - val_acc: 0.5246\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9883\n",
      "Epoch 00035: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0746 - acc: 0.9883 - val_loss: 2.7527 - val_acc: 0.5222\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9907\n",
      "Epoch 00036: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0659 - acc: 0.9907 - val_loss: 2.8140 - val_acc: 0.5232\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9894\n",
      "Epoch 00037: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0680 - acc: 0.9894 - val_loss: 2.8010 - val_acc: 0.5201\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9920\n",
      "Epoch 00038: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0602 - acc: 0.9920 - val_loss: 2.8288 - val_acc: 0.5267\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9913\n",
      "Epoch 00039: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0614 - acc: 0.9913 - val_loss: 2.8908 - val_acc: 0.5206\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9889\n",
      "Epoch 00040: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0648 - acc: 0.9889 - val_loss: 2.8679 - val_acc: 0.5225\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9920\n",
      "Epoch 00041: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0583 - acc: 0.9920 - val_loss: 2.9117 - val_acc: 0.5267\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9935\n",
      "Epoch 00042: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0504 - acc: 0.9935 - val_loss: 2.9217 - val_acc: 0.5285\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9926\n",
      "Epoch 00043: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0538 - acc: 0.9926 - val_loss: 2.9497 - val_acc: 0.5264\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9925\n",
      "Epoch 00044: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0513 - acc: 0.9925 - val_loss: 2.9470 - val_acc: 0.5288\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9927\n",
      "Epoch 00045: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0508 - acc: 0.9927 - val_loss: 2.9457 - val_acc: 0.5304\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9936\n",
      "Epoch 00046: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0480 - acc: 0.9936 - val_loss: 3.0293 - val_acc: 0.5225\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9922\n",
      "Epoch 00047: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0534 - acc: 0.9922 - val_loss: 3.0324 - val_acc: 0.5204\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9927\n",
      "Epoch 00048: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0508 - acc: 0.9927 - val_loss: 3.0347 - val_acc: 0.5232\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9928\n",
      "Epoch 00049: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0498 - acc: 0.9928 - val_loss: 3.0108 - val_acc: 0.5288\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9930\n",
      "Epoch 00050: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0482 - acc: 0.9930 - val_loss: 3.0432 - val_acc: 0.5323\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9950\n",
      "Epoch 00051: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0434 - acc: 0.9950 - val_loss: 3.0491 - val_acc: 0.5241\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9955\n",
      "Epoch 00052: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0393 - acc: 0.9955 - val_loss: 3.0780 - val_acc: 0.5243\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9923\n",
      "Epoch 00053: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0487 - acc: 0.9923 - val_loss: 3.1517 - val_acc: 0.5188\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9930\n",
      "Epoch 00054: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0452 - acc: 0.9930 - val_loss: 3.1340 - val_acc: 0.5304\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9940\n",
      "Epoch 00055: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0409 - acc: 0.9940 - val_loss: 3.1146 - val_acc: 0.5278\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9941\n",
      "Epoch 00056: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0405 - acc: 0.9941 - val_loss: 3.1656 - val_acc: 0.5297\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9943\n",
      "Epoch 00057: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0387 - acc: 0.9943 - val_loss: 3.1173 - val_acc: 0.5306\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9934\n",
      "Epoch 00058: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0442 - acc: 0.9934 - val_loss: 3.1419 - val_acc: 0.5299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9947\n",
      "Epoch 00059: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0373 - acc: 0.9947 - val_loss: 3.1576 - val_acc: 0.5302\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9935\n",
      "Epoch 00060: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0414 - acc: 0.9935 - val_loss: 3.2528 - val_acc: 0.5195\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9951\n",
      "Epoch 00061: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0371 - acc: 0.9951 - val_loss: 3.2081 - val_acc: 0.5232\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9961\n",
      "Epoch 00062: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0329 - acc: 0.9961 - val_loss: 3.1849 - val_acc: 0.5285\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9947\n",
      "Epoch 00063: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0350 - acc: 0.9947 - val_loss: 3.2802 - val_acc: 0.5248\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9943\n",
      "Epoch 00064: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0372 - acc: 0.9943 - val_loss: 3.2221 - val_acc: 0.5339\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9956\n",
      "Epoch 00065: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0332 - acc: 0.9956 - val_loss: 3.2766 - val_acc: 0.5229\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9949\n",
      "Epoch 00066: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0355 - acc: 0.9949 - val_loss: 3.2947 - val_acc: 0.5218\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9951\n",
      "Epoch 00067: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0355 - acc: 0.9951 - val_loss: 3.2959 - val_acc: 0.5236\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9944\n",
      "Epoch 00068: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0360 - acc: 0.9944 - val_loss: 3.3060 - val_acc: 0.5243\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9960\n",
      "Epoch 00069: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0312 - acc: 0.9960 - val_loss: 3.2887 - val_acc: 0.5264\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9944\n",
      "Epoch 00070: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0366 - acc: 0.9944 - val_loss: 3.3338 - val_acc: 0.5195\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9953\n",
      "Epoch 00071: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0324 - acc: 0.9953 - val_loss: 3.3340 - val_acc: 0.5262\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9941\n",
      "Epoch 00072: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0388 - acc: 0.9941 - val_loss: 3.4444 - val_acc: 0.5104\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9962\n",
      "Epoch 00073: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0300 - acc: 0.9962 - val_loss: 3.3200 - val_acc: 0.5295\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9956\n",
      "Epoch 00074: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0338 - acc: 0.9956 - val_loss: 3.3771 - val_acc: 0.5241\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9948\n",
      "Epoch 00075: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0346 - acc: 0.9948 - val_loss: 3.3686 - val_acc: 0.5269\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9957\n",
      "Epoch 00076: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0303 - acc: 0.9957 - val_loss: 3.3663 - val_acc: 0.5229\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9957\n",
      "Epoch 00077: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0301 - acc: 0.9957 - val_loss: 3.3785 - val_acc: 0.5215\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9963\n",
      "Epoch 00078: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0270 - acc: 0.9963 - val_loss: 3.4463 - val_acc: 0.5260\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9970\n",
      "Epoch 00079: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0257 - acc: 0.9970 - val_loss: 3.4380 - val_acc: 0.5269\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9948\n",
      "Epoch 00080: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0322 - acc: 0.9948 - val_loss: 3.4383 - val_acc: 0.5260\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9955\n",
      "Epoch 00081: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0301 - acc: 0.9955 - val_loss: 3.4534 - val_acc: 0.5239\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9964\n",
      "Epoch 00082: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0268 - acc: 0.9964 - val_loss: 3.4302 - val_acc: 0.5278\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9962\n",
      "Epoch 00083: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0265 - acc: 0.9963 - val_loss: 3.4303 - val_acc: 0.5358\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9974\n",
      "Epoch 00084: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0242 - acc: 0.9974 - val_loss: 3.4573 - val_acc: 0.5320\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9961\n",
      "Epoch 00085: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0286 - acc: 0.9961 - val_loss: 3.5273 - val_acc: 0.5204\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9948\n",
      "Epoch 00086: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0305 - acc: 0.9948 - val_loss: 3.5198 - val_acc: 0.5285\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9964\n",
      "Epoch 00087: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0285 - acc: 0.9964 - val_loss: 3.4777 - val_acc: 0.5257\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9962\n",
      "Epoch 00088: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0273 - acc: 0.9962 - val_loss: 3.4876 - val_acc: 0.5264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9968\n",
      "Epoch 00089: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0251 - acc: 0.9968 - val_loss: 3.5090 - val_acc: 0.5248\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9965\n",
      "Epoch 00090: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0283 - acc: 0.9965 - val_loss: 3.5442 - val_acc: 0.5269\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9969\n",
      "Epoch 00091: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0257 - acc: 0.9969 - val_loss: 3.5757 - val_acc: 0.5220\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9952\n",
      "Epoch 00092: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0319 - acc: 0.9952 - val_loss: 3.6863 - val_acc: 0.5211\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9967\n",
      "Epoch 00093: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0246 - acc: 0.9967 - val_loss: 3.5678 - val_acc: 0.5250\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9971\n",
      "Epoch 00094: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0233 - acc: 0.9971 - val_loss: 3.5548 - val_acc: 0.5260\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9972\n",
      "Epoch 00095: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0220 - acc: 0.9972 - val_loss: 3.5299 - val_acc: 0.5325\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9955\n",
      "Epoch 00096: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0287 - acc: 0.9955 - val_loss: 3.6902 - val_acc: 0.5232\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9944\n",
      "Epoch 00097: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0334 - acc: 0.9944 - val_loss: 3.5881 - val_acc: 0.5316\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9964\n",
      "Epoch 00098: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0262 - acc: 0.9964 - val_loss: 3.5991 - val_acc: 0.5290\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9971\n",
      "Epoch 00099: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0235 - acc: 0.9971 - val_loss: 3.5783 - val_acc: 0.5311\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9970\n",
      "Epoch 00100: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0245 - acc: 0.9970 - val_loss: 3.5856 - val_acc: 0.5262\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9974\n",
      "Epoch 00101: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0219 - acc: 0.9974 - val_loss: 3.6195 - val_acc: 0.5257\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9963\n",
      "Epoch 00102: val_loss did not improve from 1.49341\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0246 - acc: 0.9963 - val_loss: 3.6351 - val_acc: 0.5351\n",
      "\n",
      "1D_CNN_1_only_conv_pool_3_ch_128_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 622us/sample - loss: 1.5713 - acc: 0.5067\n",
      "Loss: 1.5712665378366553 Accuracy: 0.50674975\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8144 - acc: 0.4209\n",
      "Epoch 00001: val_loss improved from inf to 1.36917, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_128_DO_checkpoint/001-1.3692.hdf5\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 1.8143 - acc: 0.4209 - val_loss: 1.3692 - val_acc: 0.5816\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2141 - acc: 0.6318\n",
      "Epoch 00002: val_loss improved from 1.36917 to 1.16543, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_128_DO_checkpoint/002-1.1654.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 1.2140 - acc: 0.6318 - val_loss: 1.1654 - val_acc: 0.6480\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9757 - acc: 0.7066\n",
      "Epoch 00003: val_loss improved from 1.16543 to 1.05215, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_128_DO_checkpoint/003-1.0522.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.9756 - acc: 0.7066 - val_loss: 1.0522 - val_acc: 0.6839\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7983 - acc: 0.7626\n",
      "Epoch 00004: val_loss improved from 1.05215 to 1.02354, saving model to model/checkpoint/1D_CNN_2_only_conv_pool_3_ch_128_DO_checkpoint/004-1.0235.hdf5\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.7984 - acc: 0.7626 - val_loss: 1.0235 - val_acc: 0.6841\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6533 - acc: 0.8063\n",
      "Epoch 00005: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.6533 - acc: 0.8063 - val_loss: 1.0811 - val_acc: 0.6727\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5228 - acc: 0.8467\n",
      "Epoch 00006: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.5228 - acc: 0.8468 - val_loss: 1.0619 - val_acc: 0.6956\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8821\n",
      "Epoch 00007: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.4126 - acc: 0.8821 - val_loss: 1.1274 - val_acc: 0.6806\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3285 - acc: 0.9076\n",
      "Epoch 00008: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.3286 - acc: 0.9076 - val_loss: 1.2038 - val_acc: 0.6844\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.9292\n",
      "Epoch 00009: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.2606 - acc: 0.9292 - val_loss: 1.2427 - val_acc: 0.6925\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9463\n",
      "Epoch 00010: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.2041 - acc: 0.9463 - val_loss: 1.3096 - val_acc: 0.6918\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9560\n",
      "Epoch 00011: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1707 - acc: 0.9560 - val_loss: 1.4097 - val_acc: 0.6816\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9628\n",
      "Epoch 00012: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1445 - acc: 0.9627 - val_loss: 1.4389 - val_acc: 0.6813\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9682\n",
      "Epoch 00013: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1253 - acc: 0.9682 - val_loss: 1.4926 - val_acc: 0.6765\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9752\n",
      "Epoch 00014: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.1054 - acc: 0.9752 - val_loss: 1.5418 - val_acc: 0.6869\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9790\n",
      "Epoch 00015: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0892 - acc: 0.9790 - val_loss: 1.6498 - val_acc: 0.6792\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9811\n",
      "Epoch 00016: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0808 - acc: 0.9811 - val_loss: 1.6041 - val_acc: 0.6939\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9840\n",
      "Epoch 00017: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0741 - acc: 0.9840 - val_loss: 1.7531 - val_acc: 0.6723\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9828\n",
      "Epoch 00018: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0727 - acc: 0.9828 - val_loss: 1.6714 - val_acc: 0.6872\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9847\n",
      "Epoch 00019: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0674 - acc: 0.9847 - val_loss: 1.6621 - val_acc: 0.6993\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9879\n",
      "Epoch 00020: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0573 - acc: 0.9879 - val_loss: 1.6941 - val_acc: 0.6979\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9871\n",
      "Epoch 00021: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0577 - acc: 0.9871 - val_loss: 1.7222 - val_acc: 0.6958\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9877\n",
      "Epoch 00022: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0551 - acc: 0.9877 - val_loss: 1.7777 - val_acc: 0.6946\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9892\n",
      "Epoch 00023: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0515 - acc: 0.9892 - val_loss: 1.7844 - val_acc: 0.6962\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9894\n",
      "Epoch 00024: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0512 - acc: 0.9894 - val_loss: 1.8201 - val_acc: 0.6928\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9894\n",
      "Epoch 00025: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0478 - acc: 0.9894 - val_loss: 1.7976 - val_acc: 0.7009\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9904\n",
      "Epoch 00026: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0453 - acc: 0.9904 - val_loss: 1.8039 - val_acc: 0.7088\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9915\n",
      "Epoch 00027: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0406 - acc: 0.9915 - val_loss: 1.8669 - val_acc: 0.6932\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9915\n",
      "Epoch 00028: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0412 - acc: 0.9915 - val_loss: 1.8549 - val_acc: 0.7037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9919\n",
      "Epoch 00029: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0417 - acc: 0.9919 - val_loss: 1.8510 - val_acc: 0.7032\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9902\n",
      "Epoch 00030: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0422 - acc: 0.9902 - val_loss: 1.8460 - val_acc: 0.7016\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9913\n",
      "Epoch 00031: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0402 - acc: 0.9913 - val_loss: 1.8349 - val_acc: 0.7016\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9929\n",
      "Epoch 00032: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0368 - acc: 0.9929 - val_loss: 1.8806 - val_acc: 0.7074\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9923\n",
      "Epoch 00033: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0377 - acc: 0.9923 - val_loss: 1.8727 - val_acc: 0.7049\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9931\n",
      "Epoch 00034: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0347 - acc: 0.9931 - val_loss: 1.8817 - val_acc: 0.7063\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9932\n",
      "Epoch 00035: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0348 - acc: 0.9932 - val_loss: 1.9542 - val_acc: 0.6995\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9934\n",
      "Epoch 00036: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0342 - acc: 0.9934 - val_loss: 1.9281 - val_acc: 0.7042\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9944\n",
      "Epoch 00037: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0325 - acc: 0.9944 - val_loss: 1.9740 - val_acc: 0.7035\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9932\n",
      "Epoch 00038: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0346 - acc: 0.9932 - val_loss: 1.9344 - val_acc: 0.7032\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9937\n",
      "Epoch 00039: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0315 - acc: 0.9938 - val_loss: 1.9624 - val_acc: 0.7102\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9948\n",
      "Epoch 00040: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0292 - acc: 0.9948 - val_loss: 1.9600 - val_acc: 0.7079\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9940\n",
      "Epoch 00041: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0315 - acc: 0.9940 - val_loss: 1.9549 - val_acc: 0.7100\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9933\n",
      "Epoch 00042: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0352 - acc: 0.9933 - val_loss: 1.9698 - val_acc: 0.7018\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9933\n",
      "Epoch 00043: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0324 - acc: 0.9933 - val_loss: 1.9784 - val_acc: 0.7091\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9940\n",
      "Epoch 00044: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0305 - acc: 0.9940 - val_loss: 1.9236 - val_acc: 0.7079\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9945\n",
      "Epoch 00045: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0292 - acc: 0.9945 - val_loss: 1.9547 - val_acc: 0.7030\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9956\n",
      "Epoch 00046: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0269 - acc: 0.9956 - val_loss: 2.0578 - val_acc: 0.6967\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9951\n",
      "Epoch 00047: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0269 - acc: 0.9951 - val_loss: 1.9961 - val_acc: 0.7163\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9944\n",
      "Epoch 00048: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0300 - acc: 0.9944 - val_loss: 2.0972 - val_acc: 0.6937\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9953\n",
      "Epoch 00049: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0264 - acc: 0.9953 - val_loss: 1.9724 - val_acc: 0.7086\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9956\n",
      "Epoch 00050: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0260 - acc: 0.9956 - val_loss: 1.9697 - val_acc: 0.7098\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9960\n",
      "Epoch 00051: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0249 - acc: 0.9960 - val_loss: 2.0074 - val_acc: 0.7165\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9947\n",
      "Epoch 00052: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0278 - acc: 0.9947 - val_loss: 2.0537 - val_acc: 0.7105\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9954\n",
      "Epoch 00053: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0257 - acc: 0.9954 - val_loss: 2.0196 - val_acc: 0.7184\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9950\n",
      "Epoch 00054: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0269 - acc: 0.9950 - val_loss: 2.0326 - val_acc: 0.7072\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9961\n",
      "Epoch 00055: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0236 - acc: 0.9961 - val_loss: 2.0850 - val_acc: 0.7086\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9946\n",
      "Epoch 00056: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0282 - acc: 0.9946 - val_loss: 1.9948 - val_acc: 0.7177\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9948\n",
      "Epoch 00057: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0273 - acc: 0.9948 - val_loss: 2.0653 - val_acc: 0.7072\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9961\n",
      "Epoch 00058: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0242 - acc: 0.9961 - val_loss: 2.0289 - val_acc: 0.7228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9954\n",
      "Epoch 00059: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0260 - acc: 0.9954 - val_loss: 1.9834 - val_acc: 0.7184\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9961\n",
      "Epoch 00060: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0234 - acc: 0.9961 - val_loss: 2.0399 - val_acc: 0.7058\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9968\n",
      "Epoch 00061: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0225 - acc: 0.9968 - val_loss: 2.0416 - val_acc: 0.7158\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9959\n",
      "Epoch 00062: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0247 - acc: 0.9959 - val_loss: 2.0456 - val_acc: 0.7181\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9961\n",
      "Epoch 00063: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0247 - acc: 0.9961 - val_loss: 2.1762 - val_acc: 0.7028\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9960\n",
      "Epoch 00064: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0236 - acc: 0.9960 - val_loss: 2.1152 - val_acc: 0.7100\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9968\n",
      "Epoch 00065: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0216 - acc: 0.9968 - val_loss: 2.0986 - val_acc: 0.7105\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9955\n",
      "Epoch 00066: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0272 - acc: 0.9955 - val_loss: 2.0914 - val_acc: 0.7128\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9958\n",
      "Epoch 00067: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0246 - acc: 0.9958 - val_loss: 2.0596 - val_acc: 0.7147\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9962\n",
      "Epoch 00068: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0232 - acc: 0.9962 - val_loss: 2.0465 - val_acc: 0.7158\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9972\n",
      "Epoch 00069: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0203 - acc: 0.9972 - val_loss: 2.0993 - val_acc: 0.7130\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9970\n",
      "Epoch 00070: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0210 - acc: 0.9970 - val_loss: 2.0343 - val_acc: 0.7174\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9965\n",
      "Epoch 00071: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0219 - acc: 0.9965 - val_loss: 2.0928 - val_acc: 0.7163\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9966\n",
      "Epoch 00072: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0231 - acc: 0.9966 - val_loss: 2.0979 - val_acc: 0.7144\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9965\n",
      "Epoch 00073: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0226 - acc: 0.9965 - val_loss: 2.0751 - val_acc: 0.7223\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9971\n",
      "Epoch 00074: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0201 - acc: 0.9971 - val_loss: 2.1145 - val_acc: 0.7135\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9964\n",
      "Epoch 00075: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0230 - acc: 0.9964 - val_loss: 2.0792 - val_acc: 0.7156\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9967\n",
      "Epoch 00076: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0226 - acc: 0.9967 - val_loss: 2.1366 - val_acc: 0.7147\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9974\n",
      "Epoch 00077: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0199 - acc: 0.9974 - val_loss: 2.0847 - val_acc: 0.7223\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9977\n",
      "Epoch 00078: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0187 - acc: 0.9977 - val_loss: 2.1235 - val_acc: 0.7205\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9959\n",
      "Epoch 00079: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0236 - acc: 0.9959 - val_loss: 2.1942 - val_acc: 0.7128\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9962\n",
      "Epoch 00080: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0228 - acc: 0.9962 - val_loss: 2.1291 - val_acc: 0.7209\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9960\n",
      "Epoch 00081: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0235 - acc: 0.9960 - val_loss: 2.1420 - val_acc: 0.7191\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9969\n",
      "Epoch 00082: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0208 - acc: 0.9969 - val_loss: 2.1613 - val_acc: 0.7081\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9968\n",
      "Epoch 00083: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0215 - acc: 0.9968 - val_loss: 2.2102 - val_acc: 0.7091\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9972\n",
      "Epoch 00084: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0201 - acc: 0.9972 - val_loss: 2.1372 - val_acc: 0.7191\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9970\n",
      "Epoch 00085: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0204 - acc: 0.9970 - val_loss: 2.1667 - val_acc: 0.7140\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9972\n",
      "Epoch 00086: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0200 - acc: 0.9972 - val_loss: 2.0569 - val_acc: 0.7258\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9968\n",
      "Epoch 00087: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0210 - acc: 0.9968 - val_loss: 2.1578 - val_acc: 0.7219\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9967\n",
      "Epoch 00088: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0210 - acc: 0.9967 - val_loss: 2.2205 - val_acc: 0.7140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9966\n",
      "Epoch 00089: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0223 - acc: 0.9966 - val_loss: 2.1530 - val_acc: 0.7275\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9970\n",
      "Epoch 00090: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0206 - acc: 0.9970 - val_loss: 2.0925 - val_acc: 0.7254\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9969\n",
      "Epoch 00091: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0210 - acc: 0.9969 - val_loss: 2.0602 - val_acc: 0.7314\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9972\n",
      "Epoch 00092: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0202 - acc: 0.9972 - val_loss: 2.1587 - val_acc: 0.7237\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9973\n",
      "Epoch 00093: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0199 - acc: 0.9973 - val_loss: 2.2177 - val_acc: 0.7167\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9979\n",
      "Epoch 00094: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0185 - acc: 0.9979 - val_loss: 2.1671 - val_acc: 0.7207\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9968\n",
      "Epoch 00095: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 124s 3ms/sample - loss: 0.0211 - acc: 0.9968 - val_loss: 2.2210 - val_acc: 0.7200\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9968\n",
      "Epoch 00096: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0210 - acc: 0.9968 - val_loss: 2.0911 - val_acc: 0.7303\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9970\n",
      "Epoch 00097: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0211 - acc: 0.9970 - val_loss: 2.0935 - val_acc: 0.7300\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9977\n",
      "Epoch 00098: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0184 - acc: 0.9977 - val_loss: 2.1228 - val_acc: 0.7286\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9972\n",
      "Epoch 00099: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0202 - acc: 0.9972 - val_loss: 2.0842 - val_acc: 0.7293\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9969\n",
      "Epoch 00100: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0205 - acc: 0.9969 - val_loss: 2.1064 - val_acc: 0.7256\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9979\n",
      "Epoch 00101: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 125s 3ms/sample - loss: 0.0184 - acc: 0.9979 - val_loss: 2.3223 - val_acc: 0.7186\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9978\n",
      "Epoch 00102: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0182 - acc: 0.9978 - val_loss: 2.1922 - val_acc: 0.7219\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9973\n",
      "Epoch 00103: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0202 - acc: 0.9973 - val_loss: 2.0946 - val_acc: 0.7244\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9976\n",
      "Epoch 00104: val_loss did not improve from 1.02354\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0185 - acc: 0.9976 - val_loss: 2.2033 - val_acc: 0.7261\n",
      "\n",
      "1D_CNN_2_only_conv_pool_3_ch_128_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 930us/sample - loss: 1.1116 - acc: 0.6563\n",
      "Loss: 1.1115837047404589 Accuracy: 0.6562824\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6976 - acc: 0.4620\n",
      "Epoch 00001: val_loss improved from inf to 1.15375, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_128_DO_checkpoint/001-1.1538.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 1.6975 - acc: 0.4620 - val_loss: 1.1538 - val_acc: 0.6546\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0506 - acc: 0.6845\n",
      "Epoch 00002: val_loss improved from 1.15375 to 0.86570, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_128_DO_checkpoint/002-0.8657.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 1.0505 - acc: 0.6845 - val_loss: 0.8657 - val_acc: 0.7522\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8155 - acc: 0.7616\n",
      "Epoch 00003: val_loss improved from 0.86570 to 0.76517, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_128_DO_checkpoint/003-0.7652.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.8155 - acc: 0.7616 - val_loss: 0.7652 - val_acc: 0.7750\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6589 - acc: 0.8078\n",
      "Epoch 00004: val_loss improved from 0.76517 to 0.66391, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_128_DO_checkpoint/004-0.6639.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.6588 - acc: 0.8079 - val_loss: 0.6639 - val_acc: 0.8153\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5433 - acc: 0.8439\n",
      "Epoch 00005: val_loss improved from 0.66391 to 0.65687, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_128_DO_checkpoint/005-0.6569.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.5433 - acc: 0.8439 - val_loss: 0.6569 - val_acc: 0.8262\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8750\n",
      "Epoch 00006: val_loss improved from 0.65687 to 0.57198, saving model to model/checkpoint/1D_CNN_3_only_conv_pool_3_ch_128_DO_checkpoint/006-0.5720.hdf5\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.4395 - acc: 0.8750 - val_loss: 0.5720 - val_acc: 0.8430\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3563 - acc: 0.8989\n",
      "Epoch 00007: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.3563 - acc: 0.8989 - val_loss: 0.5820 - val_acc: 0.8400\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2797 - acc: 0.9190\n",
      "Epoch 00008: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.2797 - acc: 0.9190 - val_loss: 0.5967 - val_acc: 0.8465\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9342\n",
      "Epoch 00009: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.2232 - acc: 0.9342 - val_loss: 0.6588 - val_acc: 0.8218\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9537\n",
      "Epoch 00010: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1677 - acc: 0.9537 - val_loss: 0.6196 - val_acc: 0.8481\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9625\n",
      "Epoch 00011: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1356 - acc: 0.9625 - val_loss: 0.6810 - val_acc: 0.8379\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9703\n",
      "Epoch 00012: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.1037 - acc: 0.9703 - val_loss: 0.7040 - val_acc: 0.8423\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9775\n",
      "Epoch 00013: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0853 - acc: 0.9775 - val_loss: 0.6872 - val_acc: 0.8460\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9810\n",
      "Epoch 00014: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0712 - acc: 0.9810 - val_loss: 0.7485 - val_acc: 0.8512\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9847\n",
      "Epoch 00015: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0597 - acc: 0.9847 - val_loss: 0.8365 - val_acc: 0.8390\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9823\n",
      "Epoch 00016: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0670 - acc: 0.9823 - val_loss: 0.8308 - val_acc: 0.8393\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9881\n",
      "Epoch 00017: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0457 - acc: 0.9881 - val_loss: 0.8752 - val_acc: 0.8372\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9882\n",
      "Epoch 00018: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0454 - acc: 0.9882 - val_loss: 0.8253 - val_acc: 0.8514\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9888\n",
      "Epoch 00019: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0437 - acc: 0.9888 - val_loss: 0.8861 - val_acc: 0.8328\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9842\n",
      "Epoch 00020: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0610 - acc: 0.9842 - val_loss: 0.8225 - val_acc: 0.8514\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9901\n",
      "Epoch 00021: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0376 - acc: 0.9901 - val_loss: 0.8943 - val_acc: 0.8407\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9911\n",
      "Epoch 00022: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0357 - acc: 0.9911 - val_loss: 0.9062 - val_acc: 0.8493\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9915\n",
      "Epoch 00023: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0334 - acc: 0.9915 - val_loss: 0.8374 - val_acc: 0.8488\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9896\n",
      "Epoch 00024: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0395 - acc: 0.9896 - val_loss: 0.8631 - val_acc: 0.8509\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9929\n",
      "Epoch 00025: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0310 - acc: 0.9929 - val_loss: 0.9431 - val_acc: 0.8472\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9923\n",
      "Epoch 00026: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0309 - acc: 0.9923 - val_loss: 0.8740 - val_acc: 0.8491\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9917\n",
      "Epoch 00027: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0358 - acc: 0.9917 - val_loss: 0.9059 - val_acc: 0.8404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9931\n",
      "Epoch 00028: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0289 - acc: 0.9931 - val_loss: 0.9329 - val_acc: 0.8465\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9940\n",
      "Epoch 00029: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0262 - acc: 0.9940 - val_loss: 0.9127 - val_acc: 0.8516\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9943\n",
      "Epoch 00030: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0260 - acc: 0.9943 - val_loss: 0.9427 - val_acc: 0.8495\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9923\n",
      "Epoch 00031: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0305 - acc: 0.9923 - val_loss: 1.1536 - val_acc: 0.8255\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9939\n",
      "Epoch 00032: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0250 - acc: 0.9939 - val_loss: 0.9195 - val_acc: 0.8542\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9908\n",
      "Epoch 00033: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0340 - acc: 0.9908 - val_loss: 0.9303 - val_acc: 0.8579\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9941\n",
      "Epoch 00034: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0250 - acc: 0.9941 - val_loss: 1.0480 - val_acc: 0.8458\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9943\n",
      "Epoch 00035: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0237 - acc: 0.9943 - val_loss: 1.0288 - val_acc: 0.8467\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9940\n",
      "Epoch 00036: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0255 - acc: 0.9940 - val_loss: 0.9611 - val_acc: 0.8539\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9945\n",
      "Epoch 00037: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0237 - acc: 0.9945 - val_loss: 1.0336 - val_acc: 0.8465\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9941\n",
      "Epoch 00038: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0239 - acc: 0.9941 - val_loss: 1.0049 - val_acc: 0.8453\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9957\n",
      "Epoch 00039: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0199 - acc: 0.9957 - val_loss: 1.0295 - val_acc: 0.8386\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9945\n",
      "Epoch 00040: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0236 - acc: 0.9945 - val_loss: 0.9407 - val_acc: 0.8556\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9949\n",
      "Epoch 00041: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0224 - acc: 0.9949 - val_loss: 1.0851 - val_acc: 0.8390\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9938\n",
      "Epoch 00042: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0239 - acc: 0.9938 - val_loss: 1.0071 - val_acc: 0.8560\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9940\n",
      "Epoch 00043: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0257 - acc: 0.9940 - val_loss: 1.0066 - val_acc: 0.8493\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9963\n",
      "Epoch 00044: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0178 - acc: 0.9963 - val_loss: 1.0539 - val_acc: 0.8432\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9954\n",
      "Epoch 00045: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0207 - acc: 0.9954 - val_loss: 0.9717 - val_acc: 0.8514\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0247 - acc: 0.9940 - val_loss: 1.0107 - val_acc: 0.8439\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9965\n",
      "Epoch 00047: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0164 - acc: 0.9965 - val_loss: 0.9580 - val_acc: 0.8595\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9959\n",
      "Epoch 00048: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0185 - acc: 0.9959 - val_loss: 1.0685 - val_acc: 0.8467\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9961\n",
      "Epoch 00049: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0180 - acc: 0.9961 - val_loss: 1.0000 - val_acc: 0.8614\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9961\n",
      "Epoch 00050: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0179 - acc: 0.9961 - val_loss: 1.0394 - val_acc: 0.8453\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9948\n",
      "Epoch 00051: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0216 - acc: 0.9948 - val_loss: 0.9924 - val_acc: 0.8584\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9939\n",
      "Epoch 00052: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0247 - acc: 0.9939 - val_loss: 0.9877 - val_acc: 0.8521\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9965\n",
      "Epoch 00053: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0169 - acc: 0.9965 - val_loss: 0.9661 - val_acc: 0.8658\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9972\n",
      "Epoch 00054: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0146 - acc: 0.9972 - val_loss: 0.9834 - val_acc: 0.8572\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9967\n",
      "Epoch 00055: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0167 - acc: 0.9967 - val_loss: 1.0622 - val_acc: 0.8484\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9942\n",
      "Epoch 00056: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0256 - acc: 0.9942 - val_loss: 1.0493 - val_acc: 0.8500\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9954\n",
      "Epoch 00057: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0198 - acc: 0.9954 - val_loss: 1.0087 - val_acc: 0.8516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9966\n",
      "Epoch 00058: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0162 - acc: 0.9966 - val_loss: 1.1136 - val_acc: 0.8514\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9965\n",
      "Epoch 00059: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0167 - acc: 0.9965 - val_loss: 1.0315 - val_acc: 0.8509\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9970\n",
      "Epoch 00060: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0154 - acc: 0.9970 - val_loss: 0.9941 - val_acc: 0.8612\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9968\n",
      "Epoch 00061: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0162 - acc: 0.9968 - val_loss: 1.0670 - val_acc: 0.8539\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9966\n",
      "Epoch 00062: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0171 - acc: 0.9966 - val_loss: 1.0701 - val_acc: 0.8516\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9965\n",
      "Epoch 00063: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0168 - acc: 0.9965 - val_loss: 1.0696 - val_acc: 0.8556\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9972\n",
      "Epoch 00064: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0150 - acc: 0.9972 - val_loss: 1.0666 - val_acc: 0.8528\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9961\n",
      "Epoch 00065: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0188 - acc: 0.9961 - val_loss: 1.0770 - val_acc: 0.8514\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9958\n",
      "Epoch 00066: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0182 - acc: 0.9958 - val_loss: 1.1854 - val_acc: 0.8428\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9975\n",
      "Epoch 00067: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0137 - acc: 0.9975 - val_loss: 1.1121 - val_acc: 0.8460\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9962\n",
      "Epoch 00068: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0178 - acc: 0.9962 - val_loss: 1.1288 - val_acc: 0.8498\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9971\n",
      "Epoch 00069: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0140 - acc: 0.9971 - val_loss: 1.1829 - val_acc: 0.8500\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9957\n",
      "Epoch 00070: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0184 - acc: 0.9957 - val_loss: 1.0740 - val_acc: 0.8539\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9961\n",
      "Epoch 00071: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0180 - acc: 0.9961 - val_loss: 1.0179 - val_acc: 0.8570\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9970\n",
      "Epoch 00072: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0148 - acc: 0.9970 - val_loss: 1.0803 - val_acc: 0.8530\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9973\n",
      "Epoch 00073: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0144 - acc: 0.9973 - val_loss: 1.0968 - val_acc: 0.8519\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9968\n",
      "Epoch 00074: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0149 - acc: 0.9968 - val_loss: 1.0791 - val_acc: 0.8523\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9963\n",
      "Epoch 00075: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0189 - acc: 0.9963 - val_loss: 1.1129 - val_acc: 0.8532\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9973\n",
      "Epoch 00076: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0144 - acc: 0.9973 - val_loss: 1.0448 - val_acc: 0.8621\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9971\n",
      "Epoch 00077: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0146 - acc: 0.9971 - val_loss: 1.0406 - val_acc: 0.8602\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9958\n",
      "Epoch 00078: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0195 - acc: 0.9958 - val_loss: 0.9984 - val_acc: 0.8556\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9962\n",
      "Epoch 00079: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0177 - acc: 0.9963 - val_loss: 0.9834 - val_acc: 0.8661\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9976\n",
      "Epoch 00080: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0132 - acc: 0.9976 - val_loss: 1.0444 - val_acc: 0.8544\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9973\n",
      "Epoch 00081: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0145 - acc: 0.9973 - val_loss: 1.0501 - val_acc: 0.8567\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9962\n",
      "Epoch 00082: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0173 - acc: 0.9962 - val_loss: 1.0855 - val_acc: 0.8556\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9978\n",
      "Epoch 00083: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0132 - acc: 0.9978 - val_loss: 1.0893 - val_acc: 0.8563\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9966\n",
      "Epoch 00084: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0163 - acc: 0.9966 - val_loss: 1.0130 - val_acc: 0.8612\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9976\n",
      "Epoch 00085: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0132 - acc: 0.9976 - val_loss: 1.1110 - val_acc: 0.8526\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9970\n",
      "Epoch 00086: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0156 - acc: 0.9970 - val_loss: 1.2141 - val_acc: 0.8488\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9971\n",
      "Epoch 00087: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0146 - acc: 0.9971 - val_loss: 1.0982 - val_acc: 0.8556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9972\n",
      "Epoch 00088: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0144 - acc: 0.9972 - val_loss: 1.0876 - val_acc: 0.8584\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9978\n",
      "Epoch 00089: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0129 - acc: 0.9978 - val_loss: 1.1644 - val_acc: 0.8488\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9971\n",
      "Epoch 00090: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0151 - acc: 0.9971 - val_loss: 1.0715 - val_acc: 0.8563\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9970\n",
      "Epoch 00091: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0154 - acc: 0.9970 - val_loss: 1.0225 - val_acc: 0.8630\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9974\n",
      "Epoch 00092: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0139 - acc: 0.9974 - val_loss: 1.1027 - val_acc: 0.8516\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9973\n",
      "Epoch 00093: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0145 - acc: 0.9973 - val_loss: 1.2640 - val_acc: 0.8355\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9980\n",
      "Epoch 00094: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0121 - acc: 0.9980 - val_loss: 1.0418 - val_acc: 0.8612\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9978\n",
      "Epoch 00095: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0122 - acc: 0.9978 - val_loss: 1.0881 - val_acc: 0.8572\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9960\n",
      "Epoch 00096: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0194 - acc: 0.9960 - val_loss: 1.0605 - val_acc: 0.8570\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9977\n",
      "Epoch 00097: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0124 - acc: 0.9977 - val_loss: 1.0995 - val_acc: 0.8614\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9971\n",
      "Epoch 00098: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0155 - acc: 0.9971 - val_loss: 1.1057 - val_acc: 0.8626\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9973\n",
      "Epoch 00099: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0153 - acc: 0.9973 - val_loss: 1.1792 - val_acc: 0.8495\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9966\n",
      "Epoch 00100: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0173 - acc: 0.9966 - val_loss: 1.0763 - val_acc: 0.8593\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9977\n",
      "Epoch 00101: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0127 - acc: 0.9977 - val_loss: 1.0400 - val_acc: 0.8642\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9976\n",
      "Epoch 00102: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0145 - acc: 0.9976 - val_loss: 1.0961 - val_acc: 0.8647\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9987\n",
      "Epoch 00103: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0094 - acc: 0.9987 - val_loss: 1.1196 - val_acc: 0.8630\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9983\n",
      "Epoch 00104: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0111 - acc: 0.9983 - val_loss: 1.2026 - val_acc: 0.8505\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9964\n",
      "Epoch 00105: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0176 - acc: 0.9964 - val_loss: 1.0775 - val_acc: 0.8682\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9974\n",
      "Epoch 00106: val_loss did not improve from 0.57198\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0144 - acc: 0.9974 - val_loss: 1.0862 - val_acc: 0.8567\n",
      "\n",
      "1D_CNN_3_only_conv_pool_3_ch_128_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6639 - acc: 0.8077\n",
      "Loss: 0.6639084923861555 Accuracy: 0.8076843\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7850 - acc: 0.4216\n",
      "Epoch 00001: val_loss improved from inf to 1.10983, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/001-1.1098.hdf5\n",
      "36805/36805 [==============================] - 196s 5ms/sample - loss: 1.7849 - acc: 0.4217 - val_loss: 1.1098 - val_acc: 0.6564\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9409 - acc: 0.7132\n",
      "Epoch 00002: val_loss improved from 1.10983 to 0.68557, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/002-0.6856.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.9409 - acc: 0.7132 - val_loss: 0.6856 - val_acc: 0.8022\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6308 - acc: 0.8110\n",
      "Epoch 00003: val_loss improved from 0.68557 to 0.57648, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/003-0.5765.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.6310 - acc: 0.8110 - val_loss: 0.5765 - val_acc: 0.8318\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8518\n",
      "Epoch 00004: val_loss improved from 0.57648 to 0.46770, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/004-0.4677.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.4947 - acc: 0.8518 - val_loss: 0.4677 - val_acc: 0.8714\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4002 - acc: 0.8810\n",
      "Epoch 00005: val_loss improved from 0.46770 to 0.36896, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/005-0.3690.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.4001 - acc: 0.8810 - val_loss: 0.3690 - val_acc: 0.9003\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3369 - acc: 0.8949\n",
      "Epoch 00006: val_loss improved from 0.36896 to 0.35074, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/006-0.3507.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.3369 - acc: 0.8949 - val_loss: 0.3507 - val_acc: 0.9029\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.9094\n",
      "Epoch 00007: val_loss improved from 0.35074 to 0.31982, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/007-0.3198.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.2894 - acc: 0.9094 - val_loss: 0.3198 - val_acc: 0.9147\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9225\n",
      "Epoch 00008: val_loss did not improve from 0.31982\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.2518 - acc: 0.9225 - val_loss: 0.3312 - val_acc: 0.9106\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9317\n",
      "Epoch 00009: val_loss improved from 0.31982 to 0.31090, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/009-0.3109.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.2179 - acc: 0.9317 - val_loss: 0.3109 - val_acc: 0.9208\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9390\n",
      "Epoch 00010: val_loss improved from 0.31090 to 0.30251, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/010-0.3025.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1936 - acc: 0.9390 - val_loss: 0.3025 - val_acc: 0.9231\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9451\n",
      "Epoch 00011: val_loss improved from 0.30251 to 0.30190, saving model to model/checkpoint/1D_CNN_4_only_conv_pool_3_ch_128_DO_checkpoint/011-0.3019.hdf5\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1705 - acc: 0.9451 - val_loss: 0.3019 - val_acc: 0.9271\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9518\n",
      "Epoch 00012: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1508 - acc: 0.9518 - val_loss: 0.3050 - val_acc: 0.9199\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9574\n",
      "Epoch 00013: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1317 - acc: 0.9574 - val_loss: 0.3085 - val_acc: 0.9292\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9604\n",
      "Epoch 00014: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1223 - acc: 0.9604 - val_loss: 0.3276 - val_acc: 0.9252\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9636\n",
      "Epoch 00015: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1117 - acc: 0.9636 - val_loss: 0.3219 - val_acc: 0.9245\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9670\n",
      "Epoch 00016: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.1007 - acc: 0.9670 - val_loss: 0.3028 - val_acc: 0.9322\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9708\n",
      "Epoch 00017: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0916 - acc: 0.9708 - val_loss: 0.3436 - val_acc: 0.9266\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9709\n",
      "Epoch 00018: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0883 - acc: 0.9708 - val_loss: 0.3282 - val_acc: 0.9287\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9742\n",
      "Epoch 00019: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0805 - acc: 0.9742 - val_loss: 0.3336 - val_acc: 0.9322\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9762\n",
      "Epoch 00020: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0746 - acc: 0.9763 - val_loss: 0.3396 - val_acc: 0.9292\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9798\n",
      "Epoch 00021: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0653 - acc: 0.9798 - val_loss: 0.3371 - val_acc: 0.9343\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9807\n",
      "Epoch 00022: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0610 - acc: 0.9807 - val_loss: 0.3560 - val_acc: 0.9271\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9830\n",
      "Epoch 00023: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0558 - acc: 0.9830 - val_loss: 0.3914 - val_acc: 0.9285\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9783\n",
      "Epoch 00024: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0645 - acc: 0.9783 - val_loss: 0.3348 - val_acc: 0.9371\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9837\n",
      "Epoch 00025: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0510 - acc: 0.9838 - val_loss: 0.3829 - val_acc: 0.9292\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9849\n",
      "Epoch 00026: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0497 - acc: 0.9849 - val_loss: 0.3653 - val_acc: 0.9297\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9854\n",
      "Epoch 00027: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0477 - acc: 0.9854 - val_loss: 0.3768 - val_acc: 0.9380\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9865\n",
      "Epoch 00028: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0443 - acc: 0.9864 - val_loss: 0.3727 - val_acc: 0.9290\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9854\n",
      "Epoch 00029: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0477 - acc: 0.9854 - val_loss: 0.3550 - val_acc: 0.9373\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9872\n",
      "Epoch 00030: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0425 - acc: 0.9872 - val_loss: 0.4125 - val_acc: 0.9145\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9867\n",
      "Epoch 00031: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0406 - acc: 0.9867 - val_loss: 0.3990 - val_acc: 0.9327\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9884\n",
      "Epoch 00032: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0374 - acc: 0.9884 - val_loss: 0.3719 - val_acc: 0.9331\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9887\n",
      "Epoch 00033: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0368 - acc: 0.9888 - val_loss: 0.4143 - val_acc: 0.9294\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9871\n",
      "Epoch 00034: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0410 - acc: 0.9871 - val_loss: 0.3595 - val_acc: 0.9369\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 00035: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0309 - acc: 0.9905 - val_loss: 0.4094 - val_acc: 0.9352\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9904\n",
      "Epoch 00036: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0321 - acc: 0.9904 - val_loss: 0.4245 - val_acc: 0.9311\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9894\n",
      "Epoch 00037: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0338 - acc: 0.9894 - val_loss: 0.4007 - val_acc: 0.9348\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9917\n",
      "Epoch 00038: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0281 - acc: 0.9917 - val_loss: 0.3945 - val_acc: 0.9341\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9907\n",
      "Epoch 00039: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0308 - acc: 0.9907 - val_loss: 0.4208 - val_acc: 0.9327\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9899\n",
      "Epoch 00040: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0358 - acc: 0.9899 - val_loss: 0.4311 - val_acc: 0.9317\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9924\n",
      "Epoch 00041: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0259 - acc: 0.9924 - val_loss: 0.4225 - val_acc: 0.9322\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9925\n",
      "Epoch 00042: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0267 - acc: 0.9925 - val_loss: 0.4191 - val_acc: 0.9392\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9921\n",
      "Epoch 00043: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0282 - acc: 0.9921 - val_loss: 0.4059 - val_acc: 0.9364\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9927\n",
      "Epoch 00044: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0255 - acc: 0.9927 - val_loss: 0.4318 - val_acc: 0.9299\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9905\n",
      "Epoch 00045: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0320 - acc: 0.9905 - val_loss: 0.4239 - val_acc: 0.9376\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0222 - acc: 0.9940 - val_loss: 0.4317 - val_acc: 0.9343\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9921\n",
      "Epoch 00047: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0273 - acc: 0.9921 - val_loss: 0.3995 - val_acc: 0.9392\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9934\n",
      "Epoch 00048: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0230 - acc: 0.9934 - val_loss: 0.4315 - val_acc: 0.9380\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9924\n",
      "Epoch 00049: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0269 - acc: 0.9924 - val_loss: 0.4351 - val_acc: 0.9341\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9943\n",
      "Epoch 00050: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0200 - acc: 0.9943 - val_loss: 0.4328 - val_acc: 0.9308\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9920\n",
      "Epoch 00051: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0269 - acc: 0.9920 - val_loss: 0.3980 - val_acc: 0.9387\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9942\n",
      "Epoch 00052: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0211 - acc: 0.9942 - val_loss: 0.4357 - val_acc: 0.9338\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9949\n",
      "Epoch 00053: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0194 - acc: 0.9949 - val_loss: 0.4339 - val_acc: 0.9350\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9936\n",
      "Epoch 00054: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0218 - acc: 0.9936 - val_loss: 0.4334 - val_acc: 0.9371\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9946\n",
      "Epoch 00055: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0196 - acc: 0.9946 - val_loss: 0.4147 - val_acc: 0.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9936\n",
      "Epoch 00056: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0218 - acc: 0.9936 - val_loss: 0.4561 - val_acc: 0.9341\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9949\n",
      "Epoch 00057: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0184 - acc: 0.9949 - val_loss: 0.4374 - val_acc: 0.9371\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9943\n",
      "Epoch 00058: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0206 - acc: 0.9943 - val_loss: 0.4403 - val_acc: 0.9413\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9940\n",
      "Epoch 00059: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0206 - acc: 0.9940 - val_loss: 0.4435 - val_acc: 0.9338\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9946\n",
      "Epoch 00060: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0195 - acc: 0.9946 - val_loss: 0.4112 - val_acc: 0.9357\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9943\n",
      "Epoch 00061: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0199 - acc: 0.9943 - val_loss: 0.4622 - val_acc: 0.9369\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 00062: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0231 - acc: 0.9930 - val_loss: 0.4563 - val_acc: 0.9327\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9951\n",
      "Epoch 00063: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0181 - acc: 0.9951 - val_loss: 0.4371 - val_acc: 0.9446\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9957\n",
      "Epoch 00064: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0156 - acc: 0.9957 - val_loss: 0.5032 - val_acc: 0.9283\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9942\n",
      "Epoch 00065: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0213 - acc: 0.9942 - val_loss: 0.4126 - val_acc: 0.9425\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9960\n",
      "Epoch 00066: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0156 - acc: 0.9960 - val_loss: 0.4380 - val_acc: 0.9380\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9952\n",
      "Epoch 00067: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0169 - acc: 0.9952 - val_loss: 0.4315 - val_acc: 0.9401\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9947\n",
      "Epoch 00068: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0171 - acc: 0.9947 - val_loss: 0.4309 - val_acc: 0.9385\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9952\n",
      "Epoch 00069: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0174 - acc: 0.9952 - val_loss: 0.4316 - val_acc: 0.9371\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9959\n",
      "Epoch 00070: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0157 - acc: 0.9959 - val_loss: 0.4380 - val_acc: 0.9387\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9936\n",
      "Epoch 00071: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0224 - acc: 0.9936 - val_loss: 0.4478 - val_acc: 0.9369\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9960\n",
      "Epoch 00072: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0157 - acc: 0.9960 - val_loss: 0.4383 - val_acc: 0.9411\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9934\n",
      "Epoch 00073: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0252 - acc: 0.9934 - val_loss: 0.4334 - val_acc: 0.9387\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9968\n",
      "Epoch 00074: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0119 - acc: 0.9968 - val_loss: 0.4430 - val_acc: 0.9392\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9958\n",
      "Epoch 00075: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0145 - acc: 0.9958 - val_loss: 0.4225 - val_acc: 0.9429\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9957\n",
      "Epoch 00076: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0151 - acc: 0.9957 - val_loss: 0.4418 - val_acc: 0.9378\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 00077: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0128 - acc: 0.9963 - val_loss: 0.4801 - val_acc: 0.9338\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9941\n",
      "Epoch 00078: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0205 - acc: 0.9941 - val_loss: 0.4697 - val_acc: 0.9366\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9973\n",
      "Epoch 00079: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0112 - acc: 0.9973 - val_loss: 0.4408 - val_acc: 0.9406\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9954\n",
      "Epoch 00080: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0185 - acc: 0.9954 - val_loss: 0.4287 - val_acc: 0.9429\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9965\n",
      "Epoch 00081: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0123 - acc: 0.9965 - val_loss: 0.4389 - val_acc: 0.9420\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9954\n",
      "Epoch 00082: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 195s 5ms/sample - loss: 0.0171 - acc: 0.9954 - val_loss: 0.4679 - val_acc: 0.9378\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9963\n",
      "Epoch 00083: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0139 - acc: 0.9963 - val_loss: 0.4439 - val_acc: 0.9348\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9966\n",
      "Epoch 00084: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0139 - acc: 0.9966 - val_loss: 0.4534 - val_acc: 0.9378\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9962\n",
      "Epoch 00085: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0143 - acc: 0.9962 - val_loss: 0.4291 - val_acc: 0.9392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9965\n",
      "Epoch 00086: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0124 - acc: 0.9965 - val_loss: 0.4734 - val_acc: 0.9369\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9958\n",
      "Epoch 00087: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0159 - acc: 0.9958 - val_loss: 0.4305 - val_acc: 0.9422\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9960\n",
      "Epoch 00088: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0146 - acc: 0.9960 - val_loss: 0.4570 - val_acc: 0.9385\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9964\n",
      "Epoch 00089: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0138 - acc: 0.9964 - val_loss: 0.4612 - val_acc: 0.9385\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9962\n",
      "Epoch 00090: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0143 - acc: 0.9963 - val_loss: 0.4647 - val_acc: 0.9362\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9960\n",
      "Epoch 00091: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0158 - acc: 0.9960 - val_loss: 0.4440 - val_acc: 0.9390\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9972\n",
      "Epoch 00092: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0104 - acc: 0.9972 - val_loss: 0.4556 - val_acc: 0.9415\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9959\n",
      "Epoch 00093: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0148 - acc: 0.9959 - val_loss: 0.4557 - val_acc: 0.9350\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9965\n",
      "Epoch 00094: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0131 - acc: 0.9965 - val_loss: 0.4631 - val_acc: 0.9373\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9968\n",
      "Epoch 00095: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0132 - acc: 0.9968 - val_loss: 0.4825 - val_acc: 0.9399\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9958\n",
      "Epoch 00096: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0153 - acc: 0.9958 - val_loss: 0.4869 - val_acc: 0.9357\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9958\n",
      "Epoch 00097: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0166 - acc: 0.9958 - val_loss: 0.4571 - val_acc: 0.9387\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9970\n",
      "Epoch 00098: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0121 - acc: 0.9970 - val_loss: 0.4575 - val_acc: 0.9432\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9978\n",
      "Epoch 00099: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0098 - acc: 0.9978 - val_loss: 0.4860 - val_acc: 0.9355\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9967\n",
      "Epoch 00100: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0135 - acc: 0.9967 - val_loss: 0.4976 - val_acc: 0.9359\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9964\n",
      "Epoch 00101: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0134 - acc: 0.9964 - val_loss: 0.4990 - val_acc: 0.9348\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9960\n",
      "Epoch 00102: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0140 - acc: 0.9960 - val_loss: 0.4898 - val_acc: 0.9385\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9976\n",
      "Epoch 00103: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0100 - acc: 0.9976 - val_loss: 0.4638 - val_acc: 0.9371\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9967\n",
      "Epoch 00104: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0123 - acc: 0.9967 - val_loss: 0.5194 - val_acc: 0.9355\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9973\n",
      "Epoch 00105: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0111 - acc: 0.9973 - val_loss: 0.4835 - val_acc: 0.9432\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9965\n",
      "Epoch 00106: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0131 - acc: 0.9965 - val_loss: 0.5293 - val_acc: 0.9392\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9971\n",
      "Epoch 00107: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0117 - acc: 0.9971 - val_loss: 0.4683 - val_acc: 0.9373\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9973\n",
      "Epoch 00108: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0103 - acc: 0.9973 - val_loss: 0.4978 - val_acc: 0.9334\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9968\n",
      "Epoch 00109: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0127 - acc: 0.9968 - val_loss: 0.4794 - val_acc: 0.9390\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9963\n",
      "Epoch 00110: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0137 - acc: 0.9963 - val_loss: 0.4673 - val_acc: 0.9401\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9978\n",
      "Epoch 00111: val_loss did not improve from 0.30190\n",
      "36805/36805 [==============================] - 194s 5ms/sample - loss: 0.0092 - acc: 0.9978 - val_loss: 0.4914 - val_acc: 0.9413\n",
      "\n",
      "1D_CNN_4_only_conv_pool_3_ch_128_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3504 - acc: 0.8984\n",
      "Loss: 0.3504037736732269 Accuracy: 0.8984424\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6411 - acc: 0.4618\n",
      "Epoch 00001: val_loss improved from inf to 0.87938, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/001-0.8794.hdf5\n",
      "36805/36805 [==============================] - 213s 6ms/sample - loss: 1.6409 - acc: 0.4619 - val_loss: 0.8794 - val_acc: 0.7314\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7419 - acc: 0.7673\n",
      "Epoch 00002: val_loss improved from 0.87938 to 0.42909, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/002-0.4291.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.7418 - acc: 0.7674 - val_loss: 0.4291 - val_acc: 0.8691\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.8594\n",
      "Epoch 00003: val_loss improved from 0.42909 to 0.30176, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/003-0.3018.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.4458 - acc: 0.8594 - val_loss: 0.3018 - val_acc: 0.9052\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3275 - acc: 0.8963\n",
      "Epoch 00004: val_loss improved from 0.30176 to 0.24436, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/004-0.2444.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.3275 - acc: 0.8963 - val_loss: 0.2444 - val_acc: 0.9271\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9156\n",
      "Epoch 00005: val_loss did not improve from 0.24436\n",
      "36805/36805 [==============================] - 213s 6ms/sample - loss: 0.2625 - acc: 0.9156 - val_loss: 0.2687 - val_acc: 0.9262\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9282\n",
      "Epoch 00006: val_loss improved from 0.24436 to 0.20800, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/006-0.2080.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.2266 - acc: 0.9282 - val_loss: 0.2080 - val_acc: 0.9371\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9399\n",
      "Epoch 00007: val_loss did not improve from 0.20800\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.1884 - acc: 0.9399 - val_loss: 0.2265 - val_acc: 0.9341\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9447\n",
      "Epoch 00008: val_loss improved from 0.20800 to 0.17732, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/008-0.1773.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.1734 - acc: 0.9447 - val_loss: 0.1773 - val_acc: 0.9471\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9539\n",
      "Epoch 00009: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.1430 - acc: 0.9539 - val_loss: 0.1857 - val_acc: 0.9460\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9579\n",
      "Epoch 00010: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.1279 - acc: 0.9578 - val_loss: 0.1836 - val_acc: 0.9478\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9619\n",
      "Epoch 00011: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.1131 - acc: 0.9619 - val_loss: 0.1957 - val_acc: 0.9432\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9670\n",
      "Epoch 00012: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.1007 - acc: 0.9670 - val_loss: 0.1907 - val_acc: 0.9485\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9690\n",
      "Epoch 00013: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0928 - acc: 0.9691 - val_loss: 0.1776 - val_acc: 0.9578\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9707\n",
      "Epoch 00014: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0850 - acc: 0.9707 - val_loss: 0.1808 - val_acc: 0.9497\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9733\n",
      "Epoch 00015: val_loss did not improve from 0.17732\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0780 - acc: 0.9733 - val_loss: 0.1814 - val_acc: 0.9546\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9769\n",
      "Epoch 00016: val_loss improved from 0.17732 to 0.16331, saving model to model/checkpoint/1D_CNN_5_only_conv_pool_3_ch_128_DO_checkpoint/016-0.1633.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0692 - acc: 0.9769 - val_loss: 0.1633 - val_acc: 0.9562\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9796\n",
      "Epoch 00017: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0616 - acc: 0.9796 - val_loss: 0.1786 - val_acc: 0.9518\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9803\n",
      "Epoch 00018: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0599 - acc: 0.9803 - val_loss: 0.1876 - val_acc: 0.9590\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9825\n",
      "Epoch 00019: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0507 - acc: 0.9825 - val_loss: 0.2000 - val_acc: 0.9509\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9818\n",
      "Epoch 00020: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0535 - acc: 0.9819 - val_loss: 0.1907 - val_acc: 0.9520\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9840\n",
      "Epoch 00021: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0471 - acc: 0.9840 - val_loss: 0.2051 - val_acc: 0.9488\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9848\n",
      "Epoch 00022: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0430 - acc: 0.9848 - val_loss: 0.1966 - val_acc: 0.9567\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9862\n",
      "Epoch 00023: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0424 - acc: 0.9863 - val_loss: 0.2151 - val_acc: 0.9536\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9867\n",
      "Epoch 00024: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0396 - acc: 0.9867 - val_loss: 0.1876 - val_acc: 0.9588\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9867\n",
      "Epoch 00025: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0419 - acc: 0.9867 - val_loss: 0.2119 - val_acc: 0.9543\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9890\n",
      "Epoch 00026: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0341 - acc: 0.9891 - val_loss: 0.2194 - val_acc: 0.9553\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9894\n",
      "Epoch 00027: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0322 - acc: 0.9894 - val_loss: 0.2334 - val_acc: 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9893\n",
      "Epoch 00028: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0335 - acc: 0.9893 - val_loss: 0.2133 - val_acc: 0.9534\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9907\n",
      "Epoch 00029: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0304 - acc: 0.9907 - val_loss: 0.2070 - val_acc: 0.9532\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9914\n",
      "Epoch 00030: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0267 - acc: 0.9914 - val_loss: 0.2372 - val_acc: 0.9539\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9912\n",
      "Epoch 00031: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0291 - acc: 0.9912 - val_loss: 0.2552 - val_acc: 0.9478\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9902\n",
      "Epoch 00032: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0281 - acc: 0.9902 - val_loss: 0.2559 - val_acc: 0.9504\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9914\n",
      "Epoch 00033: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0261 - acc: 0.9914 - val_loss: 0.2607 - val_acc: 0.9532\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9923\n",
      "Epoch 00034: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0242 - acc: 0.9923 - val_loss: 0.2684 - val_acc: 0.9506\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9920\n",
      "Epoch 00035: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0256 - acc: 0.9920 - val_loss: 0.2777 - val_acc: 0.9495\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9922\n",
      "Epoch 00036: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0231 - acc: 0.9922 - val_loss: 0.2265 - val_acc: 0.9581\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9926\n",
      "Epoch 00037: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0228 - acc: 0.9926 - val_loss: 0.2330 - val_acc: 0.9534\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9934\n",
      "Epoch 00038: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0215 - acc: 0.9934 - val_loss: 0.2271 - val_acc: 0.9574\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9931\n",
      "Epoch 00039: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0207 - acc: 0.9931 - val_loss: 0.2643 - val_acc: 0.9557\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9929\n",
      "Epoch 00040: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0219 - acc: 0.9929 - val_loss: 0.2331 - val_acc: 0.9588\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9952\n",
      "Epoch 00041: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0153 - acc: 0.9952 - val_loss: 0.2493 - val_acc: 0.9562\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9930\n",
      "Epoch 00042: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0221 - acc: 0.9930 - val_loss: 0.2446 - val_acc: 0.9564\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9932\n",
      "Epoch 00043: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0214 - acc: 0.9932 - val_loss: 0.2244 - val_acc: 0.9562\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9948\n",
      "Epoch 00044: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0154 - acc: 0.9948 - val_loss: 0.2586 - val_acc: 0.9595\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0186 - acc: 0.9938 - val_loss: 0.2862 - val_acc: 0.9567\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0186 - acc: 0.9940 - val_loss: 0.2457 - val_acc: 0.9588\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9951\n",
      "Epoch 00047: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0156 - acc: 0.9951 - val_loss: 0.2440 - val_acc: 0.9585\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9940\n",
      "Epoch 00048: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0170 - acc: 0.9940 - val_loss: 0.2336 - val_acc: 0.9520\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9959\n",
      "Epoch 00049: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0127 - acc: 0.9959 - val_loss: 0.2673 - val_acc: 0.9597\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9939\n",
      "Epoch 00050: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0189 - acc: 0.9939 - val_loss: 0.2662 - val_acc: 0.9578\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9949\n",
      "Epoch 00051: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0152 - acc: 0.9949 - val_loss: 0.2861 - val_acc: 0.9581\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9951\n",
      "Epoch 00052: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0167 - acc: 0.9951 - val_loss: 0.2428 - val_acc: 0.9567\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9939\n",
      "Epoch 00053: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0186 - acc: 0.9939 - val_loss: 0.2487 - val_acc: 0.9550\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 00054: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0115 - acc: 0.9963 - val_loss: 0.2497 - val_acc: 0.9578\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9954\n",
      "Epoch 00055: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0143 - acc: 0.9954 - val_loss: 0.3001 - val_acc: 0.9515\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9954\n",
      "Epoch 00056: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0149 - acc: 0.9954 - val_loss: 0.2783 - val_acc: 0.9555\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9954\n",
      "Epoch 00057: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0153 - acc: 0.9954 - val_loss: 0.2484 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9960\n",
      "Epoch 00058: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0113 - acc: 0.9960 - val_loss: 0.2845 - val_acc: 0.9543\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 00059: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0125 - acc: 0.9957 - val_loss: 0.2961 - val_acc: 0.9546\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 00060: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0129 - acc: 0.9958 - val_loss: 0.2347 - val_acc: 0.9609\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9957\n",
      "Epoch 00061: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0144 - acc: 0.9957 - val_loss: 0.2590 - val_acc: 0.9567\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9962\n",
      "Epoch 00062: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0130 - acc: 0.9962 - val_loss: 0.2784 - val_acc: 0.9560\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9958\n",
      "Epoch 00063: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0137 - acc: 0.9958 - val_loss: 0.2349 - val_acc: 0.9623\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9965\n",
      "Epoch 00064: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0110 - acc: 0.9965 - val_loss: 0.2678 - val_acc: 0.9564\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9962\n",
      "Epoch 00065: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0115 - acc: 0.9962 - val_loss: 0.2477 - val_acc: 0.9616\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9970\n",
      "Epoch 00066: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0099 - acc: 0.9970 - val_loss: 0.2932 - val_acc: 0.9557\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9960\n",
      "Epoch 00067: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0142 - acc: 0.9960 - val_loss: 0.2973 - val_acc: 0.9588\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9963\n",
      "Epoch 00068: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0133 - acc: 0.9963 - val_loss: 0.2305 - val_acc: 0.9639\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 00069: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0069 - acc: 0.9979 - val_loss: 0.2907 - val_acc: 0.9606\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9965\n",
      "Epoch 00070: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0104 - acc: 0.9965 - val_loss: 0.3007 - val_acc: 0.9571\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 00071: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0105 - acc: 0.9969 - val_loss: 0.2672 - val_acc: 0.9567\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9954\n",
      "Epoch 00072: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0143 - acc: 0.9954 - val_loss: 0.2666 - val_acc: 0.9585\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9967\n",
      "Epoch 00073: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0098 - acc: 0.9967 - val_loss: 0.2558 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9973\n",
      "Epoch 00074: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0084 - acc: 0.9973 - val_loss: 0.3071 - val_acc: 0.9564\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9954\n",
      "Epoch 00075: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0139 - acc: 0.9954 - val_loss: 0.2771 - val_acc: 0.9592\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9966\n",
      "Epoch 00076: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0102 - acc: 0.9966 - val_loss: 0.2653 - val_acc: 0.9585\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9966\n",
      "Epoch 00077: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.0112 - acc: 0.9966 - val_loss: 0.2670 - val_acc: 0.9616\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9972\n",
      "Epoch 00078: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0077 - acc: 0.9972 - val_loss: 0.2648 - val_acc: 0.9597\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9974\n",
      "Epoch 00079: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0072 - acc: 0.9974 - val_loss: 0.2657 - val_acc: 0.9597\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9970\n",
      "Epoch 00080: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0093 - acc: 0.9970 - val_loss: 0.2671 - val_acc: 0.9611\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9966\n",
      "Epoch 00081: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0110 - acc: 0.9966 - val_loss: 0.3008 - val_acc: 0.9576\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9960\n",
      "Epoch 00082: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0123 - acc: 0.9960 - val_loss: 0.2516 - val_acc: 0.9592\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9964\n",
      "Epoch 00083: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0109 - acc: 0.9964 - val_loss: 0.2637 - val_acc: 0.9574\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9970\n",
      "Epoch 00084: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0092 - acc: 0.9970 - val_loss: 0.2704 - val_acc: 0.9592\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 00085: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0071 - acc: 0.9977 - val_loss: 0.2948 - val_acc: 0.9590\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9961\n",
      "Epoch 00086: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0110 - acc: 0.9961 - val_loss: 0.2958 - val_acc: 0.9606\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 00087: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0096 - acc: 0.9970 - val_loss: 0.2480 - val_acc: 0.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9974\n",
      "Epoch 00088: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0077 - acc: 0.9974 - val_loss: 0.2597 - val_acc: 0.9648\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9959\n",
      "Epoch 00089: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0145 - acc: 0.9959 - val_loss: 0.2779 - val_acc: 0.9578\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9982\n",
      "Epoch 00090: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0059 - acc: 0.9982 - val_loss: 0.2794 - val_acc: 0.9585\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9974\n",
      "Epoch 00091: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0080 - acc: 0.9974 - val_loss: 0.2521 - val_acc: 0.9618\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9973\n",
      "Epoch 00092: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0088 - acc: 0.9973 - val_loss: 0.2587 - val_acc: 0.9597\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9971\n",
      "Epoch 00093: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0085 - acc: 0.9971 - val_loss: 0.3207 - val_acc: 0.9602\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9961\n",
      "Epoch 00094: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0112 - acc: 0.9961 - val_loss: 0.2772 - val_acc: 0.9595\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 00095: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0077 - acc: 0.9978 - val_loss: 0.2629 - val_acc: 0.9630\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 00096: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0083 - acc: 0.9975 - val_loss: 0.2592 - val_acc: 0.9618\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9975\n",
      "Epoch 00097: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0069 - acc: 0.9975 - val_loss: 0.3222 - val_acc: 0.9557\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 00098: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0082 - acc: 0.9975 - val_loss: 0.2786 - val_acc: 0.9616\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00099: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0085 - acc: 0.9974 - val_loss: 0.2674 - val_acc: 0.9625\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9973\n",
      "Epoch 00100: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0090 - acc: 0.9973 - val_loss: 0.2781 - val_acc: 0.9606\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9982\n",
      "Epoch 00101: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0057 - acc: 0.9982 - val_loss: 0.2936 - val_acc: 0.9623\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9971\n",
      "Epoch 00102: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0098 - acc: 0.9971 - val_loss: 0.3210 - val_acc: 0.9560\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9979\n",
      "Epoch 00103: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0068 - acc: 0.9979 - val_loss: 0.2927 - val_acc: 0.9613\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9968\n",
      "Epoch 00104: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0119 - acc: 0.9968 - val_loss: 0.3240 - val_acc: 0.9564\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9967\n",
      "Epoch 00105: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0113 - acc: 0.9967 - val_loss: 0.3076 - val_acc: 0.9604\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 00106: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 0.2526 - val_acc: 0.9634\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9983\n",
      "Epoch 00107: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0055 - acc: 0.9983 - val_loss: 0.3145 - val_acc: 0.9595\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 00108: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0087 - acc: 0.9972 - val_loss: 0.2711 - val_acc: 0.9641\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9972\n",
      "Epoch 00109: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0096 - acc: 0.9972 - val_loss: 0.2818 - val_acc: 0.9576\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9984\n",
      "Epoch 00110: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0045 - acc: 0.9984 - val_loss: 0.3344 - val_acc: 0.9581\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00111: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.3481 - val_acc: 0.9555\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9983\n",
      "Epoch 00112: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0052 - acc: 0.9983 - val_loss: 0.3014 - val_acc: 0.9592\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 00113: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0085 - acc: 0.9976 - val_loss: 0.3288 - val_acc: 0.9602\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9971\n",
      "Epoch 00114: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.2929 - val_acc: 0.9630\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9988\n",
      "Epoch 00115: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0035 - acc: 0.9988 - val_loss: 0.2749 - val_acc: 0.9660\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9975\n",
      "Epoch 00116: val_loss did not improve from 0.16331\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0083 - acc: 0.9975 - val_loss: 0.3115 - val_acc: 0.9602\n",
      "\n",
      "1D_CNN_5_only_conv_pool_3_ch_128_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEKCAYAAAA8QgPpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4VNX9+PH3mT3JZE9I2APIvgUBhSKKVSlqq6hVtGrVunTT1vqrFa1VtN9Wa21tXVqKVmurdanWVitKtYKIggqIgICyQ0LIvk1mMuv5/XFmspGdDAnweT3PPMnce+65Z+7MnM8959w5V2mtEUIIIbrK0tsFEEIIcXSSACKEEKJbJIAIIYToFgkgQgghukUCiBBCiG6RACKEEKJbJIAIIYToFgkgQgghukUCiBBCiG6x9XYBelJWVpbOy8vr7WIIIcRRY926dWVa6+zubHtMBZC8vDzWrl3b28UQQoijhlJqb3e3lS4sIYQQ3SIBRAghRLdIABFCCNEtx9QYSGuCwSAFBQXU19f3dlGOSi6Xi0GDBmG323u7KEKIPuaYDyAFBQUkJyeTl5eHUqq3i3NU0VpTXl5OQUEBw4YN6+3iCCH6mGO+C6u+vp7MzEwJHt2glCIzM1Nab0KIVh3zAQSQ4HEY5NgJIdpyXASQjvj9BwiFqnu7GEIIcVSRAAIEAgcJhWrikndVVRV/+MMfurXtOeecQ1VVVafTL1q0iAcffLBb+xJCiK6SAAKAAnRccm4vgIRCoXa3Xbp0KWlpafEolhBCHDYJIIBSFuIVQBYuXMjOnTvJz8/n1ltvZcWKFcyePZvzzjuPcePGATB//nymTp3K+PHjWbJkScO2eXl5lJWVsWfPHsaOHcv111/P+PHjmTt3Lj6fr939btiwgRkzZjBp0iQuuOACKisrAXj44YcZN24ckyZN4tJLLwXg3XffJT8/n/z8fKZMmUJtbW1cjoUQ4thyzF/G29T27Tfj8Ww4ZHk4XIdSViwWV5fzdLvzGTnyd22uv//++9m8eTMbNpj9rlixgvXr17N58+aGS2OffPJJMjIy8Pl8TJ8+nYsuuojMzMwWZd/Oc889x+OPP84ll1zCyy+/zBVXXNHmfr/5zW/yyCOPcNppp3HXXXdxzz338Lvf/Y7777+f3bt343Q6G7rHHnzwQR577DFmzZqFx+PB5er6cRBCHH+kBdILTjrppGa/q3j44YeZPHkyM2bMYP/+/Wzfvv2QbYYNG0Z+fj4AU6dOZc+ePW3mX11dTVVVFaeddhoAV111FStXrgRg0qRJXH755TzzzDPYbOb8YdasWdxyyy08/PDDVFVVNSwXQoj2HFc1RVsthbq6zVgsCSQkjDgi5UhKSmr4f8WKFbz99tusXr2axMRE5syZ0+rvLpxOZ8P/Vqu1wy6strz++uusXLmS1157jV/84hds2rSJhQsXcu6557J06VJmzZrFsmXLGDNmTLfyF0IcP6QFAoAFreMzBpKcnNzumEJ1dTXp6ekkJiaybds21qxZc9j7TE1NJT09nffeew+Av/3tb5x22mlEIhH279/P6aefzq9+9Suqq6vxeDzs3LmTiRMncttttzF9+nS2bdt22GUQQhz7jqsWSNsUEIlLzpmZmcyaNYsJEyZw9tlnc+655zZbP2/ePBYvXszYsWMZPXo0M2bM6JH9Pv3003znO9/B6/UyfPhwnnrqKcLhMFdccQXV1dVorfnBD35AWloaP/vZz1i+fDkWi4Xx48dz9tln90gZhBDHNhWvM+/eMG3aNN3yhlJbt25l7Nix7W7n9W4DFImJo+NYuqNXZ46hEOLopJRap7We1p1tpQsLABW3LiwhhDhWSQABzGGQACKEEF0hAQSI5xiIEEIcqySAEJtxVlogQgjRFRJAABkDEUKIrotbAFFKPamUKlFKbW5j/RylVLVSakP0cVeTdfOUUp8rpXYopRbGq4yNZAxECCG6Kp4tkL8A8zpI857WOj/6uBdAKWUFHgPOBsYBlymlxsWxnNEurL4zBuJ2u7u0XAghekPcAojWeiVQ0Y1NTwJ2aK13aa0DwPPA+T1auENIF5YQQnRVb4+BzFRKfaqUekMpNT66bCCwv0maguiyVimlblBKrVVKrS0tLe1mMeI7nftjjz3W8Dx20yePx8MZZ5zBiSeeyMSJE/n3v//d6Ty11tx6661MmDCBiRMn8sILLwBQVFTEqaeeSn5+PhMmTOC9994jHA5z9dVXN6R96KGHevw1CiGOT705lcl6YKjW2qOUOgf4FzCyq5lorZcAS8D8Er3dxDffDBsOnc7dEfFj0wGwJnd195CfD79rezr3BQsWcPPNN/P9738fgBdffJFly5bhcrl45ZVXSElJoaysjBkzZnDeeed16h7k//znP9mwYQOffvopZWVlTJ8+nVNPPZW///3vfOUrX+GnP/0p4XAYr9fLhg0bKCwsZPNmMxTVlTscCiFEe3otgGita5r8v1Qp9QelVBZQCAxuknRQdFkcmUpbN/zXc6ZMmUJJSQkHDhygtLSU9PR0Bg8eTDAY5I477mDlypVYLBYKCwspLi4mNze3wzxXrVrFZZddhtVqJScnh9NOO42PP/6Y6dOn861vfYtgMMj8+fPJz89n+PDh7Nq1i5tuuolzzz2XuXPn9vArFEIcr3otgCilcoFirbVWSp2E6UcqB6qAkUqpYZjAcSnwjR7ZaRsthaC/iECgELf7RFA936t38cUX89JLL3Hw4EEWLFgAwLPPPktpaSnr1q3DbreTl5fX6jTuXXHqqaeycuVKXn/9da6++mpuueUWvvnNb/Lpp5+ybNkyFi9ezIsvvsiTTz7ZEy9LCHGci1sAUUo9B8wBspRSBcDdgB1Aa70Y+DrwXaVUCPABl2ozkh1SSt0ILAOswJNa68/iVU5T1ljQiBCPYaEFCxZw/fXXU1ZWxrvvvguYadz79euH3W5n+fLl7N27t9P5zZ49mz/96U9cddVVVFRUsHLlSn7961+zd+9eBg0axPXXX4/f72f9+vWcc845OBwOLrroIkaPHt3uXQyFEKIr4hZAtNaXdbD+UeDRNtYtBZbGo1ytU7H90okhiC4bP348tbW1DBw4kP79+wNw+eWX87WvfY2JEycybdq0Lt3A6YILLmD16tVMnjwZpRQPPPAAubm5PP300/z617/Gbrfjdrv561//SmFhIddccw2RiLlM+b777uv5FyiEOC7JdO5AIFCK37+XpKRJWCyOeBbxqCTTuQtx7JLp3A9T45VPx04wFUKIeJMAAsQOg9Z959foQgjR10kAARov3pUWiBBCdJYEEEACiBBCdJ0EEBrHQI6lCwqEECLeJIAAjYdBxkCEEKKzJIAA8ezCqqqq4g9/+EO3tj3nnHNk7iohRJ8lAYT4dmG1F0BCoVC72y5dupS0tLQeL5MQQvQECSBAYwuk57uwFi5cyM6dO8nPz+fWW29lxYoVzJ49m/POO49x48x9subPn8/UqVMZP348S5Ysadg2Ly+PsrIy9uzZw9ixY7n++usZP348c+fOxefzHbKv1157jZNPPpkpU6Zw5plnUlxcDIDH4+Gaa65h4sSJTJo0iZdffhmAN998kxNPPJHJkydzxhln9PhrF0Ic23pzOvcjro3Z3NHaRSQyGovF1eWpTDqYzZ3777+fzZs3syG64xUrVrB+/Xo2b97MsGHDAHjyySfJyMjA5/Mxffp0LrroIjIzM5vls337dp577jkef/xxLrnkEl5++eVD5rU65ZRTWLNmDUopnnjiCR544AF+85vf8POf/5zU1FQ2bdoEQGVlJaWlpVx//fWsXLmSYcOGUVHRnXt/CSGOZ8dVAGlLPOa/as9JJ53UEDwAHn74YV555RUA9u/fz/bt2w8JIMOGDSM/Px+AqVOnsmfPnkPyLSgoYMGCBRQVFREIBBr28fbbb/P88883pEtPT+e1117j1FNPbUiTkZHRo69RCHHsO64CSFsthUgkRF3d5zidQ3E4suNejqSkpIb/V6xYwdtvv83q1atJTExkzpw5rU7r7nQ6G/63Wq2tdmHddNNN3HLLLZx33nmsWLGCRYsWxaX8QggBMgYSFb8xkOTkZGpra9tcX11dTXp6OomJiWzbto01a9Z0e1/V1dUMHGju/vv00083LD/rrLOa3Va3srKSGTNmsHLlSnbv3g0gXVhCiC6TAELT+4H0/FVYmZmZzJo1iwkTJnDrrbcesn7evHmEQiHGjh3LwoULmTFjRrf3tWjRIi6++GKmTp1KVlZWw/I777yTyspKJkyYwOTJk1m+fDnZ2dksWbKECy+8kMmTJzfc6EoIITpLpnPHTKLo8azH4RiI09k/nkU8Ksl07kIcu2Q698Mmc2EJIURXSQAh9kNChUxlIoQQnScBpIGSyRSFEKILJIA0UEgXlhBCdJ4EkChzJZYEECGE6Ky4BRCl1JNKqRKl1OY21l+ulNqolNqklPpAKTW5ybo90eUblFJrW9s+DiWWW9oKIUQXxLMF8hdgXjvrdwOnaa0nAj8HlrRYf7rWOr+7l5d1Xd/pwnK73b1dBCGE6FDcpjLRWq9USuW1s/6DJk/XAIPiVZbOMFdi9Y0AIoQQR4O+MgZyLfBGk+ca+K9Sap1S6ob2NlRK3aCUWquUWltaWnoYRbDE5SqshQsXNptGZNGiRTz44IN4PB7OOOMMTjzxRCZOnMi///3vDvNqa9r31qZlb2sKdyGE6Clx/SV6tAXyH631hHbSnA78AThFa10eXTZQa12olOoHvAXcpLVe2dH+Ovol+s1v3syGg63M5w6Ew16UUlgsCZ15aQ3yc/P53by253P/5JNPuPnmm3n33XcBGDduHMuWLaN///54vV5SUlIoKytjxowZbN++HaUUbrcbj8dzSF4VFRXNpn1/9913iUQinHjiic2mZc/IyOC2227D7/fzu+gMkpWVlaSnp3fptcXIL9GFOHYdzi/Re3U2XqXUJOAJ4OxY8ADQWhdG/5YopV4BTgI6DCCHVxaIRxfWlClTKCkp4cCBA5SWlpKens7gwYMJBoPccccdrFy5EovFQmFhIcXFxeTm5raZV2vTvpeWlrY6LXtrU7gLIURP6rUAopQaAvwTuFJr/UWT5UmARWtdG/1/LnBvT+yzvZaC1/s5WmuSksb0xK6aufjii3nppZc4ePBgw6SFzz77LKWlpaxbtw673U5eXl6r07jHdHbadyGEOFLieRnvc8BqYLRSqkApda1S6jtKqe9Ek9wFZAJ/aHG5bg6wSin1KfAR8LrW+s14lbNR/H4HsmDBAp5//nleeuklLr74YsBMvd6vXz/sdjvLly9n79697ebR1rTvbU3L3toU7kII0ZPieRXWZR2svw64rpXlu4DJh24Rb/GbC2v8+PHU1tYycOBA+vc3s/1efvnlfO1rX2PixIlMmzaNMWPab/nMmzePxYsXM3bsWEaPHt0w7XvTadkjkQj9+vXjrbfe4s477+T73/8+EyZMwGq1cvfdd3PhhRfG5fUJIY5PMp17lM+3k0jER1JSm+P9xy0ZRBfi2CXTufcImUxRCCG6QgJIA5kLSwghuuK4CCCdaVmYX6LLXFgtSatMCNGWYz6AuFwuysvLO1ERShdWS1prysvLcblcvV0UIUQf1Ks/JDwSBg0aREFBAR1NcxIMVhIO1+JybT1CJTs6uFwuBg3q1WnKhBB91DEfQOx2e8OvtNuza9ed7Nt3P1OmhI5AqYQQ4uh3zHdhdZbF4gDCaB3u7aIIIcRRQQJIlMXiBCASCfRySYQQ4uggASRKKQcAWksAEUKIzpAAEmW6sKQFIoQQnSUBJEpaIEII0TUSQKIax0D8vVwSIYQ4OkgAiYq1QKQLSwghOkcCSFRsDES6sIQQonMkgERJC0QIIbpGAkhUbAxEaxkDEUKIzpAAEiWX8QohRNdIAImSy3iFEKJrJIBESQtECCG6RgJIlFLyOxAhhOiKuAYQpdSTSqkSpdTmNtYrpdTDSqkdSqmNSqkTm6y7Sim1Pfq4Kp7lBLmMVwghuireLZC/APPaWX82MDL6uAH4I4BSKgO4GzgZOAm4WymVHs+CymW8QgjRNXENIFrrlUBFO0nOB/6qjTVAmlKqP/AV4C2tdYXWuhJ4i/YD0WGTFogQQnRNb9+RcCCwv8nzguiytpbHjcyF1TGtwe9vfCgFFgvY7ZCUBFarSePzQU0N1NWB1wuBgFlntZp8wmGIRCAYhFDI5OXzQX29WR9La7Wa/GtqoLAQioshJQUGDIDMzMYyeTxQUQFVVaYsbjc4nWYf4bDJ2+MxZUlIgORks21pqXk4nZCTAxkZpix1daYssXImJEBqqkl38CAUFJg0iYlmXex1gTkmSjW+rkDAPI+9nkjEPGLHTilzHAIBsz+bzbyGcNiUwe836ZoeW5+v8XUmJpr8QiFTpvJycyycTkhLM681tt5uh/R0s9zvh+pqqK01+6mvB4fDHIfs7Mb1Xm/jcW76msJh8wCTb9OHzWb273Sa/0Ohxm1jj9jrsFjMe5mRYcrp9ZpH7LMRK3Nqqnl/Dxwwr9HpBJfLrLdYGh9KmX263eYzGQiY9JWVjZ+tWLqWYu9d00esrH6/OdZut8k/9nl1Ohv3Fcs3EDCf2Zoas10waF5bcrJ5OE1VQyRi3rOaGpOfw2HWaW3yCIXM84SExtdqt5vPcnm5eX+SksyxGToU3n23577rndXbAeSwKaVuwHR/MWTIkMPI5+htgYTDjR/eSATKykxFV1trPph1deYLVFlpPnzBoHlobbavrzdfzMJCs03syxur5EIh8+WtqmqsNFrjcplt20tzOOx2k393ORzmixljszVWlhUt2sk2m6lslGoMbGCOx4ABptKIVYKRiFmndeMxtVjM8XA4zLJYMGpaecWCid1uKorYsQ4Gzb4TEppvD42VSazMXq9Ja7OZ5VlZMGqUeZ2VleY9s1rNPmprYd8+s7xpgIkFSL8fduyANWvM+pQUU0HFymuzmefp6eZ/S7T/IvZ5in1ufD7zGfT7G4OA1doYVBISTMBISDCvq7wcdu0yaRITzT5ilWXsdezda8o7apTZNhg0+wmFGo+P1s2DaWmpOX6ZmTBihHkdsfch9n41DSSx7WPvo9amvImJJh+vt/H7E3sfAgFzXOvqGstgt8OwYebYxip+pcy2NTXNP8NutznOCQkmr9iJmcNhjkcgYPZbX9/42Rg+3Lym1FSzrqqqMSgdab0dQAqBwU2eD4ouKwTmtFi+orUMtNZLgCUA06ZN090tSF+8jNfrhW3bYOtW2LPHfIlKS82HKfYlPXDAfMGUaqzAQ524rXvszC32/4ABMHCgOQONfeGhsdKLnbm63Y0VY2x9IGC+QB6P2TY11Xx5kpIaK4PYGWssKMVaLna7ySv2hYydvce+6JGIyWPgQFOG+nooKjKVTuwsMSmp8QsVDJqyND1zT0gwaWw2k6/HY77oqamNFUggYL6ILpepMGxNvhmRSOOZemZm83VCHM96+6vwKnCjUup5zIB5tda6SCm1DPhlk4HzucDt8SyIUnbgyLVAysrMWdfBg6ZrpqzMPIqLYf9+Eyz27Ws8owVztpyTYypEp9Ocjc2ZY5bHughsNujfH3JzTQWZmGge6enmEatIW2vCHw0SEswZ2PDhra93OMxrbIvVao5La9v169f6NhaL2aa17YToLREdwaJ695cYcQ0gSqnnMC2JLKVUAebKKjuA1noxsBQ4B9gBeIFrousqlFI/Bz6OZnWv1rq9wfgeKKsFpexxGQOpq4NNm2DDBli7Flatgs8/PzRdQoKpxIYMgVNOMQFi3DjzyMszgSCmqLaINFcaCfaELpdHa01hzQGyErNw2nqn7RsIB3BYHe2m0VpTXFdMREfIdee2+WXRWlPqLWVP1R6yErMYnDIYu9VOfaieYk8x9aF6rBYrLpuLgckDUdHoqbVmU8kmfEEf2UnZZCZkopQiHAljs9hwO9wNaZuKaNMH0lp5quqrWFOwBpvFxuwhsw85vrX+WpbvWU44EiY/N5+8tLyGfUR0hLUH1vLfnf8lyZ7EmcPPZEK/Ceyr3seqfauoqq9iTt4cxmWPQymFN+jl87LP+WD/B6zav4oKXwUjM0YyKnMUozNHMzZ7LINTBjd7DfWheg56DrKxeCNrD6ylqLaI04edzrwT5pHuSqfCV8H+GjP86LK5CEVC7Krcxa7KXYQjYfol9SMrMQu71d7wPlbVV1FVX0W6K50xWWMYkTECb9BLha+CYDhIdlI2WYlZ+EN+Sr2lVPjMV9mqrPjDfsq95ZR6S9lcspm1B9byefnnaK2xWqwMSR3C/NHzmT9mPtlJ2dSH6qmqr2J7+Xa+KP+CYCRIrjuXnKQclFIEwgEiOoLL5sJlc1FSV8LW0q3sqtqF3WInxZnCgOQBnDHsDKb0n0IwHGR1wWo+2P8BVfVV1AXqUEqRnZhNdlI2gXCAcm859aF6Zg2ZxRnDziDJkcSm4k2sLlhNTlIOMwfPJNedS0ldCZ8e/JRtZdvYWbmTvdV7GeAewKScSeS4c1hftJ6PD3xMoj2Rc0eey9knnE2aK41AOIDVYsXtcDe8T56Ahy/Kv6C6vpq6YB0Vvgp2V+5mT/UedlbsZGflToo9xZzY/0TOHH4mZww7g9OHnX7EA4rSutu9Pn3OtGnT9Nq1a7u9/cqVbgYM+A4nnPDgYZWjqgr++lczqLVxI+zc2diSyMiAWbPgS1/SMHQV/6t9hPdKXuXkATO55sSrmD5gOmsPrOXDwg/ZV72Pcl85dYE6xmaPZVr/aQQjQV7e+jLri9aT6kzlkvGXcPG4i7FarNT4a3BanYzMHMnglMG8u/dd/rbxb3yw/wMGpQxiRPoIagO1rNq3ioOeg9gtdib0m8CYrDH4w368QS9WZSU9IZ1UZyoumwu7xY7daseiLFiVlbAOUx+qJxwJc9LAkzhz+JmkJ6QTjoQp8hSxp2oPuyt3c9BzkBx3DkNSh5DrziXFmYLT6uS1L17jifVP8P7+9xmePpyTB56M2+FmY/FGtpRuwWqxkpmQidPmZG/VXuqCdQDYLXYGJA/AbrUTjoSJ6AhWixWrslLqLaWqvqrh+FuUBbfDTY2/5pD3ZmjqUL466qtkJGTwwmcv8EX5F22+j1ZlJc2VRkZCBpmJmSTaE9lfvZ+91XtJtCdy1vCzmDtiLp6Ah0+LP2XdgXVsLtmMxrzZifZE5uTNITMhk7AOc6D2AO/ve59gpLETPMWZQrorHZfNRZm3jHJfebMyJNoT8Qa9zZblunOxKiuFtYUNywYmDyTXncv2iu3NXrfD6iDBloDdascf8lMbqG12nJIdyVT7q7EoC0n2pGbrjzSn1Ul+bj4T+k1o+Kx9Wvwpaw90/zsN5nUOShlEOBKmNlDbcHyyErOoC9ThC/kAEzAT7Yloramsr2y2vc1iIxAOYLfYSXIkNfu8gXkfmx73JHsSQ1KHUFhb2LDcoiyMzx5PVX1VQ5BuKs2VxuCUwdT4a9hbvfeQ9QrFgOQBDE8fzoiMEWQlZLGmcA1rCtaQkZDBwf93sNUTno4opdZprad1eUMkgDSzalUGOTlXMHLkw13etrgkwv+9/hSvfPEiRfsSiPiScacGSMgqxequZETaSOaMPJmRA7J5f/8qlu9Zzo6KHaS50pg/Zj7v7X2PnZU7G/JLcaYwIn0EmYmZuGwuNpdsZk/VHgBOHngy548+n61lW3l568uHVDBNpbnS+PKwL1NSV8LOip04bU5OGXIK0wdMp6i2iLVFa9lVuYsEWwKJ9kRCkVDDGaU/7CcYDjar8MB80bTW+MN+LMrCgOQBFNUWEdadGz0flTmK+aPns6NyBx8WfIgv5GNSziQmZE8AoNxXji/kIy81jxEZI7AqK/tr9lNQU0BYh7Eqa0NLIazDpLvSGZ05mry0PMp95eyu3E21v5qcpBxy3Dkk2hOJ6AjV9dW8test3tr1Fr6gjzl5c7hswmUMTBlISV0J5d5ylFJYlbXhzLqyvpIKX0VDIB+UMohhacMo85bxxo43KPIUAZCTlEN+bj6zBs9i1pBZ+II+3tjxBu/sfgdfyIdVWUl1pXLGsDM4+4SzSXIk8UnRJ2wu2UxtoBZfyNcsKHmDXv6363+sK1rH2KyxzBoyi1RnKsv3LGf5nuVYlZUR6SMYmTmSmYNmMiR1CEqphlbb52Wfs7VsK7sqd+EP+QlGgtgtdnLcOfRL6se47HFMzplMgj2BtQfW8voXr1NZX8mwtGEMTRuKQlEfqkcpZSqs9BHYrXZK6koorStteK9tFhvprnRSXamUecvYWrqV3VW7SbInkZmYid1ip9RbSmldKS6bi35J/chIyGh4/+xWO5kJmWQmZjI0dWhDy6apfdX7eGP7G/jDflw2F26HmxMyTmBU5iicVicHPQcpritGoXBYHSil8If8+EI+MhIyGJU5CpfN1ZDfQc9B3t71Nv/b/T+SHcmcOfxM5uTNIcWZ0pAmGA5S7ivHYXWQ5kojFAnxwf4PWLp9KdX11Zwy5BRmDZlFSV0JH+z/gB0VOxiVOYpJOZMYlz2uoUWktWZf9T6KPEVM6DcBt8Pd0PL9367/maBktRMMBymoKWg4OZnYbyJjs8eSkZBBkj2JNFcaQ1KHtNpjUOuvZUfFDqb0n9Kp719LEkCiDjeAvP9+LllZ8xk9enG76UKREC9+9iK7KnZzcNtwXvtHCvuG3QuDPkKVjyY92UVCWg2JLhv9kvqR4kxhS+mWhrOKVGcqpww5hfNHn8/lky5vOOt5f//77KjYwfQB0xmbPfaQ5miZt4xgOEj/5P4Ny2r9tawuWI3T6iTFmUJdsI7t5dvZVbmL/Nx8zh11brMvT3dprQnrMBZlwaIshCIhPir8iGU7lrG7ajeDUwYzJHUIeWl55KXlNTTp91Xvo7iumFp/LZ6Ah+kDpzN7yOxunSn1FF/QhzfoJTMx87Dy0VrzefnnpLvSyXHn9FDphDiyJIBEHW4AWb16KOnpX2bMmKeaLf+48GMOeg6S5EhiT9Ue7lt1HzsqdjRLk0wuPxz3axaeczlJSa1XjsWeYkq9pYzNGovVYm01jRBCHEmHE0B6+yqsPsVicRxyGe/LHkkMAAAgAElEQVRjHz3GjW/c2GxZSl0+vPovhnEm3719N+NnFnDK0C81awK3JsedI2eqQohjhgSQJpRyNLuMNxY8zht9Hj879Wc882Idj/7Oga6cwYN3KW66CRyOCcCE3iu0EEL0EgkgTTRtgfx5/Z8bgscLF/2Du37q4Pe/hq9+FZ54wvweQwghjmcSQJpQyonWAQpqCvjhmz/kjGFn8OLX/8G1Vzt49ln43vfg4Yebz30khBDHK7mhVBOmBeLnR8t+RFiHefxrj/PSCyZ4LFoEjz4qwUMIIWKkBQLw4x/D7NmooQ5WHSzipS3L+b/T/49M6zB+/GOYPh1+9rOjd/oPIYSIh061QJRSP1RKpUTvIPhnpdR6pdTceBfuiFmyBFasIKitPLBpJ6MyR/HjL/2Yn//czE312GONEw8KIYQwOlstfktrXYOZ1DAduBK4P26lOtKSk8HjYVVJJfu9fn4797fs2u7kd7+Da681LRAhhBDNdbYLK9Z5cw7wN631Z6o3f0rc09xu8HjYUeNFAV8e9mWuvcrM6vrLX/Z24YQQom/qbAtknVLqv5gAskwplQxE4lesIyw5GWpr2VProX+CDZctgXfeMZfsZmf3duGEEKJv6mwL5FogH9iltfYqpTKITr1+TIi2QHbV1jI0ycaOHWbsY/bs3i6YEEL0XZ1tgcwEPtdaVymlrgDuBKrjV6wjzO0mXFvD7tpqhiYq3nvPLJYAIoQQbetsAPkj4FVKTQb+H7AT+GvcSnWkJSezV1fiD4cZkgjvvWduXTp2bG8XTAgh+q7OBpCQNtP2ng88qrV+DEiOX7GOMLebrQ7ToBqSEOa998wdAY+hywSEEKLHdTaA1Cqlbsdcvvu6UspC9Na0x4TkZLYlmJsyJfky2blTuq+EEKIjnQ0gCwA/5vcgB4FBwK/jVqojze1ma4qfTFcSu7ecAkgAEUKIjnQqgESDxrNAqlLqq0C91vqYGgPZmgUjk7PZtOkUEhM1U7p3d0ghhDhudHYqk0uAj4CLgUuAD5VSX49nwY4knZTE1mw4ISGTTZtmM2NGGPux00EnhBBx0dkurJ8C07XWV2mtvwmcBPyso42UUvOUUp8rpXYopRa2sv4hpdSG6OMLpVRVk3XhJute7ewL6o7SRE1lAgxRuezcOZlZs/zx3J0QQhwTOvtDQovWuqTJ83I6CD5KKSvwGHAWUAB8rJR6VWu9JZZGa/2jJulvApp2HPm01vmdLN9h2WqrNGUoHIvWFmbO9AFJR2LXQghx1OpsAHlTKbUMeC76fAGwtINtTgJ2aK13ASilnsdcBryljfSXAXd3sjw9aitlALhKRwAwdKi3N4ohhBBHlc4Oot8KLAEmRR9LtNa3dbDZQGB/k+cF0WWHUEoNBYYB7zRZ7FJKrVVKrVFKze9MObtra6iIpADoUlO81NT6eO5OCCGOCZ2+oZTW+mXg5TiV41LgJa11uMmyoVrrQqXUcOAdpdQmrfXOlhsqpW4AbgAYMmRIt3a+tb6AMWVQU+XCYgmRkuLrVj5CCHE86Wgco1YpVdPKo1YpVdNB3oXA4CbPB0WXteZSGrvHANBaF0b/7gJW0Hx8pGm6JVrraVrradndnDp3m2cPY0uhqjqJ5ORKwuFjZ5ovIYSIl3YDiNY6WWud0sojWWud0kHeHwMjlVLDlFIOTJA45GoqpdQYzE2qVjdZlq6Uckb/zwJm0fbYyWEJRUIMTxvGyYVQWZtESkoFwWB5PHYlhBDHlLjdqFVrHQJuBJYBW4EXozeiulcpdV6TpJcCz0fn2ooZC6xVSn0KLAfub3r1Vk+yWWys+OY73PgRVHkSSEkplwAihBCd0OkxkO7QWi+lxdVaWuu7Wjxf1Mp2HwAT41m2ZhwOcDio8CSS3K+CUEgCiBBCdCRuLZCjTnIyFb4EUlKqpQUihBCdIAEkxu2moj6RtDSvBBAhhOgECSBRgaR0aoMJpKcHJIAIIUQnSACJqnT1ByAjIyhjIEII0QkSQKIqnCaApKdraYEIIUQnSACJKrflAJCRYZEAIoQQnSABJKrC1g+ArCwroVAFzX+WIoQQoiUJIFEVKhOArCwnWocIhzuaqUUIIY5vEkCiynUGAFlZiQDSjSWEEB2QABJVEU7FSoiMZAkgQgjRGRJAoipCKWRQgSOYAEgAEUKIjkgAiSoPuE0AqXcCyG9BhBCiAxJAoirqk8ikHGu9A5AWiBBCdEQCSFS510UGFdh9ClASQIQQogMSQKIq6pxkUo6q82GzpUkAEUKIDkgAiaqotZNBBdTWYrdnyhiIEEJ0QAIIEAiAx2s1AcTjwWbLlBaIEEJ0QAIIUFFh/mZS3tACkQAihBDtkwBCYwCJtUAkgAghRMckgADl0ViRQaWMgQghRCdJAKFJF1aCt2EMJBz2EIkEerdgQgjRh8U1gCil5imlPldK7VBKLWxl/dVKqVKl1Ibo47om665SSm2PPq6KZzkburDcgYYWCMiPCYUQoj22eGWslLICjwFnAQXAx0qpV7XWW1okfUFrfWOLbTOAu4FpgAbWRbetjEdZG7qwkoMNYyBgAogzeqdCIYQQzcWzBXISsENrvUtrHQCeB87v5LZfAd7SWldEg8ZbwLw4lZOKCrDZIDnV0qwFIuMgQgjRtngGkIHA/ibPC6LLWrpIKbVRKfWSUmpwF7ftEeXlkJEBKtndMAYC0oUlhBDt6e1B9NeAPK31JEwr4+muZqCUukEptVYptba0tLRbhaiogMxMIDn5kC4sIYQQrYtnACkEBjd5Pii6rIHWulxr7Y8+fQKY2tltm+SxRGs9TWs9LTs7u1sFragwLRDcbhlEF0KITopnAPkYGKmUGqaUcgCXAq82TaCUajpCfR6wNfr/MmCuUipdKZUOzI0ui4tYFxZu04VltSZisbgIhSritUshhDjqxe0qLK11SCl1I6bitwJPaq0/U0rdC6zVWr8K/EApdR4QAiqAq6PbViilfo4JQgD3aq3jVptXVMCUKZgurNpaAJkPSwghOhC3AAKgtV4KLG2x7K4m/98O3N7Gtk8CT8azfDENXViJpgWC1jKdiRBCdCCuAeRooDU88wzk5QH/TTYLvF6ZzkQIITpw3AcQpWD+/OiTD9zmr8eD3Z6Nx7O+18olhBB9XW9fxtu3JCebv7W1JCaOxefbSThc17tlEkKIPkoCSFMpKeZvZSVudz6gqavb3KtFEkKIvkoCSFOjRpm/27bhdk8GwOPZ0IsFEkKIvksCSFMnnAAOB2zahMuVh9WagsfzaW+XSggh+iQJIE3Z7TBmDGzejFIKt3uyBBAhhGiDBJCWJkyAzWbcIxZAtI70cqGEEKLvkQDS0sSJsH8/VFfjducTidTh8+3q7VIJIUSfIwGkpQkTzN/PPiMpSQbShRCiLRJAWooFkM2bSUoaD1ipq5NxECGEaEkCSEtDhphZeTdvxmpNIDFxtLRAhBCiFRJAWrJYYPz4JgPp+XIllhDiyFixAr74ordL0WkSQFrT4kosv38/waDcG0QIESf798MFF8Dpp5u/kaPjyk8JIK2ZMAFKS6GkJDqlCdIKEULEx/LlMG4cLFsGF10EW7bAf/7TPE0g0Dtl64AEkNY0GUiPTWlSW7uuFwskhOiU6O0YOmXnTnMzoK4IhaCuxQSrZWXwyCPmXkLdcffdkJkJn30Gzz9v7i1x333mtWgN111nlpWWdi//OJIA0pomAcThyCEpaQLl5a+2v40Qovc98ggMGABFRe2nCwZh5kxYsKDzeQcC8OUvm9kqiovNMq3hyivhBz+AadNg48ZDt/N64d13W89z0yZ47z248UYYNgxsNrj1VlizBlauNK/nz382r+e221rPo6am+8HrMEkAaU1ODmRlNYyDZGdfQnX1Kvz+wl4umBBxsn49rF3b26U4fI8/DtXV8KtftZ/uv/81Z/Rvv20q8M744Q9N2pISuOwy0xr5wx/gzTfhe98z+z35ZHjuuebbPfAAzJljAkJLjz0GLhd861uNy665BrKzTZ633ALnn2+CylNPwapVh+Zxxx3mpLdly+hI0FofM4+pU6fqHjNnjtYnnaS11rqubptevhy9f//vei5/cfSLRLT+1a+0Xreu47ShkNZVVT277127tH7/ffN/S36/1n/5i9bXXqt1ZWX7efn9Wufmap2UpPXnnx9euYqKtL7xRvO3MwIBU74DB7QOhw9v3xs3mk6ffv20djq1LixsO+3ll2udnm5e9+mnd5z344+bvH/yE62fftr8f8UVWickaD1vnnkPiou1njlT67Q0revqzHaRiNYjRpj0c+Y0z7Oqyhzza645dH+/+IXZZswYraurtfZ4tB48WOsJE8wxi1m/XmuLxRzzbgLW6m7Wub1e6ffko0cDyD33aK2U1nv2aK21/uijyXrdui/1XP7i6Pfmm+YrlJys9QcftJ4mEtH61VfNFz85WeuSksPbZySi9XXXaZ2SEush1/qtt5qnWbJE64EDG9dfd137ef797yadw6H1lCla19d3v2zz55u8fvSj9tOGw1pfdVVjGUHru+/u3n5jFi7U2mrVes0arW02rW+6qfV0dXWm4r7+eq0fesjse8WKtvN99llzbObONScCWmv97W+b7TIyTPCLWbHCLH/6afN8zRrz/OSTzd/lyxvTPvywWfbxx4fus7pa6x/8QOsvvmhc9sorJv3CheZYh8MmYGVnd3yS0A4JIPEIIHv2mAByzz3Rp7/Qy5ejfb59PbcPER8PPWS+WB5P17cNBLS+4Qatzzuv9TP7ps4+W+ucHK1POMEEh/ffb77e49H6tNPM12zoUPP30Ufbzq+j/WndGLS+/nWtFy/W2u02FWHMzp1m/cyZWr/xhta33tp6kGlqxgytR47U+l//6lzl35YXXzTbZ2eb49FWiysSMZU7mGP9299qfeqp5sy9trbt/P1+rQ8ebL2yDIe1HjLEvCdam5aX06l1QcGhaV94wez7nXe09nq17t/fvE8tVVZq/Y1vmLRf+pLW5eWN63w+E0RaHtdIROtRo7SeNcs8v+kmU46DB81+Tj3VpKmt1Xr06IZejk6JRExrBUy5HnvM/P/UU53PoxUSQOIRQLTW+swztc7L0zoc1nV12/Xy5eh9+37Ts/s4HpSXm66e8eO1/vOf47uvpUtN4Aet/+//urZtba3WX/mKbjgjfuWVttNu3WrS3HOPqaRGjjSV5tatjWluu60xaAQCWk+caCr2lmJBa+zY9itQrbU+5RStBw0ylanWWl92mdZZWVoHg+b5PfeYfe7da557vaZCy8trPe+PPjLpH37YPL/xRvP8zju1rqlpvyxNlZWZrqMTT2w86/5NG9+V++4z62+5pXFZbJuHHjo0/QcfNAZgMBXyu+82T/Pee2bdM8+Y57t3m1bI2WdrXVraPO3555vKPNaa+P3vzbaXX6719u3mmP3+91oPGGBaNPfc03h8O+PBB01+GzaYY3LRRWZ5rMVx/fVaZ2aa///xj87nq7UJIr/4ReNn/EtfOuyuvz4bQIB5wOfADmBhK+tvAbYAG4H/AUObrAsDG6KPVzuzvx4PILGm/f/+p7XW+vNHTtCVp6X3bF/2sSoQMJX5lVeafmIwZ8tDhnT8ZQyFtN60qev73L7dnMXm55uKIzn50MqjqdgYxje+Yc4mp0wx/cmLF5tKd9Kktr+c3/ue6dYoLjbP9+83Ffnkyebs9LPPTAX2rW81bnP//eY47NjRuKy21vShxyrH++9vXFdUpPXVV2v96afm+bvvNq/stdb65ZfNsrffbuxvb9mn/957psKZMcN0G333u1q//rpJf+WV5n2prjZpfT6tFyzQDS2JO+4wgfDaa80xWrRI6z/+UetHHjHH7mc/M2fZJ51kXu+GDSafU09t/l5v3ar1vfdqPW2ayfuyyw49trNnm22a9vH/9a/mOI8YofXPf26C8ahRpmLe16Q34Dvf0ToxsXmQfPhhre128778/e8m6FZWmvxuvrkxXSBgXmNCggkYWVmmjLNnm8DWVaWlZh+TJ5t8/vnPxmMb61o85xytV6/uet4xr75qjuXGjd3PI6pPBhDACuwEhgMO4FNgXIs0pwOJ0f+/C7zQZJ2nq/vs8QDi9WqdmmrOTNas0eEEu9agfY/8rGf3czTz+UzXzdtva/3aa6YCPP/8xjOstDRT8Wzc2FjZxb5Qbfnxj7t+dub1mjP8jAwzuPzZZyYY/PCHbW/z3HNmPwMHmsoyN7ex1fHss22XoaLCVFZXX918+X/+Y7b5/vdNl0h6evMxj717zfp77zXPy8vNGbvVasYt5s0zx62mxlTuX/uaSZ+aqvXKlaYPvl8/81qbvu6kJFOBfvCBSf/kk4eW+YEHTMU7dGjj+MnUqaaia20A9sMPTSCKjY30799YsbZ8pKaafJt2z8W6w377WxO0lGoMYg880NiCauq113RDK6K42AS62OBzWVljui1bzMnB9Okm3Ysvmvf9sssOzXPTJpMOTICLVeAffnho2qIiE1guvLD9MZHOuPTSxs9/0zGlL75oPCHoI/pqAJkJLGvy/Hbg9nbSTwHeb/K89wOI1uZD7HJpnZmpIyOGae8Ai645MVlHIod5xcixYOdO0y3VskIZOdJUGv/+d/MvTzBoriRp76qXLVvMF91mM5VCrA/b5zNnvn//uzmDbzleEOsueuONxmXXXWfOQLdvP3Q/JSWmQpw+vfUWUShkupTGjTOV3Zo1plvj3ntNgAStP/nk0O1uuaXxOPzpT4euP+000/ddV2e6HxwOU3FqbSo10PqXvzRn3mDGMEaPNunAnPW3dMklJrDccIP5rMZaE23x+7V+4gmthw83x2fbtrbTer3Nj7Xfb65uKikxYzxttdBCITM2FOtyuvXWjq/MCofNMR8wwLSKrFZzAtC0RRITC1CxR1ZW64PRWpv39x//0Pr22817d+WVnRtvOhzvvKM7dQFDH9BXA8jXgSeaPL8SeLSd9I8CdzZ5HgLWAmuA+e1sd0M03dohQ4b07JHV2nwoY5cG7tiha35yodagiz9q5Yt8PHnnHVPBp6dr/be/me6VNWs6vsoo1o3TWhdVJKL1WWeZM9pVq8xZ/llnmQouP795hTFsWOOZ3Pr1prK59trm+RUUNHafJSWZbpBFi8yZ/2WXmcqzva6y55832yYmNt+302kq7db4/WYA9bTTWq9clywxeUybZs7IW7ZwzjnHHNO0NJNPKGS6RE46yXwGWxuXiA1eW62tn4W3JRhs/1LXw/Xmm6Y1Fr2SsVOeeUY3XCTQXmDT2gTBn/zEtM66MkZxJEQiZixk9+7eLkmHjvoAAlwRDRTOJssGRv8OB/YAIzraZ1xaIJGI6RPfvNk8jV7lsvv6BO33t9O/fjQrKtL6rrtMC6M1K1aYFsLYsa2f3benrMycJd9wgxk3WLzYDLZu2NDYxfX735u0ixfrhq6HjAxz1vnJJ2b5wIGmkn33XdMNlJtrupZaWr3aDKb/6EeNA+SxgLBoUftlDYdNN9W115pgcuBA62fDrW3XVoVWUdHYmnjssUPXxwa1Xa7mv8kIhdq+VLO2tjFQLl3acfn6utbeRxE3fTWAdKoLCzgT2Ar0ayevvwBf72ifcQkgrQjNPFF7hqC3bb3WnMFdfXXj4OHRLBIxZ3VpaeajkZNz6OsqKzOV98iR3b+Y4NprzfhEa/3pEyY0Vr6xQd6zzmo+YKq1OasdObLxapSXXurcvjduNGNa55zTej/8kfDQQ+1fznvffZ1/PTELFpj3pa+diYs+r68GEBuwCxjWZBB9fIs0U6ID7SNbLE+PtUaALGB7ywH41h5HKoDoP/1Ja9DbfowOD+hnDuO8eUdm34dj61YzxtDS/v1msHPqVPNaTj3VDAgPGmS6k2IDipGI6UO22zv36+u27NhhfnB2//1msLugwPxq+rrrupbvwYNmHOFI9Gn3ddXV8e2OEsesPhlATLk4B/giGiR+Gl12L3Be9P+3geKWl+sCXwI2RYPOJuDazuzviAWQigodiXZD+HOdOnL11eZQRru5+oTKyubdLS+8YLpFUlOb/7r1179uPIufMsW0QGJ993v3mgFcMN1VF1ygG66sEUIcE/psADnSjyMWQLTW+qabdP0pY/T7L6NLtjxu+qA7c8VFT58pb9lizuRjg8H19Vr/9KdmQLVfP3P1y09/at7qmTPNZaLjxpnB2KeeMssvuqh5UGmqosIEjLPOMn33X/3q4c9ZJIToMw4ngCiz/bFh2rRpeu0RnFFU6zBr104lFKrk5KfnYvnL32DvXjObb0sbNsBPfmJm5JwyBWbNgksvNVNAd0dZGSxaBIsXQzhslp1+upkp9LPP4BvfMNNIv/aaWX/FFfDEE2Y2z7lzYfp0M/vql79sbl7jcHS8z/p6sNvBau1emYUQfY5Sap3WulsVkQSQw1RZuYJPPz2dnKqTGHvBR3D77TB1KvzlL6Yyz801w8P/+Q+kp8Mll5h7AKxda+4vcO215uYxqamwezccOGCWB4MwY4a50UxTGzfCH/8IzzxjAsS3v23uRfDvf5upoS0Ws/7ss036gwdhxw4TsJQyy377W/h//8+Uc/lySE4+osdMCNF3SACJ6o0AAlBU9BQ7dvyAcQt9ZH4QbQ0MHAjjx5sKvLLStDbuuAPS0sz6mhq49174/e/NWX0g0NiSiBkwwASGadNMMPrOd+CVV8z9Ay69FH78Y7OPGK0bg0R7tIZXX4XZsyEjo2cOghDiqCQBJKq3AgiAz7ebPa9fTOpf1pF0xZ2kXryoc109W7bAo4+a1smoUTB4sAkQtbWmdVFcbALFkiVQVQV33QXf/a5U/EKIHiEBJKo3AwhAJBJg/fqZ1NfvYdq0T3G5Bh1ehiUl8PWvm7ugTZ5suq1it9sVQogecDgBRG5p24MsFgfjxj1HJOJn27Yr0Trc8Ubt6dfP3HLzP/+BDz+U4CGE6FMkgPSwxMRRjBz5CFVVK9i587bDDyIOB5x7LjidPVNAIYToIRJA4iA392r697+BgoLf8Mknp+L17ujtIgkhRI+TABIHSilGjVrM2LHP4vVuYe3ayRQW/pFjabxJCCEkgMSJUoqcnG8wbdomUlNPYfv277Fx41zq6/f1dtGEEKJHSACJM5drEJMmvcmoUYuprl7Nxx+PZ+/eXxIO+3q7aEIIcVgkgBwBSikGDPg206dvJC3tDHbv/ikffTSGwsI/EgxW9HbxhBCiWySAHEEJCcOZOPFfTJ78DnZ7Ntu3f48PPshl8+YLKC19mXC4vreLKIQQnWbr7QIcj9LTT2fq1I/xeDZQXPwMJSV/p6zsX1itqWRnX0hW1oWkp5+J1erq7aIKIUSb5JfofYDWYSor36G4+BnKyv5FOFyD1eomK+tCBgz4NikpM1GdmeNKCCG66HB+iS4tkD5AKSsZGWeRkXEWkUiAysp3KCt7mZKSFygu/itJSRPIybmSfv0uxeUa0tvFFUIIQFogfVoo5KGk5DmKiv5Mbe2HACQmjsPhyMVuzyI9/cv063c5Npu7l0sqhDhayWSKUcdaAGnK59tJScnz1NR8RDBYTiBQSH39HqzWFLKy5hMO11FfvweLxUVm5tlkZJyD2z0ZpeQ6CSFE2ySARB3LAaQlrTU1NWsoLHyMioqlOBw5uFx5BINl1NaaY2CxJJKUNJGkpHFYrUlYLC5stkxcrqE4nYMJh2sJBA6gdYjMzK/idA7s5VclhDjSZAzkOKSUIjV1JqmpMw9ZFwgUU1GxjNraddTVbaSiYhmRiC/6aOtSYUVa2hzS0k7H4cjBbs8iEvERClWjdYSEhOEkJJyAyzUci0U+NkIIaYEcd0IhD37/Xvz+AqzWZJzOgYTDPkpLX6C4+O/4fF+0u71SDhITx5CQMJJQqAK/fz+hUDVWqxurNRm7PROHIzcahLKx2/thsTgJhaoJh6uxWlNwOgfjdPZHKSdK2bBaE7BaU7HZUrBYmt+bPRIJoJStWVec1ppQqAqLxYHFkiDddEIchj7bhaWUmgf8HrACT2it72+x3gn8FZgKlAMLtNZ7outuB64FwsAPtNbLOtqfBJDDF4n4CQRKCQbLsFoTsNnS0FpTX78Ln287dXVbqavbjM+3A7s9E6dzMDZbKuFwHeFwbXR85iDBYDHhsKfL+1fKFg0KNsJhD1oHsdkyyMw8h/T0M/F4NlJW9i/q63c1bONyDSM9fS5paacRClXj820nEChC6wgAdnsmCQkjcDqHoLWfUKgKsOJ25+N2T6K+fg8VFW9QW7sWp3MISUnjsdv7EQpVEgpVEgyWEgiUEInUk55+JpmZX8VmS0brMH7/AcJhD5GIH60DaB0kEglit2eQmDjmkIDYeJyDhEJVhMM1WCyJ2GxpWCyu6Pb1WCyJHbb0tI7g9x/AYrFjtbqxWBI7vNxba00gUITdntVm2UIhD1ZrYp8KzIFAKXZ7Bkp14i6fokv6ZABR5p3+AjgLKAA+Bi7TWm9pkuZ7wCSt9XeUUpcCF2itFyilxgHPAScBA4C3gVG6g5trSADpW8LheoLBUiKRemy2NGy2FEKhavz+/QQCB4lEAmgdIhLxEgrVEA7XEA57iUR8aB2MtmrceL2fU16+lFCoHKUcpKefSVraHEATDnvxeDZQVfUO4XAtABaLC4djYENlEwyWRING+5zOwQQCxWgdOGSdzWZuIRwKVaCUE6dzIH7/PrQOtZmfUjYSEkahlCX6+uqaBJmOZh2w4nQOwuk0d7XUOohSVmy2DOz2dOrr9+HxfNLwmk0ZM8nImEdm5tloHaaubgv19bujZdQEAsXU1W0mHK5BKQdu92Tc7snY7VnYbGnU1++nqmoFXu9nWCxJJCWNw+UaSiRSTzhch82WSmLiWBITR2O1JqOUA61DBAIHCQSKCAbNiUcwWE4oVBXt/gxhs6Vht6djs2Vit2dit2dFW6m5aB3A49mE17sFUJzKtUQAAAtlSURBVNHPSToOh2m91tfvobz8VerqNuN0DiI391tkZV1AOOwhECgiFKpq0jWrUMpKJOLH798XvagkoaHFHFtnjlUaNlsqWoejreNatA6idSj6CBKJBHA4ckhIGIXDkYvP9zkezwbCYQ8u13BcriH4fDuprn6furrPUMoa/ezl4HafSHLyFByOgdjt6Shlw+fbGT25KYmWOUBS0lhSUmaRkDAMn28XXu82lLLgcg3D4RhAIFCI1/sFfv8+wmFPdN/mhCkx8QSCwXJqaj4iEDhI//7XdPgZb/1z2jcDyExgkdb6K9HntwNore9rkmZZNM1qpZQNOAhkAwubpm2arr19SgA5dpkKcTMu13BstuRD1kciQerqNmG3Z+N0Djzk7DkYrKC+fh9Wqznbj0R81NZ+gsezAadzABkZ83C5hhCJhPD5dhAKVWCzpWOzpWO3Z2Kx2NE6THX1akpLXyIQOEhCwnBcrjxstlSUcmKx2FHKPExlvZG6ui0oZcFqTY5eyOBEKdNiMPmnEA77ohWhF4vFhcXiJBisjHY1FgIKi8VU1sFgOcFgBQ5HLsnJU0lKmgBECIc91NV9RkXFGwSDZQAoZcflykMpB0opbLZ0kpImkpg4Gr+/gNraj6mr20IoVIHWISyWJFJTZ5Ga+iWCwQrq6j6LdnUmYrEkEgyW4fPtwHQKtKQagoPNltlwwqCULRpMKgkGK6LlL2uWh1J2EhNHo5SNYLCSUKiiSWC0kJo6m4yMs6iuXkVFxTKg4zordrFIJOLF59vRbqDvGhUNnP6GJU7nYNzuKYAiEqnH79+P17vt/7d37zFylWUcx7+/md2dndnddluohJbeaFcqoC2IgFINARNbJNA/aqwiopLwD0YwJkpTjZH/jEbUBIEGkIINILVoQ6JcCqlBU0pBLuVSKPeSlqIt28uyO93dxz/ed7fT7U47e7q7M2f3+SSbnXOd98k7c55z3vfMeYHe8ntRHZA9bD8Vvbty/dvU1Z1Ad/f/AMhmJ7Jw4e5EV4212ok+DXivZHo7cF65dcysW1I7cEKcv3HAtoPeIiTpGuAagBkz/Ed2Y5WUpbl5ftnlmUw9LS1nl11eXz+Z+vrJh81rbJzJlClLBuynjqameWXL0Nq6kNbWhRWWelmF6w0fsx7273+ebLaJxsY5Fd3wYGb09nbEJHj09Xt7i3R2vkNvb0fsn8rQ0HBy7Ouq7HBi1svBg7spFncgZcjn245oTgtXr7tiv9qk/vmdne/S3v6v/quYurpJZLP52PxnQE/sV2sqKfNBurrCMAqh1dz6++QgS13dRLLZlngCUBf/wuticScdHa9RLO4gn2+jufnTZDJ5isWddHa+TS43ncbG6UfE2NNzgAMHtlAsfkB39x56e7vI5+f0X82EExKjo2Mre/f+m87Od8jn2ygUTotxvkVX1/vkctPI5z8ZT1RagAwff/wGe/Y8zL59mykU5tHSch4tLedUpckx9bfTmNlKYCWEK5AqF8e5qpKyR02kg2+jww64R5PJNFAotCUpWsn7ZWhoOJGGhhPLrpPNNpLNHnlC2Ng4Y8hPY8hk6snn5wyYe+RBfzDl3i+Xm0ouN7XsdtlsExMmDDxfPpwkmprmDXrCMmHC58puVyjMpVCYe9R9j5aRTFnvc3gtnRLnDbpObMKaSOhMr2Rb55xzVTSSCeRpoE3SbEkNhOv5dQPWWQdcFV8vBR63cB26DlgmKSdpNtAGbBrBsjrnnBuiEWvCin0a3wceJtzGe6eZvSTpRmCzma0D7gDukbQN2E1sNI7r/Rl4GegGrj3WHVjOOedGl/+Q0DnnxrHjuQurdn4p5JxzLlU8gTjnnEvEE4hzzrlEPIE455xLZEx1okv6EHgn4eYnAv8dxuLUAo8pHTym2jfW4oFDMc00sylJdjCmEsjxkLQ56Z0ItcpjSgePqfaNtXhgeGLyJiznnHOJeAJxzjmXiCeQQ1ZWuwAjwGNKB4+p9o21eGAYYvI+EOecc4n4FYhzzrlExn0CkbRI0lZJ2yTdUO3yJCFpuqQnJL0s6SVJ18X5kyU9Kun1+H/SsfZVayRlJf1H0kNxerakp2J93R+f9JwaklolrZH0qqRXJH0+7fUk6Yfxc7dF0r2SGtNWT5LulLRL0paSeYPWi4Lfx9hekDS0AVhGSZmYfhU/ey9IelBSa8my5TGmrZK+Usl7jOsEEsdtvxlYDJwOfCOOx5423cCPzOx04Hzg2hjHDcB6M2sD1sfptLkOeKVk+pfATWY2F9gDXF2VUiX3O+AfZjYPmE+ILbX1JGka8APgHDM7k/Dk7WWkr57uAhYNmFeuXhYThphoI4yGessolXGo7uLImB4FzjSzzwCvAcsB4vFiGXBG3OYP8fh4VOM6gQDnAtvM7E0zKwL3AZdXuUxDZmY7zOzZ+Hof4aA0jRDLqrjaKmDJ4HuoTZJOAb4K3B6nBVwErImrpComSROBLxGGMcDMimb2ESmvJ8KwEPk4KFwB2EHK6snM/kkYUqJUuXq5HLjbgo1Aq6STR6eklRssJjN7xA4NEL+RMFgfhJjuM7MuM3sL2EY4Ph7VeE8gg43bPujY62khaRZwFvAUcJKZ7YiLdgInValYSf0W+DHQG6dPAD4q+QKkrb5mAx8Cf4zNcrdLaiLF9WRm7wO/Bt4lJI524BnSXU99ytXLWDlufA/4e3ydKKbxnkDGFEnNwF+A681sb+myONJjam65k3QpsMvMnql2WYZRHXA2cIuZnQUcYEBzVQrraRLh7HU2MBVo4shmk9RLW70ci6QVhKbv1cezn/GeQMbM2OuS6gnJY7WZrY2zP+i7tI7/d1WrfAlcAFwm6W1C0+JFhP6D1thUAumrr+3AdjN7Kk6vISSUNNfTl4G3zOxDMzsIrCXUXZrrqU+5ekn1cUPSd4BLgSvs0O84EsU03hNIJeO217zYN3AH8IqZ/aZkUemY81cBfxvtsiVlZsvN7BQzm0Wol8fN7ArgCWBpXC1tMe0E3pN0Wpx1MWHY5tTWE6Hp6nxJhfg57IsptfVUoly9rAO+He/GOh9oL2nqqmmSFhGahS8zs46SReuAZZJykmYTbhDYdMwdmtm4/gMuIdyN8AawotrlSRjDQsLl9QvAc/HvEkKfwXrgdeAxYHK1y5owvguBh+LrU+MHexvwAJCrdvmGGMsCYHOsq78Ck9JeT8AvgFeBLcA9QC5t9QTcS+jDOUi4Ury6XL0AIty9+QbwIuEOtKrHUGFM2wh9HX3HiVtL1l8RY9oKLK7kPfyX6M455xIZ701YzjnnEvIE4pxzLhFPIM455xLxBOKccy4RTyDOOecS8QTiXA2QdGHfE4edSwtPIM455xLxBOLcEEj6lqRNkp6TdFscr2S/pJvimBjrJU2J6y6QtLFk7IW+8STmSnpM0vOSnpU0J+6+uWSskNXxl93O1SxPIM5VSNKngK8DF5jZAqAHuILwAMHNZnYGsAH4edzkbuAnFsZeeLFk/mrgZjObD3yB8GthCE9Rvp4wNs2phGdKOVez6o69inMuuhj4LPB0vDjIEx6w1wvcH9f5E7A2jv3RamYb4vxVwAOSWoBpZvYggJl1AsT9bTKz7XH6OWAW8OTIh+VcMp5AnKucgFVmtvywmdLPBqyX9PlAXSWve/Dvp6tx3oTlXOXWA0slfQL6x8yeSfge9T159pvAk2bWDuyR9MU4/0pgg4URI7dLWhL3kZNUGNUonBsmfobjXIXM7GVJPwUekZQhPOX0WsLAUOfGZbsI/SQQHgF+a0wQbwLfjfOvBG6TdGPcx9dGMQznho0/jde54yRpv5k1V7sczo02b8JyzjmXiF+BOOecS8SvQJxzziXiCcQ551winkCcc84l4gnEOedcIp5AnHPOJeIJxDnnXCL/B96MwQUb5u8IAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2044 - acc: 0.9450\n",
      "Loss: 0.20442304390241794 Accuracy: 0.94496363\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5510 - acc: 0.4901\n",
      "Epoch 00001: val_loss improved from inf to 0.72826, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_128_DO_checkpoint/001-0.7283.hdf5\n",
      "36805/36805 [==============================] - 227s 6ms/sample - loss: 1.5509 - acc: 0.4902 - val_loss: 0.7283 - val_acc: 0.7720\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6616 - acc: 0.7913\n",
      "Epoch 00002: val_loss improved from 0.72826 to 0.34537, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_128_DO_checkpoint/002-0.3454.hdf5\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.6615 - acc: 0.7914 - val_loss: 0.3454 - val_acc: 0.8963\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3967 - acc: 0.8774\n",
      "Epoch 00003: val_loss did not improve from 0.34537\n",
      "36805/36805 [==============================] - 226s 6ms/sample - loss: 0.3968 - acc: 0.8773 - val_loss: 0.4638 - val_acc: 0.8544\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3096 - acc: 0.9036\n",
      "Epoch 00004: val_loss improved from 0.34537 to 0.19348, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_128_DO_checkpoint/004-0.1935.hdf5\n",
      "36805/36805 [==============================] - 226s 6ms/sample - loss: 0.3095 - acc: 0.9037 - val_loss: 0.1935 - val_acc: 0.9392\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2298 - acc: 0.9268\n",
      "Epoch 00005: val_loss did not improve from 0.19348\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.2298 - acc: 0.9268 - val_loss: 0.1951 - val_acc: 0.9418\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9390\n",
      "Epoch 00006: val_loss improved from 0.19348 to 0.17830, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_128_DO_checkpoint/006-0.1783.hdf5\n",
      "36805/36805 [==============================] - 226s 6ms/sample - loss: 0.1921 - acc: 0.9390 - val_loss: 0.1783 - val_acc: 0.9446\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9456\n",
      "Epoch 00007: val_loss improved from 0.17830 to 0.14923, saving model to model/checkpoint/1D_CNN_6_only_conv_pool_3_ch_128_DO_checkpoint/007-0.1492.hdf5\n",
      "36805/36805 [==============================] - 226s 6ms/sample - loss: 0.1676 - acc: 0.9456 - val_loss: 0.1492 - val_acc: 0.9564\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9531\n",
      "Epoch 00008: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.1435 - acc: 0.9530 - val_loss: 0.1737 - val_acc: 0.9502\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9597\n",
      "Epoch 00009: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 226s 6ms/sample - loss: 0.1248 - acc: 0.9597 - val_loss: 0.1589 - val_acc: 0.9518\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9619\n",
      "Epoch 00010: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.1142 - acc: 0.9619 - val_loss: 0.2003 - val_acc: 0.9457\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9674\n",
      "Epoch 00011: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0957 - acc: 0.9675 - val_loss: 0.1764 - val_acc: 0.9527\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9699\n",
      "Epoch 00012: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0919 - acc: 0.9699 - val_loss: 0.1910 - val_acc: 0.9506\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9739\n",
      "Epoch 00013: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0787 - acc: 0.9739 - val_loss: 0.1990 - val_acc: 0.9485\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9750\n",
      "Epoch 00014: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0781 - acc: 0.9750 - val_loss: 0.1528 - val_acc: 0.9569\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9774\n",
      "Epoch 00015: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0679 - acc: 0.9774 - val_loss: 0.1532 - val_acc: 0.9562\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9788\n",
      "Epoch 00016: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0658 - acc: 0.9788 - val_loss: 0.2006 - val_acc: 0.9509\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9799\n",
      "Epoch 00017: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0626 - acc: 0.9799 - val_loss: 0.1637 - val_acc: 0.9574\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9820\n",
      "Epoch 00018: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0537 - acc: 0.9820 - val_loss: 0.1981 - val_acc: 0.9520\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9835\n",
      "Epoch 00019: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0534 - acc: 0.9834 - val_loss: 0.2024 - val_acc: 0.9543\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9829\n",
      "Epoch 00020: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0548 - acc: 0.9829 - val_loss: 0.2064 - val_acc: 0.9557\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9866\n",
      "Epoch 00021: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0436 - acc: 0.9866 - val_loss: 0.2158 - val_acc: 0.9590\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9870\n",
      "Epoch 00022: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0421 - acc: 0.9870 - val_loss: 0.2164 - val_acc: 0.9562\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9869\n",
      "Epoch 00023: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0406 - acc: 0.9869 - val_loss: 0.2005 - val_acc: 0.9564\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9881\n",
      "Epoch 00024: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0379 - acc: 0.9881 - val_loss: 0.2565 - val_acc: 0.9511\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9878\n",
      "Epoch 00025: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0379 - acc: 0.9878 - val_loss: 0.2219 - val_acc: 0.9564\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9890\n",
      "Epoch 00026: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0353 - acc: 0.9890 - val_loss: 0.1993 - val_acc: 0.9553\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9898\n",
      "Epoch 00027: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0324 - acc: 0.9898 - val_loss: 0.1834 - val_acc: 0.9625\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9899\n",
      "Epoch 00028: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0331 - acc: 0.9899 - val_loss: 0.2556 - val_acc: 0.9467\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9896\n",
      "Epoch 00029: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0336 - acc: 0.9896 - val_loss: 0.2079 - val_acc: 0.9602\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9910\n",
      "Epoch 00030: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0315 - acc: 0.9910 - val_loss: 0.2034 - val_acc: 0.9592\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9914\n",
      "Epoch 00031: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0282 - acc: 0.9914 - val_loss: 0.2299 - val_acc: 0.9611\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9907\n",
      "Epoch 00032: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0311 - acc: 0.9907 - val_loss: 0.2123 - val_acc: 0.9576\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9912\n",
      "Epoch 00033: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0278 - acc: 0.9913 - val_loss: 0.2734 - val_acc: 0.9534\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9916\n",
      "Epoch 00034: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 0.0282 - acc: 0.9916 - val_loss: 0.2250 - val_acc: 0.9618\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9931\n",
      "Epoch 00035: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0230 - acc: 0.9931 - val_loss: 0.2412 - val_acc: 0.9625\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9933\n",
      "Epoch 00036: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0227 - acc: 0.9933 - val_loss: 0.2186 - val_acc: 0.9632\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9923\n",
      "Epoch 00037: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0268 - acc: 0.9923 - val_loss: 0.2058 - val_acc: 0.9611\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9937\n",
      "Epoch 00038: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0219 - acc: 0.9937 - val_loss: 0.2317 - val_acc: 0.9595\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9936\n",
      "Epoch 00039: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0223 - acc: 0.9936 - val_loss: 0.2296 - val_acc: 0.9611\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9929\n",
      "Epoch 00040: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0235 - acc: 0.9929 - val_loss: 0.2309 - val_acc: 0.9618\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9944\n",
      "Epoch 00041: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0192 - acc: 0.9944 - val_loss: 0.2098 - val_acc: 0.9616\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9950\n",
      "Epoch 00042: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0177 - acc: 0.9950 - val_loss: 0.2405 - val_acc: 0.9574\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9935\n",
      "Epoch 00043: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0234 - acc: 0.9935 - val_loss: 0.2214 - val_acc: 0.9595\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9943\n",
      "Epoch 00044: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0206 - acc: 0.9943 - val_loss: 0.2569 - val_acc: 0.9562\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9949\n",
      "Epoch 00045: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0171 - acc: 0.9949 - val_loss: 0.3057 - val_acc: 0.9529\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0204 - acc: 0.9940 - val_loss: 0.2474 - val_acc: 0.9550\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9950\n",
      "Epoch 00047: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0185 - acc: 0.9950 - val_loss: 0.2375 - val_acc: 0.9597\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 00048: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0138 - acc: 0.9956 - val_loss: 0.2174 - val_acc: 0.9646\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9951\n",
      "Epoch 00049: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0178 - acc: 0.9951 - val_loss: 0.2416 - val_acc: 0.9578\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9946\n",
      "Epoch 00050: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0186 - acc: 0.9946 - val_loss: 0.2284 - val_acc: 0.9632\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9960\n",
      "Epoch 00051: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0145 - acc: 0.9960 - val_loss: 0.2341 - val_acc: 0.9599\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9948\n",
      "Epoch 00052: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0183 - acc: 0.9948 - val_loss: 0.2844 - val_acc: 0.9543\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9954\n",
      "Epoch 00053: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0182 - acc: 0.9954 - val_loss: 0.2766 - val_acc: 0.9585\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9949\n",
      "Epoch 00054: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0176 - acc: 0.9949 - val_loss: 0.1806 - val_acc: 0.9658\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9958\n",
      "Epoch 00055: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0143 - acc: 0.9958 - val_loss: 0.2401 - val_acc: 0.9625\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9965\n",
      "Epoch 00056: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0124 - acc: 0.9965 - val_loss: 0.2626 - val_acc: 0.9595\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9951\n",
      "Epoch 00057: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0182 - acc: 0.9951 - val_loss: 0.2680 - val_acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9959\n",
      "Epoch 00058: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0138 - acc: 0.9959 - val_loss: 0.2774 - val_acc: 0.9632\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9956\n",
      "Epoch 00059: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0158 - acc: 0.9956 - val_loss: 0.2114 - val_acc: 0.9644\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9950\n",
      "Epoch 00060: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0168 - acc: 0.9950 - val_loss: 0.2591 - val_acc: 0.9641\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9955\n",
      "Epoch 00061: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0151 - acc: 0.9955 - val_loss: 0.2233 - val_acc: 0.9639\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9972\n",
      "Epoch 00062: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0112 - acc: 0.9972 - val_loss: 0.1966 - val_acc: 0.9641\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 00063: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0125 - acc: 0.9961 - val_loss: 0.2651 - val_acc: 0.9557\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9964\n",
      "Epoch 00064: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0127 - acc: 0.9964 - val_loss: 0.2373 - val_acc: 0.9634\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 00065: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0148 - acc: 0.9958 - val_loss: 0.2669 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9965\n",
      "Epoch 00066: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0132 - acc: 0.9965 - val_loss: 0.2106 - val_acc: 0.9648\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 00067: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.2780 - val_acc: 0.9653\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9965\n",
      "Epoch 00068: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0122 - acc: 0.9965 - val_loss: 0.2727 - val_acc: 0.9611\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 00069: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0094 - acc: 0.9972 - val_loss: 0.2206 - val_acc: 0.9655\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9960\n",
      "Epoch 00070: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0137 - acc: 0.9960 - val_loss: 0.2399 - val_acc: 0.9639\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9950\n",
      "Epoch 00071: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0180 - acc: 0.9950 - val_loss: 0.2238 - val_acc: 0.9637\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 00072: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0149 - acc: 0.9957 - val_loss: 0.2275 - val_acc: 0.9667\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9965\n",
      "Epoch 00073: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0128 - acc: 0.9965 - val_loss: 0.2250 - val_acc: 0.9651\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9972\n",
      "Epoch 00074: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0097 - acc: 0.9972 - val_loss: 0.2473 - val_acc: 0.9597\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 00075: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 0.2867 - val_acc: 0.9620\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9948\n",
      "Epoch 00076: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0185 - acc: 0.9948 - val_loss: 0.2813 - val_acc: 0.9595\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 00077: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0108 - acc: 0.9970 - val_loss: 0.2887 - val_acc: 0.9590\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9967\n",
      "Epoch 00078: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0134 - acc: 0.9967 - val_loss: 0.2679 - val_acc: 0.9590\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9964\n",
      "Epoch 00079: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0122 - acc: 0.9964 - val_loss: 0.2498 - val_acc: 0.9604\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9979\n",
      "Epoch 00080: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0084 - acc: 0.9979 - val_loss: 0.3752 - val_acc: 0.9522\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 00081: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0127 - acc: 0.9960 - val_loss: 0.2795 - val_acc: 0.9618\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9968\n",
      "Epoch 00082: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0120 - acc: 0.9968 - val_loss: 0.3021 - val_acc: 0.9590\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9970\n",
      "Epoch 00083: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0108 - acc: 0.9970 - val_loss: 0.2627 - val_acc: 0.9623\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9974\n",
      "Epoch 00084: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0080 - acc: 0.9974 - val_loss: 0.2404 - val_acc: 0.9646\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 00085: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0087 - acc: 0.9977 - val_loss: 0.2702 - val_acc: 0.9630\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9954\n",
      "Epoch 00086: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0167 - acc: 0.9954 - val_loss: 0.2519 - val_acc: 0.9611\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9971\n",
      "Epoch 00087: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0106 - acc: 0.9971 - val_loss: 0.2595 - val_acc: 0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9965\n",
      "Epoch 00088: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0139 - acc: 0.9965 - val_loss: 0.2314 - val_acc: 0.9648\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9981\n",
      "Epoch 00089: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0072 - acc: 0.9981 - val_loss: 0.2638 - val_acc: 0.9660\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00090: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.2572 - val_acc: 0.9641\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9969\n",
      "Epoch 00091: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0112 - acc: 0.9969 - val_loss: 0.2414 - val_acc: 0.9639\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9967\n",
      "Epoch 00092: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0119 - acc: 0.9967 - val_loss: 0.2573 - val_acc: 0.9627\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9974\n",
      "Epoch 00093: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0102 - acc: 0.9974 - val_loss: 0.2567 - val_acc: 0.9648\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9970\n",
      "Epoch 00094: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0116 - acc: 0.9970 - val_loss: 0.2280 - val_acc: 0.9632\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 00095: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 0.2775 - val_acc: 0.9625\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9973\n",
      "Epoch 00096: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0110 - acc: 0.9973 - val_loss: 0.2610 - val_acc: 0.9662\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9978\n",
      "Epoch 00097: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0093 - acc: 0.9978 - val_loss: 0.2302 - val_acc: 0.9655\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9966\n",
      "Epoch 00098: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0152 - acc: 0.9966 - val_loss: 0.2810 - val_acc: 0.9590\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9977\n",
      "Epoch 00099: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0089 - acc: 0.9977 - val_loss: 0.2503 - val_acc: 0.9665\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9973\n",
      "Epoch 00100: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0103 - acc: 0.9973 - val_loss: 0.2879 - val_acc: 0.9632\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9973\n",
      "Epoch 00101: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0094 - acc: 0.9973 - val_loss: 0.3108 - val_acc: 0.9613\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9960\n",
      "Epoch 00102: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0154 - acc: 0.9960 - val_loss: 0.2437 - val_acc: 0.9646\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9980\n",
      "Epoch 00103: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0056 - acc: 0.9980 - val_loss: 0.2926 - val_acc: 0.9616\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9974\n",
      "Epoch 00104: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0109 - acc: 0.9974 - val_loss: 0.2714 - val_acc: 0.9644\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9983\n",
      "Epoch 00105: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0068 - acc: 0.9983 - val_loss: 0.2479 - val_acc: 0.9651\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9968\n",
      "Epoch 00106: val_loss did not improve from 0.14923\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.0134 - acc: 0.9968 - val_loss: 0.2973 - val_acc: 0.9609\n",
      "Epoch 107/500\n",
      "11520/36805 [========>.....................] - ETA: 2:30 - loss: 0.0126 - acc: 0.9964"
     ]
    }
   ],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_128_DO'.format(i)\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_128_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_128_DO'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_pool_3_ch_128_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=25, filters=128, strides=1, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=128*(2**int((i+1)/2)), strides=1))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_128_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_128_BN'.format(i)\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_128_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_128_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_only_conv_pool_3_ch_128_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=25, filters=128, strides=1, input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=25, filters=128*(2**int((i+1)/2)), strides=1))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_128_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_128_DO_BN'.format(i)\n",
    "    model = build_1d_cnn_only_conv_pool_3_ch_128ch_64_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 7):\n",
    "    model_name = '1D_CNN_{}_only_conv_pool_3_ch_128_DO_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "#         model = build_cnn(conv_num=i, fcn_num=j)\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "#         model_filename = model_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
