{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    init_channel = 256\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel/(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                65536016  \n",
      "=================================================================\n",
      "Total params: 65,538,576\n",
      "Trainable params: 65,538,064\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1365248)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1365248)           0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                21843984  \n",
      "=================================================================\n",
      "Total params: 22,175,504\n",
      "Trainable params: 22,174,480\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 454912)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 454912)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                7278608   \n",
      "=================================================================\n",
      "Total params: 7,939,088\n",
      "Trainable params: 7,937,552\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,037,392\n",
      "Trainable params: 2,035,600\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,310,992\n",
      "Trainable params: 1,308,944\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,123,216\n",
      "Trainable params: 1,120,912\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,052,880\n",
      "Trainable params: 1,050,448\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,059,344\n",
      "Trainable params: 1,056,784\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 64)             256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,075,024\n",
      "Trainable params: 1,072,336\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9653 - acc: 0.4222\n",
      "Epoch 00001: val_loss improved from inf to 1.54442, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/001-1.5444.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 1.9652 - acc: 0.4222 - val_loss: 1.5444 - val_acc: 0.5167\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2705 - acc: 0.6099\n",
      "Epoch 00002: val_loss improved from 1.54442 to 1.13743, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/002-1.1374.hdf5\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 1.2706 - acc: 0.6099 - val_loss: 1.1374 - val_acc: 0.6452\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0540 - acc: 0.6768\n",
      "Epoch 00003: val_loss did not improve from 1.13743\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 1.0542 - acc: 0.6768 - val_loss: 1.3629 - val_acc: 0.6054\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9074 - acc: 0.7199\n",
      "Epoch 00004: val_loss improved from 1.13743 to 0.97372, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/004-0.9737.hdf5\n",
      "36805/36805 [==============================] - 413s 11ms/sample - loss: 0.9074 - acc: 0.7199 - val_loss: 0.9737 - val_acc: 0.7151\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8009 - acc: 0.7563\n",
      "Epoch 00005: val_loss improved from 0.97372 to 0.95047, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/005-0.9505.hdf5\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.8011 - acc: 0.7562 - val_loss: 0.9505 - val_acc: 0.7310\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7140 - acc: 0.7799\n",
      "Epoch 00006: val_loss did not improve from 0.95047\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.7141 - acc: 0.7798 - val_loss: 0.9895 - val_acc: 0.7102\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6316 - acc: 0.8038\n",
      "Epoch 00007: val_loss improved from 0.95047 to 0.93125, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/007-0.9312.hdf5\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.6317 - acc: 0.8038 - val_loss: 0.9312 - val_acc: 0.7412\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5709 - acc: 0.8211\n",
      "Epoch 00008: val_loss improved from 0.93125 to 0.93065, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/008-0.9307.hdf5\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.5710 - acc: 0.8211 - val_loss: 0.9307 - val_acc: 0.7524\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.8428\n",
      "Epoch 00009: val_loss did not improve from 0.93065\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.5019 - acc: 0.8428 - val_loss: 1.0533 - val_acc: 0.7074\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8557\n",
      "Epoch 00010: val_loss did not improve from 0.93065\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.4543 - acc: 0.8557 - val_loss: 0.9336 - val_acc: 0.7473\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8731\n",
      "Epoch 00011: val_loss did not improve from 0.93065\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.4031 - acc: 0.8731 - val_loss: 1.0078 - val_acc: 0.7331\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3672 - acc: 0.8812\n",
      "Epoch 00012: val_loss improved from 0.93065 to 0.91734, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/012-0.9173.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.3672 - acc: 0.8812 - val_loss: 0.9173 - val_acc: 0.7540\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.8918\n",
      "Epoch 00013: val_loss did not improve from 0.91734\n",
      "36805/36805 [==============================] - 414s 11ms/sample - loss: 0.3299 - acc: 0.8918 - val_loss: 1.0900 - val_acc: 0.7352\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9027\n",
      "Epoch 00014: val_loss did not improve from 0.91734\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.3025 - acc: 0.9027 - val_loss: 1.0160 - val_acc: 0.7414\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.9077\n",
      "Epoch 00015: val_loss did not improve from 0.91734\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2850 - acc: 0.9077 - val_loss: 1.0779 - val_acc: 0.7442\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2565 - acc: 0.9153\n",
      "Epoch 00016: val_loss did not improve from 0.91734\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2565 - acc: 0.9153 - val_loss: 1.1341 - val_acc: 0.7338\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9245\n",
      "Epoch 00017: val_loss improved from 0.91734 to 0.91277, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_4_conv_checkpoint/017-0.9128.hdf5\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2327 - acc: 0.9245 - val_loss: 0.9128 - val_acc: 0.7864\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9264\n",
      "Epoch 00018: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.2231 - acc: 0.9264 - val_loss: 1.3150 - val_acc: 0.6879\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9344\n",
      "Epoch 00019: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1965 - acc: 0.9343 - val_loss: 1.1261 - val_acc: 0.7568\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9366\n",
      "Epoch 00020: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1956 - acc: 0.9366 - val_loss: 1.0857 - val_acc: 0.7612\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9391\n",
      "Epoch 00021: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1855 - acc: 0.9391 - val_loss: 1.0884 - val_acc: 0.7591\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9424\n",
      "Epoch 00022: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1739 - acc: 0.9424 - val_loss: 1.1201 - val_acc: 0.7584\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9437\n",
      "Epoch 00023: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1715 - acc: 0.9437 - val_loss: 1.2291 - val_acc: 0.7442\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9485\n",
      "Epoch 00024: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1575 - acc: 0.9485 - val_loss: 1.3898 - val_acc: 0.7223\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9533\n",
      "Epoch 00025: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1457 - acc: 0.9533 - val_loss: 1.0337 - val_acc: 0.7876\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9532\n",
      "Epoch 00026: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1477 - acc: 0.9532 - val_loss: 1.2322 - val_acc: 0.7435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9548\n",
      "Epoch 00027: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1387 - acc: 0.9548 - val_loss: 1.1522 - val_acc: 0.7699\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9554\n",
      "Epoch 00028: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1400 - acc: 0.9554 - val_loss: 1.1829 - val_acc: 0.7678\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9603\n",
      "Epoch 00029: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 415s 11ms/sample - loss: 0.1210 - acc: 0.9603 - val_loss: 1.3837 - val_acc: 0.7284\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9623\n",
      "Epoch 00030: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1172 - acc: 0.9623 - val_loss: 1.2310 - val_acc: 0.7615\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9624\n",
      "Epoch 00031: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1174 - acc: 0.9624 - val_loss: 1.1703 - val_acc: 0.7766\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9629\n",
      "Epoch 00032: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1154 - acc: 0.9629 - val_loss: 1.1036 - val_acc: 0.7901\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9646\n",
      "Epoch 00033: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1111 - acc: 0.9645 - val_loss: 1.3188 - val_acc: 0.7508\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9651\n",
      "Epoch 00034: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1119 - acc: 0.9651 - val_loss: 1.2025 - val_acc: 0.7650\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9657\n",
      "Epoch 00035: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1058 - acc: 0.9657 - val_loss: 1.5214 - val_acc: 0.7209\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9672\n",
      "Epoch 00036: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1001 - acc: 0.9672 - val_loss: 1.4657 - val_acc: 0.7324\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9680\n",
      "Epoch 00037: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1047 - acc: 0.9679 - val_loss: 1.1957 - val_acc: 0.7685\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9676\n",
      "Epoch 00038: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.1017 - acc: 0.9676 - val_loss: 1.4961 - val_acc: 0.7307\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9711\n",
      "Epoch 00039: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0916 - acc: 0.9710 - val_loss: 1.2921 - val_acc: 0.7717\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9691\n",
      "Epoch 00040: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0975 - acc: 0.9691 - val_loss: 1.2243 - val_acc: 0.7794\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9751\n",
      "Epoch 00041: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0842 - acc: 0.9751 - val_loss: 1.5947 - val_acc: 0.7354\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9720\n",
      "Epoch 00042: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0909 - acc: 0.9720 - val_loss: 1.2582 - val_acc: 0.7738\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9743\n",
      "Epoch 00043: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0839 - acc: 0.9743 - val_loss: 1.3827 - val_acc: 0.7584\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9735\n",
      "Epoch 00044: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0826 - acc: 0.9735 - val_loss: 1.3628 - val_acc: 0.7589\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9767\n",
      "Epoch 00045: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0760 - acc: 0.9767 - val_loss: 1.4652 - val_acc: 0.7403\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9757\n",
      "Epoch 00046: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0777 - acc: 0.9757 - val_loss: 1.2764 - val_acc: 0.7745\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9742\n",
      "Epoch 00047: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0860 - acc: 0.9742 - val_loss: 1.2972 - val_acc: 0.7724\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9749\n",
      "Epoch 00048: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0817 - acc: 0.9749 - val_loss: 1.1441 - val_acc: 0.7957\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9770\n",
      "Epoch 00049: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0741 - acc: 0.9770 - val_loss: 1.2970 - val_acc: 0.7738\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9778\n",
      "Epoch 00050: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0716 - acc: 0.9778 - val_loss: 1.2301 - val_acc: 0.7829\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9764\n",
      "Epoch 00051: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0753 - acc: 0.9764 - val_loss: 1.5335 - val_acc: 0.7398\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9786\n",
      "Epoch 00052: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0709 - acc: 0.9786 - val_loss: 1.4036 - val_acc: 0.7580\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9808\n",
      "Epoch 00053: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0633 - acc: 0.9808 - val_loss: 1.2524 - val_acc: 0.7894\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9783\n",
      "Epoch 00054: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0727 - acc: 0.9783 - val_loss: 1.4711 - val_acc: 0.7547\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9792\n",
      "Epoch 00055: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0686 - acc: 0.9792 - val_loss: 1.3818 - val_acc: 0.7640\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9812\n",
      "Epoch 00056: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0640 - acc: 0.9812 - val_loss: 1.3783 - val_acc: 0.7636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9803\n",
      "Epoch 00057: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0672 - acc: 0.9803 - val_loss: 1.3208 - val_acc: 0.7682\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9812\n",
      "Epoch 00058: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0629 - acc: 0.9812 - val_loss: 1.4386 - val_acc: 0.7594\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9793\n",
      "Epoch 00059: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0702 - acc: 0.9793 - val_loss: 1.2999 - val_acc: 0.7803\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9792\n",
      "Epoch 00060: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0687 - acc: 0.9792 - val_loss: 1.2573 - val_acc: 0.7820\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9838\n",
      "Epoch 00061: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0548 - acc: 0.9838 - val_loss: 1.2667 - val_acc: 0.7843\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9826\n",
      "Epoch 00062: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0594 - acc: 0.9826 - val_loss: 1.3787 - val_acc: 0.7734\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9857\n",
      "Epoch 00063: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0500 - acc: 0.9857 - val_loss: 1.2584 - val_acc: 0.7871\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9818\n",
      "Epoch 00064: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0598 - acc: 0.9818 - val_loss: 1.4818 - val_acc: 0.7587\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9832\n",
      "Epoch 00065: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0557 - acc: 0.9832 - val_loss: 1.2619 - val_acc: 0.7859\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9825\n",
      "Epoch 00066: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0572 - acc: 0.9825 - val_loss: 1.3839 - val_acc: 0.7696\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9841\n",
      "Epoch 00067: val_loss did not improve from 0.91277\n",
      "36805/36805 [==============================] - 416s 11ms/sample - loss: 0.0534 - acc: 0.9840 - val_loss: 1.3744 - val_acc: 0.7794\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 1.0501 - acc: 0.7425\n",
      "Loss: 1.050109894302899 Accuracy: 0.74247146\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8993 - acc: 0.4221\n",
      "Epoch 00001: val_loss improved from inf to 1.38086, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/001-1.3809.hdf5\n",
      "36805/36805 [==============================] - 424s 12ms/sample - loss: 1.8993 - acc: 0.4221 - val_loss: 1.3809 - val_acc: 0.5602\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1975 - acc: 0.6273\n",
      "Epoch 00002: val_loss improved from 1.38086 to 1.11458, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/002-1.1146.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 1.1976 - acc: 0.6273 - val_loss: 1.1146 - val_acc: 0.6613\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9848 - acc: 0.6977\n",
      "Epoch 00003: val_loss improved from 1.11458 to 0.85773, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/003-0.8577.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.9847 - acc: 0.6977 - val_loss: 0.8577 - val_acc: 0.7442\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8679 - acc: 0.7342\n",
      "Epoch 00004: val_loss improved from 0.85773 to 0.72154, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/004-0.7215.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.8681 - acc: 0.7341 - val_loss: 0.7215 - val_acc: 0.7866\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7785 - acc: 0.7645\n",
      "Epoch 00005: val_loss did not improve from 0.72154\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.7785 - acc: 0.7645 - val_loss: 0.7395 - val_acc: 0.7952\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7106 - acc: 0.7831\n",
      "Epoch 00006: val_loss did not improve from 0.72154\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.7108 - acc: 0.7831 - val_loss: 0.7334 - val_acc: 0.7852\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6601 - acc: 0.7991\n",
      "Epoch 00007: val_loss improved from 0.72154 to 0.71598, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/007-0.7160.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.6601 - acc: 0.7991 - val_loss: 0.7160 - val_acc: 0.7950\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6130 - acc: 0.8137\n",
      "Epoch 00008: val_loss did not improve from 0.71598\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.6130 - acc: 0.8137 - val_loss: 0.7789 - val_acc: 0.7680\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5690 - acc: 0.8284\n",
      "Epoch 00009: val_loss did not improve from 0.71598\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.5690 - acc: 0.8284 - val_loss: 0.8232 - val_acc: 0.7610\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5344 - acc: 0.8351\n",
      "Epoch 00010: val_loss improved from 0.71598 to 0.59682, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/010-0.5968.hdf5\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.5343 - acc: 0.8351 - val_loss: 0.5968 - val_acc: 0.8325\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.8472\n",
      "Epoch 00011: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4959 - acc: 0.8472 - val_loss: 0.6115 - val_acc: 0.8171\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4753 - acc: 0.8553\n",
      "Epoch 00012: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4753 - acc: 0.8553 - val_loss: 0.6423 - val_acc: 0.8169\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8591\n",
      "Epoch 00013: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4536 - acc: 0.8591 - val_loss: 0.6022 - val_acc: 0.8295\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4227 - acc: 0.8696\n",
      "Epoch 00014: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4226 - acc: 0.8696 - val_loss: 0.6497 - val_acc: 0.8216\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8766\n",
      "Epoch 00015: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.3965 - acc: 0.8766 - val_loss: 0.6960 - val_acc: 0.8018\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8814\n",
      "Epoch 00016: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3765 - acc: 0.8815 - val_loss: 0.6139 - val_acc: 0.8325\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3591 - acc: 0.8874\n",
      "Epoch 00017: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3591 - acc: 0.8874 - val_loss: 0.6607 - val_acc: 0.8218\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3326 - acc: 0.8964\n",
      "Epoch 00018: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3330 - acc: 0.8963 - val_loss: 0.7489 - val_acc: 0.7906\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3290 - acc: 0.8968\n",
      "Epoch 00019: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3290 - acc: 0.8968 - val_loss: 0.6379 - val_acc: 0.8362\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.9026\n",
      "Epoch 00020: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3044 - acc: 0.9025 - val_loss: 0.7557 - val_acc: 0.7997\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2808 - acc: 0.9100\n",
      "Epoch 00021: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2808 - acc: 0.9100 - val_loss: 0.7133 - val_acc: 0.8118\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9114\n",
      "Epoch 00022: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2757 - acc: 0.9113 - val_loss: 0.6555 - val_acc: 0.8272\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2634 - acc: 0.9157\n",
      "Epoch 00023: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2634 - acc: 0.9157 - val_loss: 0.6790 - val_acc: 0.8190\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9211\n",
      "Epoch 00024: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2477 - acc: 0.9211 - val_loss: 0.6473 - val_acc: 0.8332\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2368 - acc: 0.9236\n",
      "Epoch 00025: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2370 - acc: 0.9235 - val_loss: 0.6818 - val_acc: 0.8185\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9280\n",
      "Epoch 00026: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2288 - acc: 0.9280 - val_loss: 0.7517 - val_acc: 0.8162\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9303\n",
      "Epoch 00027: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2128 - acc: 0.9303 - val_loss: 0.7256 - val_acc: 0.8167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9340\n",
      "Epoch 00028: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2033 - acc: 0.9340 - val_loss: 0.5998 - val_acc: 0.8549\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9346\n",
      "Epoch 00029: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1958 - acc: 0.9346 - val_loss: 0.6737 - val_acc: 0.8351\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9392\n",
      "Epoch 00030: val_loss did not improve from 0.59682\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1856 - acc: 0.9391 - val_loss: 0.6920 - val_acc: 0.8337\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9387\n",
      "Epoch 00031: val_loss improved from 0.59682 to 0.58541, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_5_conv_checkpoint/031-0.5854.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1868 - acc: 0.9387 - val_loss: 0.5854 - val_acc: 0.8539\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9417\n",
      "Epoch 00032: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1756 - acc: 0.9417 - val_loss: 0.6870 - val_acc: 0.8404\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9451\n",
      "Epoch 00033: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1679 - acc: 0.9451 - val_loss: 0.6191 - val_acc: 0.8509\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9500\n",
      "Epoch 00034: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1570 - acc: 0.9500 - val_loss: 0.8187 - val_acc: 0.8116\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9490\n",
      "Epoch 00035: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1543 - acc: 0.9490 - val_loss: 0.7329 - val_acc: 0.8220\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1592 - acc: 0.9481\n",
      "Epoch 00036: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1592 - acc: 0.9481 - val_loss: 0.7168 - val_acc: 0.8395\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9552\n",
      "Epoch 00037: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1424 - acc: 0.9551 - val_loss: 0.7070 - val_acc: 0.8425\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9510\n",
      "Epoch 00038: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1487 - acc: 0.9510 - val_loss: 0.7229 - val_acc: 0.8472\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9540\n",
      "Epoch 00039: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1409 - acc: 0.9540 - val_loss: 0.6546 - val_acc: 0.8481\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9551\n",
      "Epoch 00040: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1407 - acc: 0.9551 - val_loss: 0.6443 - val_acc: 0.8474\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9586\n",
      "Epoch 00041: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1255 - acc: 0.9586 - val_loss: 0.6834 - val_acc: 0.8453\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9591\n",
      "Epoch 00042: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1252 - acc: 0.9591 - val_loss: 0.6803 - val_acc: 0.8425\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9575\n",
      "Epoch 00043: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1294 - acc: 0.9575 - val_loss: 0.7054 - val_acc: 0.8523\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9624\n",
      "Epoch 00044: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1168 - acc: 0.9624 - val_loss: 0.8310 - val_acc: 0.8192\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9643\n",
      "Epoch 00045: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1113 - acc: 0.9644 - val_loss: 0.6514 - val_acc: 0.8488\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9644\n",
      "Epoch 00046: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1087 - acc: 0.9644 - val_loss: 0.6421 - val_acc: 0.8591\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9652\n",
      "Epoch 00047: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1098 - acc: 0.9651 - val_loss: 0.7741 - val_acc: 0.8393\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9652\n",
      "Epoch 00048: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1083 - acc: 0.9652 - val_loss: 0.7339 - val_acc: 0.8435\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9663\n",
      "Epoch 00049: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1055 - acc: 0.9663 - val_loss: 0.7095 - val_acc: 0.8407\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9659\n",
      "Epoch 00050: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1096 - acc: 0.9659 - val_loss: 0.7170 - val_acc: 0.8484\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9690\n",
      "Epoch 00051: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0973 - acc: 0.9690 - val_loss: 0.6789 - val_acc: 0.8556\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9690\n",
      "Epoch 00052: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0981 - acc: 0.9690 - val_loss: 0.7598 - val_acc: 0.8453\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9682\n",
      "Epoch 00053: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0997 - acc: 0.9681 - val_loss: 0.7698 - val_acc: 0.8393\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9694\n",
      "Epoch 00054: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0942 - acc: 0.9694 - val_loss: 0.8521 - val_acc: 0.8202\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9703\n",
      "Epoch 00055: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0913 - acc: 0.9703 - val_loss: 0.6834 - val_acc: 0.8535\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9738\n",
      "Epoch 00056: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0874 - acc: 0.9738 - val_loss: 0.6873 - val_acc: 0.8551\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9716\n",
      "Epoch 00057: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0891 - acc: 0.9716 - val_loss: 0.6679 - val_acc: 0.8591\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9741\n",
      "Epoch 00058: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 422s 11ms/sample - loss: 0.0831 - acc: 0.9741 - val_loss: 0.8034 - val_acc: 0.8290\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9743\n",
      "Epoch 00059: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0837 - acc: 0.9743 - val_loss: 0.7370 - val_acc: 0.8467\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9706\n",
      "Epoch 00060: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0918 - acc: 0.9706 - val_loss: 0.6714 - val_acc: 0.8593\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9733\n",
      "Epoch 00061: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0833 - acc: 0.9733 - val_loss: 0.7113 - val_acc: 0.8642\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9746\n",
      "Epoch 00062: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0822 - acc: 0.9746 - val_loss: 0.6805 - val_acc: 0.8572\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9759\n",
      "Epoch 00063: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0746 - acc: 0.9759 - val_loss: 0.7174 - val_acc: 0.8572\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9755\n",
      "Epoch 00064: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0769 - acc: 0.9755 - val_loss: 0.7444 - val_acc: 0.8491\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9757\n",
      "Epoch 00065: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0785 - acc: 0.9757 - val_loss: 0.8115 - val_acc: 0.8383\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9798\n",
      "Epoch 00066: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0663 - acc: 0.9798 - val_loss: 0.7830 - val_acc: 0.8465\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9762\n",
      "Epoch 00067: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0767 - acc: 0.9763 - val_loss: 0.7719 - val_acc: 0.8560\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9786\n",
      "Epoch 00068: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0672 - acc: 0.9786 - val_loss: 0.8884 - val_acc: 0.8255\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9747\n",
      "Epoch 00069: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0816 - acc: 0.9747 - val_loss: 0.7166 - val_acc: 0.8579\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9783\n",
      "Epoch 00070: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0660 - acc: 0.9782 - val_loss: 0.7185 - val_acc: 0.8560\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9782\n",
      "Epoch 00071: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.0692 - acc: 0.9782 - val_loss: 0.6969 - val_acc: 0.8600\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9803\n",
      "Epoch 00072: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0637 - acc: 0.9803 - val_loss: 0.8126 - val_acc: 0.8409\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9801\n",
      "Epoch 00073: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0615 - acc: 0.9801 - val_loss: 0.7482 - val_acc: 0.8539\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9781\n",
      "Epoch 00074: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0685 - acc: 0.9781 - val_loss: 0.7455 - val_acc: 0.8479\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9803\n",
      "Epoch 00075: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0618 - acc: 0.9803 - val_loss: 0.8884 - val_acc: 0.8288\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9793\n",
      "Epoch 00076: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0674 - acc: 0.9793 - val_loss: 0.8172 - val_acc: 0.8512\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9784\n",
      "Epoch 00077: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0680 - acc: 0.9784 - val_loss: 0.7230 - val_acc: 0.8509\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9806\n",
      "Epoch 00078: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 422s 11ms/sample - loss: 0.0634 - acc: 0.9806 - val_loss: 0.7678 - val_acc: 0.8435\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9812\n",
      "Epoch 00079: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 422s 11ms/sample - loss: 0.0602 - acc: 0.9812 - val_loss: 0.7495 - val_acc: 0.8495\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9787\n",
      "Epoch 00080: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 422s 11ms/sample - loss: 0.0687 - acc: 0.9787 - val_loss: 0.8142 - val_acc: 0.8376\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9837\n",
      "Epoch 00081: val_loss did not improve from 0.58541\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.0528 - acc: 0.9836 - val_loss: 0.7529 - val_acc: 0.8542\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXd8VUX6/9+T3kNIQg0tASmhhCpIUxFEEERdxIJd/OqP1WXdZWXdVRF1xbKraxcrqIBYWMFFEVcgovQQIIBSAiGBQBoJ6cm99/n9Mbnp5aZcEmDer9d53XvPmTPznHPvnc/MM8/MUSKCwWAwGAx14dLcBhgMBoPh/MAIhsFgMBgcwgiGwWAwGBzCCIbBYDAYHMIIhsFgMBgcwgiGwWAwGBzCCIbBYDAYHMIIhsFgMBgcwgiGwWAwGBzCrbkNaEpCQkKka9euzW2GwWAwnDfs3LkzTURCHUl7QQlG165d2bFjR3ObYTAYDOcNSqkER9Mal5TBYDAYHMIIhsFgMBgcwgiGwWAwGBzighrDqI7i4mKSkpIoKChoblPOS7y8vAgLC8Pd3b25TTEYDM3MBS8YSUlJ+Pv707VrV5RSzW3OeYWIkJ6eTlJSEt26dWtucwwGQzNzwbukCgoKCA4ONmLRAJRSBAcHm96ZwWAALgLBAIxYNAJz7wwGg52LQjDqorDwJBZLVnObYTAYDC0aIxhAUdEpLJazTsk7MzOTN998s0HnTpo0iczMTIfTz58/n5deeqlBZRkMBkNdGMEAlHIFrE7JuzbBsFgstZ67Zs0aWrVq5QyzDAaDod4YwQDAFRHnCMa8efM4cuQIUVFRzJ07lw0bNjB69GimTp1Knz59AJg2bRqDBw8mMjKSRYsWlZ7btWtX0tLSOHbsGL1792bWrFlERkYyYcIE8vPzay03NjaW4cOH079/f66//nrOnDkDwKuvvkqfPn3o378/N998MwAbN24kKiqKqKgoBg4cSHZ2tlPuhcFgOL+54MNqy3Po0BxycmKr7LfZ8gCFi4t3vfP084uiR49Xajy+cOFC4uLiiI3V5W7YsIGYmBji4uJKQ1U/+OADWrduTX5+PkOHDuXGG28kODi4ku2HWLZsGe+++y433XQTX375JTNnzqyx3DvuuIPXXnuNsWPH8sQTT/DUU0/xyiuvsHDhQo4ePYqnp2epu+ull17ijTfeYOTIkeTk5ODl5VXv+2AwGC58TA+jFDlnJQ0bNqzCvIZXX32VAQMGMHz4cBITEzl06FCVc7p160ZUVBQAgwcP5tixYzXmn5WVRWZmJmPHjgXgzjvvJDo6GoD+/ftz22238cknn+DmptsLI0eO5JFHHuHVV18lMzOzdL/BYDCU56KqGWrqCeTlHUKkGF/fPufEDl9f39L3GzZs4IcffmDz5s34+Phw+eWXVzvvwdPTs/S9q6trnS6pmvjvf/9LdHQ0q1ev5tlnn2Xv3r3MmzePyZMns2bNGkaOHMnatWvp1atXg/I3GAwXLqaHgR70dtYYhr+/f61jAllZWQQFBeHj48Ovv/7Kli1bGl1mYGAgQUFB/PTTTwB8/PHHjB07FpvNRmJiIldccQXPP/88WVlZ5OTkcOTIEfr168ejjz7K0KFD+fXXXxttg8FguPC4qHoYNeHMKKng4GBGjhxJ3759ueaaa5g8eXKF4xMnTuTtt9+md+/e9OzZk+HDhzdJuYsXL+aBBx4gLy+P8PBwPvzwQ6xWKzNnziQrKwsR4eGHH6ZVq1Y8/vjjrF+/HhcXFyIjI7nmmmuaxAaDwXBhoUTOne/e2QwZMkQqP0DpwIED9O7du9bzCgoSKS5Oxd9/kDPNO29x5B4aDIbzE6XUThEZ4kha45LC3sOwcSGJp8FgMDQ1RjCwCwZOG8cwGAyGCwEjGEDZbbA1qxUGg8HQkjGCgelhGAwGgyM4LUpKKfUBcC2QIiJ9qzk+F7itnB29gVARyVBKHQOy0aFLFkcHZBpuq2vJOyMYBoPBUBPO7GF8BEys6aCIvCgiUSISBfwV2CgiGeWSXFFy3KlioXEpscm4pAwGg6EmnCYYIhINZNSZUHMLsMxZttRFS3NJ+fn51Wu/wWAwnAuafQxDKeWD7ol8WW63AN8rpXYqpe6v4/z7lVI7lFI7UlNTG2iD/Ta0DMEwGAyGlkizCwYwBfi5kjtqlIgMAq4BZiulxtR0sogsEpEhIjIkNDS0gSbYexhN75KaN28eb7zxRuln+0OOcnJyGDduHIMGDaJfv358/fXXDucpIsydO5e+ffvSr18/PvvsMwCSk5MZM2YMUVFR9O3bl59++gmr1cpdd91Vmvbll19u8ms0GAwXBy1haZCbqeSOEpETJa8pSqmVwDAgutElzZkDsVWXN1eAtzUbF+UJLh71yzMqCl6peXnzGTNmMGfOHGbPng3AihUrWLt2LV5eXqxcuZKAgADS0tIYPnw4U6dOdegZ2l999RWxsbHs3r2btLQ0hg4dypgxY1i6dClXX301f/vb37BareTl5REbG8uJEyeIi4sDqNcT/AwGg6E8zSoYSqlAYCwws9w+X8BFRLJL3k8AFpwbi5p+pvfAgQNJSUnh5MmTpKamEhQURKdOnSguLuaxxx4jOjoaFxcXTpw4wenTp2nXrl2deW7atIlbbrkFV1dX2rZty9ixY9m+fTtDhw7lnnvuobi4mGnTphEVFUV4eDjx8fE89NBDTJ48mQkTJjT5NRoMhosDZ4bVLgMuB0KUUknAk4A7gIi8XZLseuB7Ecktd2pbYGVJS9sNWCoi3zWJUTX0BBSQn70Ld/dgvLw6N0lR5Zk+fTpffPEFp06dYsaMGQB8+umnpKamsnPnTtzd3enatWu1y5rXhzFjxhAdHc1///tf7rrrLh555BHuuOMOdu/ezdq1a3n77bdZsWIFH3zwQVNclsFguMhwmmCIyC0OpPkIHX5bfl88MMA5VtWMM5c4nzFjBrNmzSItLY2NGzcCelnzNm3a4O7uzvr160lISHA4v9GjR/POO+9w5513kpGRQXR0NC+++CIJCQmEhYUxa9YsCgsLiYmJYdKkSXh4eHDjjTfSs2fPWp/SZzAYDLXREsYwWgQ6Uso58zAiIyPJzs6mY8eOtG/fHoDbbruNKVOm0K9fP4YMGVKvBxZdf/31bN68mQEDBqCU4oUXXqBdu3YsXryYF198EXd3d/z8/FiyZAknTpzg7rvvxmbT1/bcc8855RoNBsOFj1nevITc3AMo5YqPzyXOMu+8xSxvbjBcuJjlzRuAM11SBoPBcCFgBKMEZ7qkDAaD4ULACEYppodhMBgMtWEEowSlXMzigwaDwVALRjBKccWsJWUwGAw1YwSjBL1irZhehsFgMNSAEYwS7CvWNrVgZGZm8uabbzbo3EmTJpm1nwwGQ4vBCEYpznnqXm2CYbFYaj13zZo1tGrVqkntMRgMhoZiBKOEsh5G0wrGvHnzOHLkCFFRUcydO5cNGzYwevRopk6dSp8+fQCYNm0agwcPJjIykkWLFpWe27VrV9LS0jh27Bi9e/dm1qxZREZGMmHCBPLz86uUtXr1ai699FIGDhzIVVddxenTpwHIycnh7rvvpl+/fvTv358vv9SPHvnuu+8YNGgQAwYMYNy4cU163QaD4cLjoloapIbVzQEQCcBm64mLiycOrDBeSh2rm7Nw4ULi4uKILSl4w4YNxMTEEBcXR7du3QD44IMPaN26Nfn5+QwdOpQbb7yR4ODgCvkcOnSIZcuW8e6773LTTTfx5ZdfVlkXatSoUWzZsgWlFO+99x4vvPAC//znP3n66acJDAxk7969AJw5c4bU1FRmzZpFdHQ03bp1IyPD0YcjGgyGi5WLSjBqx64Szl8qZdiwYaViAfDqq6+ycuVKABITEzl06FAVwejWrRtRUVEADB48mGPHjlXJNykpiRkzZpCcnExRUVFpGT/88APLly8vTRcUFMTq1asZM2ZMaZrWrVs36TUaDIYLj4tKMGrrCVitheTl/YaXVzju7s6tPH19fUvfb9iwgR9++IHNmzfj4+PD5ZdfXu0y556enqXvXV1dq3VJPfTQQzzyyCNMnTqVDRs2MH/+fKfYbzAYLk7MGEYJOqy26aOk/P39yc7OrvF4VlYWQUFB+Pj48Ouvv7Jly5YGl5WVlUXHjh0BWLx4cen+8ePHV3hM7JkzZxg+fDjR0dEcPXoUwLikDAZDnRjBKMU5UVLBwcGMHDmSvn37Mnfu3CrHJ06ciMVioXfv3sybN4/hw4c3uKz58+czffp0Bg8eTEhISOn+v//975w5c4a+ffsyYMAA1q9fT2hoKIsWLeKGG25gwIABpQ92MhgMhpowy5uXIGIjJycGD4+OeHq2d5aJ5yVmeXOD4cKlRSxvrpT6QCmVopSKq+H45UqpLKVUbMn2RLljE5VSvymlDiul5jnLxor2uADKLEBoMBgMNeBMl9RHwMQ60vwkIlEl2wIApQcT3gCuAfoAtyil+jjRznKY9aQMBoOhJpwmGCISDTRkJHUYcFhE4kWkCFgOXNekxtWAWbHWYDAYaqa5B71HKKV2K6W+VUpFluzrCCSWS5NUss/p6M6N6WEYDAZDdTTnPIwYoIuI5CilJgH/AXrUNxOl1P3A/QCdO3dupEnmIUoGg8FQE83WwxCRsyKSU/J+DeCulAoBTgCdyiUNK9lXUz6LRGSIiAwJDQ1tlE3GJWUwGAw102yCoZRqp5RetUkpNazElnRgO9BDKdVNKeUB3AysOjc2tQyXlJ+fX3ObYDAYDFVwmktKKbUMuBwIUUolAU8C7gAi8jbwO+BBpZQFyAduFj0pxKKU+j2wFh229IGI7HOWnRVxNT0Mg8FgqAFnRkndIiLtRcRdRMJE5H0RebtELBCR10UkUkQGiMhwEfml3LlrROQSEYkQkWedZWNltEuq6Zc3L78sx/z583nppZfIyclh3LhxDBo0iH79+vH111/XmVdNy6BXt0x5TUuaGwwGQ0O5qBYfnPPdHGJP1bC+OWCzFSJShKurv8N5RrWL4pWJNa9qOGPGDObMmcPs2bMBWLFiBWvXrsXLy4uVK1cSEBBAWloaw4cPZ+rUqaha1lavbhl0m81W7TLl1S1pbjAYDI3hohKMuim/xHk9HopRCwMHDiQlJYWTJ0+SmppKUFAQnTp1ori4mMcee4zo6GhcXFw4ceIEp0+fpl27djXmVd0y6KmpqdUuU17dkuYGg8HQGC4qwaitJwBQVJRCYeFxfH0H4OLi3mTlTp8+nS+++IJTp06VLvL36aefkpqays6dO3F3d6dr167VLmtux9Fl0A0Gg8FZNPfEvRaFsx7TOmPGDJYvX84XX3zB9OnTAb0UeZs2bXB3d2f9+vUkJCTUmkdNy6DXtEx5dUuaGwwGQ2MwglEB+xLnTRspFRkZSXZ2Nh07dqR9e70S7m233caOHTvo168fS5YsoVevXrXmUdMy6DUtU17dkuYGg8HQGMzy5uWwWM6Sn38Qb++euLk5PvB9oWOWNzcYLlzqs7z5RTWGUSMiIFLqkmoJk/cMBoOhpWFcUiKwaxckJ2N3SZnJewaDwVCVi0IwanW7KQXu7lBYWO653qaHYedCclkaDIbGccELhpeXF+np6bVXfB4eUFhI2e0wPQzQYpGeno6Xl1dzm2IwGFoAF/wYRlhYGElJSaSmptacKD0d8vIQEQoL03BzK8bNrSHPfrrw8PLyIiwsrLnNMBgMLYALXjDc3d1LZ0HXyPPPw7x5cPYs0buG0LHjbCIiXjw3BhoMBsN5wgXvknKI8HD9Gh+Pq6s/Fkt289pjMBgMLRAjGFBFMKxWIxgGg8FQGSMYUEEw3NyMYBgMBkN1GMEACAqCVq1MD8NgMBhqwQiGnYgIM4ZhMBgMtWAEw054OBw5YnoYBoPBUANOEwyl1AdKqRSlVFwNx29TSu1RSu1VSv2ilBpQ7tixkv2xSqkd1Z3f5ISHw7FjuClfIxgGg8FQDc7sYXwETKzl+FFgrIj0A54GFlU6foWIRDm6imKjCQ+H4mI805QRDIPBYKgGpwmGiEQDNU6XFpFfRMT+VJ8tQPNOJy6JlPI8UYzVmmMWIDQYDIZKtJQxjHuBb8t9FuB7pdROpdT958SCiAgAPJLyAbBac89JsQaDwXC+0OxLgyilrkALxqhyu0eJyAmlVBtgnVLq15IeS3Xn3w/cD9C5c+eGG9KpE7i64pGUA0PBas02D1EyGAyGcjRrD0Mp1R94D7hORNLt+0XkRMlrCrASGFZTHiKySESGiMiQ0NDQhhvj5gZduuCWmAlgxjEMBoOhEs0mGEqpzsBXwO0icrDcfl+llL/9PTABqDbSqskJD8ctIQ3AzMUwGAyGSjjNJaWUWgZcDoQopZKAJwF3ABF5G3gCCAbeVEoBWEoiotoCK0v2uQFLReQ7Z9lZgfBwXHdtB0wPw2AwGCrjNMEQkVvqOH4fcF81++OBAVXPOAdEROCSnoVrrhEMg8FgqExLiZJqGZSE1nolQ3FxLQ9cMhgMhosQIxjlKREMn1Pu5OYeaGZjDAaDoWVhBKM8JYIRkBZKXt6+ZjbGYDAYWhZGMMrTqhUEBeF7ypfc3P3NbY3BYDC0KIxgVCY8HO9kKCw8bkJrDQaDoRxGMCoTEYFHkl4WJC/P9DIMBoPBjhGMyoSH45KYClaMW8pgMBjKYQSjMuHhqOJivDM8yc01A98Gg8FgxwhGZUoipVpldDKRUgaDwVAOIxiVKREM/9PBpodhMBgM5TCCUZlOncDdHd9TXhQWJmKxnG1uiwwGg6FFYASjMm5u0LUrXicsAOTlmRnfBoPBAEYwqqd7d9yP6+diGLeUwWAwaIxgVEdEBCo+ERdlIqUMBoPBjhGM6oiIQJ09S0DxJWbynsFgMJRgBKM6uncHIDCtg+lhGAwGQwlGMKojIgIA/9OBJlLKYDAYSnBIMJRSf1BKBSjN+0qpGKXUBGcb12x06wZK4X3SFTBLhBgMBgM43sO4R0TOAhOAIOB2YGFdJymlPlBKpSil4mo4rpRSryqlDiul9iilBpU7dqdS6lDJdqeDdjYNXl4QFoZnUj5gFiE0GAwGcFwwVMnrJOBjEdlXbl9tfARMrOX4NUCPku1+4C0ApVRr4EngUmAY8KRSKshBW5uG7t1xPXoKFxdvM45hMBgMOC4YO5VS36MFY61Syh+w1XWSiEQDGbUkuQ5YIpotQCulVHvgamCdiGSIyBlgHbULT9MTEYE6Eo+PTy8jGAaDwQC4OZjuXiAKiBeRvJIewN1NUH5HILHc56SSfTXtP3dEREBKCv5cQUbez+e0aIPBYGiJOCoYI4BYEclVSs0EBgH/dp5ZjqOUuh/tzqJz585Nl3FJaK1/ShuSfZKwWLJwcwtsuvwNBoPTKS7Wm49P0+UpAnl5kJWl83ZxAaX0q68v+PmBq2tZeotFp83LA3d38PTUm5eXPqeyvVlZkJkJhYX6s8UCNhsEBEDr1hAUpM9LSoIjR+DwYcjNhT/+semusSYcFYy3gAFKqQHAn4D3gCXA2EaWfwLoVO5zWMm+E8DllfZvqC4DEVkELAIYMmSINNKeMuyhtSmtoCtkZf1McPCkJsveYDhfsVigqAhyciA5WW+nTul9gYFlW3ExZGTo7cwZ/VlEb66u0LYtdOgAHTvqyjAjA9LSID1dV5r5+VW3vDz9CjoP+yaiK1WbTR9PTITjx7VtItqeDh30BtqeM2fg7Flo1QrCwrQdoaHaDvt1paeXXbdS+hqzsvQ9qA0/Py0eOTm6Mq8JV1ctHh4eOu+8PMe+A1dXsFrLPoeEwJw52kZn4qhgWERElFLXAa+LyPtKqXuboPxVwO+VUsvRA9xZIpKslFoL/KPcQPcE4K9NUJ7jlAiG7ylPXCP8SEtbZQTD4FREICVFV3SZmboyO3u2rBKxV7ZWa1nLubhYV5Ll8ygshIIC/VpYqFujrq76tbhYl5GSAqdPV62g3Nx05WXfCgsrVtiFhRXLO1d4eoK3t+4peHnpitFqLdvKt/K9vPSi0xMnQufO+jqSk+HkSb0BtGsHvXtrocrM1K31zZv1fQkO1sJyySX6vYuLvq+gewjlRdHDo6JY5eaWfW+5uVo0WrXSaX189P23fy+FhVokior0ew8Pndae3stLl+fmpq/t7FktYBkZ+rvo1k07Qrp312LnbLEAxwUjWyn1V3Q47WillAvgXtdJSqll6J5CiFIqCR355A4gIm8Da9AD6YeBPErGRUQkQyn1NLC9JKsFIlLb4HnTExAAoaG4xCfQespE0tNXI/Im+tINFwuFhRAXB7t36wqrc2ddGbVvD9nZkJqqK5n0dF1JFxToP3NWVlkrNTlZp7VadcvUatUVoJ+f3jw9y9wLOTmNt9nu7vDy0pWQvTKzWnXl06aNbt337KkrNHtFYxcjewVWXKzP9/Yu2+zuFA8PfW67dvpetGun92dllW0eHtqFYnejuLvrspTS9+HUKV2Bnzih70/r1rqlHBysK0x7mV5eFV08huZDidTtxVFKtQNuBbaLyE9Kqc7A5SKyxNkG1ochQ4bIjh07mi7Dyy4DLy9OLb2bX3+9g0GDthMQMKTp8jc4FRHtdjh1qqyFeeRI2ZacXNGnXHlLTIS9e3XF2RD8/XVl2r69bn+4uenN1VVXyHZ3RX6+biFGROita1ddwQYE6M3Hp6xSt7eiPTy07e7uVf3gBkN9UErtFBGHKjaHehgickop9SkwVCl1LbCtpYmFU4iIgOjoEleUC+npq4xgnCNEtKvg9GlduVosesvOhmPH4OhR/ZqRoStge0Wck1PW6k9N1a3l8iilewgRETBqlM7T7h4oKNDpc3P159BQeOQRGDwYBg7UwnH8eJlvvKQTSps2unXs41PWIvb31y1wg+FCwiHBUErdBLyIHnhWwGtKqbki8oUTbWt+IiLg009xt/kRGDiKtLRVdOu2oLmtOq+xWLQIHDtWtqWk6J5AZqZ+tfcG7IOb1eHqqiv+kJAyd4vFoivpDh1gwABdmdtdJvatSxddoTeU3r0bfq7BcL7j6BjG34ChIpICoJQKBX4ALmzB6N5dN3WPHiUkZCpHjvyZgoIEvLy6NLdlLRKbrUwMfvsNDh7Ur/aeQEaGHrirTGCgHugLCtKvQ4eWRc+0a1dx8M/bW7tswsL0Z4PBcO5w9C/nYheLEtK5GFa6LYmU4sgRgq/QgpGWtpqwsN83r13NgIgemN22DXbs0OMCeXl6y83VA5cJCdqVY8fNTd/C8HCIjCwb/GzTRkd4dO2qB5GbMkbeYDA4D0cF47uSUNdlJZ9noCOcLmxKJu9x+DA+kyfj49OL9PRVF5xg2MUgP79srCAzE379FQ4c0FtsrO49gG7tt29fFubo46NdQNddp0WgSxcdktitm+kFGAwXEo4Oes9VSt0IjCzZtUhEVjrPrBZCSIgevTxyBIDg4KkkJb183s/6Li7WrqKffoING/SWklJ9Wm9v6NULrr5au4qGDdPi4Ol5Li02GJzEb7/pVo6zf9BFRboeOc8HwRxu/4nIl8CXTrSl5aGU9qkcPgxASMhUEhNfICNjLW3a3NTMxtWOfRJY+TDSAwdg3z49tmAPFe3YESZM0BHE5UM/fX21UHTubMI2DRcoJ05A377w/PM6HM6ZvPWWXrsjJgaiopxblhOpVTCUUtlAdRM1FCAiEuAUq1oS3bvDnj0ABAQMx909hLS0VS1OME6fhuho2LlTbzExepDZjlJ6LKFPH5gyRY8pjBih952LGaIGQ4tj9Wrtf920yfmCsW6dbsUtWABffeXcspxIrYIhIv7nypAWS0QEfP01WK0oV1eCg68lLe0/WK0FuLo2Ij6zkWRn6970t9/CN9/owWjQ4wv9+sENN+jX7t3LJoMZN9L5T05RDm4ubni5Nd9vry4sNgspuSm09W2Lq0vdU7SLrEXEnorlcMZhjmQc4fCZw7goFwa2G8jg9oMZ0G4Afh5+TW/oqlX6dfv20l02seFSaTUHEeFMwRkSsxIJ8g6ic2A9Fzm1WrX/188PVq7UA4LnaS/DDEnWRffu2n9z7BhERNC27UxOnfqItLSvaNv2VqcXn5UFW7fCzz9rUUhI0APU2dn6uFJ6XOHpp/U4Q//+F44wHM86zlMbnuLWfrcyLnxcrWkLLAW8H/M+NrFxS79bCPEJqXA8rziPfSn7GNxhcJUKobkQEQ6mH2Rvyl6ujrgaf8+q7TMRYV/qPr499C1rDq9h0/FNtPJqxfyx87l/8P24u9a5Qk8F0vPS2Zm8kx0nd7Dj5A7cXd25pvs1TOw+kXZ+7Wo+sbhYt5KvuQaUYu/pvXwY+yFnC8+SW5xLTlEOqbmpJJ1NIjknGZvYGNJhCKtuXkV7//ZVsrOJjU3HN7F071I+3/85Gfll3eGO/h0pthXzUexHAChUBcFQStEntA+XhV3GyM4jGdlpJG392tZoutVmJSY5hnXx69iYsJHLwi7j8cF/xOV//9Mx3UlJcOoUHyZ/y+w1s7GKFX8PfwI8A3BRLpzMPkm+RU8KclWu3DPwHp4c+yQdA/QTF0SEmOQYvjzwJX4efkSGRtK3TV+6BXXTv7XYWB1P/uab8Ne/woIFpHz8NttPaKFyUS64KBc6BnSkd0jvKiJrExvpeemE+ISgKrkDCiwFfLz7Y+JS4vj3Nc5fQNyhpUHOF5p8aRDQ7qgBA+DDD+GuuxCxsXXrJXh6hjFw4IamLauEY8dgxQr4/HPtXhLR4wh9+0KPHnrcoWNHHY10xRU6TPVCIyU3hdEfjuZg+kEArr3kWl646gV6h1YcNBQRvjrwFXPXzeVo5lEA3F3cmdJzCrf3v53k7GS+OfQNPx79kQJLAQ8Pe5hXJr5S5Y9XGavNyunc06TkppCSm8LpnNMczzpO/Jl4jmYe5XjWcfKK8yi0FlJoKcRis+Dm4oa7qzvuLu54uXkR6BVIoGcggV6BtPZuTYh3CCE+IbTyakXsqVi+j/+e41nHARjSYQjf3vZtBaHLLszm9pW38/VvXwPQv21/JkZMZNvJbWw4toGewT15YfwLDGw3kONZx0nISuBk9kl83X0J9Q0lxCcEdxd3dibvZOuJrWxJ2kL8mfjS/Hu07kFucS4nXkuIAAAgAElEQVQns/WKfIPaD+KysMvo26Yvfdv0JbJNJK28WunE//wn/PnP8Msv/NTBwrXLrqXQUkiwTzC+7r74efjR2rs1nQI70SmgE95u3jz707MEeQfxzS3fMKDdAADyi/N5Z+c7vLzlZY5nHcfH3YdpvaZxfa/r6RPah26tuuHt7o2IkJyTTExyDDHJMWQWZJbaXWwtJvZ0LNtPbKfQWlhq+9RLpjKl5xT6hPYhJjmGn4//zM+JPxOdEM2ZgjMAhAeFE38mnhsDhrPk0S34PL4AeeIJXlh0J/NOLmZsl7Fc2vFSsouyyS7KpthaTEf/joQFhBEWEMam45t4a8dbuLm48YdL/0Arr1Ys2bOE/an7cVWuWKVsCVl/D39mD53No7G+tJr7OJw4gW3RO7zz3wXMm+bHWUvVhcN83X0Z3GEwg9sPJrMgk7iUOPan7ie3OJeewT2Z3mc60yOn0yWwC2/veJtXtr7CqZxTDO0wlOi7oxvU86zP0iBGMOrCZtMrtU2cCB9/DEBCwkKOHv0rw4b9ho/PJY3K3h7SGhsL0THJrIvOZvePOs9hw2DSJBg5Ur8PaMSI0bHMY1hsFrq37l5n2s2Jm/ls32f8Y9w/8HFv3CSJo2eOciDtAOO6jcPTzbGuT1ZBFlcsvoJf035l1S2riEmO4dmfniW3KJcZfWfQKaATPu4++Lj7sPrgaqITounXph8vX/0ybXzb8GHsh3yy5xNS81IBXUlc2+Nasouy+TD2Q54b9xzzRs2rtuwCSwHvxbzHwk0LOZF9osrxdn7tCA8Kp0tgF/w8/PB09cTD1QM3FzcsNgvFtmKKrcXkW/I5W3iWzIJMsgqzOJN/htS8VHKKdCUR4BnAuG7juDrianzcfbj/m/vp1qob39/+PWEurUiwpDNl2RT2p+5nwRULuGPAHYQFhAFaJL85+A1z183lt/TfHLqnHf07cmnYpQzrMIyhHYcyuP1gAr0CERH2nN7DmkNr+Pbwt+w6tavURoCbIm/i2bEL6D5sIhw7xrfPz+KG4o/pEtiFdbevo1NgpxrL3JW8iynLppBZkMlH0z4iMSuR539+ntO5p7m86+XMGjSL63peh69Hw9ZQKbQUEpMcw4ZjG/jm0DdsTtyMICgUUjL02r11d0Z3Hs348PFc2e1K2vi24d9b/80j3/2Roadd+frx/bxwb09eHg43972ZxdMW4+HqUWu58WfieWL9EyzduxRBGNlpJHcMuIPpfabj5uLG/tT9xKXE8cPRH/gs7jNaWdx4bE8gV7z1HQ9/8//4JXkb47JDeeKhL/By80JEsIqV+DPxbDuxjW0ntrHr1C6CvIK0cIdG0sG/A+vi17H+2HpsYiv9vY0PH8+8UfO4ousVdTaCasIIRlMzY4YeGEtKAqUoLDzFli2dCAubQ0TEiw3Kcvt2ePPfxaz+ryI90w2UDR6IgrZ7iXC5kkfH/oF7Rk2u0j3NK87jm4PfsHTvUqIToukT2ocRYSMY0WkEozqPoo1v1e7G4tjF3Lf6Piw2Cz2DezLlkilM7TmVUZ1HVfmRJWYlMmjRINLy0hgfPp5Vt6yqsdViExtrD69lyZ4ltPFpU+oeaOPbhtUHV7No5yK+P/I9ghDiE8K9A+/l/wb/H92CutV4X/KL87n6k6vZnLSZr2/+mkk99JLyqbmpLNi4gGVxy8gpyiltWYb4hPDMFc9w36D7KtyrImsR0QnRhAWE0TO4J0opbGLj9pW3s3TvUj687kPuirqrNH12YTbv73qfF35+geScZEZ3Hs3NfW+mnV872vi2IdQnlE6BnRotoAWWAjLyM2jj2wY3lzKP8MZjG5mybApB4sU/vjzDH28KpBgrK363gvER46vNq9hazIp9K8grzqNzYGc6B3amg38H8orzSMtLIy0vjbziPAa0G1AqNnVhExuJWYnEpcQRnRDNG9vfoLC4gPu3WYk6Df/vWkW/9lGsnbmWUN/QOvM7mX2S65Zfx46T+n95ZbcreXLsk4zpMsYhe+pDam4qaw6t4VDGIYZ0GMKIsBHVu6qsVr4eHsStk/LA05O84jweOtWFV96Mr5e78nCGHmsJDwqvMU3siZ389W/D+a6bfoBGsHcwL+eOZuaC/6BiY7X3ohqqG0sB3fNeeWAlB9IOcMeAOxjUfpDD9taEEYymZtEi+L//03GpvXoBEBd3I1lZ0YwYkYSLi2Mt57w8WL5cuzJ37gRflzxuVCsZ9q+byey0kr/vmc5t/W4jOiGaxLOJhAeFM7TD0FIfZ74ln++PfE9OUQ4d/DswIWICv6X9xs7knRRZi/Bw9eChYQ/xt9F/I8g7CBFh/ob5LIhewFXhVzH1kqmsPriaDcc2UGwrZnqf6Sy5fkmpIBRaChnz0RgOpB7gz5f9mSc3PMmkHpP46qavKvQOcopyWBy7mFe3vcrB9IMEeweTV5xX6uf1dvMm35JPWEAY9w68l0HtB/FR7Ed8/dvXiAiD2g8ixCeEIO8ggryCcHdxxypWLDYLu0/vZmvSVj694VNu6XdLjffSarOSV5yHl5tXvfz4RdYirl16LT8e/ZH3jvUn666b+W/CD6X35MpuV/LEmCcY27WxzwarPzHJMVz95mWkuRXSw6M9q2etp2dIz3NuR3lO5Zzi6UcGs6j9SSwuMOq0F9/86xSBXo7PQ8orzuOVLa8wuvNoRncZ7URrS7DZao8F37QJRo9m5+KF3JnzMTMPevHop8dQKan1CxnMztZRJrUtThYTA4MHs/7dx9jay5/7Bt1HSKGrjkK56ir4sgEzFYqLdXx8Ew2c10cwEJELZhs8eLA4hcOH9bNrXn+9dFd6+neyfj1y+vRndZ7+668ic+aItGqls4mMFHl99HLJwl8ExHpgv/R9s6/0er2XWKwWKbYWy4q4FXLl4ivlktcukR6v9pCIf0dI91e7y71f3ys/xv8oFqulNP+C4gLZnLhZ7v7P3aLmK2n9fGt5ZfMrcvtXtwvzkXv+c48UWYpK02cVZMk/ov8hzEdGfTBK0vPSRUTkwW8eFOYjX+7/UkRE3tnxjjAfmbZ8mpwtOCtf7f9KZnw+Q3ye9RHmI8PeHSaf7vlUCi2FUmQpkm1J2+TlzS/LA6sfkNW/rZZia3GF+5CYlShP/PiETPh4ggx7d5j0eLWHhLwQIoHPBUrw88HS5sU20ulfneS9ne816uuqi7MFZ2XwE+2E+Qjzkd6v95Y/r/2zbEnc4tRy68Rikd8iWsljVyIZ8+Y0ry12du8WATn03Fx5+dlrJdcdkdTU+udz+rSIzdb09lXm9ddFgoNFVq2qOc3cuSLu7iJZWfrzm2/qP+bRo/Ura8AAkYkTa7+uf/5T552UVHH/vHkiLi5V9zvCnDk6z7Vr639uNQA7xME6ttkr+abcnCYYNptIly4i119fbpdVojd1lk9+HCrbT2wXq81a4RSrVeSLr3Nk6HXbBNdCcXcXuflmkY0bRWzvva9v/YQJIiBffPQXYT7yye5PGm3qruRdMm7xuNLK8JmNz4ithh/0Z3GficfTHtLztZ6lAjL3+7kV0ry29TVhPuK2wE2Yj4S8ECIPrH5ANidubrStzUnadRPkgyjkyGW9z01F5ghbt4rYH6w3fnxzW6O5914Rb2+R9HSR9eu1bd9+W788TpwQ8fAQeeklp5hYSkaGbpW5uWk7FyzQf8TKXHKJ/u/Z2b5dp1+xwvGyfv217Luq7X5MnSrSvXvV/QcP6nMXLnS8TBGRI0e02IFI794iRUV1n1MHRjCcwd13i7RqJcmZSfL0xqdl/JLx4vOMR2nFHPJCiNz25W2yaNtHcsM/nxefB8YJf9fHw54aJtsPHdP5bNmi/zzjx4tkZIhVIf2faieXvHZJhV5DY7DZbLL28FpZc3BNnWmjj0VL0MIgYT5y+UeXV+kViOiexqxVs2Tt4bXVHj8v6dxZxNdX/wU2txDxe+opEaVErrtOt5KbW8hSU0W8vET+7//057NntX1PPVW/fD76SN/nVq10pe4s/vrXsu9z5kz9/oYbtN127BV9OW+BFBbq/+TcuVXzrInnn9f5dOgg0reviKWa/67Foq/5vvuqz2PUKJGePev3Pc+YoQX8rbd0+f/+t+Pn1oARDGfwySeS6Yn0fqmbMB/p/1Z/eXDVXfLEZ0r+ue5aueXzmeL3VGipgHg90lcmvfInefnnVyXguQAJWhgkq7d+rH9g3brpFpuIfHWZrqyXxC5xnu11cCD1gMz+72w5lX2q2Ww4p5w5o3/6jz0m4u8vcvvtzW2RZvhwkUsvFXnjDW3fsWN1n+NMUfnHP7QdcXFl+yIjRSZPrl8+t98u4uenxeYvf2laG+0kJ4v4+Ijccov+bLOJvPyyiKurSNu2WvTWrBF5+ml9TQkJFc8fOlTk8ssdL++yy0QGDtS9EhB5//2qaWJi9LGPP64+j/dLPA2//OJYmfYe6N//rq9vwgQtSA1xEZajxQgGMBH4Df3M7nnVHH8ZiC3ZDgKZ5Y5Zyx1b5Uh5zhSM4qTjcvVMxG2+i/wY/2Pp/l27bpRHH50tnTtbBGWVwZN2y/I1SRX+x4fTD8vAtwcK85E/XuMiOzYsk4LiArHZbBL1Zz/pMdfrwmm5nw/89JP+6f/3vyKzZ+vWZSP/dI0mLU37tJ98UvdCQeSrr2o/x2oViYoSeeCBphWO7Gw9BtChg8hVV1U8dvfdIqGhjpdns+l8brpJ5I47dI8lMbHpbLUze7Z2RR06VHH/xo0iv/tdWW8S9D2rzP/7f7rxUJ0LqzKnT2vxmz9fX9/w4SLt24vk5FRM9/LLurzjx6vP5+xZLXL331/12MaNFe+TzSYyZoxImzZlPaZ9+7QgPvBA3TbXQosQDMAVOAKEAx7AbqBPLekfAj4o9zmnvmU6UzAeXvOwMB95d2af0n3JySJDhuQKiPTrlyjff1/z/yh/+2a5fwqlPRD3Be7S6/Vewnxk8XDv5nc/1IbV2rLtqy/2Fvzx47r1DNrF0JwsWyal7pS8PF0R/O1vtZ+zc2dZJfj4401jw5VXlvnI/fxEoqMrprG7QhwdID5wQKd/5x3dY/Lw0OMiTcmRI1osaqs48/PLGgjffFP1+Icfajv376+7PHvPYNcu/XnTJikdMynPddeJRETUntcdd4gEBIjk5pbt++ILnZ+Hh8jDD+uKZtUqve/NNyue//DDuqERG1u33TXQUgRjBLC23Oe/An+tJf0vwPhyn1uMYLy1/S3dO3g0SvsPCwpk717tBvfxEXnhhVdlwwYfKShIrj4Dm03kiitEQkLkaMJu+Xzf5zJv3TyZ8PEEufbZvlLsgv5RNBdWq8iGDTWLwkMP6VaZM/zP776ru+znUpAeeEB35e1ljh2r3YTV+aHPFXfeKdK6dZkN/frpCJzasPvRb7xRvy5a1PDy4+N1xdOjh/bl/+9/IgUFVdPZReqzuqMDRUTktdd0+sOH9ec5c3Q5jlTMjjJzpv5fnjjR8DzsDYfFi+tOO3Wq/vOX/83ecIMW2PXr9YB2WppIUJDIPffUnpc9kOCTkoCXfft0PsOG6bEPV1ddybRtqwfrKw9yZ2To8a7LL2/wf6ilCMbvgPfKfb4deL2GtF2AZMC13D4LsAPYAkyrpZz7S9Lt6Ny5c4NuWG1sTdoqrk+5yuRPJ4vlK638372wW/z9dU9754rDkv/1B/Lz5y5y8LffV5/Jf/6jb/Ubb1Q9tm6dPrZ+fZPb7jAffCA1RnsUFYkEBurj48Y1SVRGKQcO6MoDtMsiM7Pp8q6Nyy4TGT267PNnn0mpi6o5sFp1hXDzzWX77rqrbtfPVVfpAdeiIpFrrtGVS3WtZ0f44x91K72uMM+iIhFPT5E//cmxfKdNE+natew6UlO166dcxGGj+PJL7R569NHG5WOxaLfV72v4D9vJzdXiVDndwYPa3Wbv8dm3ugTIatX356qr9O+/Rw/tdrK7ow4eFLntNv3drF5dfR5vvSVy660Veyn14HwUjEeB1yrt61jyGg4cAyLqKtMZPYwbP7tRWj/fWrIKskTOnJGP1F3iqiwyoGeeJE68r8KPo8gfsYwaJvKvf5V9eYWF+kfQu7dIcTXjFImJUm1X81wybJi2obpojv/9Tx+bMUO/NqW//JZb9J/073/XlV23btp/70xsNl1hzZ5dtq+wUKRdOy0klQdDzwX2wdHylYu9ZV6Tvz8vT1fcf/yj/pydLTJokG6N1lSx1ERWlr4nt97qWPrhwysKbk3Yo4Qqu6AWLJBGR6cVFuprBz1gfeZMw/OyM2aMDjqoja+/1mWuW1f1WEKCbnR9/LEev1i4UH9PdTF/vha9sWO1MGzcWDVNUzbUKtFSBMNhlxSwC7islrw+An5XV5lNLRgJmQni8pSLPLpOt14+/lhEYZXxrv+Ts/hp3+OTT4r8+KMUvfy0nJjiInmRwfq2hoZql8Ezz+jPa2oIcbXZdKX58MNNarvD7Nql7fP3FwkJqeqWmTNHV0w5OboVByKvvtr4cuPi9J9k3jz9+Zdf9FwXNzeR775rfP41cfSovoa33664/+23tWi5uuqKc+fOmvPYu1dXeiWRbo3GHo1U3i35889633/+U/05339f9XeVnCzSv3+Z+JcPJ62NV17R52zb5lj6hx/WwlRdA6g827bpfJcurbg/O1v3qEaPbljjIyFBixZoWwoL659HdfzpT/q3Xlio/weZmVUHsu+5R//vm6pMkbLfZFP9t+pJSxEMNyAe6FZu0DuymnS9SnoQqty+IMCz5H0IcKi2AXP71tSCMW/dPHF5ykUSMhPks8+09+TKiGOS5xuiByQrVRiHDv1J1q93kbzvPy6dlCcgcvXVtRc0eHDFiUTnkgce0F3pd9/Vtm7YUHbMZtODdtdcoz9brdrF4OLS+Ep9+nTtq01LK9uXkaFb+jfd1Li8a8PeQqwulDEhQeSRR7R4gv5eHntMt/gKC/XM2vLf60MPNY1No0frEM3y5Obq+/zEE9WfY5+tXLlCKyjQwu7iontsK1dql+ODD+rrGT26ojBZLCLh4SIjRzpu7yef6Ovfvbv2dM89p9OdqiZc2z67urre0IkT2hVTHbGx2mfv7y/y+eeO2+wIy5drm7y9y75jT0/dA8jP1/cqNLSi67CpePBBLVjNEFzSIgRD28GkknDZI8DfSvYtAKaWSzMfWFjpvMuAvSUisxe415HymlIw8orypPXzreXGz26Ur77SDc/Ro0Vysm01fqmFhakSHe0vu3ZdKTabVbtXHnywbMCvJmbO1INo55qzZ3WlfccduuLx8qrY09m3T/9E3nqrbF92tvabd+jgeAu2MiXLTcjf/1712N1368HCulqvDcXe46vN9sxMvaTDyJH6i4eyyKF27USefVZ/Z+7ujs2VqI3fftNlPPZY1WO1zXmIitIujJrYtEmLvb3iCwjQEVA+ProXYg9gsI+v1afytc9Sfq+OJVzsYyzVUVSkXbWRkRV7tQkJ+rfl6Vl15vX+/brCDgvT962pyc7WDYZHHtGeg5de0o0X0Pfy2Wer7zGd57QYwTjXW1MKxns73xPmI298s0Hc3UVGjHCsfjx58j1Zvx45fvxfjhdmr8QqtxYbw4oVumVZG++8o8v9+Wf9edo0/We0C+LChVKtH33LFu1OmtPA9Y6mTdMD6dVFXdkHoO021UZaWv0jY266Sbe8HSUzU8+HmDNHh17aI4eOH9dhj3VFwdSEzaZ7db6+WiAPHKia5vbbdXx/ZU6f1vfomWdqLyM7W/eoDhwom1/w/fdS+oPOydGi06VL/QTaZtNjE9XNH7CTn68bIH/4Q81pPv9cX4f9d5qersf6AgPLxtVeeEGXd+iQvhdt2zpHLGrjhx/0jGzQLtOmGC9pQRjBaCQ2m036v9Vf+r/VX8aMtUn79o4H8NhsNtm7d5ps2OAh2dl7HDvJHnddm9+8PmzcqFutHh7VuwPsDBqkW4B2gViyRCr4skeOrOoqsfPAA9rtERNTP9t27NBl1LS8RHq6zre2eQUZGbpF7usr0rFj9eGwNpt2GVUWnl69dHx8U/CHP+j7XFcFdvSojl7atk33SJKStGjaI89qGti2jy2cPFlx/9Klev/WrQ2z+4sv9D0ePFjn05A1niZM0K6sZ57Rv4XJk3Vv2h5l9eOPOu/aFgG02bQwhIXp73TUKP2bXb9eC469dX/XXboHHhysx4+ag4ICLV7//GfzlO9EjGA0kg1HNwjzkT9/+l6DxqEKC1Nk06a2sm1bP7FY8us+wR4D/umnDTO4PCdPardJ5861V8z2BdfKr6mTkaFbUPPmiaSklM08ro6MDB3+d+mlZa1Xm01H+gwbpiuMyqSkaHdIUFDtCnzZZTrypTIFBXppB3uYr70VWl1Isn3QuG/fMvvy8/U1VecKawinTmnRqs2nvXt3mb3lN/tifLXNLLbPSK/s57e77Rozb8Q++czXt2EtZvtAPehgiQED9DV5e2sxf/hhLab2FWFrYsMGnUdYmH5dvrzsmNVaFmgRGFj/xonBIYxgNBJ7KO1lY/OkY0ddz9SXtLQ1sn49cujQI3UnLiiou1XtCMXF2sXg7S2yZ48erG7XrvqIjvvu0/7syhX3hAnat2xfMG7HjprL+/hjKY04SkoSmTRJSgcNPTwq/vmTk0X69NHHvv++9utYsEC7vFJSKu63Vx7TpumKOCdHX8ODD1bNY/bssgrNLsT2SWf1WZW0Lh57TOdZ3Uzb+Hh9/8PCtFtj1Srt93/+ef391EV2dtXF/mw2kU6d9GS9xrJ8ecPvhcWie07lw0bj43WEmf2+jxjhWF6TJ+v0/6rBjbt6dcX1rAxNihGMRpCYlSguT7nIjHcflZrm2jnKb7/NlvXrkfT0OipIEb0E8vTpDS9MpKxCXVKykOF33+nPlRc/S0rSLcvq/O9vvy2lLfMOHWqP2rDPYA8I0C1Ab2/tRklL0xEC9kogKUnPUvX1dWyCoj0c0z77VUS7qvz8yhaXszN9uvZrl29tFxfrwdEbb9Q9mogIPchqF8HqxgsaSkaGvvbJkyvGyp8+rb/ToKDGVXa9eumZxXbsq61WDgtuSezYoWc+L1vmWPrU1IZPODQ0GiMYjeDFn18U5iMDxx2STp2qXx3BUSyWXNm6NVI2bQqVgoI6BmenTNHLQTQU+1oz5QcirVY9WDdkSFnFX1SkfcV+ftX73pOTdasWypa1ro0DB3Qrf8yYigu/5eeXLVnRqpUOg9y0ybFrsVq1m2PmzLJ9Tz6p86rsw7avFlpeiOxCuXKlbp2CXjbjkUf0QGxTR2DZ3TMBAXqhu/ff1+MD3t6ODd7Xxm236fs7a5buEdgnvR050jS2Gy56jGA0goFvD5SeLw2rEk3aUHJy9snGjT4SEzNWrLWtSDt3rg4lrMkvvWmTdunYew/lOXZMt2QHDqzqP7MvtGefd/CXv0idoYGjRuk0jrb6srKq74lYLHpguF27+g/Q3nab7iVYrTo8LSio+sHq6txSd9yhW/0FBdquESP04PioUboib2qsVh2NNGuW7pVB45bpKE9MjL7u8uMg4eGNz9dgKMEIRgPZn7JfmI90mfGKdO7cdJM5k5OXyPr1yJEjtaw+ah+ErG7OxvLlWkzc3KrOhC4q0rNeAwKqPzc7W1c2M2aU9UKq8/mX58MPdeipI8saOEJDJiPZx0e2by9bZK+mmcjl3VJ5ebr3VN7dZl/gzR5x40xsNj17fvv2ps23uFiL7nPPOXcmvOGiwwhGA3n8x8fFZb6L4HeyQvBQU3DgwL2yfr2S9PQa/uz2qJ7yrVKbrWwuxKhRepAxKkpXiPYQ3D//WeocyP3Tn3SLt1UrHUrbkFH8c419rsFjj2kxqO2RpeXdUvbY/h9+qJhm/HipdWDVYLhIMYLRAGw2m0T8O0L6Pn+VQNMHZVgsebJtWz/ZtClE8vOreaBKWppUiInfv1+7ZUCHbdor+RMndMhsu3Zl7qa6egz2pasDA88v3/eQIWUzrMsvWVKZ8m6p66/X96aya2/HDt0La6q5LgbDBUJ9BMMFAwDbT27nyJkjdD57K+7u0KNH0+bv6upNZOTn2GxFxMVNw2rNq5ggOBhCQ2HlSrjySujTBz7/HB5/HD79FLy8dLoOHeDbb6GgAGbPhqgo+Ne/ai+8WzdYvFifFx7etBfmTCZOhOJiGDkSxoypOZ2vL0yerO/XmjUwYwa4ulZMM3gwZGbCoEHOtdlguIAxglHC0r1L8XT1xBp3Az17godH05fh49OT3r0/JSdnF7/9Nkt38coTGQk//wzx8fDcc5CYCAsWgEulr6lPH1i1SgvLihVlYlIbM2fCiBFNdzHnghtuAHd3mD8flKo97fTpkJYGhYVw663Vp6krD4PBUCuqSqV1HjNkyBDZsWNHvc+z2qx0/FdHRnYeScyjXzJiBCxd6gQDSzh27BmOHXuc8PAX6dz5z2UHfv0VEhLgqquqtpAvVvLzwdu77nS5udCmDbRvD4cOGXEwGBxEKbVTRIY4ktbN2cacD6w/tp7Tuae5PuJWvjoGs2Y5t7wuXf5GTk4s8fGP4ufXj9atr9YHevXSm6EMR8QCtFvqjTe0aBixMBicgnFJod1RAZ4BhBVMAqBvX+eWp5SiV6+P8PWNZN++GZw9u9W5BV4s3HUXTJrU3FYYDBcsF71gFFgK+PLAl9zQ+wYOH9Ct2X79nF+um5sf/fp9g7t7MLt3jycr62fnF2owGAyN4KIXDDcXN5bduIw5l85h717t2ejS5dyU7eXVmaiojXh4tGP37qvJzIw+NwUbDAZDAzCC4eLGpB6TGNBuAHFxOlCpclCSM/HyCiMqaiNeXp3Ys+cazpz58dwVbjAYDPXAqVWjUmqiUuo3pdRhpdS8ao7fpZRKVUrFlmz3lTt2p1LqUMl2pzPttBMXd27cUZXx9GxPVNQGvL3D2bt3CllZm8+9EQaDwVAHThMMpZQr8AZwDdAHuONewbIAABYfSURBVEUp1aeapJ+JSFTJ9l7Jua2BJ4FLgWHAk0qpIGfZCpCSojdnD3jXhIdHW/r3X4eHR3v27p1MTk5c8xhiMBgMNeDMHsYw4LCIxItIEbAcuM7Bc68G1olIhoicAdYBE51kJ6B7F9A8PQw7np7tGDBgHS4u3uzZM4H8/KPNZ4zBYDBUwpmC0RFILPc5qWRfZW5USu1RSn2hlOpUz3ObjL179Wtz9TDseHt3o3//tdhsBezePZ7CwuTmNchgMBhKaO5B79VAVxHpj+5FLK5vBkqp+5VSO5RSO1JTUxtsSFwchIToeV/NjZ9fX/r1W0NR0Sm2b48kKel1bDZLc5tlMBgucpwpGCeATuU+h5XsK0VE0kWksOTje8BgR88tl8ciERkiIkNCQ0MbbKx9wLulTBIODBzO4MFb8fMbyOHDD7Fz50ATQWUwGJoVZwrGdqCHUqqbUsoDuBlYVT6BUqp9uY9TgQMl79cCE5RSQSWD3RNK9jkFm00LRnO7oyrj6xvJgAE/EBn5JVZrDrt3j2PfvpsoLKxWOw0Gg8GpOE0wRMQC/B5d0R8AVojIPqXUAqXU1JJkDyul9imldgMPA3eVnJsBPI0Wne3AgpJ9TuH4ccjJaXmCAXoZkdDQGxg69ABduy4gPX0127b1IjHxZeOmMhgM5xSzWi3wzTcwZQr88kvLXwE8Pz+eQ4ceIiNjDb6+/YmM/AIfnyZ+eIfBYLhoqM9qtc096N0isEdIRUY2rx2O4O0dTr9+3xAZ+RVFRSeJiRlBVtYvzW2WwWC4CDCCgR6/6NwZAgKa2xLH0G6q6xk4cDPu7q2Jjb2SlJTPm9ssg8FwgWMEg+ZbEqSx+Ph0Z+DAX/D3H8L+/Tdx/PiLVZ/iZzAYDE3ERS8YxcX6QXctccDbETw8Qhgw4AdCQ28iPv4vxMVdT3Gx0+IDDAbDRcxF/8Q9NzcdJXU+4+rqRZ8+y0lKGk58/KPs2BFF795LadVqVHObZjAYLiAu+h6GUtC2rd7OZ5RSdOr0RwYO/AWlPIiNHcvRo49jteY1t2kGg+EC4aIXjAuNgIAhDBkSQ9u2t5GQ8Axbt17CqVMfI2JrbtMMBsN5jhGMCxA3twB6915CVFQ0np7t+fXXO4iJuZQzZ340g+IGg6HBGMG4gGnVajSDBm2lV68lFBYms3v3OHbtGk1GxvdGOAwGQ70xgnGBo5QL7drdzqWXHqZHj9cpLExgz56riYkZwdmz25rbPIPBcB5hBOMiwdXVi44dZ3PppYe55JJ3KCo6wa5dI0vmbpjxDYPBUDdGMC4yXFw86dDhfoYM2UNw8FTi4//Cnj2TKCpKaW7TDAZDC+ein4dxseLuHkRk5BecPPk2hw//kW3b+uDvPwRPzzC8vDrh69ufkJBpqJbygBCDwdDsGMG4iFFK0bHjgwQGjiIh4RkKCo6Sm7uboqLTgNC69UR69nwfT88OzW2qwWBoARjBMODn14/IyM9KP9tsRSQnv8uRI3PZvr0fl1zyDm3a/K4ZLTQYDC0BM4ZhqIKLiwcdO85myJBdeHtHsH//dPbvn2nWqDIYLnKMYBhqxMenJwMH/kzXrvNJTf2M7dsjSUv7urnNMhgMzYQRDEOtuLi407XrkwwatA1397bExU1j//7byM3dh9Va0NzmGQyGc4hTxzCUUhOBfwOuwHsisrDS8UeA+wALkArcIyIJJcesQMmz8DguIlMxNBv+/gMZPHgbx48vJCHhaVJSlgIKT8/OeHt3p3Xr8bRpczNeXl2a21SDweAknPZMb6WUK3AQGA8kAduBW0Rkf7k0VwBbRSRPKfUgcLmIzCg5liMifvUps6HP9DbUj/z8I5w9u4X8/MPk5R0iL28fOTmxAAQEXEbbtrfStu1M3NwCm9lSg8FQF/V5prczexjDgMMiEl9i1HLgOqBUMERkfbn0W4CZTrTH0ER4e0fg7R1RYV9+fjwpKctJSVnGoUO/Jz5+Hu3a3UtY2MN4e4c3k6UGg6EpceYYRkcgsdznpJJ9NXEv8G25z15KqR1KqS1KqWnOMNDQdHh7h9Oly2MMHbqXQYO2Exx8HSdPvsHWrd3Zu3cqp04tpqgorbnNNBgMjaBFzMNQSs0EhgBjy+3uIiInlFLhwI9K/f/27j04rvo64Pj33N3VvleSJfmBZYONGWNMiA3U2AHyMKSA08Q0QxsgzaSZdMgfJA1MZtowfYZ/+g7tdEjCIxQKFFIoNI7ThIIhpBCCY7CJbbDBYGJblixb1q5e+97TP+7PRraFWYGlu7bOZ2ZHe+/evXt2712dvb/fvecnm1X1zTGeewNwA8DcuXMnJV5zfJnMhZxzzgMUi39PV9ft9PTcS1/fjwCPTGYFbW1X0dx8Cen0bxEKJYIO1xhTp4nsw1gB/LWqXuGmbwFQ1b85arnLgX8FPqaqYxY0EpF7gbWq+ujxXtP6MBqTqjI09DIHDvyIvr41DA1tBEAkTCq1lPb2qznttK8QibQFHKkxU894+jAmMmGE8Tu9LwO68Du9r1fVraOWWQo8Clypqm+Mmt8KjKhqUUTagReA1aM7zMdiCePkUC73MTDwS3K558lmf87AwPN4XpyZM79EZ+fNJBILgg7RmCmjITq9VbUiIl8FnsA/rfYeVd0qIrcCG1R1DfAPQAp4xBW5O3T67CLgDhGp4fez/O17JQtz8ohE2mhr+xRtbZ8CYGhoC3v2fJvu7rvZu/e7pNPLaG29nGnTPkkmswLPawo4YmMMTOARRhDsCOPkVix20919NwcP/sQN7lTF8xKk0xeQTi8jk1lGJrOcWMz6qow5URqiSSoIljBOHZVKjmz2Z/T3P83g4HoGBzeiWgQgkVjEtGmraGtbRSq1lFqtSK2Wp1bLE43Otus/jBkHSxjmlFOrlRge3kw2+3MOHvwJ2eyzqJaOWU4kQkvLSjo6fpe2ttVEozMDiNaYk4clDHPKq1SGyGafJp/fgeclCIXiiEQZGtrIgQOPkc/vAIRkcjHp9EVkMheRySwnmTzXBoUyZhRLGGZKU1WGh7fS1/dDcrnnGRh4kUrFL83e1DSb9vZP09a2mtbWT+B50WOeX63mKRR20tQ0k0hk2mSHb8ykaoizpIwJioiQSp1LKnUu4CeQfP5Ncrnn6OtbS0/P/ezd+z1EwoTDbUQi7e4aEH+5UmkvAJ4XZ9asP2LOnG8cUVRRValWBwmF0na0YqYUO8IwU061WiCbfYZc7jnK5f2Uy32UywcAJRabTzx+JrHYPLLZdezb9wAA06dfRzjcwvDwZoaGNlOp9BGJzCCTWU4ms5xUaok7/Vfwq/jOJpE4K8i3aUxdrEnKmBOkUNjF7t3/RHf3XYBHMnkuqdSHiMXmMzKyjYGBF8jn3xjzuS0tK5k9+2u0t38av3jz2FTVjlRMYCxhGHOC1WolRMKIHFuvs1Q6wMjINqCK/31SBgfX09X1HYrFXUSjp9PautIlDQ8QyuX9FIu7KBR2Uy7vp7n5UmbMuJ6Ojmus38RMKksYxjSAWq1CX98aurpuJ59/HdUaUEO1RiTSRjQ6l1hsLqFQhr6+teTz2xGJ0Np6GanUUhKJs0kkziYeP5NwuOW4RynGvF+WMIw5yfgFGjfR2/sf9PX9mHz+DVQro5YQwuFWIpE2RJqo1QrUagVUi4iE8bwkoVACz0sQibQRiXQQibQTCqUolfZSKOyiWPwNILS3f5YZM64jmVwc1Ns1DcQShjEnuVqtTKHwFiMj2ygU3qZcPki53Eel0ketVsLz4nheFM+LolqhWh2hVhumWh1yy+6nXN5PrVYgEplBLDaXaHQu1WqO/v6ngRrJ5IdIp5ehWka1RK1WolYboVr11+NfOd856kjnLHeqsZ+MPC8S9MdkTgA7rdaYk5znRUgkFpJILPxA66nVKnjekV/zUmkfvb2P0Nv7MAcP/g+eF0WkCc9rchdBJolGOxFpoljcRU/PfVSrg8esOxyeRjQ629068bwE1erQ4VtT03QSicUkk4tJJBbheTGXnCpUKjkGB18kl3ueXO4XlEo9ZDLLaWm5lObmj5JMLnZJMeb6juykgEZgRxjGmONSVUqlbvL5HZRKvYePXkqlHorFLnfbTa1WIBRKEwqlCIUSlErdlEo9x113JDKd5uaLaWqaycDACwwNvQIc/T/JIxY7g0zmItLpZaTTFyISolLpp1LJUqlkXZIaplodxvNitLdfTTp9wRGJplIZIpd7Fs9L0Nz8kSMu2hwefpW9e++gv/9Jpk1bRWfn14649uZUZk1SxpiGUC73MTy8lZGR7ahW3dFCmFDIr0Ici80/4p96uZxlYOB58vmdqBap1QpUqyOMjGxjcHA9xeKe476e5yWo1YpAlVjsTKZP/xxNTTPo6/sx2ezPDtcf87w4zc2XksmsIJtdRy73HCJNZDIXkcv9AlA6Oj7L9OnXU6uNUCrto1TqRUSIxxe6o7+ziURaj3h9VaVQ2Mng4Mvk868Ti80nnV5KPL4AkRC1WoVC4U2Gh1+jVOpBtXL4qCscbiYWm+duc8cs618o7CaX+z+KxS6mT7+OWKzzA28jSxjGmFNSsbjXjdgYIhJpJRxuIRxuIRRK4XlxRDzK5X4OHHic3t6HXX9NlXh8oRuDZRXVap7+/qfo73+KkZGtxOMLmDXrK8yc+Yc0NbVTKOyiq+t2urvvpFLJHn5tEb/PRrV8eJ7nxV0MzYRCKfL5N6lU+o+J2/OSRKOnUSi8fcTz351HJNJBU9NMmppmEgqlGBp6iULh7VHxhOno+H06O28mk6nr//2YLGEYYwxQKu2nWh0mHj9jzMfL5SzhcGbM62uq1WGGhl5xZ51NJxxuQbVKobCTkZHtjIxso1zed7hZrFIZJBY7nXT6AlKp80kkFlIovMXg4EaGhjZRLO4hHl9AMrmIRGLR4X6iQ0ddlcpBCoWd5PM7KRTeck16+yiVeqhU+kkmz6Ol5aM0N19KONziktpdVKuDNDd/jPPO+ymhUGzcn5ElDGOMmQIqlQG6u7/PyMirLFx41/tah50lZYwxU0A4nGHOnJsn7fWOPQ47gUTkShHZLiI7ROSbYzweFZEfuMdfFJEzRj12i5u/XUSumMg4jTHGvLcJSxji1zG4HbgKOAe4TkTOOWqxLwP9qroAuA34O/fcc4BrgcXAlcB3xOoiGGNMoCbyCGMZsENV31L/XLaHgdVHLbMauM/dfxS4TPxz7FYDD6tqUVV3Ajvc+owxxgRkIhPGbGD3qOk9bt6Yy6hfOCcHtNX5XGOMMZNoQvswJoOI3CAiG0Rkw/79+4MOxxhjTlkTmTC6gDmjpjvdvDGXEZEw0Az01flcAFT1TlW9UFUv7OjoOEGhG2OMOdpEJoxfAWeJyDwRacLvxF5z1DJrgC+6+9cAT6t/Ycga4Fp3FtU84Cxg/QTGaowx5j1M2HUYqloRka8CTwAh4B5V3SoitwIbVHUN8H3gfhHZARzETyq45f4TeBWoADeqanWiYjXGGPPeTqkrvUVkP/Cb9/n0duDACQznRLG4xsfiGh+La3xOxbhOV9W62vNPqYTxQYjIhnovj59MFtf4WFzjY3GNz1SP66Q/S8oYY8zksIRhjDGmLpYw3nFn0AG8C4trfCyu8bG4xmdKx2V9GMYYY+piRxjGGGPqMuUTxnuVYJ/kWO4RkV4R2TJq3jQReVJE3nB/W4+3jgmIaY6IPCMir4rIVhH5eoPEFROR9SLyiovrW27+PFcqf4crnX/swMiTE19IRDaKyNoGi+ttEdksIptEZIObF+i2dDG0iMijIrJNRF4TkRVBxyUiC93ndOg2ICI3BR2Xi+1mt99vEZGH3PdhwvexKZ0w6izBPpnuxS/nPto3gXWqehawzk1PpgrwDVU9B1gO3Og+o6DjKgIrVfXDwBLgShFZjl8i/zZXMr8fv4R+EL4OvDZqulHiAviEqi4ZdRpm0NsS4F+An6rq2cCH8T+7QONS1e3uc1oCXACMAI8HHZeIzAb+GLhQVc/FvzD6WiZjH1PVKXsDVgBPjJq+Bbgl4JjOALaMmt4OzHL3ZwHbA47vh8AnGykuIAG8DFyEf/FSeKztO4nxdOL/I1kJrAWkEeJyr/020H7UvEC3JX4NuZ24PtVGieuoWH4beL4R4uKdat7T8Kt1rAWumIx9bEofYXBylFGfoard7n4PMCOoQNyIiEuBF2mAuFyzzyagF3gSeBPIql8qH4Lbnv8M/AlQc9NtDRIXgAL/KyIvicgNbl7Q23IesB/4N9eMd7eIJBsgrtGuBR5y9wONS1W7gH8EdgHd+MNCvMQk7GNTPWGcVNT/6RDIaW0ikgL+C7hJVQcaIS5VrarfXNCJP8DW2ZMdw9FE5HeAXlV9KehY3sUlqno+fjPsjSLy0dEPBrQtw8D5wHdVdSkwzFHNPAHv+03AZ4BHjn4siLhcn8lq/ER7GpDk2KbsCTHVE0bdZdQDtE9EZgG4v72THYCIRPCTxYOq+lijxHWIqmaBZ/APw1tcqXwIZnteDHxGRN7GH2VyJX77fNBxAYd/naKqvfjt8csIflvuAfao6otu+lH8BBJ0XIdcBbysqvvcdNBxXQ7sVNX9qloGHsPf7yZ8H5vqCaOeEuxBG10C/ov4fQiTRkQEv6rwa6r67QaKq0NEWtz9OH6/ymv4ieOaoOJS1VtUtVNVz8Dfn55W1c8HHReAiCRFJH3oPn67/BYC3paq2gPsFpGFbtZl+JWqA41rlOt4pzkKgo9rF7BcRBLu+3no85r4fSyoTqRGuQGrgNfx27//LOBYHsJvkyzj/+r6Mn779zrgDeApYNokx3QJ/iH3r4FN7raqAeI6D9jo4toC/KWbPx9/7JQd+E0I0QC358eBtY0Sl4vhFXfbemh/D3pbuhiWABvc9vxvoLVB4kriD+rWPGpeI8T1LWCb2/fvB6KTsY/Zld7GGGPqMtWbpIwxxtTJEoYxxpi6WMIwxhhTF0sYxhhj6mIJwxhjTF0sYRjTAETk44cq2xrTqCxhGGOMqYslDGPGQUT+wI3DsUlE7nAFEIdE5DY3PsE6Eelwyy4RkV+KyK9F5PFD4yaIyAIRecqN5fGyiJzpVp8aNSbEg+4qXmMahiUMY+okIouAzwEXq1/0sAp8Hv9q4A2quhh4Fvgr95R/B/5UVc8DNo+a/yBwu/pjeXwE/+p+8CsB34Q/Nst8/PpAxjSM8HsvYoxxLsMfSOdX7sd/HL/wXA34gVvmAeAxEWkGWlT1WTf/PuARV8tptqo+DqCqBQC3vvWqusdNb8IfG+W5iX9bxtTHEoYx9RPgPlW95YiZIn9x1HLvt95OcdT9Kvb9NA3GmqSMqd864BoRmQ6Hx8I+Hf97dKhK6PXAc6qaA/pF5FI3/wvAs6o6COwRkavdOqIikpjUd2HM+2S/YIypk6q+KiJ/jj9inYdfVfhG/AF/lrnHevH7OcAvMf09lxDeAr7k5n8BuENEbnXr+L1JfBvGvG9WrdaYD0hEhlQ1FXQcxkw0a5IyxhhTFzvCMMYYUxc7wjDGGFMXSxjGGGPqYgnDGGNMXSxhGGOMqYslDGOMMXWxhGGMMaYu/w800/vFhHASSwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.7079 - acc: 0.8201\n",
      "Loss: 0.7078870166004138 Accuracy: 0.82014537\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9959 - acc: 0.3841\n",
      "Epoch 00001: val_loss improved from inf to 1.39864, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/001-1.3986.hdf5\n",
      "36805/36805 [==============================] - 430s 12ms/sample - loss: 1.9961 - acc: 0.3841 - val_loss: 1.3986 - val_acc: 0.5430\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2138 - acc: 0.6169\n",
      "Epoch 00002: val_loss improved from 1.39864 to 0.86774, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/002-0.8677.hdf5\n",
      "36805/36805 [==============================] - 423s 11ms/sample - loss: 1.2137 - acc: 0.6170 - val_loss: 0.8677 - val_acc: 0.7466\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9536 - acc: 0.7040\n",
      "Epoch 00003: val_loss improved from 0.86774 to 0.78398, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/003-0.7840.hdf5\n",
      "36805/36805 [==============================] - 422s 11ms/sample - loss: 0.9537 - acc: 0.7040 - val_loss: 0.7840 - val_acc: 0.7741\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8225 - acc: 0.7494\n",
      "Epoch 00004: val_loss improved from 0.78398 to 0.65587, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/004-0.6559.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.8226 - acc: 0.7494 - val_loss: 0.6559 - val_acc: 0.8132\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7251 - acc: 0.7807\n",
      "Epoch 00005: val_loss did not improve from 0.65587\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.7252 - acc: 0.7806 - val_loss: 0.6809 - val_acc: 0.8071\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6629 - acc: 0.8009\n",
      "Epoch 00006: val_loss improved from 0.65587 to 0.54196, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/006-0.5420.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.6631 - acc: 0.8009 - val_loss: 0.5420 - val_acc: 0.8560\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6038 - acc: 0.8191\n",
      "Epoch 00007: val_loss improved from 0.54196 to 0.53233, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/007-0.5323.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.6040 - acc: 0.8190 - val_loss: 0.5323 - val_acc: 0.8528\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5529 - acc: 0.8351\n",
      "Epoch 00008: val_loss improved from 0.53233 to 0.49623, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/008-0.4962.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.5530 - acc: 0.8350 - val_loss: 0.4962 - val_acc: 0.8567\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5086 - acc: 0.8475\n",
      "Epoch 00009: val_loss did not improve from 0.49623\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.5086 - acc: 0.8475 - val_loss: 0.5634 - val_acc: 0.8439\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4840 - acc: 0.8558\n",
      "Epoch 00010: val_loss did not improve from 0.49623\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4840 - acc: 0.8558 - val_loss: 0.5168 - val_acc: 0.8633\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8674\n",
      "Epoch 00011: val_loss improved from 0.49623 to 0.44870, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/011-0.4487.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.4465 - acc: 0.8674 - val_loss: 0.4487 - val_acc: 0.8782\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4224 - acc: 0.8743\n",
      "Epoch 00012: val_loss did not improve from 0.44870\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.4224 - acc: 0.8743 - val_loss: 0.4713 - val_acc: 0.8663\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3953 - acc: 0.8811\n",
      "Epoch 00013: val_loss did not improve from 0.44870\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.3952 - acc: 0.8811 - val_loss: 0.4958 - val_acc: 0.8567\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3735 - acc: 0.8857\n",
      "Epoch 00014: val_loss improved from 0.44870 to 0.44802, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/014-0.4480.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3735 - acc: 0.8857 - val_loss: 0.4480 - val_acc: 0.8768\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8931\n",
      "Epoch 00015: val_loss improved from 0.44802 to 0.39892, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/015-0.3989.hdf5\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.3533 - acc: 0.8931 - val_loss: 0.3989 - val_acc: 0.8921\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.8973\n",
      "Epoch 00016: val_loss did not improve from 0.39892\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.3341 - acc: 0.8973 - val_loss: 0.4246 - val_acc: 0.8852\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.9015\n",
      "Epoch 00017: val_loss did not improve from 0.39892\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3225 - acc: 0.9014 - val_loss: 0.4355 - val_acc: 0.8896\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3100 - acc: 0.9066\n",
      "Epoch 00018: val_loss improved from 0.39892 to 0.38238, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/018-0.3824.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3100 - acc: 0.9066 - val_loss: 0.3824 - val_acc: 0.8908\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.9139\n",
      "Epoch 00019: val_loss did not improve from 0.38238\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2815 - acc: 0.9139 - val_loss: 0.4130 - val_acc: 0.8996\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2761 - acc: 0.9152\n",
      "Epoch 00020: val_loss did not improve from 0.38238\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2761 - acc: 0.9152 - val_loss: 0.4765 - val_acc: 0.8679\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9166\n",
      "Epoch 00021: val_loss did not improve from 0.38238\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2683 - acc: 0.9166 - val_loss: 0.4220 - val_acc: 0.8807\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2557 - acc: 0.9217\n",
      "Epoch 00022: val_loss did not improve from 0.38238\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2557 - acc: 0.9217 - val_loss: 0.4237 - val_acc: 0.8819\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9236\n",
      "Epoch 00023: val_loss did not improve from 0.38238\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2445 - acc: 0.9236 - val_loss: 0.4290 - val_acc: 0.8880\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9294\n",
      "Epoch 00024: val_loss did not improve from 0.38238\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2270 - acc: 0.9294 - val_loss: 0.4462 - val_acc: 0.8812\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9326\n",
      "Epoch 00025: val_loss improved from 0.38238 to 0.36210, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_6_conv_checkpoint/025-0.3621.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2155 - acc: 0.9326 - val_loss: 0.3621 - val_acc: 0.8982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9327\n",
      "Epoch 00026: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2111 - acc: 0.9327 - val_loss: 0.3653 - val_acc: 0.9050\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9364\n",
      "Epoch 00027: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.2061 - acc: 0.9363 - val_loss: 0.3900 - val_acc: 0.8968\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9389\n",
      "Epoch 00028: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1963 - acc: 0.9389 - val_loss: 0.3984 - val_acc: 0.9017\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1852 - acc: 0.9402\n",
      "Epoch 00029: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1852 - acc: 0.9402 - val_loss: 0.3855 - val_acc: 0.8998\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9435\n",
      "Epoch 00030: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1782 - acc: 0.9435 - val_loss: 0.3743 - val_acc: 0.9003\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9433\n",
      "Epoch 00031: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1784 - acc: 0.9433 - val_loss: 0.4054 - val_acc: 0.8938\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9510\n",
      "Epoch 00032: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1597 - acc: 0.9509 - val_loss: 0.3856 - val_acc: 0.9038\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9478\n",
      "Epoch 00033: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1677 - acc: 0.9478 - val_loss: 0.4146 - val_acc: 0.8963\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9504\n",
      "Epoch 00034: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 417s 11ms/sample - loss: 0.1528 - acc: 0.9504 - val_loss: 0.4127 - val_acc: 0.8987\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9519\n",
      "Epoch 00035: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1502 - acc: 0.9519 - val_loss: 0.3867 - val_acc: 0.9019\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9533\n",
      "Epoch 00036: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1475 - acc: 0.9533 - val_loss: 0.4644 - val_acc: 0.8835\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9549\n",
      "Epoch 00037: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1388 - acc: 0.9549 - val_loss: 0.4586 - val_acc: 0.8945\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9577\n",
      "Epoch 00038: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1329 - acc: 0.9578 - val_loss: 0.4181 - val_acc: 0.9015\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9613\n",
      "Epoch 00039: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1238 - acc: 0.9613 - val_loss: 0.3628 - val_acc: 0.9108\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9608\n",
      "Epoch 00040: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1223 - acc: 0.9608 - val_loss: 0.4282 - val_acc: 0.8935\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9624\n",
      "Epoch 00041: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1188 - acc: 0.9625 - val_loss: 0.4301 - val_acc: 0.8947\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9617\n",
      "Epoch 00042: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1189 - acc: 0.9617 - val_loss: 0.3855 - val_acc: 0.9080\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9586\n",
      "Epoch 00043: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1266 - acc: 0.9586 - val_loss: 0.3769 - val_acc: 0.9059\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9643\n",
      "Epoch 00044: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1090 - acc: 0.9643 - val_loss: 0.4501 - val_acc: 0.8924\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9665\n",
      "Epoch 00045: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1053 - acc: 0.9666 - val_loss: 0.4049 - val_acc: 0.9050\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9670\n",
      "Epoch 00046: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1021 - acc: 0.9670 - val_loss: 0.4253 - val_acc: 0.9022\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9685\n",
      "Epoch 00047: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0986 - acc: 0.9685 - val_loss: 0.4865 - val_acc: 0.8940\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9674\n",
      "Epoch 00048: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1007 - acc: 0.9674 - val_loss: 0.4991 - val_acc: 0.8963\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9707\n",
      "Epoch 00049: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0930 - acc: 0.9706 - val_loss: 0.4714 - val_acc: 0.8980\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9685\n",
      "Epoch 00050: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0985 - acc: 0.9685 - val_loss: 0.4847 - val_acc: 0.8852\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9698\n",
      "Epoch 00051: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0919 - acc: 0.9698 - val_loss: 0.3690 - val_acc: 0.9152\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9733\n",
      "Epoch 00052: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0847 - acc: 0.9733 - val_loss: 0.4095 - val_acc: 0.9024\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9742\n",
      "Epoch 00053: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0851 - acc: 0.9742 - val_loss: 0.3773 - val_acc: 0.9138\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9738\n",
      "Epoch 00054: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0816 - acc: 0.9738 - val_loss: 0.4603 - val_acc: 0.8982\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9704\n",
      "Epoch 00055: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0975 - acc: 0.9703 - val_loss: 0.4027 - val_acc: 0.9085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9761\n",
      "Epoch 00056: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0763 - acc: 0.9760 - val_loss: 0.3908 - val_acc: 0.9159\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9749\n",
      "Epoch 00057: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0787 - acc: 0.9748 - val_loss: 0.4213 - val_acc: 0.9099\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9728\n",
      "Epoch 00058: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0841 - acc: 0.9728 - val_loss: 0.4122 - val_acc: 0.9078\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9788\n",
      "Epoch 00059: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0682 - acc: 0.9788 - val_loss: 0.4493 - val_acc: 0.9012\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9774\n",
      "Epoch 00060: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0705 - acc: 0.9774 - val_loss: 0.3943 - val_acc: 0.9117\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9790\n",
      "Epoch 00061: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0659 - acc: 0.9791 - val_loss: 0.4071 - val_acc: 0.9124\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9777\n",
      "Epoch 00062: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0713 - acc: 0.9777 - val_loss: 0.4794 - val_acc: 0.8940\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9793\n",
      "Epoch 00063: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0680 - acc: 0.9792 - val_loss: 0.4217 - val_acc: 0.9078\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9787\n",
      "Epoch 00064: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0692 - acc: 0.9787 - val_loss: 0.3993 - val_acc: 0.9085\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9745\n",
      "Epoch 00065: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0786 - acc: 0.9745 - val_loss: 0.3920 - val_acc: 0.9143\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9811\n",
      "Epoch 00066: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0613 - acc: 0.9810 - val_loss: 0.5424 - val_acc: 0.8905\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9799\n",
      "Epoch 00067: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0650 - acc: 0.9798 - val_loss: 0.4288 - val_acc: 0.9124\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9778\n",
      "Epoch 00068: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0732 - acc: 0.9778 - val_loss: 0.3916 - val_acc: 0.9157\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9772\n",
      "Epoch 00069: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0686 - acc: 0.9771 - val_loss: 0.3804 - val_acc: 0.9182\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9792\n",
      "Epoch 00070: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0690 - acc: 0.9792 - val_loss: 0.4359 - val_acc: 0.9080\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9804\n",
      "Epoch 00071: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0633 - acc: 0.9804 - val_loss: 0.4438 - val_acc: 0.9136\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9832\n",
      "Epoch 00072: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0570 - acc: 0.9832 - val_loss: 0.4358 - val_acc: 0.9066\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9819\n",
      "Epoch 00073: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0577 - acc: 0.9819 - val_loss: 0.5913 - val_acc: 0.8807\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9834\n",
      "Epoch 00074: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0555 - acc: 0.9834 - val_loss: 0.4306 - val_acc: 0.9145\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9810\n",
      "Epoch 00075: val_loss did not improve from 0.36210\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0604 - acc: 0.9810 - val_loss: 0.5589 - val_acc: 0.8831\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.4514 - acc: 0.8721\n",
      "Loss: 0.4514356895646821 Accuracy: 0.87206644\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3991 - acc: 0.2643\n",
      "Epoch 00001: val_loss improved from inf to 1.76993, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/001-1.7699.hdf5\n",
      "36805/36805 [==============================] - 427s 12ms/sample - loss: 2.3991 - acc: 0.2644 - val_loss: 1.7699 - val_acc: 0.4428\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5254 - acc: 0.5048\n",
      "Epoch 00002: val_loss improved from 1.76993 to 1.06657, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/002-1.0666.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 1.5255 - acc: 0.5048 - val_loss: 1.0666 - val_acc: 0.6923\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1529 - acc: 0.6319\n",
      "Epoch 00003: val_loss improved from 1.06657 to 0.86496, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/003-0.8650.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 1.1529 - acc: 0.6319 - val_loss: 0.8650 - val_acc: 0.7519\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9234 - acc: 0.7144\n",
      "Epoch 00004: val_loss improved from 0.86496 to 0.74884, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/004-0.7488.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.9235 - acc: 0.7144 - val_loss: 0.7488 - val_acc: 0.7778\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7751 - acc: 0.7639\n",
      "Epoch 00005: val_loss improved from 0.74884 to 0.59745, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/005-0.5974.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.7752 - acc: 0.7639 - val_loss: 0.5974 - val_acc: 0.8381\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6718 - acc: 0.7994\n",
      "Epoch 00006: val_loss improved from 0.59745 to 0.47639, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/006-0.4764.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.6717 - acc: 0.7994 - val_loss: 0.4764 - val_acc: 0.8607\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5890 - acc: 0.8235\n",
      "Epoch 00007: val_loss improved from 0.47639 to 0.43729, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/007-0.4373.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.5889 - acc: 0.8235 - val_loss: 0.4373 - val_acc: 0.8833\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5274 - acc: 0.8426\n",
      "Epoch 00008: val_loss did not improve from 0.43729\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.5276 - acc: 0.8425 - val_loss: 0.5126 - val_acc: 0.8486\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4762 - acc: 0.8575\n",
      "Epoch 00009: val_loss improved from 0.43729 to 0.41772, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/009-0.4177.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4762 - acc: 0.8575 - val_loss: 0.4177 - val_acc: 0.8898\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8664\n",
      "Epoch 00010: val_loss did not improve from 0.41772\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4402 - acc: 0.8664 - val_loss: 0.4215 - val_acc: 0.8866\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4028 - acc: 0.8790\n",
      "Epoch 00011: val_loss improved from 0.41772 to 0.33599, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/011-0.3360.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.4028 - acc: 0.8790 - val_loss: 0.3360 - val_acc: 0.9122\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.8889\n",
      "Epoch 00012: val_loss did not improve from 0.33599\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3767 - acc: 0.8888 - val_loss: 0.3653 - val_acc: 0.9096\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8918\n",
      "Epoch 00013: val_loss did not improve from 0.33599\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3574 - acc: 0.8919 - val_loss: 0.3563 - val_acc: 0.9015\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3290 - acc: 0.9005\n",
      "Epoch 00014: val_loss improved from 0.33599 to 0.30520, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/014-0.3052.hdf5\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.3290 - acc: 0.9005 - val_loss: 0.3052 - val_acc: 0.9192\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3136 - acc: 0.9058\n",
      "Epoch 00015: val_loss improved from 0.30520 to 0.30019, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/015-0.3002.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.3136 - acc: 0.9058 - val_loss: 0.3002 - val_acc: 0.9189\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2941 - acc: 0.9107\n",
      "Epoch 00016: val_loss did not improve from 0.30019\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2940 - acc: 0.9107 - val_loss: 0.3146 - val_acc: 0.9129\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2793 - acc: 0.9155\n",
      "Epoch 00017: val_loss improved from 0.30019 to 0.29466, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/017-0.2947.hdf5\n",
      "36805/36805 [==============================] - 421s 11ms/sample - loss: 0.2794 - acc: 0.9155 - val_loss: 0.2947 - val_acc: 0.9229\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.9170\n",
      "Epoch 00018: val_loss did not improve from 0.29466\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2702 - acc: 0.9170 - val_loss: 0.4196 - val_acc: 0.8845\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9224\n",
      "Epoch 00019: val_loss improved from 0.29466 to 0.26718, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/019-0.2672.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2526 - acc: 0.9225 - val_loss: 0.2672 - val_acc: 0.9292\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2430 - acc: 0.9255\n",
      "Epoch 00020: val_loss did not improve from 0.26718\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2433 - acc: 0.9254 - val_loss: 0.3572 - val_acc: 0.8959\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2324 - acc: 0.9276\n",
      "Epoch 00021: val_loss improved from 0.26718 to 0.24148, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/021-0.2415.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2324 - acc: 0.9275 - val_loss: 0.2415 - val_acc: 0.9341\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9315\n",
      "Epoch 00022: val_loss did not improve from 0.24148\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2214 - acc: 0.9315 - val_loss: 0.2577 - val_acc: 0.9315\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9366\n",
      "Epoch 00023: val_loss did not improve from 0.24148\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2100 - acc: 0.9366 - val_loss: 0.2625 - val_acc: 0.9259\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9354\n",
      "Epoch 00024: val_loss did not improve from 0.24148\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.2038 - acc: 0.9354 - val_loss: 0.2626 - val_acc: 0.9327\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9405\n",
      "Epoch 00025: val_loss improved from 0.24148 to 0.21660, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_7_conv_checkpoint/025-0.2166.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1933 - acc: 0.9404 - val_loss: 0.2166 - val_acc: 0.9408\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9390\n",
      "Epoch 00026: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1965 - acc: 0.9390 - val_loss: 0.2325 - val_acc: 0.9366\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9439\n",
      "Epoch 00027: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1784 - acc: 0.9439 - val_loss: 0.2278 - val_acc: 0.9345\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9451\n",
      "Epoch 00028: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1745 - acc: 0.9451 - val_loss: 0.3348 - val_acc: 0.9178\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9488\n",
      "Epoch 00029: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1641 - acc: 0.9488 - val_loss: 0.3183 - val_acc: 0.9143\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9512\n",
      "Epoch 00030: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1581 - acc: 0.9511 - val_loss: 0.2584 - val_acc: 0.9331\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1618 - acc: 0.9503\n",
      "Epoch 00031: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1618 - acc: 0.9503 - val_loss: 0.2672 - val_acc: 0.9311\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9546\n",
      "Epoch 00032: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1474 - acc: 0.9546 - val_loss: 0.2828 - val_acc: 0.9217\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9541\n",
      "Epoch 00033: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1483 - acc: 0.9541 - val_loss: 0.2916 - val_acc: 0.9238\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9567\n",
      "Epoch 00034: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1359 - acc: 0.9567 - val_loss: 0.2746 - val_acc: 0.9334\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9572\n",
      "Epoch 00035: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1368 - acc: 0.9572 - val_loss: 0.2355 - val_acc: 0.9406\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9592\n",
      "Epoch 00036: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1289 - acc: 0.9592 - val_loss: 0.2643 - val_acc: 0.9322\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9588\n",
      "Epoch 00037: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1293 - acc: 0.9588 - val_loss: 0.2467 - val_acc: 0.9371\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9599\n",
      "Epoch 00038: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1291 - acc: 0.9599 - val_loss: 0.2529 - val_acc: 0.9401\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9645\n",
      "Epoch 00039: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1141 - acc: 0.9645 - val_loss: 0.2510 - val_acc: 0.9408\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9659\n",
      "Epoch 00040: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1107 - acc: 0.9659 - val_loss: 0.2678 - val_acc: 0.9336\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9650\n",
      "Epoch 00041: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1131 - acc: 0.9650 - val_loss: 0.2568 - val_acc: 0.9308\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9649\n",
      "Epoch 00042: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1127 - acc: 0.9649 - val_loss: 0.2204 - val_acc: 0.9455\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9667\n",
      "Epoch 00043: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1055 - acc: 0.9667 - val_loss: 0.2315 - val_acc: 0.9380\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9695\n",
      "Epoch 00044: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.1004 - acc: 0.9695 - val_loss: 0.2310 - val_acc: 0.9415\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9703\n",
      "Epoch 00045: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0964 - acc: 0.9703 - val_loss: 0.2474 - val_acc: 0.9397\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9717\n",
      "Epoch 00046: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0904 - acc: 0.9717 - val_loss: 0.2642 - val_acc: 0.9329\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9719\n",
      "Epoch 00047: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0891 - acc: 0.9719 - val_loss: 0.2381 - val_acc: 0.9371\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9709\n",
      "Epoch 00048: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0899 - acc: 0.9709 - val_loss: 0.3918 - val_acc: 0.9152\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9721\n",
      "Epoch 00049: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0857 - acc: 0.9721 - val_loss: 0.2900 - val_acc: 0.9320\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9745\n",
      "Epoch 00050: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0817 - acc: 0.9745 - val_loss: 0.2232 - val_acc: 0.9499\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9728\n",
      "Epoch 00051: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0877 - acc: 0.9728 - val_loss: 0.2949 - val_acc: 0.9257\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9743\n",
      "Epoch 00052: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0831 - acc: 0.9743 - val_loss: 0.2791 - val_acc: 0.9359\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9758\n",
      "Epoch 00053: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0781 - acc: 0.9758 - val_loss: 0.2909 - val_acc: 0.9343\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9771\n",
      "Epoch 00054: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0720 - acc: 0.9770 - val_loss: 0.3760 - val_acc: 0.9073\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9771\n",
      "Epoch 00055: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0738 - acc: 0.9771 - val_loss: 0.2796 - val_acc: 0.9399\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9768\n",
      "Epoch 00056: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0738 - acc: 0.9768 - val_loss: 0.2462 - val_acc: 0.9453\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9774\n",
      "Epoch 00057: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0727 - acc: 0.9774 - val_loss: 0.2974 - val_acc: 0.9280\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9754\n",
      "Epoch 00058: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0772 - acc: 0.9754 - val_loss: 0.2890 - val_acc: 0.9331\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9750\n",
      "Epoch 00059: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0814 - acc: 0.9750 - val_loss: 0.2293 - val_acc: 0.9474\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9816\n",
      "Epoch 00060: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0595 - acc: 0.9816 - val_loss: 0.2787 - val_acc: 0.9397\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9811\n",
      "Epoch 00061: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0610 - acc: 0.9811 - val_loss: 0.2884 - val_acc: 0.9359\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9823\n",
      "Epoch 00062: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0556 - acc: 0.9823 - val_loss: 0.2838 - val_acc: 0.9306\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9824\n",
      "Epoch 00063: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0580 - acc: 0.9824 - val_loss: 0.2653 - val_acc: 0.9457\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9795\n",
      "Epoch 00064: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0653 - acc: 0.9795 - val_loss: 0.2504 - val_acc: 0.9415\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9814\n",
      "Epoch 00065: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0598 - acc: 0.9813 - val_loss: 0.2649 - val_acc: 0.9404\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9816\n",
      "Epoch 00066: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0607 - acc: 0.9816 - val_loss: 0.2400 - val_acc: 0.9478\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9818\n",
      "Epoch 00067: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0581 - acc: 0.9818 - val_loss: 0.2430 - val_acc: 0.9443\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9849\n",
      "Epoch 00068: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0490 - acc: 0.9849 - val_loss: 0.3667 - val_acc: 0.9269\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9825\n",
      "Epoch 00069: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0572 - acc: 0.9825 - val_loss: 0.2364 - val_acc: 0.9485\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9851\n",
      "Epoch 00070: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0485 - acc: 0.9851 - val_loss: 0.2692 - val_acc: 0.9385\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9852\n",
      "Epoch 00071: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0471 - acc: 0.9852 - val_loss: 0.2696 - val_acc: 0.9476\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9822\n",
      "Epoch 00072: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0561 - acc: 0.9822 - val_loss: 0.3253 - val_acc: 0.9306\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9789\n",
      "Epoch 00073: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0668 - acc: 0.9789 - val_loss: 0.2549 - val_acc: 0.9457\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9857\n",
      "Epoch 00074: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0452 - acc: 0.9857 - val_loss: 0.2782 - val_acc: 0.9415\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9867\n",
      "Epoch 00075: val_loss did not improve from 0.21660\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0421 - acc: 0.9867 - val_loss: 0.2537 - val_acc: 0.9457\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 17s 4ms/sample - loss: 0.2694 - acc: 0.9196\n",
      "Loss: 0.2693716149463832 Accuracy: 0.9196262\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4663 - acc: 0.2626\n",
      "Epoch 00001: val_loss improved from inf to 1.86050, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/001-1.8605.hdf5\n",
      "36805/36805 [==============================] - 431s 12ms/sample - loss: 2.4662 - acc: 0.2626 - val_loss: 1.8605 - val_acc: 0.4109\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5667 - acc: 0.4987\n",
      "Epoch 00002: val_loss improved from 1.86050 to 1.01159, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/002-1.0116.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 1.5669 - acc: 0.4986 - val_loss: 1.0116 - val_acc: 0.7209\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1397 - acc: 0.6403\n",
      "Epoch 00003: val_loss improved from 1.01159 to 0.94592, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/003-0.9459.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 1.1396 - acc: 0.6403 - val_loss: 0.9459 - val_acc: 0.7074\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8945 - acc: 0.7211\n",
      "Epoch 00004: val_loss improved from 0.94592 to 0.60025, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/004-0.6002.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.8946 - acc: 0.7212 - val_loss: 0.6002 - val_acc: 0.8474\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7282 - acc: 0.7737\n",
      "Epoch 00005: val_loss improved from 0.60025 to 0.48207, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/005-0.4821.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.7282 - acc: 0.7737 - val_loss: 0.4821 - val_acc: 0.8642\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.8151\n",
      "Epoch 00006: val_loss improved from 0.48207 to 0.36782, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/006-0.3678.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.6076 - acc: 0.8151 - val_loss: 0.3678 - val_acc: 0.8994\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.8417\n",
      "Epoch 00007: val_loss improved from 0.36782 to 0.33206, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/007-0.3321.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.5204 - acc: 0.8416 - val_loss: 0.3321 - val_acc: 0.9068\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8630\n",
      "Epoch 00008: val_loss improved from 0.33206 to 0.29876, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/008-0.2988.hdf5\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.4567 - acc: 0.8630 - val_loss: 0.2988 - val_acc: 0.9161\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8783\n",
      "Epoch 00009: val_loss improved from 0.29876 to 0.28035, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/009-0.2804.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.4015 - acc: 0.8783 - val_loss: 0.2804 - val_acc: 0.9157\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3647 - acc: 0.8903\n",
      "Epoch 00010: val_loss improved from 0.28035 to 0.23718, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/010-0.2372.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3648 - acc: 0.8903 - val_loss: 0.2372 - val_acc: 0.9320\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3328 - acc: 0.8985\n",
      "Epoch 00011: val_loss did not improve from 0.23718\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3329 - acc: 0.8985 - val_loss: 0.3223 - val_acc: 0.9131\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3087 - acc: 0.9056\n",
      "Epoch 00012: val_loss improved from 0.23718 to 0.20828, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/012-0.2083.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3087 - acc: 0.9056 - val_loss: 0.2083 - val_acc: 0.9422\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9123\n",
      "Epoch 00013: val_loss improved from 0.20828 to 0.20656, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/013-0.2066.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2843 - acc: 0.9123 - val_loss: 0.2066 - val_acc: 0.9441\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2639 - acc: 0.9205\n",
      "Epoch 00014: val_loss improved from 0.20656 to 0.19942, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/014-0.1994.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2639 - acc: 0.9205 - val_loss: 0.1994 - val_acc: 0.9408\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9252\n",
      "Epoch 00015: val_loss did not improve from 0.19942\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2435 - acc: 0.9251 - val_loss: 0.2350 - val_acc: 0.9311\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2327 - acc: 0.9284\n",
      "Epoch 00016: val_loss did not improve from 0.19942\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2328 - acc: 0.9284 - val_loss: 0.2138 - val_acc: 0.9376\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9341\n",
      "Epoch 00017: val_loss improved from 0.19942 to 0.19185, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/017-0.1918.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2188 - acc: 0.9341 - val_loss: 0.1918 - val_acc: 0.9467\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9375\n",
      "Epoch 00018: val_loss improved from 0.19185 to 0.19138, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/018-0.1914.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2052 - acc: 0.9375 - val_loss: 0.1914 - val_acc: 0.9462\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9442\n",
      "Epoch 00019: val_loss did not improve from 0.19138\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1859 - acc: 0.9442 - val_loss: 0.1932 - val_acc: 0.9420\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9431\n",
      "Epoch 00020: val_loss improved from 0.19138 to 0.17784, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/020-0.1778.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1828 - acc: 0.9431 - val_loss: 0.1778 - val_acc: 0.9502\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9463\n",
      "Epoch 00021: val_loss did not improve from 0.17784\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1721 - acc: 0.9462 - val_loss: 0.2264 - val_acc: 0.9341\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9491\n",
      "Epoch 00022: val_loss did not improve from 0.17784\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1656 - acc: 0.9490 - val_loss: 0.2002 - val_acc: 0.9392\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9502\n",
      "Epoch 00023: val_loss improved from 0.17784 to 0.16663, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/023-0.1666.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1604 - acc: 0.9502 - val_loss: 0.1666 - val_acc: 0.9506\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9508\n",
      "Epoch 00024: val_loss did not improve from 0.16663\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1606 - acc: 0.9508 - val_loss: 0.1682 - val_acc: 0.9534\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9574\n",
      "Epoch 00025: val_loss did not improve from 0.16663\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1387 - acc: 0.9574 - val_loss: 0.1741 - val_acc: 0.9509\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9571\n",
      "Epoch 00026: val_loss did not improve from 0.16663\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1413 - acc: 0.9571 - val_loss: 0.1692 - val_acc: 0.9541\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9610\n",
      "Epoch 00027: val_loss improved from 0.16663 to 0.13791, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_8_conv_checkpoint/027-0.1379.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1262 - acc: 0.9610 - val_loss: 0.1379 - val_acc: 0.9611\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9619\n",
      "Epoch 00028: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1222 - acc: 0.9619 - val_loss: 0.1549 - val_acc: 0.9499\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9622\n",
      "Epoch 00029: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1196 - acc: 0.9622 - val_loss: 0.1887 - val_acc: 0.9439\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9646\n",
      "Epoch 00030: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1142 - acc: 0.9646 - val_loss: 0.1633 - val_acc: 0.9513\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9636\n",
      "Epoch 00031: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1142 - acc: 0.9636 - val_loss: 0.1822 - val_acc: 0.9525\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9688\n",
      "Epoch 00032: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1007 - acc: 0.9688 - val_loss: 0.2177 - val_acc: 0.9413\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9704\n",
      "Epoch 00033: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0974 - acc: 0.9704 - val_loss: 0.1509 - val_acc: 0.9560\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9705\n",
      "Epoch 00034: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0955 - acc: 0.9704 - val_loss: 0.1710 - val_acc: 0.9541\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9689\n",
      "Epoch 00035: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.1021 - acc: 0.9688 - val_loss: 0.1798 - val_acc: 0.9495\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9740\n",
      "Epoch 00036: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0851 - acc: 0.9741 - val_loss: 0.1535 - val_acc: 0.9557\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9744\n",
      "Epoch 00037: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0824 - acc: 0.9744 - val_loss: 0.1563 - val_acc: 0.9583\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9760\n",
      "Epoch 00038: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0812 - acc: 0.9760 - val_loss: 0.1426 - val_acc: 0.9583\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9755\n",
      "Epoch 00039: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0783 - acc: 0.9755 - val_loss: 0.2304 - val_acc: 0.9348\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9758\n",
      "Epoch 00040: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0762 - acc: 0.9758 - val_loss: 0.1615 - val_acc: 0.9548\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9777\n",
      "Epoch 00041: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0713 - acc: 0.9777 - val_loss: 0.1841 - val_acc: 0.9511\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9791\n",
      "Epoch 00042: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0685 - acc: 0.9791 - val_loss: 0.2041 - val_acc: 0.9502\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9797\n",
      "Epoch 00043: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0658 - acc: 0.9797 - val_loss: 0.1964 - val_acc: 0.9450\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9812\n",
      "Epoch 00044: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0630 - acc: 0.9812 - val_loss: 0.2096 - val_acc: 0.9460\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9820\n",
      "Epoch 00045: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0583 - acc: 0.9820 - val_loss: 0.1537 - val_acc: 0.9569\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9820\n",
      "Epoch 00046: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0583 - acc: 0.9820 - val_loss: 0.3126 - val_acc: 0.9220\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9757\n",
      "Epoch 00047: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0787 - acc: 0.9757 - val_loss: 0.1791 - val_acc: 0.9511\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9848\n",
      "Epoch 00048: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0513 - acc: 0.9848 - val_loss: 0.1511 - val_acc: 0.9613\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9857\n",
      "Epoch 00049: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0477 - acc: 0.9857 - val_loss: 0.1797 - val_acc: 0.9555\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9845\n",
      "Epoch 00050: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0508 - acc: 0.9845 - val_loss: 0.1863 - val_acc: 0.9518\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9860\n",
      "Epoch 00051: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0473 - acc: 0.9859 - val_loss: 0.1789 - val_acc: 0.9543\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9759\n",
      "Epoch 00052: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0757 - acc: 0.9759 - val_loss: 0.1438 - val_acc: 0.9620\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9869\n",
      "Epoch 00053: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0442 - acc: 0.9869 - val_loss: 0.1925 - val_acc: 0.9492\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9846\n",
      "Epoch 00054: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0490 - acc: 0.9846 - val_loss: 0.1595 - val_acc: 0.9553\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9880\n",
      "Epoch 00055: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0404 - acc: 0.9880 - val_loss: 0.1692 - val_acc: 0.9574\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9868\n",
      "Epoch 00056: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0445 - acc: 0.9868 - val_loss: 0.1679 - val_acc: 0.9539\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9871\n",
      "Epoch 00057: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0418 - acc: 0.9871 - val_loss: 0.2740 - val_acc: 0.9362\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9835\n",
      "Epoch 00058: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0523 - acc: 0.9835 - val_loss: 0.1797 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9877\n",
      "Epoch 00059: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0406 - acc: 0.9877 - val_loss: 0.1881 - val_acc: 0.9522\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9822\n",
      "Epoch 00060: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0574 - acc: 0.9822 - val_loss: 0.1587 - val_acc: 0.9609\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9900\n",
      "Epoch 00061: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0335 - acc: 0.9900 - val_loss: 0.1842 - val_acc: 0.9546\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9894\n",
      "Epoch 00062: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0362 - acc: 0.9894 - val_loss: 0.1619 - val_acc: 0.9567\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9892\n",
      "Epoch 00063: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0359 - acc: 0.9891 - val_loss: 0.1639 - val_acc: 0.9527\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9890\n",
      "Epoch 00064: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0372 - acc: 0.9889 - val_loss: 0.2408 - val_acc: 0.9434\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9876\n",
      "Epoch 00065: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0398 - acc: 0.9876 - val_loss: 0.1693 - val_acc: 0.9620\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9890\n",
      "Epoch 00066: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0372 - acc: 0.9890 - val_loss: 0.2494 - val_acc: 0.9392\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9864\n",
      "Epoch 00067: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0433 - acc: 0.9864 - val_loss: 0.1666 - val_acc: 0.9578\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9875\n",
      "Epoch 00068: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0416 - acc: 0.9875 - val_loss: 0.1627 - val_acc: 0.9602\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9902\n",
      "Epoch 00069: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0328 - acc: 0.9902 - val_loss: 0.1715 - val_acc: 0.9590\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9916\n",
      "Epoch 00070: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0285 - acc: 0.9916 - val_loss: 0.1612 - val_acc: 0.9592\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9920\n",
      "Epoch 00071: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0283 - acc: 0.9920 - val_loss: 0.1631 - val_acc: 0.9592\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9917\n",
      "Epoch 00072: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0282 - acc: 0.9917 - val_loss: 0.1983 - val_acc: 0.9511\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9915\n",
      "Epoch 00073: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0289 - acc: 0.9915 - val_loss: 0.2529 - val_acc: 0.9408\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9921\n",
      "Epoch 00074: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0272 - acc: 0.9921 - val_loss: 0.2060 - val_acc: 0.9536\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9910\n",
      "Epoch 00075: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0309 - acc: 0.9909 - val_loss: 0.1954 - val_acc: 0.9541\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9905\n",
      "Epoch 00076: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0302 - acc: 0.9905 - val_loss: 0.2351 - val_acc: 0.9462\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9880\n",
      "Epoch 00077: val_loss did not improve from 0.13791\n",
      "36805/36805 [==============================] - 418s 11ms/sample - loss: 0.0395 - acc: 0.9879 - val_loss: 0.1974 - val_acc: 0.9560\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.1775 - acc: 0.9458\n",
      "Loss: 0.1774686941275468 Accuracy: 0.9457944\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3683 - acc: 0.3014\n",
      "Epoch 00001: val_loss improved from inf to 1.60929, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/001-1.6093.hdf5\n",
      "36805/36805 [==============================] - 438s 12ms/sample - loss: 2.3683 - acc: 0.3014 - val_loss: 1.6093 - val_acc: 0.5705\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2957 - acc: 0.5954\n",
      "Epoch 00002: val_loss improved from 1.60929 to 0.89735, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/002-0.8974.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 1.2957 - acc: 0.5954 - val_loss: 0.8974 - val_acc: 0.7489\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9066 - acc: 0.7220\n",
      "Epoch 00003: val_loss improved from 0.89735 to 0.48113, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/003-0.4811.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.9067 - acc: 0.7219 - val_loss: 0.4811 - val_acc: 0.8677\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7081 - acc: 0.7871\n",
      "Epoch 00004: val_loss improved from 0.48113 to 0.43112, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/004-0.4311.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.7083 - acc: 0.7871 - val_loss: 0.4311 - val_acc: 0.8868\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5807 - acc: 0.8290\n",
      "Epoch 00005: val_loss improved from 0.43112 to 0.33165, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/005-0.3317.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.5807 - acc: 0.8290 - val_loss: 0.3317 - val_acc: 0.9119\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5023 - acc: 0.8518\n",
      "Epoch 00006: val_loss improved from 0.33165 to 0.31185, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/006-0.3118.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.5024 - acc: 0.8517 - val_loss: 0.3118 - val_acc: 0.9157\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8699\n",
      "Epoch 00007: val_loss improved from 0.31185 to 0.25672, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/007-0.2567.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.4406 - acc: 0.8698 - val_loss: 0.2567 - val_acc: 0.9338\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8871\n",
      "Epoch 00008: val_loss improved from 0.25672 to 0.22404, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/008-0.2240.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3909 - acc: 0.8871 - val_loss: 0.2240 - val_acc: 0.9422\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3522 - acc: 0.8971\n",
      "Epoch 00009: val_loss did not improve from 0.22404\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3522 - acc: 0.8971 - val_loss: 0.2253 - val_acc: 0.9413\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.9079\n",
      "Epoch 00010: val_loss improved from 0.22404 to 0.20961, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/010-0.2096.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.3173 - acc: 0.9078 - val_loss: 0.2096 - val_acc: 0.9422\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9125\n",
      "Epoch 00011: val_loss improved from 0.20961 to 0.20210, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/011-0.2021.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2970 - acc: 0.9125 - val_loss: 0.2021 - val_acc: 0.9422\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.9212\n",
      "Epoch 00012: val_loss improved from 0.20210 to 0.17642, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/012-0.1764.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2714 - acc: 0.9212 - val_loss: 0.1764 - val_acc: 0.9520\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9275\n",
      "Epoch 00013: val_loss did not improve from 0.17642\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2421 - acc: 0.9274 - val_loss: 0.1999 - val_acc: 0.9457\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9299\n",
      "Epoch 00014: val_loss improved from 0.17642 to 0.17450, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/014-0.1745.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2374 - acc: 0.9299 - val_loss: 0.1745 - val_acc: 0.9527\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9387\n",
      "Epoch 00015: val_loss improved from 0.17450 to 0.16641, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/015-0.1664.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2108 - acc: 0.9387 - val_loss: 0.1664 - val_acc: 0.9529\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9421\n",
      "Epoch 00016: val_loss improved from 0.16641 to 0.15489, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/016-0.1549.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.2000 - acc: 0.9421 - val_loss: 0.1549 - val_acc: 0.9574\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9475\n",
      "Epoch 00017: val_loss improved from 0.15489 to 0.15284, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/017-0.1528.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1823 - acc: 0.9475 - val_loss: 0.1528 - val_acc: 0.9548\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9498\n",
      "Epoch 00018: val_loss improved from 0.15284 to 0.14335, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/018-0.1434.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1713 - acc: 0.9497 - val_loss: 0.1434 - val_acc: 0.9571\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9502\n",
      "Epoch 00019: val_loss did not improve from 0.14335\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1685 - acc: 0.9502 - val_loss: 0.1557 - val_acc: 0.9609\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1542 - acc: 0.9563\n",
      "Epoch 00020: val_loss improved from 0.14335 to 0.12834, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/020-0.1283.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1542 - acc: 0.9563 - val_loss: 0.1283 - val_acc: 0.9644\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9564\n",
      "Epoch 00021: val_loss did not improve from 0.12834\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1460 - acc: 0.9564 - val_loss: 0.1522 - val_acc: 0.9585\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9582\n",
      "Epoch 00022: val_loss did not improve from 0.12834\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1370 - acc: 0.9582 - val_loss: 0.1317 - val_acc: 0.9625\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9588\n",
      "Epoch 00023: val_loss did not improve from 0.12834\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1384 - acc: 0.9587 - val_loss: 0.1737 - val_acc: 0.9467\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9599\n",
      "Epoch 00024: val_loss did not improve from 0.12834\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1292 - acc: 0.9599 - val_loss: 0.1519 - val_acc: 0.9567\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9661\n",
      "Epoch 00025: val_loss improved from 0.12834 to 0.12577, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/025-0.1258.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1144 - acc: 0.9661 - val_loss: 0.1258 - val_acc: 0.9641\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9669\n",
      "Epoch 00026: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1121 - acc: 0.9669 - val_loss: 0.1458 - val_acc: 0.9592\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9688\n",
      "Epoch 00027: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1049 - acc: 0.9687 - val_loss: 0.1446 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9692\n",
      "Epoch 00028: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1042 - acc: 0.9691 - val_loss: 0.1416 - val_acc: 0.9609\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9688\n",
      "Epoch 00029: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.1027 - acc: 0.9688 - val_loss: 0.1515 - val_acc: 0.9595\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9706\n",
      "Epoch 00030: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0959 - acc: 0.9706 - val_loss: 0.1388 - val_acc: 0.9618\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9740\n",
      "Epoch 00031: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0862 - acc: 0.9741 - val_loss: 0.1475 - val_acc: 0.9578\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9768\n",
      "Epoch 00032: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0795 - acc: 0.9768 - val_loss: 0.1651 - val_acc: 0.9511\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9707\n",
      "Epoch 00033: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0964 - acc: 0.9707 - val_loss: 0.1322 - val_acc: 0.9604\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9787\n",
      "Epoch 00034: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0749 - acc: 0.9787 - val_loss: 0.1310 - val_acc: 0.9618\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9755\n",
      "Epoch 00035: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0827 - acc: 0.9755 - val_loss: 0.1309 - val_acc: 0.9623\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9788\n",
      "Epoch 00036: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0715 - acc: 0.9788 - val_loss: 0.1497 - val_acc: 0.9578\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9793\n",
      "Epoch 00037: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0671 - acc: 0.9792 - val_loss: 0.1386 - val_acc: 0.9602\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9758\n",
      "Epoch 00038: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0780 - acc: 0.9758 - val_loss: 0.1339 - val_acc: 0.9602\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9832\n",
      "Epoch 00039: val_loss did not improve from 0.12577\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0596 - acc: 0.9832 - val_loss: 0.1347 - val_acc: 0.9623\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9829\n",
      "Epoch 00040: val_loss improved from 0.12577 to 0.12434, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/040-0.1243.hdf5\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0587 - acc: 0.9829 - val_loss: 0.1243 - val_acc: 0.9651\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9824\n",
      "Epoch 00041: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0591 - acc: 0.9824 - val_loss: 0.1259 - val_acc: 0.9641\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9819\n",
      "Epoch 00042: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0593 - acc: 0.9819 - val_loss: 0.1271 - val_acc: 0.9625\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9830\n",
      "Epoch 00043: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0550 - acc: 0.9830 - val_loss: 0.1487 - val_acc: 0.9630\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9797\n",
      "Epoch 00044: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0656 - acc: 0.9796 - val_loss: 0.1448 - val_acc: 0.9613\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9844\n",
      "Epoch 00045: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0525 - acc: 0.9843 - val_loss: 0.1497 - val_acc: 0.9569\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9856\n",
      "Epoch 00046: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0495 - acc: 0.9856 - val_loss: 0.1344 - val_acc: 0.9618\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9812\n",
      "Epoch 00047: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 420s 11ms/sample - loss: 0.0624 - acc: 0.9812 - val_loss: 0.1339 - val_acc: 0.9620\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9893\n",
      "Epoch 00048: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0402 - acc: 0.9892 - val_loss: 0.1556 - val_acc: 0.9578\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9813\n",
      "Epoch 00049: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0627 - acc: 0.9813 - val_loss: 0.1304 - val_acc: 0.9632\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9877\n",
      "Epoch 00050: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0405 - acc: 0.9877 - val_loss: 0.1418 - val_acc: 0.9609\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9883\n",
      "Epoch 00051: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0406 - acc: 0.9883 - val_loss: 0.1452 - val_acc: 0.9613\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9844\n",
      "Epoch 00052: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0492 - acc: 0.9844 - val_loss: 0.1548 - val_acc: 0.9602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9890\n",
      "Epoch 00053: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0387 - acc: 0.9889 - val_loss: 0.1292 - val_acc: 0.9646\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9830\n",
      "Epoch 00054: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0544 - acc: 0.9830 - val_loss: 0.1408 - val_acc: 0.9641\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9845\n",
      "Epoch 00055: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0512 - acc: 0.9845 - val_loss: 0.1456 - val_acc: 0.9634\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9906\n",
      "Epoch 00056: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0332 - acc: 0.9905 - val_loss: 0.1327 - val_acc: 0.9681\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9858\n",
      "Epoch 00057: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0489 - acc: 0.9858 - val_loss: 0.1359 - val_acc: 0.9644\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9882\n",
      "Epoch 00058: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0411 - acc: 0.9882 - val_loss: 0.1509 - val_acc: 0.9609\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9870\n",
      "Epoch 00059: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0441 - acc: 0.9869 - val_loss: 0.1376 - val_acc: 0.9627\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9865\n",
      "Epoch 00060: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0448 - acc: 0.9865 - val_loss: 0.1266 - val_acc: 0.9648\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9923\n",
      "Epoch 00061: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0271 - acc: 0.9923 - val_loss: 0.1291 - val_acc: 0.9639\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9919\n",
      "Epoch 00062: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0289 - acc: 0.9919 - val_loss: 0.1657 - val_acc: 0.9609\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9851\n",
      "Epoch 00063: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0493 - acc: 0.9850 - val_loss: 0.1830 - val_acc: 0.9520\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9844\n",
      "Epoch 00064: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0506 - acc: 0.9844 - val_loss: 0.1353 - val_acc: 0.9676\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9889\n",
      "Epoch 00065: val_loss did not improve from 0.12434\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0394 - acc: 0.9889 - val_loss: 0.1351 - val_acc: 0.9667\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9883\n",
      "Epoch 00066: val_loss improved from 0.12434 to 0.12042, saving model to model/checkpoint/1D_CNN_custom_4_DO_BN_9_conv_checkpoint/066-0.1204.hdf5\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0386 - acc: 0.9883 - val_loss: 0.1204 - val_acc: 0.9667\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9930\n",
      "Epoch 00067: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0259 - acc: 0.9930 - val_loss: 0.1428 - val_acc: 0.9639\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9935\n",
      "Epoch 00068: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0240 - acc: 0.9935 - val_loss: 0.1430 - val_acc: 0.9644\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9918\n",
      "Epoch 00069: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0275 - acc: 0.9917 - val_loss: 0.1403 - val_acc: 0.9653\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9872\n",
      "Epoch 00070: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0429 - acc: 0.9872 - val_loss: 0.1312 - val_acc: 0.9669\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9931\n",
      "Epoch 00071: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0239 - acc: 0.9931 - val_loss: 0.1815 - val_acc: 0.9529\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9934\n",
      "Epoch 00072: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0236 - acc: 0.9934 - val_loss: 0.1734 - val_acc: 0.9578\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9927\n",
      "Epoch 00073: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0253 - acc: 0.9927 - val_loss: 0.1487 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9906\n",
      "Epoch 00074: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0320 - acc: 0.9906 - val_loss: 0.1711 - val_acc: 0.9578\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9943\n",
      "Epoch 00075: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0220 - acc: 0.9943 - val_loss: 0.1798 - val_acc: 0.9536\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9939\n",
      "Epoch 00076: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0218 - acc: 0.9939 - val_loss: 0.1655 - val_acc: 0.9625\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9926\n",
      "Epoch 00077: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0244 - acc: 0.9926 - val_loss: 0.1629 - val_acc: 0.9630\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9919\n",
      "Epoch 00078: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0283 - acc: 0.9918 - val_loss: 0.1421 - val_acc: 0.9632\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 00079: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0269 - acc: 0.9917 - val_loss: 0.1443 - val_acc: 0.9632\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9932\n",
      "Epoch 00080: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0232 - acc: 0.9932 - val_loss: 0.1370 - val_acc: 0.9667\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9946\n",
      "Epoch 00081: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0193 - acc: 0.9946 - val_loss: 0.1429 - val_acc: 0.9667\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9925\n",
      "Epoch 00082: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0251 - acc: 0.9924 - val_loss: 0.1415 - val_acc: 0.9641\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9887\n",
      "Epoch 00083: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0380 - acc: 0.9887 - val_loss: 0.1450 - val_acc: 0.9627\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9959\n",
      "Epoch 00084: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0168 - acc: 0.9959 - val_loss: 0.1363 - val_acc: 0.9646\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9890\n",
      "Epoch 00085: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0347 - acc: 0.9889 - val_loss: 0.1818 - val_acc: 0.9567\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9935\n",
      "Epoch 00086: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0229 - acc: 0.9935 - val_loss: 0.1369 - val_acc: 0.9665\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9933\n",
      "Epoch 00087: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0232 - acc: 0.9933 - val_loss: 0.1324 - val_acc: 0.9672\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9961\n",
      "Epoch 00088: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0155 - acc: 0.9960 - val_loss: 0.1364 - val_acc: 0.9695\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9896\n",
      "Epoch 00089: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0346 - acc: 0.9896 - val_loss: 0.1409 - val_acc: 0.9639\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9943\n",
      "Epoch 00090: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0194 - acc: 0.9943 - val_loss: 0.1658 - val_acc: 0.9606\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9958\n",
      "Epoch 00091: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0168 - acc: 0.9958 - val_loss: 0.1568 - val_acc: 0.9651\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9957\n",
      "Epoch 00092: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0150 - acc: 0.9956 - val_loss: 0.1801 - val_acc: 0.9562\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9919\n",
      "Epoch 00093: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0279 - acc: 0.9919 - val_loss: 0.1529 - val_acc: 0.9653\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9959\n",
      "Epoch 00094: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0162 - acc: 0.9959 - val_loss: 0.1507 - val_acc: 0.9651\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9936\n",
      "Epoch 00095: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0216 - acc: 0.9936 - val_loss: 0.1662 - val_acc: 0.9599\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9936\n",
      "Epoch 00096: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0216 - acc: 0.9936 - val_loss: 0.1498 - val_acc: 0.9658\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9966\n",
      "Epoch 00097: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0132 - acc: 0.9966 - val_loss: 0.1643 - val_acc: 0.9639\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9924\n",
      "Epoch 00098: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0253 - acc: 0.9924 - val_loss: 0.1412 - val_acc: 0.9672\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9961\n",
      "Epoch 00099: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0137 - acc: 0.9961 - val_loss: 0.1473 - val_acc: 0.9662\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9946\n",
      "Epoch 00100: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0183 - acc: 0.9946 - val_loss: 0.1792 - val_acc: 0.9564\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9934\n",
      "Epoch 00101: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0211 - acc: 0.9934 - val_loss: 0.1355 - val_acc: 0.9688\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9934\n",
      "Epoch 00102: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0221 - acc: 0.9933 - val_loss: 0.1715 - val_acc: 0.9646\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9942\n",
      "Epoch 00103: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0189 - acc: 0.9942 - val_loss: 0.1428 - val_acc: 0.9662\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9966\n",
      "Epoch 00104: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0123 - acc: 0.9966 - val_loss: 0.1489 - val_acc: 0.9639\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9962\n",
      "Epoch 00105: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0132 - acc: 0.9962 - val_loss: 0.1530 - val_acc: 0.9674\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9962\n",
      "Epoch 00106: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0133 - acc: 0.9963 - val_loss: 0.1928 - val_acc: 0.9534\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9966\n",
      "Epoch 00107: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0135 - acc: 0.9966 - val_loss: 0.1478 - val_acc: 0.9651\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9926\n",
      "Epoch 00108: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0254 - acc: 0.9926 - val_loss: 0.1617 - val_acc: 0.9634\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9945\n",
      "Epoch 00109: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0198 - acc: 0.9945 - val_loss: 0.1552 - val_acc: 0.9655\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9961\n",
      "Epoch 00110: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0142 - acc: 0.9961 - val_loss: 0.1491 - val_acc: 0.9688\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9980\n",
      "Epoch 00111: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0092 - acc: 0.9980 - val_loss: 0.1489 - val_acc: 0.9669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9966\n",
      "Epoch 00112: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0125 - acc: 0.9966 - val_loss: 0.1852 - val_acc: 0.9595\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9958\n",
      "Epoch 00113: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0155 - acc: 0.9958 - val_loss: 0.1947 - val_acc: 0.9599\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9965\n",
      "Epoch 00114: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0135 - acc: 0.9964 - val_loss: 0.2082 - val_acc: 0.9574\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9913\n",
      "Epoch 00115: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0271 - acc: 0.9913 - val_loss: 0.1210 - val_acc: 0.9709\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9972\n",
      "Epoch 00116: val_loss did not improve from 0.12042\n",
      "36805/36805 [==============================] - 419s 11ms/sample - loss: 0.0099 - acc: 0.9972 - val_loss: 0.1339 - val_acc: 0.9697\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.1566 - acc: 0.9589\n",
      "Loss: 0.15657237921512626 Accuracy: 0.9588785\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_4_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,037,392\n",
      "Trainable params: 2,035,600\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 1.0501 - acc: 0.7425\n",
      "Loss: 1.050109894302899 Accuracy: 0.74247146\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,310,992\n",
      "Trainable params: 1,308,944\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.7079 - acc: 0.8201\n",
      "Loss: 0.7078870166004138 Accuracy: 0.82014537\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,123,216\n",
      "Trainable params: 1,120,912\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.4514 - acc: 0.8721\n",
      "Loss: 0.4514356895646821 Accuracy: 0.87206644\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,052,880\n",
      "Trainable params: 1,050,448\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2694 - acc: 0.9196\n",
      "Loss: 0.2693716149463832 Accuracy: 0.9196262\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,059,344\n",
      "Trainable params: 1,056,784\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.1775 - acc: 0.9458\n",
      "Loss: 0.1774686941275468 Accuracy: 0.9457944\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 64)             256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,075,024\n",
      "Trainable params: 1,072,336\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.1566 - acc: 0.9589\n",
      "Loss: 0.15657237921512626 Accuracy: 0.9588785\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_4_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 2,037,392\n",
      "Trainable params: 2,035,600\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 1.6124 - acc: 0.7354\n",
      "Loss: 1.6124202408399413 Accuracy: 0.73541015\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,310,992\n",
      "Trainable params: 1,308,944\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.9414 - acc: 0.8172\n",
      "Loss: 0.9414317963155506 Accuracy: 0.8172378\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,123,216\n",
      "Trainable params: 1,120,912\n",
      "Non-trainable params: 2,304\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.6862 - acc: 0.8525\n",
      "Loss: 0.6862390321115591 Accuracy: 0.8525441\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 1,052,880\n",
      "Trainable params: 1,050,448\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 18s 4ms/sample - loss: 0.2883 - acc: 0.9261\n",
      "Loss: 0.2883361962477861 Accuracy: 0.9260644\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 1,059,344\n",
      "Trainable params: 1,056,784\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.2508 - acc: 0.9410\n",
      "Loss: 0.2507669526128135 Accuracy: 0.9410176\n",
      "\n",
      "1D_CNN_custom_4_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 256)        1536      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 256)        327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 256)        1024      \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 256)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 256)         327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         163968    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 64)             20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 64)             256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2064      \n",
      "=================================================================\n",
      "Total params: 1,075,024\n",
      "Trainable params: 1,072,336\n",
      "Non-trainable params: 2,688\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 19s 4ms/sample - loss: 0.1772 - acc: 0.9616\n",
      "Loss: 0.17721055234653774 Accuracy: 0.9615784\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
