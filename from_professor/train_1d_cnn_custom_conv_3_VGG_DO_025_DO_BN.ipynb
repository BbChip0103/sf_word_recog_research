{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO_025_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                  activation='relu')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_025_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3031 - acc: 0.2810\n",
      "Epoch 00001: val_loss improved from inf to 2.06745, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_1_conv_checkpoint/001-2.0674.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 2.3031 - acc: 0.2809 - val_loss: 2.0674 - val_acc: 0.3909\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7940 - acc: 0.4683\n",
      "Epoch 00002: val_loss improved from 2.06745 to 1.91734, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_1_conv_checkpoint/002-1.9173.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.7941 - acc: 0.4683 - val_loss: 1.9173 - val_acc: 0.4130\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4094 - acc: 0.5915\n",
      "Epoch 00003: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.4095 - acc: 0.5914 - val_loss: 1.9534 - val_acc: 0.4060\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0747 - acc: 0.6979\n",
      "Epoch 00004: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.0747 - acc: 0.6979 - val_loss: 2.0254 - val_acc: 0.4086\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8051 - acc: 0.7838\n",
      "Epoch 00005: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.8051 - acc: 0.7838 - val_loss: 2.1765 - val_acc: 0.3923\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5966 - acc: 0.8476\n",
      "Epoch 00006: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5966 - acc: 0.8476 - val_loss: 2.3302 - val_acc: 0.3802\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4414 - acc: 0.8977\n",
      "Epoch 00007: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4414 - acc: 0.8977 - val_loss: 2.5191 - val_acc: 0.3755\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3215 - acc: 0.9319\n",
      "Epoch 00008: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3214 - acc: 0.9319 - val_loss: 2.7747 - val_acc: 0.3657\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2357 - acc: 0.9561\n",
      "Epoch 00009: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2357 - acc: 0.9561 - val_loss: 2.9245 - val_acc: 0.3659\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9720\n",
      "Epoch 00010: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1688 - acc: 0.9720 - val_loss: 3.0962 - val_acc: 0.3592\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9822\n",
      "Epoch 00011: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1262 - acc: 0.9822 - val_loss: 3.2985 - val_acc: 0.3645\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9885\n",
      "Epoch 00012: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0960 - acc: 0.9885 - val_loss: 3.5988 - val_acc: 0.3569\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9904\n",
      "Epoch 00013: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0863 - acc: 0.9904 - val_loss: 3.5844 - val_acc: 0.3631\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9936\n",
      "Epoch 00014: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0669 - acc: 0.9936 - val_loss: 3.9037 - val_acc: 0.3587\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9947\n",
      "Epoch 00015: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0587 - acc: 0.9947 - val_loss: 3.9493 - val_acc: 0.3666\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9943\n",
      "Epoch 00016: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0545 - acc: 0.9943 - val_loss: 3.9989 - val_acc: 0.3583\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9963\n",
      "Epoch 00017: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0454 - acc: 0.9963 - val_loss: 4.0832 - val_acc: 0.3636\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9970\n",
      "Epoch 00018: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0398 - acc: 0.9970 - val_loss: 4.2085 - val_acc: 0.3634\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9956\n",
      "Epoch 00019: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0425 - acc: 0.9956 - val_loss: 4.3299 - val_acc: 0.3594\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9981\n",
      "Epoch 00020: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0285 - acc: 0.9981 - val_loss: 4.4265 - val_acc: 0.3501\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9965\n",
      "Epoch 00021: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0338 - acc: 0.9965 - val_loss: 4.5028 - val_acc: 0.3515\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9957\n",
      "Epoch 00022: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0375 - acc: 0.9957 - val_loss: 4.5011 - val_acc: 0.3517\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9979\n",
      "Epoch 00023: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0264 - acc: 0.9979 - val_loss: 4.5442 - val_acc: 0.3494\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9976\n",
      "Epoch 00024: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0254 - acc: 0.9976 - val_loss: 4.6581 - val_acc: 0.3480\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9983\n",
      "Epoch 00025: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0227 - acc: 0.9983 - val_loss: 4.7385 - val_acc: 0.3559\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9979\n",
      "Epoch 00026: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0242 - acc: 0.9979 - val_loss: 4.7220 - val_acc: 0.3534\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9982\n",
      "Epoch 00027: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0219 - acc: 0.9982 - val_loss: 4.8304 - val_acc: 0.3555\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9955\n",
      "Epoch 00028: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0336 - acc: 0.9955 - val_loss: 4.8268 - val_acc: 0.3522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9976\n",
      "Epoch 00029: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0265 - acc: 0.9976 - val_loss: 4.8012 - val_acc: 0.3524\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9973\n",
      "Epoch 00030: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0240 - acc: 0.9973 - val_loss: 5.1162 - val_acc: 0.3403\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9974\n",
      "Epoch 00031: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0243 - acc: 0.9974 - val_loss: 4.8544 - val_acc: 0.3552\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9990\n",
      "Epoch 00032: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0156 - acc: 0.9990 - val_loss: 4.9548 - val_acc: 0.3555\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9991\n",
      "Epoch 00033: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0154 - acc: 0.9991 - val_loss: 4.9765 - val_acc: 0.3562\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9989\n",
      "Epoch 00034: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0155 - acc: 0.9989 - val_loss: 5.0320 - val_acc: 0.3534\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9993\n",
      "Epoch 00035: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0125 - acc: 0.9993 - val_loss: 5.1284 - val_acc: 0.3520\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9970\n",
      "Epoch 00036: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0208 - acc: 0.9970 - val_loss: 5.2445 - val_acc: 0.3408\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9942\n",
      "Epoch 00037: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0327 - acc: 0.9942 - val_loss: 5.1738 - val_acc: 0.3592\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9985\n",
      "Epoch 00038: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0181 - acc: 0.9985 - val_loss: 5.2430 - val_acc: 0.3489\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9992\n",
      "Epoch 00039: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0138 - acc: 0.9992 - val_loss: 5.2672 - val_acc: 0.3527\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9992\n",
      "Epoch 00040: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0131 - acc: 0.9992 - val_loss: 5.3292 - val_acc: 0.3587\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9975\n",
      "Epoch 00041: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0199 - acc: 0.9975 - val_loss: 5.3128 - val_acc: 0.3466\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9986\n",
      "Epoch 00042: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0160 - acc: 0.9986 - val_loss: 5.5020 - val_acc: 0.3508\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9966\n",
      "Epoch 00043: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0243 - acc: 0.9966 - val_loss: 5.3584 - val_acc: 0.3447\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9981\n",
      "Epoch 00044: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0192 - acc: 0.9981 - val_loss: 5.3524 - val_acc: 0.3380\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9991\n",
      "Epoch 00045: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0140 - acc: 0.9991 - val_loss: 5.3544 - val_acc: 0.3457\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9981\n",
      "Epoch 00046: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0183 - acc: 0.9981 - val_loss: 5.3306 - val_acc: 0.3496\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9990\n",
      "Epoch 00047: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0147 - acc: 0.9990 - val_loss: 5.4177 - val_acc: 0.3401\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9987\n",
      "Epoch 00048: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0161 - acc: 0.9987 - val_loss: 5.4846 - val_acc: 0.3457\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9992\n",
      "Epoch 00049: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0133 - acc: 0.9992 - val_loss: 5.4858 - val_acc: 0.3464\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9993\n",
      "Epoch 00050: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0123 - acc: 0.9993 - val_loss: 5.4960 - val_acc: 0.3480\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9993\n",
      "Epoch 00051: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0119 - acc: 0.9993 - val_loss: 5.5616 - val_acc: 0.3475\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9993\n",
      "Epoch 00052: val_loss did not improve from 1.91734\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0118 - acc: 0.9993 - val_loss: 5.6097 - val_acc: 0.3508\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 498us/sample - loss: 1.9555 - acc: 0.3886\n",
      "Loss: 1.9555140533675037 Accuracy: 0.38857737\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2499 - acc: 0.2900\n",
      "Epoch 00001: val_loss improved from inf to 1.94697, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_2_conv_checkpoint/001-1.9470.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 2.2498 - acc: 0.2900 - val_loss: 1.9470 - val_acc: 0.3976\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7238 - acc: 0.4816\n",
      "Epoch 00002: val_loss improved from 1.94697 to 1.68960, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_2_conv_checkpoint/002-1.6896.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 1.7237 - acc: 0.4816 - val_loss: 1.6896 - val_acc: 0.4889\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3963 - acc: 0.5851\n",
      "Epoch 00003: val_loss improved from 1.68960 to 1.67472, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_2_conv_checkpoint/003-1.6747.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 1.3963 - acc: 0.5851 - val_loss: 1.6747 - val_acc: 0.4801\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1099 - acc: 0.6721\n",
      "Epoch 00004: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 1.1101 - acc: 0.6721 - val_loss: 1.7665 - val_acc: 0.4754\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8602 - acc: 0.7467\n",
      "Epoch 00005: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.8603 - acc: 0.7466 - val_loss: 1.8647 - val_acc: 0.4738\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6315 - acc: 0.8206\n",
      "Epoch 00006: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.6319 - acc: 0.8206 - val_loss: 2.1008 - val_acc: 0.4519\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4581 - acc: 0.8722\n",
      "Epoch 00007: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.4581 - acc: 0.8722 - val_loss: 2.3078 - val_acc: 0.4477\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.9157\n",
      "Epoch 00008: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.3178 - acc: 0.9157 - val_loss: 2.5743 - val_acc: 0.4451\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9427\n",
      "Epoch 00009: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2245 - acc: 0.9427 - val_loss: 2.8982 - val_acc: 0.4305\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9626\n",
      "Epoch 00010: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1576 - acc: 0.9626 - val_loss: 3.0512 - val_acc: 0.4470\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9724\n",
      "Epoch 00011: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1209 - acc: 0.9724 - val_loss: 3.3138 - val_acc: 0.4491\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9781\n",
      "Epoch 00012: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1037 - acc: 0.9781 - val_loss: 3.4287 - val_acc: 0.4456\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9802\n",
      "Epoch 00013: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0917 - acc: 0.9802 - val_loss: 3.6832 - val_acc: 0.4330\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9844\n",
      "Epoch 00014: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0773 - acc: 0.9844 - val_loss: 3.8030 - val_acc: 0.4391\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9877\n",
      "Epoch 00015: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0649 - acc: 0.9877 - val_loss: 4.0264 - val_acc: 0.4281\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9867\n",
      "Epoch 00016: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0646 - acc: 0.9867 - val_loss: 3.9270 - val_acc: 0.4505\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9900\n",
      "Epoch 00017: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0555 - acc: 0.9900 - val_loss: 3.9970 - val_acc: 0.4491\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9878\n",
      "Epoch 00018: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0601 - acc: 0.9878 - val_loss: 4.2629 - val_acc: 0.4309\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9845\n",
      "Epoch 00019: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0679 - acc: 0.9845 - val_loss: 4.3256 - val_acc: 0.4251\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9883\n",
      "Epoch 00020: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0572 - acc: 0.9883 - val_loss: 4.1950 - val_acc: 0.4396\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9905\n",
      "Epoch 00021: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0493 - acc: 0.9905 - val_loss: 4.2962 - val_acc: 0.4349\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9915\n",
      "Epoch 00022: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0461 - acc: 0.9915 - val_loss: 4.3917 - val_acc: 0.4423\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9905\n",
      "Epoch 00023: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0469 - acc: 0.9905 - val_loss: 4.5053 - val_acc: 0.4461\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9919\n",
      "Epoch 00024: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0442 - acc: 0.9919 - val_loss: 4.3957 - val_acc: 0.4437\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9925\n",
      "Epoch 00025: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0384 - acc: 0.9925 - val_loss: 4.6841 - val_acc: 0.4312\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9935\n",
      "Epoch 00026: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0367 - acc: 0.9935 - val_loss: 4.5676 - val_acc: 0.4279\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9939\n",
      "Epoch 00027: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0359 - acc: 0.9939 - val_loss: 4.7028 - val_acc: 0.4309\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9913\n",
      "Epoch 00028: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0446 - acc: 0.9913 - val_loss: 4.6066 - val_acc: 0.4382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9935\n",
      "Epoch 00029: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0375 - acc: 0.9935 - val_loss: 4.6350 - val_acc: 0.4340\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9921\n",
      "Epoch 00030: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0416 - acc: 0.9921 - val_loss: 4.7316 - val_acc: 0.4321\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9932\n",
      "Epoch 00031: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0372 - acc: 0.9932 - val_loss: 4.6252 - val_acc: 0.4407\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9928\n",
      "Epoch 00032: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0365 - acc: 0.9928 - val_loss: 4.6697 - val_acc: 0.4328\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9921\n",
      "Epoch 00033: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0413 - acc: 0.9921 - val_loss: 4.8203 - val_acc: 0.4218\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9938\n",
      "Epoch 00034: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0351 - acc: 0.9938 - val_loss: 4.7668 - val_acc: 0.4449\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9942\n",
      "Epoch 00035: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0319 - acc: 0.9942 - val_loss: 4.6252 - val_acc: 0.4484\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9973\n",
      "Epoch 00036: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0221 - acc: 0.9973 - val_loss: 4.6132 - val_acc: 0.4584\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9933\n",
      "Epoch 00037: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0357 - acc: 0.9932 - val_loss: 4.8969 - val_acc: 0.4351\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9945\n",
      "Epoch 00038: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0314 - acc: 0.9945 - val_loss: 4.8052 - val_acc: 0.4433\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9961\n",
      "Epoch 00039: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0261 - acc: 0.9961 - val_loss: 4.8178 - val_acc: 0.4486\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9959\n",
      "Epoch 00040: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0261 - acc: 0.9959 - val_loss: 4.7209 - val_acc: 0.4561\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9952\n",
      "Epoch 00041: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0276 - acc: 0.9952 - val_loss: 4.7775 - val_acc: 0.4356\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9940\n",
      "Epoch 00042: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0313 - acc: 0.9940 - val_loss: 4.9548 - val_acc: 0.4300\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9925\n",
      "Epoch 00043: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0367 - acc: 0.9925 - val_loss: 4.9820 - val_acc: 0.4330\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9954\n",
      "Epoch 00044: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0275 - acc: 0.9954 - val_loss: 4.8792 - val_acc: 0.4361\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9962\n",
      "Epoch 00045: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0270 - acc: 0.9962 - val_loss: 4.9373 - val_acc: 0.4521\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9964\n",
      "Epoch 00046: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0245 - acc: 0.9964 - val_loss: 5.0007 - val_acc: 0.4449\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9960\n",
      "Epoch 00047: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0265 - acc: 0.9960 - val_loss: 5.0899 - val_acc: 0.4274\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9950\n",
      "Epoch 00048: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0291 - acc: 0.9950 - val_loss: 4.9115 - val_acc: 0.4372\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9964\n",
      "Epoch 00049: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0249 - acc: 0.9964 - val_loss: 5.0234 - val_acc: 0.4456\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9960\n",
      "Epoch 00050: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0249 - acc: 0.9960 - val_loss: 4.9727 - val_acc: 0.4468\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9963\n",
      "Epoch 00051: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0244 - acc: 0.9963 - val_loss: 4.9345 - val_acc: 0.4547\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9955\n",
      "Epoch 00052: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0262 - acc: 0.9955 - val_loss: 5.1039 - val_acc: 0.4405\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9969\n",
      "Epoch 00053: val_loss did not improve from 1.67472\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0218 - acc: 0.9969 - val_loss: 4.9499 - val_acc: 0.4486\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 754us/sample - loss: 1.7554 - acc: 0.4515\n",
      "Loss: 1.7553632275213953 Accuracy: 0.45150572\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1723 - acc: 0.3115\n",
      "Epoch 00001: val_loss improved from inf to 1.73407, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_3_conv_checkpoint/001-1.7341.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 2.1721 - acc: 0.3116 - val_loss: 1.7341 - val_acc: 0.4552\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5411 - acc: 0.5260\n",
      "Epoch 00002: val_loss improved from 1.73407 to 1.48067, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_3_conv_checkpoint/002-1.4807.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.5411 - acc: 0.5259 - val_loss: 1.4807 - val_acc: 0.5330\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2568 - acc: 0.6176\n",
      "Epoch 00003: val_loss improved from 1.48067 to 1.43181, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_3_conv_checkpoint/003-1.4318.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.2567 - acc: 0.6176 - val_loss: 1.4318 - val_acc: 0.5607\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0379 - acc: 0.6867\n",
      "Epoch 00004: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.0379 - acc: 0.6867 - val_loss: 1.4782 - val_acc: 0.5674\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8274 - acc: 0.7499\n",
      "Epoch 00005: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.8274 - acc: 0.7499 - val_loss: 1.5536 - val_acc: 0.5597\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6433 - acc: 0.8062\n",
      "Epoch 00006: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.6433 - acc: 0.8061 - val_loss: 1.6702 - val_acc: 0.5479\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8580\n",
      "Epoch 00007: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.4757 - acc: 0.8580 - val_loss: 1.8995 - val_acc: 0.5358\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8942\n",
      "Epoch 00008: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.3565 - acc: 0.8942 - val_loss: 2.0588 - val_acc: 0.5495\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2639 - acc: 0.9249\n",
      "Epoch 00009: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.2640 - acc: 0.9249 - val_loss: 2.2504 - val_acc: 0.5423\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9378\n",
      "Epoch 00010: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.2188 - acc: 0.9378 - val_loss: 2.4139 - val_acc: 0.5406\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9534\n",
      "Epoch 00011: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1678 - acc: 0.9534 - val_loss: 2.6891 - val_acc: 0.5365\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9598\n",
      "Epoch 00012: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1486 - acc: 0.9598 - val_loss: 2.6811 - val_acc: 0.5411\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9624\n",
      "Epoch 00013: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1382 - acc: 0.9624 - val_loss: 2.8268 - val_acc: 0.5406\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9734\n",
      "Epoch 00014: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1052 - acc: 0.9734 - val_loss: 3.0467 - val_acc: 0.5404\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9720\n",
      "Epoch 00015: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1083 - acc: 0.9720 - val_loss: 3.0114 - val_acc: 0.5453\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9752\n",
      "Epoch 00016: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0975 - acc: 0.9752 - val_loss: 3.0774 - val_acc: 0.5493\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9770\n",
      "Epoch 00017: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0923 - acc: 0.9770 - val_loss: 3.0816 - val_acc: 0.5476\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9782\n",
      "Epoch 00018: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0884 - acc: 0.9782 - val_loss: 3.1792 - val_acc: 0.5476\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9794\n",
      "Epoch 00019: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0838 - acc: 0.9794 - val_loss: 3.2952 - val_acc: 0.5518\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9809\n",
      "Epoch 00020: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0793 - acc: 0.9809 - val_loss: 3.2531 - val_acc: 0.5481\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9843\n",
      "Epoch 00021: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0714 - acc: 0.9843 - val_loss: 3.1686 - val_acc: 0.5570\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9839\n",
      "Epoch 00022: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0698 - acc: 0.9839 - val_loss: 3.2977 - val_acc: 0.5546\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9824\n",
      "Epoch 00023: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0730 - acc: 0.9824 - val_loss: 3.4168 - val_acc: 0.5430\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9815\n",
      "Epoch 00024: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0763 - acc: 0.9815 - val_loss: 3.3446 - val_acc: 0.5500\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9846\n",
      "Epoch 00025: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0675 - acc: 0.9846 - val_loss: 3.4596 - val_acc: 0.5495\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9889\n",
      "Epoch 00026: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0550 - acc: 0.9889 - val_loss: 3.3434 - val_acc: 0.5632\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9840\n",
      "Epoch 00027: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0713 - acc: 0.9840 - val_loss: 3.3679 - val_acc: 0.5486\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9884\n",
      "Epoch 00028: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0544 - acc: 0.9884 - val_loss: 3.3028 - val_acc: 0.5751\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9872\n",
      "Epoch 00029: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0599 - acc: 0.9872 - val_loss: 3.4433 - val_acc: 0.5593\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9880\n",
      "Epoch 00030: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0578 - acc: 0.9880 - val_loss: 3.5137 - val_acc: 0.5451\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9882\n",
      "Epoch 00031: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0561 - acc: 0.9882 - val_loss: 3.3411 - val_acc: 0.5546\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9880\n",
      "Epoch 00032: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0578 - acc: 0.9880 - val_loss: 3.3254 - val_acc: 0.5658\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9889\n",
      "Epoch 00033: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0525 - acc: 0.9889 - val_loss: 3.5417 - val_acc: 0.5602\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9893\n",
      "Epoch 00034: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0531 - acc: 0.9893 - val_loss: 3.4000 - val_acc: 0.5602\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9908\n",
      "Epoch 00035: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0461 - acc: 0.9908 - val_loss: 3.4193 - val_acc: 0.5646\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9889\n",
      "Epoch 00036: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0541 - acc: 0.9889 - val_loss: 3.5075 - val_acc: 0.5488\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9904\n",
      "Epoch 00037: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0488 - acc: 0.9904 - val_loss: 3.4453 - val_acc: 0.5577\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9885\n",
      "Epoch 00038: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0543 - acc: 0.9885 - val_loss: 3.4069 - val_acc: 0.5646\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9927\n",
      "Epoch 00039: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0414 - acc: 0.9927 - val_loss: 3.5925 - val_acc: 0.5579\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9909\n",
      "Epoch 00040: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0460 - acc: 0.9909 - val_loss: 3.5329 - val_acc: 0.5537\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9896\n",
      "Epoch 00041: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0491 - acc: 0.9896 - val_loss: 3.4513 - val_acc: 0.5586\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9911\n",
      "Epoch 00042: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0458 - acc: 0.9911 - val_loss: 3.5117 - val_acc: 0.5614\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9921\n",
      "Epoch 00043: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0421 - acc: 0.9921 - val_loss: 3.6163 - val_acc: 0.5511\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9907\n",
      "Epoch 00044: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0477 - acc: 0.9907 - val_loss: 3.4472 - val_acc: 0.5577\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9937\n",
      "Epoch 00045: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0371 - acc: 0.9937 - val_loss: 3.6023 - val_acc: 0.5595\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9893\n",
      "Epoch 00046: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0506 - acc: 0.9893 - val_loss: 3.4935 - val_acc: 0.5530\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9918\n",
      "Epoch 00047: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0426 - acc: 0.9918 - val_loss: 3.5119 - val_acc: 0.5628\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9924\n",
      "Epoch 00048: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0417 - acc: 0.9924 - val_loss: 3.4916 - val_acc: 0.5607\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9920\n",
      "Epoch 00049: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0427 - acc: 0.9920 - val_loss: 3.6972 - val_acc: 0.5611\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0419 - acc: 0.9924 - val_loss: 3.6464 - val_acc: 0.5595\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9936\n",
      "Epoch 00051: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0389 - acc: 0.9936 - val_loss: 3.8011 - val_acc: 0.5551\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9922\n",
      "Epoch 00052: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0422 - acc: 0.9922 - val_loss: 3.4141 - val_acc: 0.5642\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9943\n",
      "Epoch 00053: val_loss did not improve from 1.43181\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0355 - acc: 0.9943 - val_loss: 3.6147 - val_acc: 0.5614\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 871us/sample - loss: 1.5044 - acc: 0.5283\n",
      "Loss: 1.5043999260707313 Accuracy: 0.5283489\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1931 - acc: 0.2911\n",
      "Epoch 00001: val_loss improved from inf to 1.57875, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv_checkpoint/001-1.5788.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.1930 - acc: 0.2911 - val_loss: 1.5788 - val_acc: 0.4934\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4570 - acc: 0.5406\n",
      "Epoch 00002: val_loss improved from 1.57875 to 1.35038, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv_checkpoint/002-1.3504.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.4570 - acc: 0.5406 - val_loss: 1.3504 - val_acc: 0.5761\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2183 - acc: 0.6254\n",
      "Epoch 00003: val_loss improved from 1.35038 to 1.25668, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv_checkpoint/003-1.2567.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2185 - acc: 0.6254 - val_loss: 1.2567 - val_acc: 0.6047\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0533 - acc: 0.6808\n",
      "Epoch 00004: val_loss improved from 1.25668 to 1.22007, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv_checkpoint/004-1.2201.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0533 - acc: 0.6808 - val_loss: 1.2201 - val_acc: 0.6313\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8928 - acc: 0.7323\n",
      "Epoch 00005: val_loss improved from 1.22007 to 1.14708, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv_checkpoint/005-1.1471.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8928 - acc: 0.7323 - val_loss: 1.1471 - val_acc: 0.6445\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7493 - acc: 0.7734\n",
      "Epoch 00006: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7493 - acc: 0.7734 - val_loss: 1.1701 - val_acc: 0.6443\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.8154\n",
      "Epoch 00007: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6129 - acc: 0.8153 - val_loss: 1.2084 - val_acc: 0.6478\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.8508\n",
      "Epoch 00008: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4933 - acc: 0.8508 - val_loss: 1.2425 - val_acc: 0.6560\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8796\n",
      "Epoch 00009: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3965 - acc: 0.8796 - val_loss: 1.3081 - val_acc: 0.6650\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3245 - acc: 0.9000\n",
      "Epoch 00010: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3246 - acc: 0.9000 - val_loss: 1.3714 - val_acc: 0.6620\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9164\n",
      "Epoch 00011: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2677 - acc: 0.9163 - val_loss: 1.4252 - val_acc: 0.6611\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2168 - acc: 0.9337\n",
      "Epoch 00012: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2168 - acc: 0.9337 - val_loss: 1.5186 - val_acc: 0.6641\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9429\n",
      "Epoch 00013: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1871 - acc: 0.9429 - val_loss: 1.6317 - val_acc: 0.6620\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9520\n",
      "Epoch 00014: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1593 - acc: 0.9520 - val_loss: 1.6555 - val_acc: 0.6767\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9568\n",
      "Epoch 00015: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1421 - acc: 0.9568 - val_loss: 1.7207 - val_acc: 0.6751\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9638\n",
      "Epoch 00016: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1265 - acc: 0.9638 - val_loss: 1.8264 - val_acc: 0.6751\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9631\n",
      "Epoch 00017: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1228 - acc: 0.9631 - val_loss: 1.7454 - val_acc: 0.6862\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9645\n",
      "Epoch 00018: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1167 - acc: 0.9645 - val_loss: 1.7797 - val_acc: 0.6716\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9699\n",
      "Epoch 00019: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1032 - acc: 0.9699 - val_loss: 1.9031 - val_acc: 0.6613\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9732\n",
      "Epoch 00020: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0923 - acc: 0.9732 - val_loss: 1.9398 - val_acc: 0.6839\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9736\n",
      "Epoch 00021: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0889 - acc: 0.9736 - val_loss: 1.9493 - val_acc: 0.6790\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9741\n",
      "Epoch 00022: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0881 - acc: 0.9741 - val_loss: 1.9827 - val_acc: 0.6841\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9775\n",
      "Epoch 00023: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0826 - acc: 0.9775 - val_loss: 2.0251 - val_acc: 0.6748\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9754\n",
      "Epoch 00024: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0863 - acc: 0.9754 - val_loss: 2.0994 - val_acc: 0.6727\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9780\n",
      "Epoch 00025: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0774 - acc: 0.9780 - val_loss: 2.0471 - val_acc: 0.6809\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9806\n",
      "Epoch 00026: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0710 - acc: 0.9806 - val_loss: 2.1363 - val_acc: 0.6744\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9801\n",
      "Epoch 00027: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0709 - acc: 0.9801 - val_loss: 2.1472 - val_acc: 0.6685\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9801\n",
      "Epoch 00028: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0708 - acc: 0.9801 - val_loss: 2.1603 - val_acc: 0.6776\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9804\n",
      "Epoch 00029: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0719 - acc: 0.9804 - val_loss: 2.0469 - val_acc: 0.6872\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9845\n",
      "Epoch 00030: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0610 - acc: 0.9845 - val_loss: 2.0368 - val_acc: 0.6874\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9813\n",
      "Epoch 00031: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0686 - acc: 0.9813 - val_loss: 2.0647 - val_acc: 0.6886\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9832\n",
      "Epoch 00032: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0642 - acc: 0.9832 - val_loss: 2.1732 - val_acc: 0.6769\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9850\n",
      "Epoch 00033: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0559 - acc: 0.9850 - val_loss: 2.0810 - val_acc: 0.6944\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9845\n",
      "Epoch 00034: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0574 - acc: 0.9845 - val_loss: 2.1834 - val_acc: 0.6888\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9846\n",
      "Epoch 00035: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0593 - acc: 0.9846 - val_loss: 2.0244 - val_acc: 0.6974\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9844\n",
      "Epoch 00036: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0598 - acc: 0.9844 - val_loss: 2.0843 - val_acc: 0.6893\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9854\n",
      "Epoch 00037: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0560 - acc: 0.9854 - val_loss: 2.1486 - val_acc: 0.6806\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9853\n",
      "Epoch 00038: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0567 - acc: 0.9853 - val_loss: 2.1621 - val_acc: 0.6881\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9865\n",
      "Epoch 00039: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0526 - acc: 0.9865 - val_loss: 2.0857 - val_acc: 0.6925\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9876\n",
      "Epoch 00040: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0477 - acc: 0.9876 - val_loss: 2.1229 - val_acc: 0.6937\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9869\n",
      "Epoch 00041: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0497 - acc: 0.9869 - val_loss: 2.0870 - val_acc: 0.6916\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9872\n",
      "Epoch 00042: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0512 - acc: 0.9872 - val_loss: 2.0545 - val_acc: 0.7016\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9872\n",
      "Epoch 00043: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0513 - acc: 0.9872 - val_loss: 2.0475 - val_acc: 0.7053\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9882\n",
      "Epoch 00044: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0481 - acc: 0.9882 - val_loss: 2.1045 - val_acc: 0.7004\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9880\n",
      "Epoch 00045: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0470 - acc: 0.9880 - val_loss: 2.1801 - val_acc: 0.6983\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9878\n",
      "Epoch 00046: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0498 - acc: 0.9878 - val_loss: 2.1493 - val_acc: 0.6837\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9889\n",
      "Epoch 00047: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0455 - acc: 0.9889 - val_loss: 2.0690 - val_acc: 0.6944\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9886\n",
      "Epoch 00048: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0466 - acc: 0.9886 - val_loss: 2.1309 - val_acc: 0.6997\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9881\n",
      "Epoch 00049: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0484 - acc: 0.9881 - val_loss: 2.1761 - val_acc: 0.6951\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9902\n",
      "Epoch 00050: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0408 - acc: 0.9902 - val_loss: 2.1076 - val_acc: 0.7084\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9885\n",
      "Epoch 00051: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0478 - acc: 0.9885 - val_loss: 2.2032 - val_acc: 0.6811\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9895\n",
      "Epoch 00052: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0435 - acc: 0.9895 - val_loss: 2.1477 - val_acc: 0.6976\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9907\n",
      "Epoch 00053: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0430 - acc: 0.9907 - val_loss: 2.1206 - val_acc: 0.7007\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9914\n",
      "Epoch 00054: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0377 - acc: 0.9914 - val_loss: 2.2927 - val_acc: 0.7025\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9892\n",
      "Epoch 00055: val_loss did not improve from 1.14708\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0432 - acc: 0.9892 - val_loss: 2.1571 - val_acc: 0.7042\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 933us/sample - loss: 1.2181 - acc: 0.6274\n",
      "Loss: 1.2180704966512426 Accuracy: 0.62741435\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1287 - acc: 0.3082\n",
      "Epoch 00001: val_loss improved from inf to 1.47265, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/001-1.4726.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 2.1286 - acc: 0.3082 - val_loss: 1.4726 - val_acc: 0.5434\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4059 - acc: 0.5584\n",
      "Epoch 00002: val_loss improved from 1.47265 to 1.23049, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/002-1.2305.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.4059 - acc: 0.5584 - val_loss: 1.2305 - val_acc: 0.6152\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2035 - acc: 0.6314\n",
      "Epoch 00003: val_loss improved from 1.23049 to 1.08011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/003-1.0801.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.2036 - acc: 0.6314 - val_loss: 1.0801 - val_acc: 0.6695\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0349 - acc: 0.6863\n",
      "Epoch 00004: val_loss improved from 1.08011 to 0.95142, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/004-0.9514.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.0349 - acc: 0.6863 - val_loss: 0.9514 - val_acc: 0.7184\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8922 - acc: 0.7320\n",
      "Epoch 00005: val_loss improved from 0.95142 to 0.89145, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/005-0.8914.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8922 - acc: 0.7320 - val_loss: 0.8914 - val_acc: 0.7307\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7824 - acc: 0.7684\n",
      "Epoch 00006: val_loss improved from 0.89145 to 0.81891, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/006-0.8189.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7825 - acc: 0.7683 - val_loss: 0.8189 - val_acc: 0.7552\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6873 - acc: 0.7966\n",
      "Epoch 00007: val_loss improved from 0.81891 to 0.76615, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv_checkpoint/007-0.7661.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6872 - acc: 0.7966 - val_loss: 0.7661 - val_acc: 0.7759\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6097 - acc: 0.8183\n",
      "Epoch 00008: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6097 - acc: 0.8183 - val_loss: 0.8007 - val_acc: 0.7671\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5252 - acc: 0.8438\n",
      "Epoch 00009: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5252 - acc: 0.8438 - val_loss: 0.7783 - val_acc: 0.7675\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8649\n",
      "Epoch 00010: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4506 - acc: 0.8648 - val_loss: 0.8057 - val_acc: 0.7687\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8810\n",
      "Epoch 00011: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3958 - acc: 0.8810 - val_loss: 0.8632 - val_acc: 0.7650\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.8996\n",
      "Epoch 00012: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3297 - acc: 0.8996 - val_loss: 0.8397 - val_acc: 0.7752\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.9145\n",
      "Epoch 00013: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2816 - acc: 0.9144 - val_loss: 0.8401 - val_acc: 0.7745\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.9231\n",
      "Epoch 00014: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2470 - acc: 0.9231 - val_loss: 0.8885 - val_acc: 0.7724\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9379\n",
      "Epoch 00015: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2023 - acc: 0.9379 - val_loss: 0.9436 - val_acc: 0.7813\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9469\n",
      "Epoch 00016: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1717 - acc: 0.9469 - val_loss: 0.9640 - val_acc: 0.7827\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1559 - acc: 0.9521\n",
      "Epoch 00017: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1559 - acc: 0.9521 - val_loss: 1.0012 - val_acc: 0.7768\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9575\n",
      "Epoch 00018: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1353 - acc: 0.9575 - val_loss: 1.0054 - val_acc: 0.7822\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9629\n",
      "Epoch 00019: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1225 - acc: 0.9629 - val_loss: 1.0820 - val_acc: 0.7808\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9649\n",
      "Epoch 00020: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1193 - acc: 0.9649 - val_loss: 1.1472 - val_acc: 0.7754\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9679\n",
      "Epoch 00021: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1062 - acc: 0.9679 - val_loss: 1.1860 - val_acc: 0.7766\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9700\n",
      "Epoch 00022: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0990 - acc: 0.9700 - val_loss: 1.1133 - val_acc: 0.7866\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9722\n",
      "Epoch 00023: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0923 - acc: 0.9722 - val_loss: 1.1864 - val_acc: 0.7713\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9743\n",
      "Epoch 00024: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0877 - acc: 0.9743 - val_loss: 1.2484 - val_acc: 0.7722\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9761\n",
      "Epoch 00025: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0818 - acc: 0.9761 - val_loss: 1.2177 - val_acc: 0.7829\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9752\n",
      "Epoch 00026: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0807 - acc: 0.9752 - val_loss: 1.1988 - val_acc: 0.7754\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0746 - acc: 0.9784\n",
      "Epoch 00027: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0746 - acc: 0.9784 - val_loss: 1.1783 - val_acc: 0.7908\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9796\n",
      "Epoch 00028: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0747 - acc: 0.9796 - val_loss: 1.1283 - val_acc: 0.7775\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9795\n",
      "Epoch 00029: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0710 - acc: 0.9795 - val_loss: 1.2161 - val_acc: 0.7887\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9784\n",
      "Epoch 00030: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0727 - acc: 0.9784 - val_loss: 1.1749 - val_acc: 0.7941\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9841\n",
      "Epoch 00031: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0602 - acc: 0.9841 - val_loss: 1.2429 - val_acc: 0.7918\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9806\n",
      "Epoch 00032: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0701 - acc: 0.9806 - val_loss: 1.2895 - val_acc: 0.7696\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9836\n",
      "Epoch 00033: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0596 - acc: 0.9836 - val_loss: 1.2667 - val_acc: 0.7987\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9843\n",
      "Epoch 00034: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0559 - acc: 0.9843 - val_loss: 1.2658 - val_acc: 0.7904\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9846\n",
      "Epoch 00035: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0557 - acc: 0.9846 - val_loss: 1.3074 - val_acc: 0.7722\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9842\n",
      "Epoch 00036: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0590 - acc: 0.9842 - val_loss: 1.2526 - val_acc: 0.7822\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9846\n",
      "Epoch 00037: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0585 - acc: 0.9846 - val_loss: 1.2735 - val_acc: 0.7836\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9849\n",
      "Epoch 00038: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0569 - acc: 0.9849 - val_loss: 1.3629 - val_acc: 0.7757\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9859\n",
      "Epoch 00039: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0526 - acc: 0.9859 - val_loss: 1.2937 - val_acc: 0.7957\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9880\n",
      "Epoch 00040: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0470 - acc: 0.9880 - val_loss: 1.2824 - val_acc: 0.7885\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9843\n",
      "Epoch 00041: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0581 - acc: 0.9843 - val_loss: 1.2549 - val_acc: 0.7948\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9878\n",
      "Epoch 00042: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0486 - acc: 0.9878 - val_loss: 1.2720 - val_acc: 0.7992\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9866\n",
      "Epoch 00043: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0509 - acc: 0.9866 - val_loss: 1.2603 - val_acc: 0.7952\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9876\n",
      "Epoch 00044: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0479 - acc: 0.9876 - val_loss: 1.2724 - val_acc: 0.7990\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9877\n",
      "Epoch 00045: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0458 - acc: 0.9877 - val_loss: 1.3061 - val_acc: 0.7897\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9882\n",
      "Epoch 00046: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0443 - acc: 0.9882 - val_loss: 1.3480 - val_acc: 0.7957\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9888\n",
      "Epoch 00047: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0449 - acc: 0.9888 - val_loss: 1.2998 - val_acc: 0.7908\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9873\n",
      "Epoch 00048: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0479 - acc: 0.9873 - val_loss: 1.3308 - val_acc: 0.7915\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9881\n",
      "Epoch 00049: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0470 - acc: 0.9881 - val_loss: 1.4296 - val_acc: 0.7850\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9898\n",
      "Epoch 00050: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0423 - acc: 0.9898 - val_loss: 1.3561 - val_acc: 0.7950\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9893\n",
      "Epoch 00051: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0434 - acc: 0.9893 - val_loss: 1.3183 - val_acc: 0.7887\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9880\n",
      "Epoch 00052: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0468 - acc: 0.9880 - val_loss: 1.2505 - val_acc: 0.8041\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9893\n",
      "Epoch 00053: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0418 - acc: 0.9893 - val_loss: 1.3024 - val_acc: 0.8029\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9897\n",
      "Epoch 00054: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0423 - acc: 0.9897 - val_loss: 1.3320 - val_acc: 0.7999\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9905\n",
      "Epoch 00055: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0378 - acc: 0.9905 - val_loss: 1.3277 - val_acc: 0.7957\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9908\n",
      "Epoch 00056: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0386 - acc: 0.9908 - val_loss: 1.2657 - val_acc: 0.8029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9892\n",
      "Epoch 00057: val_loss did not improve from 0.76615\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0439 - acc: 0.9892 - val_loss: 1.2986 - val_acc: 0.8053\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 966us/sample - loss: 0.8578 - acc: 0.7391\n",
      "Loss: 0.8577612707919421 Accuracy: 0.7391485\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4270 - acc: 0.2028\n",
      "Epoch 00001: val_loss improved from inf to 1.99875, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/001-1.9987.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 2.4270 - acc: 0.2028 - val_loss: 1.9987 - val_acc: 0.3597\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7298 - acc: 0.4422\n",
      "Epoch 00002: val_loss improved from 1.99875 to 1.37548, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/002-1.3755.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.7299 - acc: 0.4422 - val_loss: 1.3755 - val_acc: 0.5495\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3212 - acc: 0.5742\n",
      "Epoch 00003: val_loss improved from 1.37548 to 1.15588, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/003-1.1559.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3211 - acc: 0.5742 - val_loss: 1.1559 - val_acc: 0.6371\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1700 - acc: 0.6263\n",
      "Epoch 00004: val_loss improved from 1.15588 to 1.08560, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/004-1.0856.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1699 - acc: 0.6264 - val_loss: 1.0856 - val_acc: 0.6515\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0593 - acc: 0.6682\n",
      "Epoch 00005: val_loss improved from 1.08560 to 0.95812, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/005-0.9581.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0595 - acc: 0.6681 - val_loss: 0.9581 - val_acc: 0.7112\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9654 - acc: 0.7028\n",
      "Epoch 00006: val_loss improved from 0.95812 to 0.88888, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/006-0.8889.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9655 - acc: 0.7028 - val_loss: 0.8889 - val_acc: 0.7449\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8657 - acc: 0.7353\n",
      "Epoch 00007: val_loss improved from 0.88888 to 0.84861, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/007-0.8486.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8657 - acc: 0.7353 - val_loss: 0.8486 - val_acc: 0.7431\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7708 - acc: 0.7666\n",
      "Epoch 00008: val_loss improved from 0.84861 to 0.69424, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/008-0.6942.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7708 - acc: 0.7666 - val_loss: 0.6942 - val_acc: 0.7980\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6976 - acc: 0.7915\n",
      "Epoch 00009: val_loss improved from 0.69424 to 0.64954, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/009-0.6495.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6975 - acc: 0.7916 - val_loss: 0.6495 - val_acc: 0.8095\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6255 - acc: 0.8101\n",
      "Epoch 00010: val_loss improved from 0.64954 to 0.59056, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/010-0.5906.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6254 - acc: 0.8101 - val_loss: 0.5906 - val_acc: 0.8302\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5612 - acc: 0.8329\n",
      "Epoch 00011: val_loss improved from 0.59056 to 0.53824, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/011-0.5382.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5612 - acc: 0.8330 - val_loss: 0.5382 - val_acc: 0.8521\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.8492\n",
      "Epoch 00012: val_loss improved from 0.53824 to 0.50511, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/012-0.5051.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5083 - acc: 0.8492 - val_loss: 0.5051 - val_acc: 0.8588\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8601\n",
      "Epoch 00013: val_loss improved from 0.50511 to 0.46901, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/013-0.4690.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4662 - acc: 0.8601 - val_loss: 0.4690 - val_acc: 0.8675\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4256 - acc: 0.8715\n",
      "Epoch 00014: val_loss did not improve from 0.46901\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4255 - acc: 0.8715 - val_loss: 0.4973 - val_acc: 0.8593\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8824\n",
      "Epoch 00015: val_loss did not improve from 0.46901\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3849 - acc: 0.8824 - val_loss: 0.5025 - val_acc: 0.8635\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3540 - acc: 0.8917\n",
      "Epoch 00016: val_loss improved from 0.46901 to 0.44263, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/016-0.4426.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3540 - acc: 0.8918 - val_loss: 0.4426 - val_acc: 0.8807\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.9002\n",
      "Epoch 00017: val_loss did not improve from 0.44263\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3288 - acc: 0.9002 - val_loss: 0.4581 - val_acc: 0.8742\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9072\n",
      "Epoch 00018: val_loss improved from 0.44263 to 0.42845, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/018-0.4285.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3025 - acc: 0.9072 - val_loss: 0.4285 - val_acc: 0.8810\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2726 - acc: 0.9161\n",
      "Epoch 00019: val_loss did not improve from 0.42845\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2726 - acc: 0.9161 - val_loss: 0.4406 - val_acc: 0.8803\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2621 - acc: 0.9182\n",
      "Epoch 00020: val_loss did not improve from 0.42845\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2621 - acc: 0.9182 - val_loss: 0.4627 - val_acc: 0.8726\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9255\n",
      "Epoch 00021: val_loss did not improve from 0.42845\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2405 - acc: 0.9255 - val_loss: 0.4476 - val_acc: 0.8908\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9313\n",
      "Epoch 00022: val_loss did not improve from 0.42845\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2181 - acc: 0.9313 - val_loss: 0.4994 - val_acc: 0.8842\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9360\n",
      "Epoch 00023: val_loss improved from 0.42845 to 0.42608, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/023-0.4261.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2052 - acc: 0.9359 - val_loss: 0.4261 - val_acc: 0.8975\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9368\n",
      "Epoch 00024: val_loss did not improve from 0.42608\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1979 - acc: 0.9368 - val_loss: 0.4418 - val_acc: 0.8987\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9420\n",
      "Epoch 00025: val_loss improved from 0.42608 to 0.41430, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv_checkpoint/025-0.4143.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1827 - acc: 0.9419 - val_loss: 0.4143 - val_acc: 0.8928\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9461\n",
      "Epoch 00026: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1680 - acc: 0.9461 - val_loss: 0.5172 - val_acc: 0.8798\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9500\n",
      "Epoch 00027: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1545 - acc: 0.9500 - val_loss: 0.4365 - val_acc: 0.8987\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9505\n",
      "Epoch 00028: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1504 - acc: 0.9505 - val_loss: 0.4625 - val_acc: 0.8940\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9542\n",
      "Epoch 00029: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1416 - acc: 0.9542 - val_loss: 0.4524 - val_acc: 0.9050\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9605\n",
      "Epoch 00030: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1252 - acc: 0.9605 - val_loss: 0.4803 - val_acc: 0.8970\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9601\n",
      "Epoch 00031: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1225 - acc: 0.9601 - val_loss: 0.4736 - val_acc: 0.8977\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9622\n",
      "Epoch 00032: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1180 - acc: 0.9622 - val_loss: 0.5062 - val_acc: 0.8940\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9649\n",
      "Epoch 00033: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1081 - acc: 0.9649 - val_loss: 0.5291 - val_acc: 0.8980\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9674\n",
      "Epoch 00034: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1036 - acc: 0.9674 - val_loss: 0.4739 - val_acc: 0.9045\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9681\n",
      "Epoch 00035: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0990 - acc: 0.9681 - val_loss: 0.5600 - val_acc: 0.8854\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9699\n",
      "Epoch 00036: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0948 - acc: 0.9699 - val_loss: 0.5390 - val_acc: 0.9003\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9700\n",
      "Epoch 00037: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0915 - acc: 0.9700 - val_loss: 0.5310 - val_acc: 0.9008\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9727\n",
      "Epoch 00038: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0868 - acc: 0.9727 - val_loss: 0.5169 - val_acc: 0.9047\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9732\n",
      "Epoch 00039: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0848 - acc: 0.9732 - val_loss: 0.5087 - val_acc: 0.9005\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9726\n",
      "Epoch 00040: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0853 - acc: 0.9726 - val_loss: 0.5209 - val_acc: 0.9029\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9745\n",
      "Epoch 00041: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0790 - acc: 0.9745 - val_loss: 0.5493 - val_acc: 0.9012\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9775\n",
      "Epoch 00042: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0700 - acc: 0.9775 - val_loss: 0.5220 - val_acc: 0.9061\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9761\n",
      "Epoch 00043: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0734 - acc: 0.9761 - val_loss: 0.5899 - val_acc: 0.8961\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9774\n",
      "Epoch 00044: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0697 - acc: 0.9774 - val_loss: 0.5126 - val_acc: 0.9040\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9788\n",
      "Epoch 00045: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0664 - acc: 0.9788 - val_loss: 0.5411 - val_acc: 0.9005\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9818\n",
      "Epoch 00046: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0590 - acc: 0.9818 - val_loss: 0.5324 - val_acc: 0.9108\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9797\n",
      "Epoch 00047: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0648 - acc: 0.9797 - val_loss: 0.5765 - val_acc: 0.9043\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9802\n",
      "Epoch 00048: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0635 - acc: 0.9802 - val_loss: 0.5335 - val_acc: 0.9087\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9823\n",
      "Epoch 00049: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0580 - acc: 0.9823 - val_loss: 0.5211 - val_acc: 0.9089\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9834\n",
      "Epoch 00050: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0541 - acc: 0.9834 - val_loss: 0.5165 - val_acc: 0.9159\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9824\n",
      "Epoch 00051: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0588 - acc: 0.9824 - val_loss: 0.5277 - val_acc: 0.9015\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9815\n",
      "Epoch 00052: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0573 - acc: 0.9815 - val_loss: 0.5072 - val_acc: 0.9080\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9838\n",
      "Epoch 00053: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0530 - acc: 0.9838 - val_loss: 0.5941 - val_acc: 0.9075\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9831\n",
      "Epoch 00054: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0551 - acc: 0.9831 - val_loss: 0.5285 - val_acc: 0.9075\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9836\n",
      "Epoch 00055: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0545 - acc: 0.9836 - val_loss: 0.5958 - val_acc: 0.9022\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9835\n",
      "Epoch 00056: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0538 - acc: 0.9835 - val_loss: 0.5438 - val_acc: 0.9050\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9864\n",
      "Epoch 00057: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0452 - acc: 0.9864 - val_loss: 0.5635 - val_acc: 0.9099\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9857\n",
      "Epoch 00058: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0486 - acc: 0.9857 - val_loss: 0.5080 - val_acc: 0.9133\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9854\n",
      "Epoch 00059: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0494 - acc: 0.9853 - val_loss: 0.5145 - val_acc: 0.9099\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9862\n",
      "Epoch 00060: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0457 - acc: 0.9862 - val_loss: 0.5429 - val_acc: 0.9075\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9858\n",
      "Epoch 00061: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0447 - acc: 0.9858 - val_loss: 0.5408 - val_acc: 0.9124\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9864\n",
      "Epoch 00062: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0438 - acc: 0.9864 - val_loss: 0.6053 - val_acc: 0.9017\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9868\n",
      "Epoch 00063: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0439 - acc: 0.9868 - val_loss: 0.5390 - val_acc: 0.9119\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9867\n",
      "Epoch 00064: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0438 - acc: 0.9867 - val_loss: 0.5566 - val_acc: 0.9099\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9882\n",
      "Epoch 00065: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0390 - acc: 0.9882 - val_loss: 0.5642 - val_acc: 0.9061\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9873\n",
      "Epoch 00066: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0423 - acc: 0.9873 - val_loss: 0.6277 - val_acc: 0.9036\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9888\n",
      "Epoch 00067: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0376 - acc: 0.9888 - val_loss: 0.5909 - val_acc: 0.9085\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9884\n",
      "Epoch 00068: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0404 - acc: 0.9883 - val_loss: 0.5885 - val_acc: 0.9059\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9882\n",
      "Epoch 00069: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0401 - acc: 0.9882 - val_loss: 0.5798 - val_acc: 0.9131\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9886\n",
      "Epoch 00070: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0410 - acc: 0.9886 - val_loss: 0.5624 - val_acc: 0.9136\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9888\n",
      "Epoch 00071: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0367 - acc: 0.9888 - val_loss: 0.5799 - val_acc: 0.9019\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9900\n",
      "Epoch 00072: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0341 - acc: 0.9900 - val_loss: 0.5974 - val_acc: 0.9103\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9885\n",
      "Epoch 00073: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0382 - acc: 0.9885 - val_loss: 0.6145 - val_acc: 0.9026\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9888\n",
      "Epoch 00074: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0378 - acc: 0.9888 - val_loss: 0.5421 - val_acc: 0.9106\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9907\n",
      "Epoch 00075: val_loss did not improve from 0.41430\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0316 - acc: 0.9907 - val_loss: 0.5597 - val_acc: 0.9126\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4719 - acc: 0.8679\n",
      "Loss: 0.4719278172911885 Accuracy: 0.86791277\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4367 - acc: 0.1950\n",
      "Epoch 00001: val_loss improved from inf to 1.83150, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/001-1.8315.hdf5\n",
      "36805/36805 [==============================] - 100s 3ms/sample - loss: 2.4368 - acc: 0.1950 - val_loss: 1.8315 - val_acc: 0.4274\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5478 - acc: 0.4939\n",
      "Epoch 00002: val_loss improved from 1.83150 to 1.27734, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/002-1.2773.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.5477 - acc: 0.4939 - val_loss: 1.2773 - val_acc: 0.6014\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1618 - acc: 0.6257\n",
      "Epoch 00003: val_loss improved from 1.27734 to 0.95295, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/003-0.9529.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.1619 - acc: 0.6257 - val_loss: 0.9529 - val_acc: 0.7140\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9333 - acc: 0.7016\n",
      "Epoch 00004: val_loss improved from 0.95295 to 0.74819, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/004-0.7482.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.9333 - acc: 0.7016 - val_loss: 0.7482 - val_acc: 0.7619\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7852 - acc: 0.7510\n",
      "Epoch 00005: val_loss improved from 0.74819 to 0.60516, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/005-0.6052.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7853 - acc: 0.7509 - val_loss: 0.6052 - val_acc: 0.8211\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6668 - acc: 0.7876\n",
      "Epoch 00006: val_loss improved from 0.60516 to 0.47846, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/006-0.4785.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6667 - acc: 0.7876 - val_loss: 0.4785 - val_acc: 0.8612\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5789 - acc: 0.8139\n",
      "Epoch 00007: val_loss improved from 0.47846 to 0.45466, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/007-0.4547.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5788 - acc: 0.8139 - val_loss: 0.4547 - val_acc: 0.8656\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.8398\n",
      "Epoch 00008: val_loss improved from 0.45466 to 0.41975, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/008-0.4197.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5011 - acc: 0.8398 - val_loss: 0.4197 - val_acc: 0.8726\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4441 - acc: 0.8584\n",
      "Epoch 00009: val_loss improved from 0.41975 to 0.35228, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/009-0.3523.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4441 - acc: 0.8584 - val_loss: 0.3523 - val_acc: 0.8956\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8734\n",
      "Epoch 00010: val_loss improved from 0.35228 to 0.34340, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/010-0.3434.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3992 - acc: 0.8734 - val_loss: 0.3434 - val_acc: 0.8959\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8844\n",
      "Epoch 00011: val_loss improved from 0.34340 to 0.31357, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/011-0.3136.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3648 - acc: 0.8844 - val_loss: 0.3136 - val_acc: 0.9108\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8920\n",
      "Epoch 00012: val_loss improved from 0.31357 to 0.29991, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/012-0.2999.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3405 - acc: 0.8920 - val_loss: 0.2999 - val_acc: 0.9117\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.9008\n",
      "Epoch 00013: val_loss improved from 0.29991 to 0.27847, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/013-0.2785.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3145 - acc: 0.9007 - val_loss: 0.2785 - val_acc: 0.9185\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9076\n",
      "Epoch 00014: val_loss improved from 0.27847 to 0.25259, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/014-0.2526.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2927 - acc: 0.9076 - val_loss: 0.2526 - val_acc: 0.9287\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9151\n",
      "Epoch 00015: val_loss did not improve from 0.25259\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2678 - acc: 0.9151 - val_loss: 0.2780 - val_acc: 0.9213\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2569 - acc: 0.9191\n",
      "Epoch 00016: val_loss improved from 0.25259 to 0.24863, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/016-0.2486.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2569 - acc: 0.9191 - val_loss: 0.2486 - val_acc: 0.9294\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9243\n",
      "Epoch 00017: val_loss improved from 0.24863 to 0.23473, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/017-0.2347.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2360 - acc: 0.9242 - val_loss: 0.2347 - val_acc: 0.9364\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9265\n",
      "Epoch 00018: val_loss improved from 0.23473 to 0.22459, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/018-0.2246.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2243 - acc: 0.9265 - val_loss: 0.2246 - val_acc: 0.9341\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9337\n",
      "Epoch 00019: val_loss did not improve from 0.22459\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2092 - acc: 0.9338 - val_loss: 0.2474 - val_acc: 0.9329\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9352\n",
      "Epoch 00020: val_loss did not improve from 0.22459\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1986 - acc: 0.9352 - val_loss: 0.2344 - val_acc: 0.9383\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9418\n",
      "Epoch 00021: val_loss improved from 0.22459 to 0.22263, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/021-0.2226.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1835 - acc: 0.9418 - val_loss: 0.2226 - val_acc: 0.9406\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9425\n",
      "Epoch 00022: val_loss did not improve from 0.22263\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1792 - acc: 0.9425 - val_loss: 0.2328 - val_acc: 0.9336\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9461\n",
      "Epoch 00023: val_loss improved from 0.22263 to 0.21672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/023-0.2167.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1665 - acc: 0.9461 - val_loss: 0.2167 - val_acc: 0.9455\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9488\n",
      "Epoch 00024: val_loss did not improve from 0.21672\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1590 - acc: 0.9488 - val_loss: 0.2187 - val_acc: 0.9418\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9484\n",
      "Epoch 00025: val_loss did not improve from 0.21672\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1551 - acc: 0.9484 - val_loss: 0.2178 - val_acc: 0.9385\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9545\n",
      "Epoch 00026: val_loss improved from 0.21672 to 0.20295, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/026-0.2029.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1415 - acc: 0.9545 - val_loss: 0.2029 - val_acc: 0.9481\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9551\n",
      "Epoch 00027: val_loss did not improve from 0.20295\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1384 - acc: 0.9551 - val_loss: 0.2490 - val_acc: 0.9336\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9551\n",
      "Epoch 00028: val_loss improved from 0.20295 to 0.19860, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv_checkpoint/028-0.1986.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1352 - acc: 0.9551 - val_loss: 0.1986 - val_acc: 0.9506\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9583\n",
      "Epoch 00029: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1266 - acc: 0.9583 - val_loss: 0.2114 - val_acc: 0.9455\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9627\n",
      "Epoch 00030: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1150 - acc: 0.9627 - val_loss: 0.2175 - val_acc: 0.9448\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9615\n",
      "Epoch 00031: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1155 - acc: 0.9615 - val_loss: 0.2218 - val_acc: 0.9408\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9632\n",
      "Epoch 00032: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1122 - acc: 0.9632 - val_loss: 0.2110 - val_acc: 0.9471\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9656\n",
      "Epoch 00033: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1052 - acc: 0.9656 - val_loss: 0.2191 - val_acc: 0.9420\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9653\n",
      "Epoch 00034: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1027 - acc: 0.9653 - val_loss: 0.2410 - val_acc: 0.9460\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9682\n",
      "Epoch 00035: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0969 - acc: 0.9682 - val_loss: 0.2298 - val_acc: 0.9413\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9686\n",
      "Epoch 00036: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0948 - acc: 0.9686 - val_loss: 0.2417 - val_acc: 0.9443\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9685\n",
      "Epoch 00037: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0927 - acc: 0.9685 - val_loss: 0.2432 - val_acc: 0.9427\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9704\n",
      "Epoch 00038: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0895 - acc: 0.9704 - val_loss: 0.2211 - val_acc: 0.9425\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9717\n",
      "Epoch 00039: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0839 - acc: 0.9717 - val_loss: 0.2640 - val_acc: 0.9411\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9724\n",
      "Epoch 00040: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0833 - acc: 0.9724 - val_loss: 0.2309 - val_acc: 0.9448\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9743\n",
      "Epoch 00041: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0774 - acc: 0.9743 - val_loss: 0.2466 - val_acc: 0.9453\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9737\n",
      "Epoch 00042: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0753 - acc: 0.9737 - val_loss: 0.2459 - val_acc: 0.9436\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9753\n",
      "Epoch 00043: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0739 - acc: 0.9753 - val_loss: 0.2377 - val_acc: 0.9406\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9767\n",
      "Epoch 00044: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0679 - acc: 0.9767 - val_loss: 0.2498 - val_acc: 0.9462\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9766\n",
      "Epoch 00045: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0698 - acc: 0.9766 - val_loss: 0.2586 - val_acc: 0.9476\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9785\n",
      "Epoch 00046: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0638 - acc: 0.9785 - val_loss: 0.2517 - val_acc: 0.9441\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9782\n",
      "Epoch 00047: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0631 - acc: 0.9782 - val_loss: 0.2626 - val_acc: 0.9415\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9797\n",
      "Epoch 00048: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0606 - acc: 0.9797 - val_loss: 0.2318 - val_acc: 0.9499\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9795\n",
      "Epoch 00049: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0626 - acc: 0.9795 - val_loss: 0.2516 - val_acc: 0.9481\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9805\n",
      "Epoch 00050: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0582 - acc: 0.9805 - val_loss: 0.2507 - val_acc: 0.9448\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9818\n",
      "Epoch 00051: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0514 - acc: 0.9818 - val_loss: 0.2534 - val_acc: 0.9467\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9804\n",
      "Epoch 00052: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0567 - acc: 0.9804 - val_loss: 0.2413 - val_acc: 0.9443\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9819\n",
      "Epoch 00053: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0517 - acc: 0.9819 - val_loss: 0.2457 - val_acc: 0.9509\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9816\n",
      "Epoch 00054: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0541 - acc: 0.9816 - val_loss: 0.2711 - val_acc: 0.9478\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9830\n",
      "Epoch 00055: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0498 - acc: 0.9830 - val_loss: 0.2582 - val_acc: 0.9457\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9814\n",
      "Epoch 00056: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0564 - acc: 0.9813 - val_loss: 0.2430 - val_acc: 0.9518\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9820\n",
      "Epoch 00057: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0517 - acc: 0.9820 - val_loss: 0.2852 - val_acc: 0.9450\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9850\n",
      "Epoch 00058: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0453 - acc: 0.9850 - val_loss: 0.2956 - val_acc: 0.9434\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9854\n",
      "Epoch 00059: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0431 - acc: 0.9854 - val_loss: 0.2630 - val_acc: 0.9495\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9840\n",
      "Epoch 00060: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0475 - acc: 0.9841 - val_loss: 0.2729 - val_acc: 0.9453\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9861\n",
      "Epoch 00061: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0433 - acc: 0.9861 - val_loss: 0.3006 - val_acc: 0.9415\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9852\n",
      "Epoch 00062: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0450 - acc: 0.9852 - val_loss: 0.2514 - val_acc: 0.9462\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9858\n",
      "Epoch 00063: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0412 - acc: 0.9858 - val_loss: 0.2861 - val_acc: 0.9488\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9862\n",
      "Epoch 00064: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0412 - acc: 0.9862 - val_loss: 0.2729 - val_acc: 0.9502\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9866\n",
      "Epoch 00065: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0393 - acc: 0.9866 - val_loss: 0.3166 - val_acc: 0.9439\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9876\n",
      "Epoch 00066: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0383 - acc: 0.9875 - val_loss: 0.2656 - val_acc: 0.9525\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9862\n",
      "Epoch 00067: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0401 - acc: 0.9862 - val_loss: 0.2911 - val_acc: 0.9488\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9860\n",
      "Epoch 00068: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0418 - acc: 0.9860 - val_loss: 0.2769 - val_acc: 0.9511\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9874\n",
      "Epoch 00069: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0371 - acc: 0.9874 - val_loss: 0.2847 - val_acc: 0.9497\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9886\n",
      "Epoch 00070: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0332 - acc: 0.9886 - val_loss: 0.2740 - val_acc: 0.9485\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9881\n",
      "Epoch 00071: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0356 - acc: 0.9881 - val_loss: 0.2823 - val_acc: 0.9492\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9879\n",
      "Epoch 00072: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0375 - acc: 0.9879 - val_loss: 0.2960 - val_acc: 0.9511\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9896\n",
      "Epoch 00073: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0321 - acc: 0.9896 - val_loss: 0.2832 - val_acc: 0.9483\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9887\n",
      "Epoch 00074: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0332 - acc: 0.9887 - val_loss: 0.3018 - val_acc: 0.9474\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9885\n",
      "Epoch 00075: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0336 - acc: 0.9885 - val_loss: 0.2802 - val_acc: 0.9492\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9902\n",
      "Epoch 00076: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0308 - acc: 0.9902 - val_loss: 0.2862 - val_acc: 0.9492\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9903\n",
      "Epoch 00077: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0318 - acc: 0.9903 - val_loss: 0.3064 - val_acc: 0.9467\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9874\n",
      "Epoch 00078: val_loss did not improve from 0.19860\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0382 - acc: 0.9874 - val_loss: 0.3090 - val_acc: 0.9432\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2490 - acc: 0.9273\n",
      "Loss: 0.24900241202345022 Accuracy: 0.92731047\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4519 - acc: 0.1938\n",
      "Epoch 00001: val_loss improved from inf to 1.79308, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/001-1.7931.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 2.4519 - acc: 0.1938 - val_loss: 1.7931 - val_acc: 0.4305\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5289 - acc: 0.4951\n",
      "Epoch 00002: val_loss improved from 1.79308 to 1.08161, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/002-1.0816.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.5290 - acc: 0.4951 - val_loss: 1.0816 - val_acc: 0.6417\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0772 - acc: 0.6485\n",
      "Epoch 00003: val_loss improved from 1.08161 to 0.77103, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/003-0.7710.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.0771 - acc: 0.6486 - val_loss: 0.7710 - val_acc: 0.7494\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7776 - acc: 0.7472\n",
      "Epoch 00004: val_loss improved from 0.77103 to 0.57406, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/004-0.5741.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.7775 - acc: 0.7472 - val_loss: 0.5741 - val_acc: 0.8206\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6250 - acc: 0.7991\n",
      "Epoch 00005: val_loss improved from 0.57406 to 0.48287, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/005-0.4829.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.6249 - acc: 0.7992 - val_loss: 0.4829 - val_acc: 0.8493\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.8291\n",
      "Epoch 00006: val_loss improved from 0.48287 to 0.42072, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/006-0.4207.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5235 - acc: 0.8291 - val_loss: 0.4207 - val_acc: 0.8726\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4484 - acc: 0.8561\n",
      "Epoch 00007: val_loss improved from 0.42072 to 0.33926, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/007-0.3393.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4483 - acc: 0.8561 - val_loss: 0.3393 - val_acc: 0.8928\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8738\n",
      "Epoch 00008: val_loss improved from 0.33926 to 0.29608, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/008-0.2961.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.3920 - acc: 0.8738 - val_loss: 0.2961 - val_acc: 0.9119\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3499 - acc: 0.8893\n",
      "Epoch 00009: val_loss improved from 0.29608 to 0.26962, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/009-0.2696.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3499 - acc: 0.8893 - val_loss: 0.2696 - val_acc: 0.9220\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.8968\n",
      "Epoch 00010: val_loss improved from 0.26962 to 0.25880, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/010-0.2588.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3150 - acc: 0.8969 - val_loss: 0.2588 - val_acc: 0.9208\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2815 - acc: 0.9088\n",
      "Epoch 00011: val_loss improved from 0.25880 to 0.22896, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/011-0.2290.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2815 - acc: 0.9088 - val_loss: 0.2290 - val_acc: 0.9311\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9154\n",
      "Epoch 00012: val_loss improved from 0.22896 to 0.21360, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/012-0.2136.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2619 - acc: 0.9154 - val_loss: 0.2136 - val_acc: 0.9311\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2402 - acc: 0.9211\n",
      "Epoch 00013: val_loss did not improve from 0.21360\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2401 - acc: 0.9211 - val_loss: 0.2278 - val_acc: 0.9297\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9261\n",
      "Epoch 00014: val_loss improved from 0.21360 to 0.19666, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/014-0.1967.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2257 - acc: 0.9261 - val_loss: 0.1967 - val_acc: 0.9415\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9339\n",
      "Epoch 00015: val_loss did not improve from 0.19666\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2067 - acc: 0.9339 - val_loss: 0.2248 - val_acc: 0.9378\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9378\n",
      "Epoch 00016: val_loss improved from 0.19666 to 0.18421, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/016-0.1842.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1908 - acc: 0.9378 - val_loss: 0.1842 - val_acc: 0.9464\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9397\n",
      "Epoch 00017: val_loss did not improve from 0.18421\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1843 - acc: 0.9397 - val_loss: 0.1845 - val_acc: 0.9455\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9459\n",
      "Epoch 00018: val_loss improved from 0.18421 to 0.16921, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/018-0.1692.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1696 - acc: 0.9459 - val_loss: 0.1692 - val_acc: 0.9499\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9470\n",
      "Epoch 00019: val_loss did not improve from 0.16921\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1589 - acc: 0.9469 - val_loss: 0.1745 - val_acc: 0.9488\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9490\n",
      "Epoch 00020: val_loss improved from 0.16921 to 0.15433, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/020-0.1543.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1519 - acc: 0.9490 - val_loss: 0.1543 - val_acc: 0.9515\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9512\n",
      "Epoch 00021: val_loss did not improve from 0.15433\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1451 - acc: 0.9512 - val_loss: 0.1559 - val_acc: 0.9529\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9564\n",
      "Epoch 00022: val_loss did not improve from 0.15433\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1323 - acc: 0.9564 - val_loss: 0.1548 - val_acc: 0.9546\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9585\n",
      "Epoch 00023: val_loss improved from 0.15433 to 0.14812, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/023-0.1481.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1259 - acc: 0.9585 - val_loss: 0.1481 - val_acc: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9598\n",
      "Epoch 00024: val_loss did not improve from 0.14812\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1198 - acc: 0.9598 - val_loss: 0.1611 - val_acc: 0.9550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9606\n",
      "Epoch 00025: val_loss did not improve from 0.14812\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1181 - acc: 0.9605 - val_loss: 0.1639 - val_acc: 0.9532\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9623\n",
      "Epoch 00026: val_loss improved from 0.14812 to 0.14049, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv_checkpoint/026-0.1405.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1122 - acc: 0.9622 - val_loss: 0.1405 - val_acc: 0.9569\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9657\n",
      "Epoch 00027: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1015 - acc: 0.9657 - val_loss: 0.1551 - val_acc: 0.9560\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9669\n",
      "Epoch 00028: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0974 - acc: 0.9669 - val_loss: 0.1651 - val_acc: 0.9543\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9681\n",
      "Epoch 00029: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0941 - acc: 0.9681 - val_loss: 0.1759 - val_acc: 0.9518\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9701\n",
      "Epoch 00030: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0894 - acc: 0.9701 - val_loss: 0.1467 - val_acc: 0.9588\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9708\n",
      "Epoch 00031: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0857 - acc: 0.9708 - val_loss: 0.1798 - val_acc: 0.9525\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9713\n",
      "Epoch 00032: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0818 - acc: 0.9713 - val_loss: 0.1524 - val_acc: 0.9557\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9739\n",
      "Epoch 00033: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0763 - acc: 0.9739 - val_loss: 0.1502 - val_acc: 0.9602\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9735\n",
      "Epoch 00034: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0768 - acc: 0.9735 - val_loss: 0.1543 - val_acc: 0.9576\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9755\n",
      "Epoch 00035: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0710 - acc: 0.9755 - val_loss: 0.1520 - val_acc: 0.9613\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9748\n",
      "Epoch 00036: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0740 - acc: 0.9748 - val_loss: 0.1808 - val_acc: 0.9536\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9772\n",
      "Epoch 00037: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0653 - acc: 0.9772 - val_loss: 0.1551 - val_acc: 0.9585\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9797\n",
      "Epoch 00038: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0607 - acc: 0.9797 - val_loss: 0.1472 - val_acc: 0.9627\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9761\n",
      "Epoch 00039: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0705 - acc: 0.9761 - val_loss: 0.1555 - val_acc: 0.9581\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9785\n",
      "Epoch 00040: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0612 - acc: 0.9785 - val_loss: 0.1585 - val_acc: 0.9630\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9808\n",
      "Epoch 00041: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0551 - acc: 0.9808 - val_loss: 0.1797 - val_acc: 0.9604\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9814\n",
      "Epoch 00042: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0555 - acc: 0.9814 - val_loss: 0.1480 - val_acc: 0.9606\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9805\n",
      "Epoch 00043: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0549 - acc: 0.9805 - val_loss: 0.1788 - val_acc: 0.9574\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9820\n",
      "Epoch 00044: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0512 - acc: 0.9820 - val_loss: 0.1496 - val_acc: 0.9618\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9830\n",
      "Epoch 00045: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0519 - acc: 0.9829 - val_loss: 0.1405 - val_acc: 0.9630\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9811\n",
      "Epoch 00046: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0570 - acc: 0.9811 - val_loss: 0.1647 - val_acc: 0.9611\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9849\n",
      "Epoch 00047: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0448 - acc: 0.9849 - val_loss: 0.1614 - val_acc: 0.9583\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9835\n",
      "Epoch 00048: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0485 - acc: 0.9835 - val_loss: 0.1549 - val_acc: 0.9655\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9842\n",
      "Epoch 00049: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0450 - acc: 0.9842 - val_loss: 0.1535 - val_acc: 0.9592\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9858\n",
      "Epoch 00050: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0427 - acc: 0.9857 - val_loss: 0.1469 - val_acc: 0.9665\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9842\n",
      "Epoch 00051: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0463 - acc: 0.9842 - val_loss: 0.1588 - val_acc: 0.9623\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9864\n",
      "Epoch 00052: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0394 - acc: 0.9864 - val_loss: 0.1897 - val_acc: 0.9611\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9867\n",
      "Epoch 00053: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0406 - acc: 0.9867 - val_loss: 0.1426 - val_acc: 0.9658\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9864\n",
      "Epoch 00054: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0414 - acc: 0.9864 - val_loss: 0.2014 - val_acc: 0.9522\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9857\n",
      "Epoch 00055: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0420 - acc: 0.9857 - val_loss: 0.1448 - val_acc: 0.9674\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9885\n",
      "Epoch 00056: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0359 - acc: 0.9885 - val_loss: 0.1945 - val_acc: 0.9609\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9862\n",
      "Epoch 00057: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0387 - acc: 0.9863 - val_loss: 0.1861 - val_acc: 0.9595\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9892\n",
      "Epoch 00058: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0334 - acc: 0.9892 - val_loss: 0.1720 - val_acc: 0.9606\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9862\n",
      "Epoch 00059: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0403 - acc: 0.9862 - val_loss: 0.1519 - val_acc: 0.9595\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9882\n",
      "Epoch 00060: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0347 - acc: 0.9882 - val_loss: 0.1602 - val_acc: 0.9625\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9897\n",
      "Epoch 00061: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0310 - acc: 0.9897 - val_loss: 0.1947 - val_acc: 0.9599\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9875\n",
      "Epoch 00062: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0365 - acc: 0.9875 - val_loss: 0.1629 - val_acc: 0.9634\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9900\n",
      "Epoch 00063: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0294 - acc: 0.9900 - val_loss: 0.1860 - val_acc: 0.9639\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9899\n",
      "Epoch 00064: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0295 - acc: 0.9899 - val_loss: 0.1786 - val_acc: 0.9632\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9889\n",
      "Epoch 00065: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0325 - acc: 0.9889 - val_loss: 0.1644 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9892\n",
      "Epoch 00066: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0312 - acc: 0.9892 - val_loss: 0.1851 - val_acc: 0.9637\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9915\n",
      "Epoch 00067: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0264 - acc: 0.9915 - val_loss: 0.1779 - val_acc: 0.9683\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9904\n",
      "Epoch 00068: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0282 - acc: 0.9904 - val_loss: 0.1640 - val_acc: 0.9651\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9909\n",
      "Epoch 00069: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0281 - acc: 0.9909 - val_loss: 0.1607 - val_acc: 0.9667\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9909\n",
      "Epoch 00070: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0295 - acc: 0.9909 - val_loss: 0.1647 - val_acc: 0.9653\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9921\n",
      "Epoch 00071: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0255 - acc: 0.9921 - val_loss: 0.1794 - val_acc: 0.9630\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9910\n",
      "Epoch 00072: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0278 - acc: 0.9910 - val_loss: 0.1840 - val_acc: 0.9646\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9920\n",
      "Epoch 00073: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0263 - acc: 0.9919 - val_loss: 0.1723 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9912\n",
      "Epoch 00074: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0275 - acc: 0.9913 - val_loss: 0.1661 - val_acc: 0.9630\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9922\n",
      "Epoch 00075: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0246 - acc: 0.9922 - val_loss: 0.2197 - val_acc: 0.9606\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9917\n",
      "Epoch 00076: val_loss did not improve from 0.14049\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0247 - acc: 0.9917 - val_loss: 0.1774 - val_acc: 0.9665\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2102 - acc: 0.9383\n",
      "Loss: 0.21015337269563664 Accuracy: 0.9383178\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2723 - acc: 0.2653\n",
      "Epoch 00001: val_loss improved from inf to 1.61925, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/001-1.6193.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 2.2724 - acc: 0.2653 - val_loss: 1.6193 - val_acc: 0.4899\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2239 - acc: 0.6012\n",
      "Epoch 00002: val_loss improved from 1.61925 to 0.73520, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/002-0.7352.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 1.2240 - acc: 0.6012 - val_loss: 0.7352 - val_acc: 0.7584\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7478 - acc: 0.7534\n",
      "Epoch 00003: val_loss improved from 0.73520 to 0.55135, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/003-0.5514.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.7478 - acc: 0.7533 - val_loss: 0.5514 - val_acc: 0.8162\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5900 - acc: 0.8071\n",
      "Epoch 00004: val_loss improved from 0.55135 to 0.46493, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/004-0.4649.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5900 - acc: 0.8071 - val_loss: 0.4649 - val_acc: 0.8460\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5003 - acc: 0.8367\n",
      "Epoch 00005: val_loss improved from 0.46493 to 0.37314, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/005-0.3731.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5003 - acc: 0.8367 - val_loss: 0.3731 - val_acc: 0.8791\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.8619\n",
      "Epoch 00006: val_loss improved from 0.37314 to 0.37016, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/006-0.3702.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4203 - acc: 0.8619 - val_loss: 0.3702 - val_acc: 0.8807\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3616 - acc: 0.8821\n",
      "Epoch 00007: val_loss improved from 0.37016 to 0.31510, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/007-0.3151.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3616 - acc: 0.8821 - val_loss: 0.3151 - val_acc: 0.8970\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3229 - acc: 0.8948\n",
      "Epoch 00008: val_loss improved from 0.31510 to 0.24530, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/008-0.2453.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3229 - acc: 0.8948 - val_loss: 0.2453 - val_acc: 0.9196\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9096\n",
      "Epoch 00009: val_loss did not improve from 0.24530\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2814 - acc: 0.9096 - val_loss: 0.2576 - val_acc: 0.9199\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9198\n",
      "Epoch 00010: val_loss improved from 0.24530 to 0.22256, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/010-0.2226.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2473 - acc: 0.9198 - val_loss: 0.2226 - val_acc: 0.9294\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2239 - acc: 0.9278\n",
      "Epoch 00011: val_loss did not improve from 0.22256\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2239 - acc: 0.9278 - val_loss: 0.2430 - val_acc: 0.9234\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9332\n",
      "Epoch 00012: val_loss improved from 0.22256 to 0.19245, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/012-0.1924.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2042 - acc: 0.9332 - val_loss: 0.1924 - val_acc: 0.9399\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9405\n",
      "Epoch 00013: val_loss improved from 0.19245 to 0.16909, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/013-0.1691.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1849 - acc: 0.9406 - val_loss: 0.1691 - val_acc: 0.9464\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9423\n",
      "Epoch 00014: val_loss did not improve from 0.16909\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1715 - acc: 0.9423 - val_loss: 0.1800 - val_acc: 0.9406\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9493\n",
      "Epoch 00015: val_loss did not improve from 0.16909\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1551 - acc: 0.9492 - val_loss: 0.1886 - val_acc: 0.9450\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9527\n",
      "Epoch 00016: val_loss improved from 0.16909 to 0.15951, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/016-0.1595.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1415 - acc: 0.9527 - val_loss: 0.1595 - val_acc: 0.9502\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9561\n",
      "Epoch 00017: val_loss did not improve from 0.15951\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1314 - acc: 0.9561 - val_loss: 0.1786 - val_acc: 0.9450\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9597\n",
      "Epoch 00018: val_loss did not improve from 0.15951\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1193 - acc: 0.9597 - val_loss: 0.1775 - val_acc: 0.9495\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9604\n",
      "Epoch 00019: val_loss improved from 0.15951 to 0.15513, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv_checkpoint/019-0.1551.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1171 - acc: 0.9604 - val_loss: 0.1551 - val_acc: 0.9504\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9629\n",
      "Epoch 00020: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1084 - acc: 0.9629 - val_loss: 0.1750 - val_acc: 0.9481\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9679\n",
      "Epoch 00021: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0952 - acc: 0.9679 - val_loss: 0.1641 - val_acc: 0.9520\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9685\n",
      "Epoch 00022: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0921 - acc: 0.9685 - val_loss: 0.2003 - val_acc: 0.9453\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9707\n",
      "Epoch 00023: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0851 - acc: 0.9707 - val_loss: 0.1793 - val_acc: 0.9476\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9733\n",
      "Epoch 00024: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0797 - acc: 0.9733 - val_loss: 0.2092 - val_acc: 0.9478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9743\n",
      "Epoch 00025: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0757 - acc: 0.9743 - val_loss: 0.1863 - val_acc: 0.9460\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9758\n",
      "Epoch 00026: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0708 - acc: 0.9757 - val_loss: 0.1856 - val_acc: 0.9509\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9753\n",
      "Epoch 00027: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0712 - acc: 0.9753 - val_loss: 0.1577 - val_acc: 0.9557\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9798\n",
      "Epoch 00028: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0616 - acc: 0.9798 - val_loss: 0.1916 - val_acc: 0.9511\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9806\n",
      "Epoch 00029: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0584 - acc: 0.9806 - val_loss: 0.1568 - val_acc: 0.9583\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9821\n",
      "Epoch 00030: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0532 - acc: 0.9821 - val_loss: 0.1854 - val_acc: 0.9483\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9799\n",
      "Epoch 00031: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0580 - acc: 0.9799 - val_loss: 0.2184 - val_acc: 0.9513\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9822\n",
      "Epoch 00032: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0536 - acc: 0.9822 - val_loss: 0.1884 - val_acc: 0.9543\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9840\n",
      "Epoch 00033: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0467 - acc: 0.9840 - val_loss: 0.2166 - val_acc: 0.9504\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9836\n",
      "Epoch 00034: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0480 - acc: 0.9836 - val_loss: 0.2040 - val_acc: 0.9511\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9855\n",
      "Epoch 00035: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0443 - acc: 0.9854 - val_loss: 0.2103 - val_acc: 0.9474\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9837\n",
      "Epoch 00036: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0469 - acc: 0.9837 - val_loss: 0.1971 - val_acc: 0.9490\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9862\n",
      "Epoch 00037: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0405 - acc: 0.9862 - val_loss: 0.2146 - val_acc: 0.9555\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9858\n",
      "Epoch 00038: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0421 - acc: 0.9858 - val_loss: 0.1759 - val_acc: 0.9560\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9886\n",
      "Epoch 00039: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0360 - acc: 0.9886 - val_loss: 0.1849 - val_acc: 0.9550\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9869\n",
      "Epoch 00040: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0411 - acc: 0.9869 - val_loss: 0.2015 - val_acc: 0.9564\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9891\n",
      "Epoch 00041: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0344 - acc: 0.9891 - val_loss: 0.1859 - val_acc: 0.9588\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9879\n",
      "Epoch 00042: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0359 - acc: 0.9879 - val_loss: 0.2140 - val_acc: 0.9571\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9891\n",
      "Epoch 00043: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0329 - acc: 0.9891 - val_loss: 0.2244 - val_acc: 0.9522\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9888\n",
      "Epoch 00044: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0336 - acc: 0.9888 - val_loss: 0.2281 - val_acc: 0.9555\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9894\n",
      "Epoch 00045: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0320 - acc: 0.9894 - val_loss: 0.2286 - val_acc: 0.9532\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9884\n",
      "Epoch 00046: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0339 - acc: 0.9884 - val_loss: 0.2038 - val_acc: 0.9557\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9903\n",
      "Epoch 00047: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0297 - acc: 0.9903 - val_loss: 0.2001 - val_acc: 0.9562\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9913\n",
      "Epoch 00048: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0285 - acc: 0.9913 - val_loss: 0.2223 - val_acc: 0.9567\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9910\n",
      "Epoch 00049: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0274 - acc: 0.9910 - val_loss: 0.1998 - val_acc: 0.9574\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9909\n",
      "Epoch 00050: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0283 - acc: 0.9909 - val_loss: 0.1887 - val_acc: 0.9590\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9906\n",
      "Epoch 00051: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0291 - acc: 0.9906 - val_loss: 0.1899 - val_acc: 0.9548\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9914\n",
      "Epoch 00052: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0271 - acc: 0.9914 - val_loss: 0.2055 - val_acc: 0.9557\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 00053: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0282 - acc: 0.9908 - val_loss: 0.1941 - val_acc: 0.9597\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9919\n",
      "Epoch 00054: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0243 - acc: 0.9919 - val_loss: 0.1815 - val_acc: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9936\n",
      "Epoch 00055: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0212 - acc: 0.9936 - val_loss: 0.2302 - val_acc: 0.9560\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9918\n",
      "Epoch 00056: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0249 - acc: 0.9918 - val_loss: 0.1945 - val_acc: 0.9590\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9914\n",
      "Epoch 00057: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0272 - acc: 0.9914 - val_loss: 0.2246 - val_acc: 0.9588\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9936\n",
      "Epoch 00058: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0194 - acc: 0.9936 - val_loss: 0.2428 - val_acc: 0.9550\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9916\n",
      "Epoch 00059: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0269 - acc: 0.9916 - val_loss: 0.2282 - val_acc: 0.9592\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9934\n",
      "Epoch 00060: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0194 - acc: 0.9934 - val_loss: 0.2314 - val_acc: 0.9585\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9922\n",
      "Epoch 00061: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0232 - acc: 0.9922 - val_loss: 0.2184 - val_acc: 0.9564\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 00062: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0201 - acc: 0.9937 - val_loss: 0.1792 - val_acc: 0.9588\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9931\n",
      "Epoch 00063: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0205 - acc: 0.9931 - val_loss: 0.1990 - val_acc: 0.9609\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9946\n",
      "Epoch 00064: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0183 - acc: 0.9946 - val_loss: 0.2285 - val_acc: 0.9574\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9935\n",
      "Epoch 00065: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0211 - acc: 0.9935 - val_loss: 0.2299 - val_acc: 0.9576\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9927\n",
      "Epoch 00066: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0227 - acc: 0.9927 - val_loss: 0.2023 - val_acc: 0.9576\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9937\n",
      "Epoch 00067: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0201 - acc: 0.9938 - val_loss: 0.2316 - val_acc: 0.9543\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9935\n",
      "Epoch 00068: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0212 - acc: 0.9935 - val_loss: 0.1926 - val_acc: 0.9620\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9931\n",
      "Epoch 00069: val_loss did not improve from 0.15513\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0201 - acc: 0.9931 - val_loss: 0.2557 - val_acc: 0.9502\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VNXd+PHPmT37RiCsEhQR2YKAYhHQWlHUopUiWrXVtvr0qW0ftfUn2s1uj7a1rUttLba2+mi1FrVWpVI3RFs31goqyipbIIEkZJnM+v39cWYmk5CEAJlMyHzfr9d9TebOnXu/czNzvvece+85RkRQSimlABzpDkAppVTvoUlBKaVUgiYFpZRSCZoUlFJKJWhSUEoplaBJQSmlVIImBaWUUgmaFJRSSiVoUlBKKZXgSncAh6pfv34yfPjwdIehlFJHlRUrVlSLSOnBljvqksLw4cNZvnx5usNQSqmjijFma1eW0+YjpZRSCZoUlFJKJWhSUEoplXDUnVNoTygUYvv27TQ3N6c7lKOWz+djyJAhuN3udIeilEqjPpEUtm/fTl5eHsOHD8cYk+5wjjoiwt69e9m+fTvl5eXpDkcplUZ9ovmoubmZkpISTQiHyRhDSUmJ1rSUUn0jKQCaEI6Q7j+lFPShpHAwkYifQGAH0Wgo3aEopVSvlTFJIRptJhjchUj3J4Xa2lp+85vfHNZ7zz33XGpra7u8/K233sodd9xxWNtSSqmDyZikYIz9qCLRbl93Z0khHA53+t7FixdTWFjY7TEppdThyJikAM7YY6Tb17xgwQI2btxIRUUFN954I0uXLmX69OnMmTOHE088EYALL7yQSZMmMWbMGBYuXJh47/Dhw6murmbLli2MHj2aq6++mjFjxjBr1iz8fn+n2129ejVTp05l/PjxfOYzn6GmpgaAu+++mxNPPJHx48dzySWXAPDqq69SUVFBRUUFEydOpL6+vtv3g1Lq6NcnLklN9tFH19HQsLqdV6JEIo04HFkYc2gfOze3gpEj7+zw9dtvv521a9eyerXd7tKlS1m5ciVr165NXOL5wAMPUFxcjN/vZ8qUKcydO5eSkpI2sX/Eo48+yv3338/FF1/ME088weWXX97hdj//+c9zzz33MHPmTL73ve/xgx/8gDvvvJPbb7+dzZs34/V6E01Td9xxB/feey/Tpk2joaEBn893SPtAKZUZMqimECc9spWTTz651TX/d999NxMmTGDq1Kls27aNjz766ID3lJeXU1FRAcCkSZPYsmVLh+uvq6ujtraWmTNnAvCFL3yBZcuWATB+/Hguu+wyHn74YVwumwCnTZvGDTfcwN13301tbW1ivlJKJetzJUNHR/TRaIjGxjV4vcPwePqnPI6cnJzE30uXLuXFF1/kjTfeIDs7m9NPP73dewK8Xm/ib6fTedDmo44899xzLFu2jGeeeYaf/OQnvPvuuyxYsIDzzjuPxYsXM23aNJYsWcIJJ5xwWOtXSvVdGVNTMMaeUxDp/nMKeXl5nbbR19XVUVRURHZ2Nh988AFvvvnmEW+zoKCAoqIiXnvtNQD+7//+j5kzZxKNRtm2bRtnnHEGP/3pT6mrq6OhoYGNGzcybtw4brrpJqZMmcIHH3xwxDEopfqePldT6JiJTd1/9VFJSQnTpk1j7NixzJ49m/POO6/V6+eccw733Xcfo0ePZtSoUUydOrVbtvvggw/yla98haamJkaMGMEf//hHIpEIl19+OXV1dYgI3/jGNygsLOS73/0ur7zyCg6HgzFjxjB79uxuiUEp1bcYkZ5pY+8ukydPlraD7Lz//vuMHj36oO+tr1+F212CzzcsVeEd1bq6H5VSRx9jzAoRmXyw5TKm+QhsE1Iq7lNQSqm+IsOSgoNU3KeglFJ9RUYlBXCm5ESzUkr1FRmVFGxNQZuPlFKqIxmVFLSmoJRSncuopGCMQ080K6VUJzIsKTjpLSeac3NzD2m+Ukr1hIxKCqA1BaWU6kxGJQVbU4jS3TfsLViwgHvvvTfxPD4QTkNDA2eeeSYnnXQS48aN4+mnn+7yOkWEG2+8kbFjxzJu3Dj+8pe/ALBr1y5mzJhBRUUFY8eO5bXXXiMSiXDllVcmlv3Vr37VrZ9PKZU5+l43F9ddB6vb6zob3BLEGQ2AMxfb5UUXVVTAnR13nT1//nyuu+46rr32WgAef/xxlixZgs/n46mnniI/P5/q6mqmTp3KnDlzujQe8pNPPsnq1atZs2YN1dXVTJkyhRkzZvDnP/+Zs88+m29/+9tEIhGamppYvXo1O3bsYO3atQCHNJKbUkol63tJoVOpGZx+4sSJ7Nmzh507d1JVVUVRURFDhw4lFApxyy23sGzZMhwOBzt27GD37t2UlZUddJ2vv/46l156KU6nkwEDBjBz5kzeeecdpkyZwhe/+EVCoRAXXnghFRUVjBgxgk2bNvH1r3+d8847j1mzZqXkcyql+r6UJQVjzFDgIWAAdhCDhSJyV5tlDHAXcC7QBFwpIiuPaMOdHNFHQntpbt5MdvZYnM7uHWRm3rx5LFq0iMrKSubPnw/AI488QlVVFStWrMDtdjN8+PB2u8w+FDNmzGDZsmU899xzXHnlldxwww18/vOfZ82aNSxZsoT77ruPxx9/nAceeKA7PpZSKsOk8pxCGPimiJwITAWuNcac2GaZ2cDI2HQN8NsUxkMqh+ScP38+jz32GIsWLWLevHmA7TK7f//+uN1uXnnlFbZu3drl9U2fPp2//OUvRCIRqqqqWLZsGSeffDJbt25lwIABXH311Xz5y19m5cqVVFdXE41GmTt3Lj/+8Y9ZufLI8qpSKnOlrKYgIruAXbG/640x7wODgfeSFrsAeEjsmd83jTGFxpiBsfd2O3tHMym5AmnMmDHU19czePBgBg4cCMBll13Gpz/9acaNG8fkyZMPaVCbz3zmM7zxxhtMmDABYww/+9nPKCsr48EHH+TnP/85breb3NxcHnroIXbs2MFVV11FNGo/12233dbtn08plRl6pOtsY8xwYBkwVkT2J81/FrhdRF6PPX8JuElElre3HjiyrrMjkUaamt7H5zsOt7vwcD5Kn6ZdZyvVd/WarrONMbnAE8B1yQnhENdxjTFmuTFmeVVV1RFEE/+4veMGNqWU6m1SmhSMMW5sQnhERJ5sZ5EdwNCk50Ni81oRkYUiMllEJpeWlh5BPPEhOfUGNqWUak/KkkLsyqI/AO+LyC87WOzvwOeNNRWoS9X5BBuT1hSUUqozqbxPYRpwBfCuMSZ+N9ktwDAAEbkPWIy9HHUD9pLUq1IYD/Grj7SmoJRS7Uvl1Uevc5C7xWJXHV2bqhjaspUXh3afrZRSHciovo9AB9pRSqnOZFxSSMVAO7W1tfzmN785rPeee+652leRUqrXyLikkIqBdjpLCuFwuNP3Ll68mMJCvWdCKdU7ZFxSsCebu7emsGDBAjZu3EhFRQU33ngjS5cuZfr06cyZM4cTT7Q9e1x44YVMmjSJMWPGsHDhwsR7hw8fTnV1NVu2bGH06NFcffXVjBkzhlmzZuH3+w/Y1jPPPMMpp5zCxIkT+dSnPsXu3bsBaGho4KqrrmLcuHGMHz+eJ554AoDnn3+ek046iQkTJnDmmWd26+dWSvU9fa6X1E56zgYgGh2GiOB0drxMWwfpOZvbb7+dtWvXsjq24aVLl7Jy5UrWrl1LeXk5AA888ADFxcX4/X6mTJnC3LlzKSkpabWejz76iEcffZT777+fiy++mCeeeILLL7+81TKnnXYab775JsYYfv/73/Ozn/2MX/ziF/zoRz+ioKCAd999F4Camhqqqqq4+uqrWbZsGeXl5ezbt6/rH1oplZH6XFI4OIPttDW1Tj755ERCALj77rt56qmnANi2bRsfffTRAUmhvLyciooKACZNmsSWLVsOWO/27duZP38+u3btIhgMJrbx4osv8thjjyWWKyoq4plnnmHGjBmJZYqLi7v1Myql+p4+lxQ6O6IH8PsriUTqyc0dn9I4cnJyEn8vXbqUF198kTfeeIPs7GxOP/30drvQ9nq9ib+dTme7zUdf//rXueGGG5gzZw5Lly7l1ltvTUn8SqnMlHHnFIzp/quP8vLyqK+v7/D1uro6ioqKyM7O5oMPPuDNN9887G3V1dUxePBgAB588MHE/LPOOqvVkKA1NTVMnTqVZcuWsXnzZgBtPlJKHVQGJgV7n0J39g5bUlLCtGnTGDt2LDfeeOMBr59zzjmEw2FGjx7NggULmDp16mFv69Zbb2XevHlMmjSJfv36JeZ/5zvfoaamhrFjxzJhwgReeeUVSktLWbhwIRdddBETJkxIDP6jlFId6ZGus7vTkXSdDRAI7CIY3EFu7klJfSEp0K6zlerLek3X2b1Ny0A72tWFUkq1lXFJoWVITu3qQiml2sq4pKA1BaWU6lgGJgXtPlsppTqScUmhpflIawpKKdVWxiWFluYjrSkopVRbGZgUekdNITc3N63bV0qp9mRcUoh/ZK0pKKXUgTIuKbScaO6+msKCBQtadTFx6623cscdd9DQ0MCZZ57JSSedxLhx43j66acPuq6OuthurwvsjrrLVkqpw9XnOsS77vnrWF3ZSd/ZQCRSjzEeHA5vp8vFVZRVcOc5Hfe0N3/+fK677jquvdYON/3444+zZMkSfD4fTz31FPn5+VRXVzN16lTmzJkTGyu6fe11sR2NRtvtAru97rKVUupI9Lmk0DUdF8qHY+LEiezZs4edO3dSVVVFUVERQ4cOJRQKccstt7Bs2TIcDgc7duxg9+7dlJWVdbiu9rrYrqqqarcL7Pa6y1ZKqSPR55JCZ0f0cQ0Na3A6C8jKGt5t2503bx6LFi2isrIy0fHcI488QlVVFStWrMDtdjN8+PB2u8yO62oX20oplSoZd04B4ucVuvfqo/nz5/PYY4+xaNEi5s2bB9hurvv374/b7eaVV15h69atna6joy62O+oCu73uspVS6khkZFIAR7dffTRmzBjq6+sZPHgwAwcOBOCyyy5j+fLljBs3joceeogTTjih03V01MV2R11gt9ddtlJKHYmM6zoboKlpPSBkZ3deSGca7Tpbqb5Lu87uVPfXFJRSqi/IyKSQiiE5lVKqL+gzSeGgzWDhMNTXQzQaO9GsNYVkR1szolIqNfpEUvD5fOzdu7fzgm3/fli/HgIBbPOR1hTiRIS9e/fi8/nSHYpSKs36xH0KQ4YMYfv27VRVVXW8kN8P1dWwfj1hp59wuA6f7z26+0a2o5XP52PIkCHpDkMplWZ9Iim43e7E3b4deuMNmD0bFi/m4zHr2LTpRsaN24/LldczQSql1FGgTzQfdUlBgX2sq0skgkikPo0BKaVU75M5SSE/3z7u34/TaccyiEQa0hiQUkr1PpmTFJJqCk5nvKagSUEppZJlTlLIzQWHI5YU4jUFbT5SSqlkKUsKxpgHjDF7jDFrO3j9dGNMnTFmdWz6XqpiiW3QNiFpTUEppTqUyquP/gT8Gniok2VeE5HzUxhDa/n5rc4phMNaU1BKqWQpqymIyDJgX6rWf1gKCrSmoJRSnUj3OYVTjTFrjDH/MMaMSfnWEklBzykopVR70pkUVgLHiMgE4B7gbx0taIy5xhiz3BizvNO7lg/mgKSgNQWllEqWtqQgIvtFpCH292LAbYzp18GyC0VksohMLi0tPfyNxpKCw+HC4fBpTUEppdpIW1IwxpQZY0zs75NjsexN6UZjJ5oBnM5crSkopVQbKbv6yBjzKHA60M8Ysx34PuAGEJH7gM8C/22MCQN+4BJJdf/NsZoCIjideVpTUEqpNlKWFETk0oO8/mvsJas9p6AAQiFobtaaglJKtSPdVx/1rDZdXeh9Ckop1VpmJYU2neJpTUEppVrLrKTQpqagSUEppVrL4KSQqyealVKqjYxNCi6X1hSUUqqtzEwKiXMKWlNQSqlkmZUU4ieaY81HIiGi0WB6Y1JKqV4kg5OCjtOslFJtZVZScLkgJ0c7xVNKqQ5kVlKAA8ZU0BvYlFKqRWYmhaTR17SmoJRSLTIvKRwwTrPWFJRSKi7zkoIOtKOUUh3K2KTgcmlNQSml2srMpKDnFJRSql2ZlxT0nIJSSnUo85JCQQE0NeGIuACH1hSUUipJZiYFwNTX65gKSinVRsYmhfh5Bb15TSmlWnQpKRhj/scYk2+sPxhjVhpjZqU6uJRo1X12EeHwvvTGo5RSvUhXawpfFJH9wCygCLgCuD1lUaVSUqd4Xu9gAoEd6Y1HKaV6ka4mBRN7PBf4PxFZlzTv6JJUU7BJYXt641FKqV6kq0lhhTHmn9iksMQYkwdEUxdWCrVKCkMIBiuJRsPpjUkppXoJVxeX+xJQAWwSkSZjTDFwVerCSqGkE81e72AgSjBYic83JK1hKaVUb9DVmsKpwHoRqTXGXA58B6hLXVgplHROweMZDEAwqOcVlFIKup4Ufgs0GWMmAN8ENgIPpSyqVPL5wONJNB8Bel5BKaViupoUwiIiwAXAr0XkXiAvdWGlWKxTPNt8hF6BpJRSMV09p1BvjLkZeynqdGOMA3CnLqwUi3WK53b3wxiP1hSUUiqmqzWF+UAAe79CJTAE+HnKokq1WE3BGKP3KiilVJIuJYVYIngEKDDGnA80i8jReU4BEj2lAni9Q7SmoJRSMV3t5uJi4G1gHnAx8JYx5rOpDCylYjUFQGsKSimVpKvnFL4NTBGRPQDGmFLgRWBRqgJLqdg5BSB2A9vfEBGMOTpv0lZKqe7S1XMKjnhCiNl7CO/tfZJqCh7PYKLRZu0YTyml6HpN4XljzBLg0djz+cDi1ITUA/LzbU0hGk26V2EHbndJmgNTSqn06lJSEJEbjTFzgWmxWQtF5KnUhZViBQUgAg0NSfcqbCc3d3yaA1NKqfTqak0BEXkCeKKryxtjHgDOB/aIyNh2XjfAXdhO9pqAK0VkZVfXf0SSO8Ur1RvYlFIqrtPzAsaYemPM/namemPM/oOs+0/AOZ28PhsYGZuuwXal0TOSOsXzeAYCRi9LVUopDlJTEJHD7spCRJYZY4Z3ssgFwEOx7jPeNMYUGmMGisiuw91mlyXVFBwONx7PAK0pKKUUh9B8lAKDgW1Jz7fH5qU+KST1lAp6A5tS7YlGwe+3UyjUehIBY8DhsI/JE7S8Fn/dEWuTCIft+8NhOxkDTie4XPYR7OvBYMvU3Nwy+f122z4fZGW1TE5ny/YcDrvuxsaWye8HrxeysyEnxz4aY+c3NdnHQADcbttfZnyKRu38QMBuPxi063c6W6ZIpOX1QMDG73K1rMvttlP8M7pcdh0H26fJnyc+b9QoGHtAY3z3SmdS6DJjzDXYJiaGDRt25CtMqimAvSy1uXnjka9XpU0kAvv2QU1N60InFGr9ow4E7A89XjjEC4hg0BYeDQ2tC5J4odHcbLeT/ANNLjSTC5WsrJZCC6C+3q63vt6ut+16QiF7Mdz+/fYr2dhoC5Pk9USjBxZybrct6OIFGNjPEQjYx1CodWHtcNj1RCJ2ikZtQRQvwOKP4bD9zMFgz/8fVeduugluT/FAyOlMCjuAoUnPh8TmHUBEFgILASZPnixHvOWkcwpgawp1da8e8WoznYgtlBsabKETDrc8xguzpqaWwnf/fltQxgvLeEHWtjCPT6FQS2HqdNqCrq4Odu+G6mpbyKVKciKQpG9g8hGr12tjjB/R+v12mbw8yM21jzk5LeuJT263/UqOGNGyTChk3x9fl8PRksRycuz2wuGWBBAI2PXGE4TXawt5aIk5Gj3wKBdaJ9D4UW52dsvnivc2Hz/idbvttkRa1hv/O/49SH4t+fXk5ON02nnxJBWODYCYfKTudrfsY5/PTsa03sd+f+v9GY3adSfvL5/P7qemppYpfnCQ/P8Lh1tqKIGA3V9er31/PAEnJ9ZIxG4r/rrPZz9f8v4MBlv2cfw3EYm03p/t7dPk/1t8Ki1N3Xc8Lp1J4e/A14wxjwGnAHU9cj4BDqgpeL2DCYdriUQacTpzeiSE3kTE/rBqauzR9t699rG2tvVRdyRil0s+8q2rg8pK2LXLPh7O0aXPZ3+4bQser7dlysmx8+I/kkgEwhJixLEuTj3VMGAA9O8PxcXxAkeop5Lq8GYG5JRRXliOz2cShUpycmpqatlGbm5L7SG5wIj/aJP3GbSe195+bbtMOBomHA0TiUaISpSo2EzmdrpxO9y4HC6MMUSiEQKRAIFwgEAkgD/kpyHYQEOwgcZQI/6QH4/Tg8/lS0xFWUWU5ZbhcXrajScqUQym0zv3g5EgwUgwEV9EWuJMjjkikcTnCEfDhKIhmsPNNIeb8Yf8BCIB8jx5lOaUUppdSr/sfnhd3th+EULREKFIiNrmWqqbqhNTMBKkOLtfq/c5Hc5W228ON1MXqCPUXEekuZZAsJ6oRHEYBwaD0xiyXFkUZhVTkl1CSVYJed489gf2U9VYRaSpiv2NVfjDfgIOF/uNE5fDhcvhIjs7m2x3NoWeHLLd2YhIYp9Xx/Z/U6iJxmAjTaEmmkJNuBwuirOKKc4qpihcRIHXli+CIC47teU2Tgp8BRT6CinwFuB0OGkKNbFh3wbWV6/nw70fUttcy5TBU5g2dBqD8wd3/EXrZilLCsaYR4HTgX7GmO3A94l1ty0i92FvfjsX2IC9JLXnhvfMybGHAEnnFMBelpqdfXyPhXGkmsPNbK3dSnO4mSH5QyjOKk784MNh2LYNNmwQ1m2oZ0NlJTvqd7LHv5N9wV3sD1cR3F9McO9AmnYPIlwzEKIuyNnTMmVXgzMAjjA4Q+AIQdSFI5KL1+Tic+SQ5fGSc0IteVOrKcytJppVTbY7i/7uEZR5RzDAW06pdzBuXwA8jYi7gairEZcniNcneH2CwxHFxH7IWe4sst3ZZLmy2B/YT2VDJbsadiUed9W3/L3Pvw+Xw8WAnAEMyB2QKBA37d3Ehn0baAo1JfZVoa+QiWUTmTRwEsMLh1MfrKcuVEcdddQ6aqlrqKOuuo66QB11zXVEJEK/7H6UZJXQL7sfxVnFOIwjUQhGJILL4aIkq4TiWOFT5CsiIpFE4dgcbqaqsYrNtZvtVLOZXQ0HP+5xGEciWRyO4qxiBuYOpCiriIZgAzX+Gmqba9kfsDXjHE8OuZ5cctw5eF1eGoON1AfrqQ/UE4qGDnu7B+NxeohEI0QkkrJtHK3yPHnUB+tbzfM4PQQj9ihreOFwTht2Gp8b+zlmj5yd0lhSlhRE5NKDvC7AtanafqeMadNTasu9Cr01KTSFmnh+w/M8te5Z3t25no/rN1MTbl3AOCJZuJqG4mgYRLM0QM5uW7i7Avbi44LYBJioC3GEu7RttyN+FOsmImF7pAr4gZqkZfpl96Mku4TqUBMrah8nsr/7fvxep5ey3DIG5g1kZMlIZhwzg7LcMprDzVQ2VLK7cTe7G3bjD/sZUTSCTw7/JMcVH8fwwuHsqN/Byl0rWblrJfe8fQ+BSAAAl8NFgbeg1RHbyOKRFPgKcBone/17qW6q5t0977K3aS+CJI4oncZJMBJkn39fYn3tcRgHQ/OHMrxwOGcfdzbD8ofhc/lwOpw4jAOncSIIoUgoccQdjobxOD14nV68Li9epxefy0eeN48cty3QfS7fAUfn+/z7WiXRff59DMkfwrj+4yj0FVLoKwSwR77BRhpCDQTCAXI8OeR58sjz5JHrycXr8iZicxiH/dvR8rfDOBL7wOVw4XQ4cTvciRpLljsLj9NDfaCeqqYqqhqrqGqqoj5Q36pG5Ha6KfIVJb43/bL74Xa4qW6qTryvuqmaqERb7S+P02P/X74CCrwF5HvzcRgHghCVKCJCU6iJff597PXvZZ9/H3XNdRT4CijNLqU0p5T+Of3JcmW1qvGEoiH8IT+NocZEbcBhHIkkGk+kObFaRI47hyx3FqFIiJrmGvb591Hjr6EuYMsVg7G1l3ZqZuFomLrmOmqba6lptkm7JKuE40uOZ1S/UYwsHonH6WF15Wr+te1fvP7x67yw8QVGlYw6epNCr9emUzzo+RvYohJlw74NrK5czerK1ayrWkeWI5ec8DDM/mPw7x7Gx7vrWO94guqifyCuJmgqht3jofYcqCmnyAynpDAL8rYTztlGKGsbwcJdDPKUUpY3hqHF/Tlu4ACOHzSAIQWDGJQ3iIG5A8n35tMQbEgcfe+o30FUovTP6Z+Y+mX3a7cpIirRRHNGc7iZoqwi8jx5rb784WiYbXXb2FSziZ31O8lyZyUKtBxPDh6np9WPRkTwh/34Q378YT9NoSbyPHmU5ZZRlltGoa+wWzosDEVC7PXvJd+bT5Yr64jXmVwA1TTX4HK4WjXp5HnycDuP3vGo0mFkych0h3BI4gl7WEE3XATTxpTBU5gyeArXTb0u0eyWapmdFA6oKXT/Zan+kJ+H//MwC1cuZHfDbtvOKIIg1PpraQrbJg4jLlx1xxMSP+Q/Ds7YUfwAcAfKGFF3JRM8c5lcOoPjT3YxciQcd5xt9z5ced488rx5HF9yaLWj+NFTjqfj8y8uh4vyonLKi8oPP8AUcDvdlOWWddv6jDGJfTG0YOjB36DUYTLGdHi+qDtpUgCczhyczgKCwe6rKVQ2VPKbd37Db5f/luqmairKKjhj+JlUVxm2bTNs32Zo2p0LlROgsoLhuScyeaKXsWPh+FERSoZX4i75mCyfgymDp+AwR2+ntEqpo0fmJoX8fNi5M/G0O25gq/HX8MyHz/DUB0+x+KPFhCIhTh/0aca7r2fHSzP5+wuG2lp7ydr06TBrFkyZAiedBEVFyWtyYu/j67krDpRSCjI5KRQUwPvvJ552dQS2+kA9L256MdGe3hxupiHYwMtbXmbplqWEo2GKXUM4Zs9Xqf7HV3llw0heAQYPhosugnPPhbPOarmpWimlepPMTgr7W/r083qH0Nj4bqdvWfzRYr7y7FfYtn/bAa8dkzeSk/zfYv3TF7HvvclkDTZ8+kyYeTOcfjqUl3d+TbtSSvUGmZ0U6uoSHY54vYMJBiuJRkM4HK2vFqluqub6Jdfz8H8e5sTSE/nn5f+kvKgcr9PH8jezuOsOH6++mM0Ol+GCC+ApZdtlAAAgAElEQVSaX8GnPtXS34tSSh0tMjspxPskyMqKXZYqBIOV+Hz2KhIR4bG1j/E/z/8Ptc21fH/m97n5tJvxOL288AL88Ifwr3/BoEFw221w1VUwYEB6P5ZSSh2JzE0KyT2lZmW1uoHN5xvKmso1fOP5b7Bs6zKmDJrCH+b8gXEDxvHqq7ZTqrfegiFD4N574YtftF01KKXU0S5zGzja6RQPYFfd+3z1ua9y0sKTWLdnHb87/3e88aU3yPOPY948e35g50743e9gwwb46lc1ISil+o7MrSm00332yhr44SNfoyEU4GtTvsatp9+KJ1rErd+Hn//cniP44Q/hW99q6RZZKaX6Ek0KsaTw3t7tfHcdDM7N4l9fepsx/cewcyecPNPWCC69FH76UxiqN60qpfqwzE0KSecUttVt47xHzyPX7eS+005jTP8xVFXZK4gqK+Gll+CTn0xvuEop1RMyNynEagq1NbuY/chsGoON3H/qBIqcNdTWwtlnw+bN8PzzMHNmmmNVSqkektEnmgNOuLDyTj7c+yFPzX+KMaWjqK3dy3nnwdq18OSTmhCUUpklc5NCfj7XngevRjbypwv/xBnlZwDH8K1v3c2bbwqPPgqzU9ttuVJK9ToZmxQiBh4dB18KjuVz4z4HwKJFZ7Ny5SdZuLCeuXPTHKBSSqVBxiaFj/Z9RJMbTqtv6Z702WdP4rjjVvHpT/8jjZEppVT6ZGxSWLVrFQAT11YDdjzjd97J58wzF1NV9WQ6Q1NKqbTJ2KSwunI1bpyMXvY+VFWxaJGdf9FFzezd+xyRiD+9ASqlVBpkbFJYVbmKsfnH4YkAL7zA44/DxIkwefJ0otFGamr+me4QlVKqx2VkUhARVlWuYmL5J6CkhK1PLOfNN+Hii6Gw8AxcriKqqp5Id5hKKdXjMvLmtZ31O+24yQMnwll+Fj1n726eNw8cDjclJXPYu/dpotEgDkfqB8pWSqneIiNrCqsqYyeZB06Es8/m8frZTDqxiWOPta+Xls4lHK6ltvaVNEaplFI9LyOTwurK1QBMGDCBLaNn8zancPExbydeLyo6C6czV5uQlFIZJyOTwqrKVRxXfBx53jz+uswOlTav9v7E606nj+Li86iu/hsikXSFqZRSPS4zk8KuVUwsmwjA44/DlLKPKV/+V2hoSCxTWjqXUKiKurrX0xWmUkr1uIxLCrXNtWyu3czEsols3gzLl8O8TwfseM1LlyaWKy6ejcPh0yYkpVRGybiksKZyDQAVZRX89a923rxvDoPsbFiyJLGcy5VLcfE5VFU9iUg0HaEqpVSPy7ikED/JPHHgRJ54AqZMgeGjvHbw5aSkANCv31yCwR3s3/92O2tSSqm+J+OSwqrKVZTlltE/u4w1a2DGjNgLZ58NH31kR9aJKSk5H2Pc7NnzSHqCVUqpHpaRSaGirIKPP4ZAAEaNir1w9tn2Mam24HYXMmDA59m583c0NW3o+WCVUqqHZVRSCIQDvFf1HhPLJrJ+vZ2XSArHHw/HHHNAE1J5+Y9xOLxs2nRjzwarlFJpkFFJYV3VOsLRMBVlFQcmBWNsbeGllyAYTLzH6y1j2LBbqK7+GzU1eoezUqpvy6ikkBhDIVZTKCiA/v2TFpg7F+rr4be/bfW+IUOux+s9hg0brteb2ZRSfVpKk4Ix5hxjzHpjzAZjzIJ2Xr/SGFNljFkdm76cynhWV64m15PLscXHsn69rSUYk7TAWWfBrFnwve/B7t2J2U6nj2OP/RmNjWvYteuPqQxRKaXSKmVJwRjjBO4FZgMnApcaY05sZ9G/iEhFbPp9quIBe5J5woAJOIwjkRTaBA133QVNTXDzza1eKi2dR37+NDZv/jbh8P5UhqmUUmmTyprCycAGEdkkIkHgMeCCFG6vU1GJsmb3GiaWTaSxEbZvbycpAJxwAlx/Pfzxj/DWW4nZxhiOO+5XhEJ72Lr1f3sucKWU6kGpTAqDgW1Jz7fH5rU11xjzH2PMImPM0FQFs3HfRhqCDUwcOJEPP7Tzjj++g4W/+10YOBC+/nWIttzNnJ8/hQEDPs/27b+iqenDVIWqlFJpk+4Tzc8Aw0VkPPAC8GB7CxljrjHGLDfGLK+qqjqsDcXHUGj3yqO28vLgZz+Dd96xNYYkI0b8FIcji/Xrr9HuL5RSfU4qk8IOIPnIf0hsXoKI7BWRQOzp74FJ7a1IRBaKyGQRmVxaWnpYwcw4ZgaPzn2UMaVjWL/enj4YObKTN1x2GUybZs8t1NYmZnu9ZRx77B3U1b3Krl0PHFYsSinVW6UyKbwDjDTGlBtjPMAlwN+TFzDGDEx6Ogd4P1XBlOWWccnYS/C6vKxfD8OGQVZWJ28wBn79a9i7F269tdVLAwd+iYKCmWzadCOBQGWqQlZKqR6XsqQgImHga8ASbGH/uIisM8b80BgzJ7bYN4wx64wxa4BvAFemKp5kH37YSdNRsooK+PKX4d57bb9IMcYYRo1aSCTiZ8OGb6QuUKWU6mFGRNIdwyGZPHmyLF++/LDfLwL5+XDVVXD33V14Q2WlbWeaNQueaD22wtatP2Hz5u8wduzT9Os3p4MVKKVU+hljVojI5IMtl+4TzT1u1y47wFqXagoAZWVw003w5JPweutR2IYOvZGcnHF8+OFX9d4FpVSfkHFJ4aBXHrXnhhtg0CD45jdbXaLqcHgYNep+gsGdfPjhVzjaal1KKdWWJoWuyM6Gn/wE3n7bDuqcJD//FMrLf8KePY+yefN3uy9QpZRKg4xMCtnZMLi92+g6c8UV9sTzggXQ3NzqpWHDFjBw4Jf5+OOfsHNnSnvqUEqplMrIpDByJDgO9ZM7nXDHHbB1K9xzT6uXjDGMHPkbiorO5sMPv8K+fUs6WIlSSvVuGZkUDqnpKNmZZ8J559kb2oYOhbFj7Q1u55+P458vMWbMX8nJGcu6dZ+loWFNt8atlFI9IaOSQiAAW7YcQVIAuP9+e+L5rLPsinw++M9/4IILcC17h/Hjn8PpLOA//zmHurp/d1foSinVI1zpDqAnbdhgLx46oqQwcKDtFynZvn0wcyZccAHel19mwoQlvPvuHFavnsmIET9lyJDrMa0GblBKqd4po2oKh3XlUVcUF9uxnUtLYfZscj52MGnSCkpKPs3Gjd9k7drPEArVHnw9SimVZhmZFDrsMvtIDBoEL7wAbjecdRbunXWMGfMExx77K/bte44VK06ivn5lCjaslFLdJ6OSwocf2taf/PwUbeDYY22NobERZs3C7N/P0KHXUVHxGiIhVq06jd27H0vRxpVS6shlVFI4oiuPumr8eHj6adi4Ef77v0GEgoKpTJq0gry8Sbz//qVs2nQzIpEUB6KUUodOk0IqzJgBP/gBPPoo/OlPAHg8/Zkw4SUGDvwvPv74dt599wLC4boeCEYppbouY5JCdbW9SKhHkgLYO5/POAO+9jX44AMg3lfSfYwc+VtqapawYsUU6ure7KGAlFLq4DImKaT0JHN7nE54+GHbp8b8+a26xhg8+CtMmPAS0WiAVaumsXHj/yMSae5kZUop1TMyJils22YHU+uxmgLYK5L+9Cd7c9uNN0IkAqtXwz33UHj1PZzy0/EMC8xj27afs2LFRK01KKXaF43a/teefTblm8qYpHDJJfaioBEjenjD550H119vh/YsKYGJE+Eb34C338bx6uuMuOgZprzzNSLhBlatmsb773+Bhoa1EArZQX3++Ec7MpBS6tCJwMqV8POf2ysDm4/SGvn3v29bHrZsSfmmMuqO5k7HZE6l226zJzS8Xpg+3U7HHAM7dsCXvkTO//s1p3zqDLZ+72yq1jzC3h8/hHeJB/feoH3/Bx/A7bfbqo5ShyIahf377Vjj+/aB329rrJGIfS0vD6ZOPXq+Wxs22N/NzJmdL7dpE/z5z/DII4lzeoAtBE4/HWbPtj1j1tVBba199Pth0iR7ocjhXrceDNrBuBobbb86gYCdN3UqjB7d/nsCAXvwV1Fhl2tr0SL48Y/hi1+Ea689vLgOhYgcVdOkSZOkT4lGRe67TyQnRyQ7WwQk6jBSPd0ja25Dds/tJwISueHrdlnVvSIRkeeeE9m1q/PlNmwQ2b//yLeXqv9hNCqyaZPIX/4icuONImecIVJaKuJwiNjj5Y6nigqRRYvsvjjYNl5/XeTLXxb5yU9EqqpS81k68uabIoWFNuYvfrH9/8f69SLnntvy2aZPF/nd70S2bxdZvFjk618XGTmy8/3hdIqcfLLITTeJ/Oc/XY/vuedEjj++/XU6HDbmbdtalo9GRZ58UmTEiJbt/uxnrb8ja9bYcmHqVJHm5sPfdyICLJculLFpL+QPdepzSSFuwwaRL3xB5Ic/FNm+XcLhJtm+/bfy9ltjZdtn7Ber+gujZd/elyXa15LD8uW2kFm/vme3u369yIwZ9meQlyfyi1+IBIOtl3nvPZHzz2/50U6ZIvKtb4k884z9wT7zjMivf20L4ssvF7n9dpG33xYJh1vWsXevyP33i5x5pv2B33KLSCjUPZ8hXrCMGtVSALndIpMn28L7298W+eUvRf70J5G//13kxRdFXnlF5NVXbQH/hz+0FGQnnijyyCMitbWtC6ZAQOShh0QmTbLL5eTYR59P5JprRNatO/S4w2GRlSsPnozjli4Vyc21Bej119tCdsQIkX/9y75eX28LcbdbJD/f/o62bOl4fRs22PeuWyeyY4dIY6NIU5PISy+JfOc7ItOmibhcIh6PyG9+03kyf/99kdmz7T45/niRxx+33+l337XfsfXrRW64wa7L57NxvvaaTdwgMmaMyNNPi8yda59fcIFITY1IdbVIebnIwIE2xiOkSaGPiEajUlf7tuy7YqwIyMefRd74d7ls3vxD8fs7+dL3Fk8+KTJnjv1htT2y273bFlzG2K+iMfYHsWzZ4R9Rd+V9oZAtvL1ekYICkV/9quVHPXq0yAsviFRWinzlKzYR5OeL/OAHtrCYPt3+uNseCXq9IoMHtzwvKLCf+9xzbeECIscd15JgTj9dZOfOzuPcsMEeOX7iE3a67TZbiMU/4xtv2MIrHve999rC6FCPKMNhkUcftYVT8tFyaanICSeI9O/fso3f/lakoUFk7VqRq6+2hVz883zve/ZovLq6/e00NIg89ZTIVVfZdce3NXy4yKWXitx9t8iKFa0TqojIP/5htzN6dEvh+Npr9n0Oh/0ODRpk13XllV1PNAdTVdXyvbjsMpt4kq1aZb8jLpf9jvzylzaBdmTLFpErrmj5vpeU2P9Z/AAhGhW58067vvJy+z/3eGwNqRtoUuhrolGJfONaEZDGE/Nk7feQpS8iq1adKTt3/kH8/o9blm1uFlm92h713XKLLWi/9CWRjz/ueP3drb7ebhNEiorsY26uyH//t/0x3XWXLThdLpFvflPkww9Fvvtd+0MBe0R+/fX2qHzBAnvEe9ddHTfhVFaKfPaz9v0PP9xxcnj7bZGTTrLb+MxnWgrmaNQe9R97bEsh73LZ5oY9e1qvo6lJ5OWXRR57zBbMu3a1NL3s2iXy5z/bgmrECFtw3XijLeziMT30kK0xDBhg1xPf/vbttgC89VaRCRNaCs1Jk1qO0sHGOGuW/XvAANs80h01j0jEFuq/+IX93vzXf9l9On++yJIl7e/TPXtEfvQjkfHjWzdVHXec3c/jxtlaTHl5SwIpKBD53OfsfvjFL+wRcrxQj79+/vkid9xhm1bdbtvE1fb/UFdnk0B8H73xxpHvg/b2yY9+ZAvyE0+0BfS997Z8h7xeW1vavbvr61y92q5j3772X//3v0WGDLHrf+CB7vkcokmhb4pGRX7/+0SbaHBokWy6oVje/gPy3k1I5UUF4h/TT6IuZ8sPzOm0R3s+n0hWlj2aa2hoWWd9vW1a+OQnRYYOtQXZCSfYH/knPtFxQRyJ2KaIBQtE/vhHewQbLxjfessWCsbYwiUYtD+mz3/e/ojisc2aZaveyRob7dHomDG2SScryx4txQuc0lLbXBNv5olGbSFcUmLXPW6cXW7u3NaFyNat9mgvXpAuWtT+Pvb7bS3immtS25y1dq3dzw6H3c/FxS37xRhbA/jFL0Q2b255z7Ztdt/Mnm1rJd///oFHr+lUX2+bpm67ze7/888Xuegim1SuuMI2obz00oFNdCL2/7h1qz2Queaa1m3zU6d2XICK2BpV29pFd3vhhda1mwkTRO65xzYNpkJ1td2X3UiTQl8WDttmmVNPbfmSgoRzXFJzklO2fA5Z912nrF80XXZu/p0Eg9W26nrJJXbZQYNsNfXKK1vah4891p7TuOwykXnzRC68sOXoND/f/qA3bbJHsz/+sT3yixdg8Rjy823zitMpMmyYbbduq7raHiU9++yhNxG99ZbIzJmSOBJ98EEbJ4iccopt/w+HbaHu8dhmj8ces4nJ57NJ4+ab7RFmb1BfbwvAU0+1TTH33GPbzlNV0BxtduywNZTkg5h02rbN1l6WLz8qL/roalIwdtmjx+TJk2X58uXpDqP3+Pe/7WV6kyfDqFFETZT9+9+kuvopqqqeJBDYCjgpLJxOUdGn6Pdhf7K/vRDzznJ7OeL8+XDllfCJT7R/WeLbb8Odd8Jf/2ovYQT7eMYZ8OUvw4UX2mun33rLTsuX204Bf/lLKCzs/s8rAosXw003wbp1duS7H/3I3gvidLYs9+679mafNbFhUT/3Ofjf/7WXAiuVgYwxK0Rk8kGX06TQd4kIDQ0rqap6gn37nqehYRUATpNPWeVEvBPOILf/qeTlTcLtLul8Zdu326FIReALX7DdhKdTJAJ/+xuMG9dx3yXBIPzhD/ba85NP7tn4lOplNCmoAwSDVdTWvkJNzYvU1LxMc/PGxGte7zHk559MQcF0CgpOIzd3PMY4O1mbUupo0tWkkFF3NGc6j6eU/v0vpn//iwEIhWpoaFhJff0K6utXsH//G1RV/RUApzOP/PxTcLv74XDk4HTayeMZRE7OWHJyxuDxlKbz4yilUkCTQgZzu4soKjqToqIzE/Oamz+mru516upep75+Oc3NHxOJNBCJNBKJNACRpPf3JydnHIWFMygs/CT5+SfjcHjS8EmUUt1Fm49Ul4kIweAuGhvX0di4lsbGtTQ0rKKhYTUgOBzZFBRMJydnDC5XYWJyu4vx+crx+cpxOtPVAZVSmU2bj1S3M8bg9Q7C6x1EcfFZifmh0D5qa5dRW/syNTUvU1f3OtFoY7vr8HgGk5V1LD7fMXi9g/F6h+DxDMbrHYTbXYrb3Q+nMxdztHTQplQfo0lBHTG3u5jS0gspLb0wMS8aDREO1xGJ1BEMVtHcvAm/fyN+/0aamzdSW/sqweBORMIHrM8YN253PzyeAXg8ZXg8A/F4yhJXSNnabRSRKD7fMHJzK8jKOh6HQ7/OSh0p/RWplHA43Hg8/YB+ZGUdS0HBgV0Ci0QJhaoIBHYQCOwkHN5LKFRNKFRNMFhFKLSbYLCShoZ3CYV2t5tAWrbnIydnHNnZo3G7S1o1X9nkYms4Llcxxhii0SDBoF1/MLg7dhK9P273ANzuYozJmKFGlGpFk4JKG2McsQJ7AHl5J3W6rEiUSKQeOy6UiRXagt+/iYaG1YmptvZlwuHa2Enx9rbpwenMJhyu7WRrTjyeMrKyRuDzjYg1dw3HGCfRaBCRINFoEGOcuN3FuFzFscdCotFmwuF6IhE7GePB5xuOzzcclyv3cHeVUj1Gk4I6KhjjwOUqOGB+bu44cnPHAVe0mh+NholE6giFagiFdhMI7CQY3EkgsJNIpDHWLBWfSolEGgkG9xAK7SEY3EMgsJ3m5k3U1LzI7t0PdstncLv74fUOQUSIRpsTk8Phw+c7JjF5PGWEQvti8e4iGNyJMa5YgirH5xuB1zsEiCatJ4AxLlyuAlyuQpzOApzOXEAQCSMSQSSMMS4cDl9iMsZFNOonGvUTiTQRjfpxOrNxu0txuQq1xpSBUpoUjDHnAHcBTuD3InJ7m9e9wEPAJGAvMF9EtqQyJpUZHA4XDkdJ7DzEcUe0rkjETyDwMWBrGg6HB2O8iIQIh2sIhfYRDu8lHK7F4fDhdOYlpmi0mUBgK37/ZpqbtxAIbD+gYI5GG2lu3kpt7asEAjuIX/brcpXg9Q7C4xmISJC6utfZs+dRIHpkO6fLnLjdJbjdxbEEEv/sLY/GuGN/O4lGQ7EEFIpN4VYTgMORjdOZnXgUiSISRCQUq305cLlKcLv7xaYSXK6iRLKLJ6pQaG9iv4dC+2I1s8bE5dMOh4/s7FGx6QQ8noGEQtX4/R/R1PQhfv9HQJSsrOPJyhpJdvbxuN2liEQIh/fF1r839n+IbzueaA3xc1oQxRhXhzd62vXVE402EY0GEklcJIzTmYvTmYfLlZdYb3w/2H0SSdq/nth2Un8BRsqSgrF76V7gLGA78I4x5u8i8l7SYl8CakTkOGPMJcBPgfmpikmpw+F0ZpGdPard17zegV1YQztDLHYgGg0TClXjdhfhcHjbeT1EIPAxgcDOpOTixeHwEo2GiETqCIfrYif5G2JH+s5EwSUSaVVLEQnhcGQlCmqbpJoIhapiNacqwuGaVs1m0WiASKQh9jwUK8DCGOOOTS4cjpa/43GCEIk0EQ7vjdVKmgBnbFmbaETChEJvEQpVIxLq8n6Li99oGYk0xNZvGeNutT5jbNGXfJ7KfvbDG8PZ/h/sth0OL5FIA+Hw/g6vwjtcw4YtYMSI27p1nW2lsqZwMrBBRDYBGGMeAy4AkpPCBcCtsb8XAb82xhg52m6eUKqbOBwuvN6yTl53k5V1LFlZae57KsVEhEikgVComnC4NjbVxc4FRWK1ieJYTaI4VjPLTjR3iUQJBHbQ1LQev389zc1b8XgGkZ1tawY+33DAEAhsTdQcmps/xuXKi607Xss0ie3ahFsPENuOI3bRQohotDFWU2kkGg3Ejv7zY7WLvFiyiCdwH+CM1Wpazj/Z9SbXwhyxpBtKJOSCgmkp3/epTAqDgW1Jz7cDp3S0jIiEjTF1QAlQncK4lFK9nDEmVkDnHeb7Hfh8Q/H5hgKf6nC5lgQ7+/AC7YOOirNIxphrjDHLjTHLq6qq0h2OUkr1WalMCjuAoUnPh8TmtbuMsY18BdgTzq2IyEIRmSwik0tLtRM2pZRKlVQmhXeAkcaYcmOMB7gE+HubZf4OfCH292eBl/V8glJKpU/KzinEzhF8DViCvST1ARFZZ4z5IXZYuL8DfwD+zxizAdiHTRxKKaXSJKX3KYjIYmBxm3nfS/q7GZiXyhiUUkp13VFxolkppVTP0KSglFIqQZOCUkqphKNu5DVjTBWw9TDf3o+j78Y4jblnHG0xH23xgsbcUzqK+RgROeg1/UddUjgSxpjlXRmOrjfRmHvG0Rbz0RYvaMw95Uhj1uYjpZRSCZoUlFJKJWRaUliY7gAOg8bcM462mI+2eEFj7ilHFHNGnVNQSinVuUyrKSillOpExiQFY8w5xpj1xpgNxpgF6Y6nPcaYB4wxe4wxa5PmFRtjXjDGfBR7LEpnjMmMMUONMa8YY94zxqwzxvxPbH5vjtlnjHnbGLMmFvMPYvPLjTFvxb4ff4l14tirGGOcxphVxphnY897dczGmC3GmHeNMauNMctj83rzd6PQGLPIGPOBMeZ9Y8ypvTzeUbF9G5/2G2OuO9KYMyIpJA0NOhs4EbjUGHNieqNq15+Ac9rMWwC8JCIjgZdiz3uLMPBNETkRO+bktbH92ptjDgCfFJEJQAVwjjFmKnYo2F+JyHFADXao2N7mf4D3k54fDTGfISIVSZdI9ubvxl3A8yJyAjABu697bbwisj62byuw49w3AU9xpDGLSJ+fgFOBJUnPbwZuTndcHcQ6HFib9Hw9MDD290Bgfbpj7CT2p7Fjch8VMQPZwErsiIDVgKu970tvmLDjkbwEfBJ4Fjt6fG+PeQvQr828XvndwI7lspnYedbeHm878c8C/tUdMWdETYH2hwYdnKZYDtUAEdkV+7sSGJDOYDpijBkOTATeopfHHGuGWQ3sAV4ANgK10jKKe2/8ftwJ/D8gGnteQu+PWYB/GmNWGGOuic3rrd+NcqAK+GOsie73xpgcem+8bV0CPBr7+4hizpSk0CeITf297nIxY0wu8ARwnYjsT36tN8YsIhGxVe4hwMnACWkOqVPGmPOBPSKyIt2xHKLTROQkbLPttcaYGckv9rLvhgs4CfitiEwEGmnT7NLL4k2InUuaA/y17WuHE3OmJIWuDA3aW+02xgwEiD3uSXM8rRhj3NiE8IiIPBmb3atjjhORWuAVbNNLYWxIWOh9349pwBxjzBbgMWwT0l307pgRkR2xxz3Ytu6T6b3fje3AdhF5K/Z8ETZJ9NZ4k80GVorI7tjzI4o5U5JCV4YG7a2Shyz9Arbdvlcwxhjs6Hnvi8gvk17qzTGXGmMKY39nYc+BvI9NDp+NLdarYhaRm0VkiIgMx353XxaRy+jFMRtjcowxefG/sW3ea+ml3w0RqQS2GWNGxWadCbxHL423jUtpaTqCI4053SdIevBEzLnAh9j242+nO54OYnwU2AWEsEcuX8K2Hb8EfAS8CBSnO86keE/DVk3/A6yOTef28pjHA6tiMa8FvhebPwJ4G9iArYZ70x1rB/GfDjzb22OOxbYmNq2L/+Z6+XejAlge+278DSjqzfHGYs4B9gIFSfOOKGa9o1kppVRCpjQfKaWU6gJNCkoppRI0KSillErQpKCUUipBk4JSSqkETQpK9SBjzOnxXk6V6o00KSillErQpKBUO4wxl8fGXVhtjPldrBO9BmPMr2LjMLxkjCmNLVthjHnTGPMfY8xT8f7rjTHHGWNejI3dsNIYc2xs9blJ/fY/ErszXKleQZOCUm0YY0YD84FpYjvOiwCXYe8eXS4iY4BXge/H3vIQcJOIjAfeTZr/CIb6Sq8AAAE7SURBVHCv2LEbPoG9Wx1sb7LXYcf2GIHt20ipXsF18EWUyjhnYgcteSd2EJ+F7VQsCvwltszDwJPGmAKgUERejc1/EPhrrN+fwSLyFICINAPE1ve2iGyPPV+NHUPj9dR/LKUOTpOCUgcywIMicnOrmcZ8t81yh9tHTCDp7wj6O1S9iDYfKXWgl4DPGmP6Q2Jc4WOwv5d4r6SfA14XkTqgxhgzPTb/CuBVEakHthtjLoytw2uMye7RT6HUYdAjFKXaEJH3jDHfwY4a5sD2WnstduCVk2Ov7cGedwDbPfF9sUJ/E3BVbP4VwO+MMT+MrWNeD34MpQ6L9pKqVBcZYxpEJDfdcSiVStp8pJRSKkFrCkoppRK0pqCUUipBk4JSSqkETQpKKaUSNCkopZRK0KSglFIqQZOCUkqphP8PfQa4Nw7lq14AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2419 - acc: 0.9315\n",
      "Loss: 0.2418968597057576 Accuracy: 0.9314642\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_025_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 547us/sample - loss: 1.9555 - acc: 0.3886\n",
      "Loss: 1.9555140533675037 Accuracy: 0.38857737\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 887us/sample - loss: 1.7554 - acc: 0.4515\n",
      "Loss: 1.7553632275213953 Accuracy: 0.45150572\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.5044 - acc: 0.5283\n",
      "Loss: 1.5043999260707313 Accuracy: 0.5283489\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.2181 - acc: 0.6274\n",
      "Loss: 1.2180704966512426 Accuracy: 0.62741435\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8578 - acc: 0.7391\n",
      "Loss: 0.8577612707919421 Accuracy: 0.7391485\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4719 - acc: 0.8679\n",
      "Loss: 0.4719278172911885 Accuracy: 0.86791277\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2490 - acc: 0.9273\n",
      "Loss: 0.24900241202345022 Accuracy: 0.92731047\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2102 - acc: 0.9383\n",
      "Loss: 0.21015337269563664 Accuracy: 0.9383178\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2419 - acc: 0.9315\n",
      "Loss: 0.2418968597057576 Accuracy: 0.9314642\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_025_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 3.8793 - acc: 0.5348\n",
      "Loss: 3.8793030217924347 Accuracy: 0.5347871\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.4637 - acc: 0.6671\n",
      "Loss: 2.463701414294456 Accuracy: 0.667082\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.6181 - acc: 0.7676\n",
      "Loss: 1.6181314632776247 Accuracy: 0.76760125\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.6822 - acc: 0.8883\n",
      "Loss: 0.6822058703916714 Accuracy: 0.88826585\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3131 - acc: 0.9317\n",
      "Loss: 0.31309920407965613 Accuracy: 0.93167186\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2605 - acc: 0.9477\n",
      "Loss: 0.26048749309918856 Accuracy: 0.94766355\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3566 - acc: 0.9369\n",
      "Loss: 0.3566372805180247 Accuracy: 0.93686396\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_025_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
